{
  "version": "https://jsonfeed.org/version/1",
  "title": "DataDog",
  "home_page_url": "https://datadoghq.com/blog/index.xml",
  "items": [
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/",
      "title": "Our Journey Taking Kubernetes State Metrics to the Next Level",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eWe contributed to the \u003ca href=\"https://github.com/kubernetes/kube-state-metrics\"\u003ekube-state-metrics\u003c/a\u003e, a popular open source Kubernetes service that listens to the Kubernetes API server and generates metrics about the state of the objects. It focuses on monitoring the health of deployments, nodes, pods etc. Kubernetes State Metrics is one of our favorite tools here at Datadog, and it powers several of our products (for example, Kubernetes metrics integration, and Orchestrator Explorer). We really appreciate KSM and use it extensively, but we were having challenges scaling it to the level we needed - we found that a large amount of data was being dumped at query time and also that the Builder did not allow a way to hook into the metric generation. We highly value our synergies with the upstream community to improve it or add new features, so we decided that instead of fixing it only for ourselves, we would contribute our discoveries back. Along the way, we discovered that contributing back to the open source community turned out to be the key to us scaling our internal Kubernetes infrastructure.\u003c/p\u003e\u003cp\u003eIn a nutshell, our results were staggering. We improved the metrics collection process duration by 15x:\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"a dashboard that shows an average execution time of 12 seconds\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003ewhich allowed us to get much more granular data at high scale:\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"a dashboard that shows an average execution time of 12 seconds with the metrics samples on every check run\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eRead on to see how we did it.\u003c/p\u003e\u003ch2 id=\"who-are-we\"\u003e\u003ca href=\"#who-are-we\"\u003eWho are we?\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eThe Datadog Containers team is in charge of observability of our Kubernetes environments. We ensure that other Datadogs and customers monitoring their services with our featureset get insight into how their infrastructure and apps are behaving. We also make sure that any log, trace, custom metric, code profile, and security signal is reliably collected.\u003c/p\u003e\u003ch2 id=\"what-is-kubernetes-state-metrics\"\u003e\u003ca href=\"#what-is-kubernetes-state-metrics\"\u003eWhat is Kubernetes State Metrics?\u003c/a\u003e\u003c/h2\u003e\u003cp\u003e\u003ca href=\"https://github.com/kubernetes/kube-state-metrics\"\u003eKubernetes State Metrics or KSM\u003c/a\u003e relies on the informer pattern to expose cluster-level metadata about any object registered in the Kubernetes APIServers. When starting the KSM deployment, you can enable collectors that correspond directly to watchers on specific objects. From there, metrics are created to track the lifecycle of the objects, which then are exposed on KSM’s metrics server.\u003c/p\u003e\u003cp\u003eMetrics are text-based, following the \u003ca href=\"https://github.com/OpenObservability/OpenMetrics/blob/main/specification/OpenMetrics.md\"\u003eOpenmetrics format\u003c/a\u003e. You can find the list of metrics that are exposed \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/tree/master/docs#exposed-metrics\"\u003ehere\u003c/a\u003e. Note that you can specify which resources you want KSM to keep track of using the \u003ccode\u003eresources\u003c/code\u003e flag, though the default has practically everything covered. See \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/master/docs/cli-arguments.md#available-options\"\u003ethe list here\u003c/a\u003e.\u003c/p\u003e\u003ch3 id=\"how-does-the-ksm-check-work\"\u003e\u003ca href=\"#how-does-the-ksm-check-work\"\u003eHow does the KSM check work?\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eAs you create the \u003ca href=\"https://docs.datadoghq.com/agent/kubernetes/?tab=daemonset\"\u003eDatadog Agent Daemonset\u003c/a\u003e, each Agent automatically starts monitoring application pods and containers that live on their respective nodes. This is also the case for the Kubernetes State Metrics pods.\u003c/p\u003e\u003cp\u003eThe Kubernetes State metrics check v1.0 in the Datadog Agent is a python based check, which runs every 15 seconds. The process starts by having the Agent identify that a container runs the kube-state-metric image (using the image name or labels) and thereafter starts by crawling the \u003ccode\u003e/metrics\u003c/code\u003e endpoint for metadata purposes.\u003c/p\u003e\u003cp\u003eThe configuration of the check allows the user to take advantage of the metadata associated with a certain metric to benefit another one.\u003c/p\u003e\u003cp\u003eExample:\nThe following metric does not contain an actionable value:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e\u003cspan\u003ekube_deployment_labels{deployment=\u0026#34;kube-dns\u0026#34;,label_addonmanager_kubernetes_io_mode = \u0026#34;Reconcile\u0026#34;}\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eIt does contain insight that can be used to know that the \u003ccode\u003ekube-dns\u003c/code\u003e deployment has the \u003ccode\u003elabel_addonmanager_kubernetes_io_mode\u003c/code\u003e label, which is not added on other metrics for the deployment.\nWe can use the following configuration to add the value of label_addonmanager_kubernetes_io_mode as a tag to the metrics pertaining to the \u003ccode\u003ekube-dns\u003c/code\u003e deployment.\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e\u003cspan\u003elabel_joins\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e\u003cspan\u003ekube_deployment_labels\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e        \u003c/span\u003e\u003cspan\u003elabel_to_match\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003edeployment\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e        \u003c/span\u003e\u003cspan\u003elabel_to_get\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e          \u003c/span\u003e- \u003cspan\u003elabel_addonmanager_kubernetes_io_mode\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eA subsequent crawl takes place, and the check reconciles the metric names, captures the values and adds the metadata that is either directly associated with the metric or that was generated using a metadata join as detailed above.\u003c/p\u003e\u003ch3 id=\"how-does-the-ksm-check-scale\"\u003e\u003ca href=\"#how-does-the-ksm-check-scale\"\u003eHow does the ksm check scale?\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eAt Datadog, we take advantage of KSM extensively. Our testing has shown that beyond a few hundred nodes and thousands of pods, one needs to split the KSM deployment. Our strategy is to split given the number of objects of a specific resource type and the number of metrics they incur.\u003c/p\u003e\u003cp\u003eWe have three deployments with the following collectors enabled:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e- \u003cspan\u003ename\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003ekube-state-metrics\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e  \u003c/span\u003e\u003cspan\u003eimage\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003ek8s.gcr.io/kube-state-metrics/kube-state-metrics:1.9.7\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e  \u003c/span\u003e\u003cspan\u003ecommand\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e- \u003cspan\u003e/kube-state-metrics\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e- --\u003cspan\u003etelemetry-port=8081\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e- --\u003cspan\u003eport=8080\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e- --\u003cspan\u003ecollectors=pods\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e- \u003cspan\u003ename\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003ekube-state-metrics\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e  \u003c/span\u003e\u003cspan\u003eimage\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003ek8s.gcr.io/kube-state-metrics/kube-state-metrics:1.9.7\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e  \u003c/span\u003e\u003cspan\u003ecommand\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e- \u003cspan\u003e/kube-state-metrics\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e- --\u003cspan\u003etelemetry-port=8081\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e- --\u003cspan\u003eport=8080\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e- --\u003cspan\u003ecollectors=nodes\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eand\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e- \u003cspan\u003ename\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003ekube-state-metrics\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e  \u003c/span\u003e\u003cspan\u003eimage\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003ek8s.gcr.io/kube-state-metrics/kube-state-metrics:1.9.7\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e  \u003c/span\u003e\u003cspan\u003ecommand\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e- \u003cspan\u003e/kube-state-metrics\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e- --\u003cspan\u003etelemetry-port=8081\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e- --\u003cspan\u003eport=8080\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e    \u003c/span\u003e- --\u003cspan\u003ecollectors=services,endpoints,daemonsets,deployments,cronjobs,statefulsets,horizontalpodautoscalers,limitranges,resourcequotas,secrets,namespaces,replicationcontrollers,ressourcequotas,secrets,namespaces,replicationcontrollers,persistentvolumeclaims,persistentvolumes,jobs,replicasets\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eTo take an initial performance snapshot of our check, we identified that resources, such as endpoints, jobs, and deployments, produce an average of five metrics per resource. A single node is around nine metrics, and a single pod generates around 40 metrics!\u003c/p\u003e\u003cp\u003eIn clusters with thousands of nodes and tens of thousands of pods, we would end up with up to millions of metrics to process, every 15 seconds.\u003c/p\u003e\u003cp\u003eThe network call to crawl the list of metrics would take tens of seconds and would weigh tens of megabytes. Initially, this forced us to slow down the frequency of the check, reducing the granularity of our metrics and degrading the experience of our internal users. As a result, we decided to revisit our design and build a better experience.\u003c/p\u003e\u003ch3 id=\"the-ksm-library-prior-to-our-contribution\"\u003e\u003ca href=\"#the-ksm-library-prior-to-our-contribution\"\u003eThe KSM library prior to our contribution\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eIn early 2020, the KSM community was starting to discuss the release of their next major version, V2.0.0. Many improvements and new features were about to be introduced. We realized that it would be a perfect time for us to introduce a significant change that could accommodate a new design to benefit the scalability and extensibility of the project.\u003c/p\u003e\u003cp\u003eKSM v1 was made out of one main loop that would instantiate a Builder with the different resources keeping track of a list of stores.\u003c/p\u003e\u003cp\u003eEach store would have the logic to keep track of the underlying resource using informers. For example, for \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/e463aed922ed3840144812ffd1d212479b2a12da/internal/store/hpa.go#L301-L310\"\u003ethe HPA store\u003c/a\u003e:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"go\"\u003e\u003cspan\u003efunc\u003c/span\u003e \u003cspan\u003ecreateHPAListWatch\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003ekubeClient\u003c/span\u003e \u003cspan\u003eclientset\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eInterface\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e \u003cspan\u003ens\u003c/span\u003e \u003cspan\u003estring\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e \u003cspan\u003ecache\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eListerWatcher\u003c/span\u003e \u003cspan\u003e{\u003c/span\u003e\n\t\u003cspan\u003ereturn\u003c/span\u003e \u003cspan\u003e\u0026amp;\u003c/span\u003e\u003cspan\u003ecache\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eListWatch\u003c/span\u003e\u003cspan\u003e{\u003c/span\u003e\n\t\t\u003cspan\u003eListFunc\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003efunc\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003eopts\u003c/span\u003e \u003cspan\u003emetav1\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eListOptions\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e \u003cspan\u003e(\u003c/span\u003e\u003cspan\u003eruntime\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eObject\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e \u003cspan\u003eerror\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e \u003cspan\u003e{\u003c/span\u003e\n\t\t\t\u003cspan\u003ereturn\u003c/span\u003e \u003cspan\u003ekubeClient\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eAutoscalingV2beta1\u003c/span\u003e\u003cspan\u003e().\u003c/span\u003e\u003cspan\u003eHorizontalPodAutoscalers\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003ens\u003c/span\u003e\u003cspan\u003e).\u003c/span\u003e\u003cspan\u003eList\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003eopts\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e\n\t\t\u003cspan\u003e},\u003c/span\u003e\n\t\t\u003cspan\u003eWatchFunc\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003efunc\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003eopts\u003c/span\u003e \u003cspan\u003emetav1\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eListOptions\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e \u003cspan\u003e(\u003c/span\u003e\u003cspan\u003ewatch\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eInterface\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e \u003cspan\u003eerror\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e \u003cspan\u003e{\u003c/span\u003e\n\t\t\t\u003cspan\u003ereturn\u003c/span\u003e \u003cspan\u003ekubeClient\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eAutoscalingV2beta1\u003c/span\u003e\u003cspan\u003e().\u003c/span\u003e\u003cspan\u003eHorizontalPodAutoscalers\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003ens\u003c/span\u003e\u003cspan\u003e).\u003c/span\u003e\u003cspan\u003eWatch\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003eopts\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e\n\t\t\u003cspan\u003e},\u003c/span\u003e\n\t\u003cspan\u003e}\u003c/span\u003e\n\u003cspan\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThe store would also take care of the registration of the MetricFamily, containing the metric names and how to generate the metric. For example, the metric \u003ccode\u003ekube_hpa_status_current_replicas\u003c/code\u003e, for a given HPA, the value would be from the current replicas in the status of the HPA](\u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/e463aed922ed3840144812ffd1d212479b2a12da/internal/store/hpa.go#L158-L171)\"\u003ehttps://github.com/kubernetes/kube-state-metrics/blob/e463aed922ed3840144812ffd1d212479b2a12da/internal/store/hpa.go#L158-L171)\u003c/a\u003e.\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"go\"\u003e\t\t\u003cspan\u003e{\u003c/span\u003e\n\t\t\t\u003cspan\u003eName\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;kube_hpa_status_current_replicas\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n\t\t\t\u003cspan\u003eType\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003emetric\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eGauge\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n\t\t\t\u003cspan\u003eHelp\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;Current number of replicas of pods managed by this autoscaler.\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n\t\t\t\u003cspan\u003eGenerateFunc\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003ewrapHPAFunc\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003efunc\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003ea\u003c/span\u003e \u003cspan\u003e*\u003c/span\u003e\u003cspan\u003eautoscaling\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eHorizontalPodAutoscaler\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e \u003cspan\u003e*\u003c/span\u003e\u003cspan\u003emetric\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eFamily\u003c/span\u003e \u003cspan\u003e{\u003c/span\u003e\n\t\t\t\t\u003cspan\u003ereturn\u003c/span\u003e \u003cspan\u003e\u0026amp;\u003c/span\u003e\u003cspan\u003emetric\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eFamily\u003c/span\u003e\u003cspan\u003e{\u003c/span\u003e\n\t\t\t\t\t\u003cspan\u003eMetrics\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e[]\u003c/span\u003e\u003cspan\u003e*\u003c/span\u003e\u003cspan\u003emetric\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eMetric\u003c/span\u003e\u003cspan\u003e{\u003c/span\u003e\n\t\t\t\t\t\t\u003cspan\u003e{\u003c/span\u003e\n\t\t\t\t\t\t\t\u003cspan\u003eValue\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003efloat64\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003ea\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eStatus\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eCurrentReplicas\u003c/span\u003e\u003cspan\u003e),\u003c/span\u003e\n\t\t\t\t\t\t\u003cspan\u003e},\u003c/span\u003e\n\t\t\t\t\t\u003cspan\u003e},\u003c/span\u003e\n\t\t\t\t\u003cspan\u003e}\u003c/span\u003e\n\t\t\t\u003cspan\u003e}),\u003c/span\u003e\n\t\t\u003cspan\u003e},\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThis process would run in the background, and all the MetricsStores would populate over time as events are received.\u003c/p\u003e\u003cp\u003eWhen the \u003ccode\u003e/metrics\u003c/code\u003e endpoint was called, the content of the stores would essentially be \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/blob/e463aed922ed3840144812ffd1d212479b2a12da/pkg/metricshandler/metrics_handler.go#L201-L203\"\u003ewritten into the \u003ccode\u003ehttp.ResponseWriter\u003c/code\u003e\u003c/a\u003e\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"go\"\u003e\u003cspan\u003e// ServeHTTP implements the http.Handler interface. It writes the metrics in\n\u003c/span\u003e\u003cspan\u003e// its stores to the response body.\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003efunc\u003c/span\u003e \u003cspan\u003e(\u003c/span\u003e\u003cspan\u003em\u003c/span\u003e \u003cspan\u003e*\u003c/span\u003e\u003cspan\u003eMetricsHandler\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e \u003cspan\u003eServeHTTP\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003ew\u003c/span\u003e \u003cspan\u003ehttp\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eResponseWriter\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e \u003cspan\u003er\u003c/span\u003e \u003cspan\u003e*\u003c/span\u003e\u003cspan\u003ehttp\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eRequest\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e \u003cspan\u003e{\u003c/span\u003e\n\t\u003cspan\u003em\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003emtx\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eRLock\u003c/span\u003e\u003cspan\u003e()\u003c/span\u003e\n\t\u003cspan\u003edefer\u003c/span\u003e \u003cspan\u003em\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003emtx\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eRUnlock\u003c/span\u003e\u003cspan\u003e()\u003c/span\u003e\n\t\u003cspan\u003eresHeader\u003c/span\u003e \u003cspan\u003e:=\u003c/span\u003e \u003cspan\u003ew\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eHeader\u003c/span\u003e\u003cspan\u003e()\u003c/span\u003e\n\t\u003cspan\u003evar\u003c/span\u003e \u003cspan\u003ewriter\u003c/span\u003e \u003cspan\u003eio\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eWriter\u003c/span\u003e \u003cspan\u003e=\u003c/span\u003e \u003cspan\u003ew\u003c/span\u003e\n\n\t\u003cspan\u003eresHeader\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eSet\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003e\u0026#34;Content-Type\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e \u003cspan\u003e`text/plain; version=`\u003c/span\u003e\u003cspan\u003e+\u003c/span\u003e\u003cspan\u003e\u0026#34;0.0.4\u0026#34;\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e\n    \u003cspan\u003e[\u003c/span\u003e\u003cspan\u003e...\u003c/span\u003e\u003cspan\u003e]\u003c/span\u003e\n\t\u003cspan\u003efor\u003c/span\u003e \u003cspan\u003e_\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e \u003cspan\u003es\u003c/span\u003e \u003cspan\u003e:=\u003c/span\u003e \u003cspan\u003erange\u003c/span\u003e \u003cspan\u003em\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003estores\u003c/span\u003e \u003cspan\u003e{\u003c/span\u003e\n\t\t\u003cspan\u003es\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eWriteAll\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003ew\u003c/span\u003e\u003cspan\u003e)\u003c/span\u003e\n\t\u003cspan\u003e}\u003c/span\u003e\n    \u003cspan\u003e[\u003c/span\u003e\u003cspan\u003e...\u003c/span\u003e\u003cspan\u003e]\u003c/span\u003e\n\u003cspan\u003e}\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eAs discussed earlier, a consequence of this approach meant that a potentially large amount of data was dumped at query time which caused downward pressure on the client/requester’s side to process it. Additionally, there was a missed opportunity, the Builder did not allow a way to hook into the metric generation. Running an informer can be expensive in terms of memory and CPU footprint, but can take a toll on the APIServers too. As KSM needs to run an informer for each type, should you need data on a certain type, it would be great if you could hook into the Builder and process the metrics as you wish!\u003c/p\u003e\u003ch2 id=\"designing-an-extensible-solution\"\u003e\u003ca href=\"#designing-an-extensible-solution\"\u003eDesigning an extensible solution\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eThe challenge was twofold, we wanted to reduce the time spent collecting the metrics, but also simultaneously reduce the memory and CPU footprint required to run the check.\u003c/p\u003e\u003cp\u003eThe solution that really stood out was to take advantage of our \u003ca href=\"https://docs.datadoghq.com/agent/cluster_agent/clusterchecks/\"\u003eCluster Check feature\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eWe introduced the Cluster Check Runner pattern at Datadog about two years ago. The idea stemmed from an internal need to monitor data sources that couldn’t be magically discovered with the kubelet (an RDS database or a Load Balancer), as well as \u003ca href=\"https://docs.datadoghq.com/network_monitoring/devices/guide/cluster-agent/\"\u003eNetwork Devices\u003c/a\u003e in very large numbers.\u003c/p\u003e\u003cp\u003eAs there needs to be a separate deployment of the Agent as dedicated cluster level check runners, the pattern seemed perfectly adapted to accommodate our use case of collecting the Kubernetes State Metrics data.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-1.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-1.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-1.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-1.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-1.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-1.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-1.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-1.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-1.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-1.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-1.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-1.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-1.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-1.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-1.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"The cluster check runner pattern\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eThe first item on the agenda was cutting down the network time. We wondered if it would be possible to just run the Kubernetes State Metric Process alongside the Agent; so instead of pushing the metrics into the \u003ccode\u003ehttp.ResponseWriter\u003c/code\u003e upon request, have them pushed into the collector of the Agent when the check is running.\u003c/p\u003e\u003cp\u003eAt that point, we realized that the Builder was an internal part of the KSM code, and it was not possible to vendor the library and just implement the interface with a custom implementation of the MetricStore. So, we started building \u003ca href=\"https://github.com/clamoriniere/ddksm\"\u003ePOCs\u003c/a\u003e and reached out to the Kubernetes State Metrics community to gauge their interest in our idea. We were lucky enough to meet them at Kubecon multiple times, and in the end, we published our PR - \u003ca href=\"https://github.com/kubernetes/kube-state-metrics/pull/989\"\u003ehttps://github.com/kubernetes/kube-state-metrics/pull/989\u003c/a\u003e - which was accepted by the ecosystem and merged into the master branch!\u003c/p\u003e\u003cp\u003eWe kept in mind how improving extensibility could potentially have a negative impact on the performance. With the new framework we were able to be neutral and even improve performances in some cases!\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e\u003cspan\u003e### Result\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eold=master new=HEAD\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003ebenchmark                                       old ns/op       new ns/op       delta\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eBenchmarkKubeStateMetrics/GenerateMetrics-2     1000992426      1000926748      -0.01%\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eBenchmarkKubeStateMetrics/MakeRequests-2        14959897766     14214421176     -4.98%\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eBenchmarkPodStore-2                             37307           37964           +1.76%\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eBenchmarkMetricWrite/value-1-2                  649             597             -8.01%\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eBenchmarkMetricWrite/value-35.7-2               775             722             -6.84%\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003ebenchmark                                    old MB/s     new MB/s     speedup\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eBenchmarkKubeStateMetrics/MakeRequests-2     694.01       730.41       1.05x\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003ebenchmark                                       old allocs     new allocs     delta\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eBenchmarkKubeStateMetrics/GenerateMetrics-2     849198         849204         +0.00%\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eBenchmarkKubeStateMetrics/MakeRequests-2        453935         453908         -0.01%\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eBenchmarkPodStore-2                             523            523            +0.00%\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eBenchmarkMetricWrite/value-1-2                  7              7              +0.00%\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eBenchmarkMetricWrite/value-35.7-2               7              7              +0.00%\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003ebenchmark                                       old bytes       new bytes       delta\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eBenchmarkKubeStateMetrics/GenerateMetrics-2     87319544        87705328        +0.44%\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eBenchmarkKubeStateMetrics/MakeRequests-2        26518620176     26518936496     +0.00%\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eBenchmarkPodStore-2                             25984           26288           +1.17%\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eBenchmarkMetricWrite/value-1-2                  536             536             +0.00%\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e\u003c/span\u003e\u003cspan\u003eBenchmarkMetricWrite/value-35.7-2               536             536             +0.00%\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eWith this solution, the KSM code base could now be vendored as a library, and the way metrics are issued could be up to the author. This was a great win for extensibility. Furthermore, there was no need to run KSM as an independent deployment anymore in our case. This meant no more network latency and we cut in half the memory and CPU footprint. All because the Agent was now taking advantage of KSM!\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-2.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-2.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-2.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-2.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-2.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-2.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-2.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-2.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-2.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-2.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-2.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-2.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-2.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"The new cluster check runner pattern\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eFurthermore, for smaller clusters, the KSM checks can even be run directly in the Datadog Cluster Agent!\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-3.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-3.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-3.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-3.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-3.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-3.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-3.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-3.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-3.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-3.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-3.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-3.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-3.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-3.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/k8s-api-server-3.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"KSM checks running directly in the Datadog Cluster Agent\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eIf you want to take advantage of the scalability and high availability of the process, we do recommend to leverage the Cluster Check Runners however.\u003c/p\u003e\u003ch2 id=\"the-new-kubernetes-state-core-check-in-the-datadog-agent\"\u003e\u003ca href=\"#the-new-kubernetes-state-core-check-in-the-datadog-agent\"\u003eThe new Kubernetes state core check in the Datadog Agent\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eThe next challenge was to enable the Datadog Agent to run a thread and pull data from it. Remember, pulling data is now possible thanks to the upstream contribution, but running the thread proved to be trickier, because the Datadog Agent has only a few agnostic core components:\nThe collector:\u003c/p\u003e\u003cul\u003e\u003cli\u003eCollects and aggregates metrics from the checks.\u003c/li\u003e\u003cli\u003eThe scheduler: In charge of ensuring the proper scheduling/descheduling of checks (works hand-in-hand with the Autodiscovery process).\u003c/li\u003e\u003cli\u003eThe forwarder: Sends the aggregated payload to Datadog’s backend.\u003c/li\u003e\u003cli\u003eThe tagger: Aggregates metadata from multiple sources (kubelet, container runtime, cloud provider, node …) to enrich logs, metrics, and traces.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe wanted to have a long-running thread that would run Kubernetes State Metrics and one that would not be terminated and respawned every 15s. We had to extend the interface of the collector for it to accommodate this use case, which we did in these two PRs: \u003ca href=\"https://github.com/DataDog/datadog-agent/pull/6636\"\u003ehttps://github.com/DataDog/datadog-agent/pull/6636\u003c/a\u003e and \u003ca href=\"https://github.com/DataDog/datadog-agent/pull/6652\"\u003ehttps://github.com/DataDog/datadog-agent/pull/6652\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eFinally, we were able to introduce the main logic to start the informers according to a configuration that would feel familiar to the community and then plug it into the scheduling loop of the Agent in \u003ca href=\"https://github.com/DataDog/datadog-agent/pull/5465\"\u003ehttps://github.com/DataDog/datadog-agent/pull/5465\u003c/a\u003e. Another very important detail is that the check is now running in the main process instead of in Python.\u003c/p\u003e\u003ch2 id=\"results\"\u003e\u003ca href=\"#results\"\u003eResults\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eFrom a performance standpoint, we were astonished by our results. For our largest resource, Pods, we cut down the average execution time from almost three minutes per run to only 12 seconds. Another very important detail is that the check is now running in the main process (core check) instead of in Python (integration check). Moving the check to a core check in Golang also had a great impact.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pods-check-exec-time.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"a dashboard that shows an average execution time of 12 seconds\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eDuring that time, we would collect up to a million metrics with high fidelity, and we were able to cut the memory footprint by half! As you can see below, the former check would only run every few minutes, whereas the new one is much more consistent.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/pod-check-metrics-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"a dashboard that shows an average execution time of 12 seconds with the metrics samples on every check run\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eMore importantly, we realized the opportunity of offering this as part of the Live Containers product.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/live-containers.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/live-containers.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/live-containers.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/live-containers.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/live-containers.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/live-containers.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/live-containers.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/live-containers.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/live-containers.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/live-containers.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/live-containers.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/live-containers.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/live-containers.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/live-containers.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/live-containers.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"a view of the Datadog Live Containers product\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eUsing this, we can now easily rely on best practices from the upstream to generate metrics about anything in your Kubernetes cluster and have an explorer view more insightful than ever.\u003c/p\u003e\u003ch2 id=\"how-can-anyone-benefit-from-the-contribution\"\u003e\u003ca href=\"#how-can-anyone-benefit-from-the-contribution\"\u003eHow can anyone benefit from the contribution?\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eKube State Metrics can now be leveraged by anyone to send and store the generated metrics in any data store. Previously, Prometheus was the only option.\u003c/p\u003e\u003cp\u003eTechnically, once you plug your application into the Kube State Metrics in-memory store, you can read the data at any frequency and with custom filters, then apply any transformations you want. After that, it’s up to you to decide what to do with the metrics. You can store the metrics in a persistent storage for audit, or even show them in real-time directly on a graph if you’re not interested in keeping historical data. As for the Datadog Agent, it \u003ca href=\"https://github.com/DataDog/datadog-agent/blob/dca-1.13.0/pkg/collector/corechecks/cluster/ksm/kubernetes_state.go#L275-L279\"\u003esends the generated data\u003c/a\u003e directly to Datadog as Datadog metrics.\u003c/p\u003e\u003ch2 id=\"whats-next-for-us\"\u003e\u003ca href=\"#whats-next-for-us\"\u003eWhat’s next for us?\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eContributing to the Kubernetes State Metrics code base has been a great experience and we are grateful for the team of maintainers. Thanks to all this work, our internal Datadog users will have a seamless experience monitoring large Kubernetes clusters with thousands of resources, cutting down maintenance costs and operation toil and they will benefit from state of the art, community based tooling.\u003c/p\u003e\u003cp\u003eNext up for us is to introduce a way to register custom MetricFamilies for any Kubernetes resource and generate metrics for CRDs. This way, users will be able to monitor any custom resource and very easily contribute back to the upstream code base for everyone to benefit from their usage.\u003c/p\u003e\u003cp\u003eWe look forward to working more closely with the Kubernetes community and highly recommend for anyone who wants to contribute to just reach out!\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/engineering/our-journey-taking-kubernetes-state-metrics-to-the-next-level/our-journey-taking-kubernetes-state-metrics-to-the-next-level-temp.png\" width=\"100%\"/\u003eWe contributed to the kube-state-metrics, a popular open source Kubernetes service that listens to the Kubernetes API server and generates metrics about the state of the objects. It focuses on monitoring the health of deployments, nodes, pods etc. Kubernetes State Metrics is one of our favorite tools here at Datadog, and it powers several of our products (for example, Kubernetes metrics integration, and Orchestrator Explorer). We really appreciate KSM and use it extensively, but we were having challenges scaling it to the level we needed - we found that a large amount of data was being dumped at query time and also that the Builder did not allow a way to hook into the metric generation.",
      "date_published": "2021-10-15T00:00:00Z",
      "author": {
        "name": "Charly Fontaine"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/container-report/",
      "title": "10 trends in real-world container use",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003csection id=\"three\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg src=\"https://imgix.datadoghq.com/img/container-report/number_3_FINAL.png\" alt=\"Trend Number 3\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003ch2\u003e\u003ca href=\"#3\"\u003eThe average number of pods per organization has doubled\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eOrganizations using Kubernetes are continuing to scale their container environments, both by devoting more hosts to running containers, and by leveraging more pods to support their workloads. Within the past two years, the average number of pods per organization has doubled, with a similar relative increase in the average number of Kubernetes hosts. This substantial growth points to how organizations are investing heavily in Kubernetes—and shifting more of their infrastructure and workloads to containers.\u003c/p\u003e\u003c/div\u003e\u003c/section\u003e\u003csection id=\"four\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg src=\"https://imgix.datadoghq.com/img/container-report/number_4_FINAL.png\" alt=\"Trend Number 4\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003ch2\u003e\u003ca href=\"#4\"\u003eHost density is 3 times higher on Kubernetes than on Amazon ECS\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eOn average, Kubernetes organizations run 16 pods per host, while organizations using Amazon Elastic Container Service (ECS) run 5 tasks per host. These numbers have remained consistent for both environments over the past year, suggesting that organizations are finding the right number of pods and tasks to support their applications. We also found that both Kubernetes pods and ECS tasks are running an average of 1.5 containers.\u003c/p\u003e\u003cp\u003eThe difference in host density suggests that Kubernetes organizations are becoming even more efficient at \u0026#34;bin packing,\u0026#34; or running more pods per host to take full advantage of available resources. The higher density is also likely related to the growth we\u0026#39;ve seen in the number of Kubernetes users \u003ca href=\"https://www.datadoghq.com/container-report/#5\"\u003eauto-scaling their pods\u003c/a\u003e in response to an application\u0026#39;s resource consumption.\u003c/p\u003e\u003c/div\u003e\u003c/section\u003e\u003csection id=\"five\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg src=\"https://imgix.datadoghq.com/img/container-report/number_5_FINAL.png\" alt=\"Trend Number 5\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003ch2\u003e\u003ca href=\"#5\"\u003ePod auto-scaling is becoming more popular\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eKubernetes can automatically scale pods horizontally or vertically based on metrics reported from Kubernetes or other sources in order to build highly available and performant container applications. Horizontally scaling out the total number of pods ensures that applications can support fluctuations in demand, while vertically scaling individual pods\u0026#39; CPU and memory helps manage an application\u0026#39;s overall performance and costs. Our research shows a clear trend: more Kubernetes organizations are auto-scaling their pods. \u003ca href=\"https://www.datadoghq.com/blog/autoscale-kubernetes-datadog/\" target=\"_blank\"\u003eScaling pods horizontally\u003c/a\u003e accounts for most of that growth, with approximately 40 percent of Kubernetes organizations using a Horizontal Pod Autoscaler (HPA), as opposed to less than 1 percent of organizations that use a Vertical Pod Autoscaler (VPA).\u003c/p\u003e\u003cp\u003eHPA\u0026#39;s ease of use may contribute to the wide gap between the two methods, as scaling vertically is more difficult than changing the total number of running pods for a workload. VPAs are also fairly new compared to HPAs, which have become the default scaling method for widely used Kubernetes services, such as Istio and NGINX Ingress Controller. Organizations are more likely to have HPAs in their environments as a result, but we are interested to see how VPA usage grows over time.\u003c/p\u003e\u003cdiv\u003e\u003cp\u003e\u0026#34;Most applications our customers deploy with the Oracle Kubernetes Engine (OKE) service face dynamic loads and require high availability at predictable, low latencies. Our developers are looking to leverage the benefits of auto-scaling and rightsizing their applications, in addition to having a consistent and portable development environment. OKE\u0026#39;s ability to auto-scale pods horizontally and vertically delivers all of those benefits, so customers can focus on developing their mission-critical applications without any disruption.\u0026#34;\u003c/p\u003e\u003cp\u003e—Dan Gerrity, SVP Developer Services, Oracle\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/section\u003e\u003csection id=\"six\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg src=\"https://imgix.datadoghq.com/img/container-report/number_6_FINAL.png\" alt=\"Trend Number 6\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003ch2\u003e\u003ca href=\"#6\"\u003eOrganizations are deploying more stateful workloads on containers\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eContainer infrastructure is short-lived and dynamic by nature, but we are seeing more organizations leverage Kubernetes to support applications that require durable storage and persistent identity, such as data-driven applications. To do this, organizations are using Kubernetes \u003ca href=\"https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/\" target=\"_blank\"\u003eStatefulSets\u003c/a\u003e and \u003ca href=\"https://kubernetes.io/docs/concepts/storage/persistent-volumes/\" target=\"_blank\"\u003ePersistent Volumes (PVs)\u003c/a\u003e. StatefulSets are responsible for scheduling and scaling pods with unique, stable identifiers and can request PVs via Persistent Volume Claims (PVCs) to provide durable storage for stateful applications.\u003c/p\u003e\u003cp\u003eToday, organizations use an average of 13 StatefulSets and 28 PVCs, which points to an increased reliance on Kubernetes to support a large variety of workloads, including stateful applications.\u003c/p\u003e\u003cdiv\u003e\u003cp\u003e\u0026#34;Since StatefulSets became generally available in 2017, we\u0026#39;ve used them to evolve our infrastructure towards a container-centric model. We\u0026#39;ve built our business around storing huge amounts of data in open source and proprietary data stores in the most efficient way possible. Running those workloads in containers allows us to stay cost efficient and performant while keeping the developer experience approachable and modern.\u0026#34;\u003c/p\u003e\u003cp\u003e—Rob Boll, Engineering Director, Runtime Infrastructure, Datadog\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/section\u003e\u003csection id=\"seven\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg src=\"https://imgix.datadoghq.com/img/container-report/number_7_FINAL.png\" alt=\"Trend Number 7\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003ch2\u003e\u003ca href=\"#7\"\u003eOrganizations running container environments create more monitors\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eOrganizations with container environments leverage more monitors than those with non-container environments to alert teams of performance issues in their applications. Container environments are highly dynamic, and setting monitors on ephemeral pods can be impractical, noisy, and even misleading as pod-level issues may not affect overall performance. Shifting that focus to monitoring service-level performance has become a best practice for managing container environments because it helps build infrastructure that is easy to replicate and scale.\u003c/p\u003e\u003cp\u003eThe greater number of monitors that organizations are setting up may suggest that they are still tracking the performance of individual pods instead of services. However, with the growth we\u0026#39;ve seen in Kubernetes adoption in general, along with the rising popularity of tools like \u003ca href=\"https://www.datadoghq.com/container-report/#6\"\u003eautoscalers\u003c/a\u003e to optimize Kubernetes infrastructure, we expect that organizations will begin to shift their focus to monitoring service-level performance.\u003c/p\u003e\u003c/div\u003e\u003c/section\u003e\u003csection id=\"eight\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg src=\"https://imgix.datadoghq.com/img/container-report/number_8_FINAL.png\" alt=\"Trend Number 8\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003ch2\u003e\u003ca href=\"#8\"\u003eOrganizations are starting to replace Docker with containerd as their preferred runtime for Kubernetes\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDocker has been instrumental in popularizing containers and has historically been the most popular \u003ca href=\"https://kubernetes.io/docs/setup/production-environment/container-runtimes/\" target=\"_blank\"\u003econtainer runtime\u003c/a\u003e for Kubernetes environments. But Kubernetes recently announced that it will deprecate Dockershim—the underlying module that enables compatibility between Docker and Kubernetes—as part of the v1.24 release. This means that organizations will have to migrate from Docker to either containerd or CRI-O, which are the two runtimes that are compatible with the Kubernetes container runtime interface (CRI).\u003c/p\u003e\u003cp\u003eWe saw a six percent increase in containerd adoption this year, which is correlated with a dip in Docker usage. These changes started soon after the announcement that Kubernetes would deprecate Docker as a container runtime. There has been little movement in CRI-O, so we expect containerd adoption to only increase over time as more organizations prepare for Kubernetes\u0026#39;s v1.24 release.\u003c/p\u003e\u003cdiv\u003e\u003cp\u003e\u0026#34;We\u0026#39;ve seen many Kubernetes users migrate to container runtimes other than Docker this year and expect to see an even faster migration rate next year as more adoption blockers are removed. The most common adoption blockers we see today are often caused by third-party apps and tools that still rely on the Docker runtime, but recent adoption numbers indicate that the migration is going well regardless. We\u0026#39;ve seen Kubernetes focus on providing backward compatibility and a smooth migration experience since it is widely used in production workloads across companies of all sizes—from small startups to enterprises.\u0026#34;\u003c/p\u003e\u003cp\u003e—Sergey Kanzhelev, Staff Software Engineer, GKE, Google\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/section\u003e\u003csection id=\"nine\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg src=\"https://imgix.datadoghq.com/img/container-report/number_9_FINAL.png\" alt=\"Trend Number 9\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003ch2\u003e\u003ca href=\"#9\"\u003eOpenShift adoption is growing rapidly\u003c/a\u003e\u003c/h2\u003e\u003cp\u003e\u003ca href=\"https://www.redhat.com/en/technologies/cloud-computing/openshift\" target=\"_blank\"\u003eRed Hat OpenShift\u003c/a\u003e is a Kubernetes platform that can be deployed as either a self-managed service or a fully managed service in the cloud. Though OpenShift can be used by organizations of all sizes, it is most popular with large-scale organizations due to its enterprise-grade security, development, and cost-management features. Our data shows a 28-point gain in organizations using OpenShift over the past year. This suggests that organizations that are adopting OpenShift are heavily investing in the ecosystem.\u003c/p\u003e\u003cp\u003eWe believe that these findings, taken together with OpenShift\u0026#39;s enterprise features, indicate that large-scale organizations are migrating more of their infrastructure to Kubernetes. This shift could also be attributed to OpenShift\u0026#39;s comprehensive support for building hybrid cloud environments, which is rising in popularity.\u003c/p\u003e\u003cdiv\u003e\u003cp\u003e\u0026#34;Datadog\u0026#39;s research helps affirm the trends that we are seeing with our joint customers, particularly as they move to a broader application transformation using containers and Kubernetes-powered hybrid cloud platforms. This next wave of transformation now includes modernizing existing applications and building a wide range of new applications—cloud-native, data analytics, AI/ML, ISV, and in-house applications—on Red Hat OpenShift, all while using Datadog\u0026#39;s services to bring observability.\u0026#34;\u003c/p\u003e\u003cp\u003e—Lars Herrmann, VP, Partner Ecosystem Products and Technologies, Red Hat\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/section\u003e\u003csection id=\"eleven\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cimg src=\"https://imgix.datadoghq.com/img/container-report/number_10_FINAL.png\" alt=\"Trend Number 11\"/\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003ch2\u003e\u003ca href=\"#10\"\u003eNGINX, Redis, and Postgres are the top three container images\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAs of October 2021, the most popular off-the-shelf container images are:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cstrong\u003eNGINX:\u003c/strong\u003e NGINX continues its lead as the most popular container image, with over 50 percent of organizations using it in their container environments.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eRedis:\u003c/strong\u003e This popular key-value data store has been a perennial contender on this list, consistently placing in the top three. Redis is often used as an in-memory database, message queue, or cache.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003ePostgres:\u003c/strong\u003e This open source relational database remains in the top three and has appeared on this list every year since the first iteration of this report.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eElasticsearch:\u003c/strong\u003e This distributed data store and full-text search engine continues to be one of the most widely deployed applications in modern container environments.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eRabbitMQ and Calico (tie):\u003c/strong\u003e RabbitMQ is an open source message broker that finds plenty of use in microservice architectures. Also tied for fifth place is Calico, an open source networking solution. Both technologies edge out MySQL for the first time in this ranking.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eMySQL, MongoDB, and Kafka (tie):\u003c/strong\u003e The popular open source relational database, document store, and event-streaming platform are tied for sixth place this year.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eGitLab:\u003c/strong\u003e GitLab is a DevOps platform that enables teams to manage their Git repositories, build CI/CD pipelines, track issues, and more.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eVault and Jenkins (tie):\u003c/strong\u003e Jenkins is an open source automation server for creating and managing CI/CD pipelines. Vault, the HashiCorp service for securing and managing access to secrets is also tied for eighth place.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eetcd:\u003c/strong\u003e The distributed key-value store is used to provide consistent configuration across a Docker cluster.\u003c/li\u003e\u003cli\u003e\u003cstrong\u003eHAProxy:\u003c/strong\u003e The open source proxy is a popular choice for TCP and HTTP load balancing.\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eThe overall ranking changes slightly for Kubernetes StatefulSets. Redis, Postgres, Elasticsearch, and RabbitMQ are still the most commonly deployed images, but Postgres edges out Elasticsearch for the first time. Jenkins also joins the list for the first time, suggesting that Kubernetes is starting to play a bigger role in supporting CI/CD pipelines.\u003c/p\u003e\u003c/div\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/container-report/container-report/container_orchestration_STATIC_hero_201005_FINAL.png\" width=\"100%\"/\u003e",
      "date_published": "2021-10-12T00:00:00Z",
      "author": {
        "name": "Datadog"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/troubleshoot-lambda-function-request-response-payloads/",
      "title": "Resolve AWS Lambda function failures faster by monitoring invocation payloads",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eIn a serverless application, \u003ca href=\"https://aws.amazon.com/lambda/\"\u003eAWS Lambda functions\u003c/a\u003e are typically invoked by JSON-formatted events from other AWS services—like API Gateway, S3, and DynamoDB—and respond with JSON-formatted payloads. Having visibility into these function request and response payloads can provide context around your function invocations and help you uncover the root causes of Lambda function failures. For example, examining these payloads can help you determine if a function failed due to a misconfigured request or a code issue within the function itself.\u003c/p\u003e\u003cp\u003eTo help you quickly identify and troubleshoot Lambda function failures, you can now use Datadog to collect and visualize the JSON request and response payloads of AWS Lambda functions, giving you deeper insight into your serverless applications and helping troubleshoot problems.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot05.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot05.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot05.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot05.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot05.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot05.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot05.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot05.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot05.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot05.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot05.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot05.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot05.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot05.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot05.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"View JSON request and response payloads of lambda functions to facilitate your troubleshooting\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"dive-into-aws-lambda-function-requests-and-responses\"\u003e\u003ca href=\"#dive-into-aws-lambda-function-requests-and-responses\"\u003eDive into AWS Lambda function requests and responses\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eOnce you’ve \u003ca href=\"https://docs.datadoghq.com/serverless/distributed_tracing/collect_lambda_payloads\"\u003econfigured payload\u003c/a\u003e ingestion, Datadog will automatically collect function requests and responses for all of your function invocations, providing key information that can help troubleshoot issues. For example, if you’re notified that one of your Lambda functions is experiencing failures, you can dive into the relevant request payloads to check for missing parameters, mistyped resource addresses, or other misconfigurations that may be behind the failures.\u003c/p\u003e\u003cp\u003eBy identifying misconfigurations in failing requests, you can more easily reproduce issues in your development environment—and then run tests to verify your bug fixes.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot06.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot06.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot06.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot06.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot06.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot06.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot06.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot06.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot06.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot06.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot06.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot06.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot06.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot06.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot06.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"View Lambda function requests to identify any misconfigurations\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eIn addition to viewing requests, viewing function responses can also help you better understand issues that may occur. For instance, let’s say you have a Lambda function that is triggered by API Gateway and is expected to return specific data to an end user. You can verify that behavior by directly viewing your function’s response payloads. This is particularly useful in situations where your functions may be failing silently by returning 200 status codes but not executing their tasks as expected.\u003c/p\u003e\u003cp\u003eDatadog also provides the option to scrub specific parameters from collected payload. This prevents any sensitive data within either request or response JSON objects—like account IDs or addresses—from being collected.\u003c/p\u003e\u003ch2 id=\"quickly-surface-relevant-function-traces\"\u003e\u003ca href=\"#quickly-surface-relevant-function-traces\"\u003eQuickly surface relevant function traces\u003c/a\u003e\u003c/h2\u003e\u003cp\u003e\u003ca href=\"https://www.datadoghq.com/blog/tracing-lambda-datadog-apm/\"\u003eTracing your serverless applications\u003c/a\u003e provides end-to-end visibility into requests as they propagate across your services. Datadog can now \u003ca href=\"https://docs.datadoghq.com/tracing/visualization/#span-tags\"\u003etag spans\u003c/a\u003e that represent function invocations with relevant data from your request and response payloads. This helps accelerate troubleshooting by allowing you to use specific payload data to \u003ca href=\"https://docs.datadoghq.com/tracing/trace_search_and_analytics/\"\u003esearch and filter\u003c/a\u003e real-time and historical traces of invoked Lambda functions without any additional code changes or configuration.\u003c/p\u003e\u003cp\u003eLet’s say you’re troubleshooting an e-commerce application. Investigating request payloads, you see that issues are connected to checking out a specific item, as indicated with the \u003ccode\u003eItemID\u003c/code\u003e parameter. You can then search your traces for \u003ccode\u003eItemID:12345\u003c/code\u003e to surface other Lambda function requests that include that particular item ID as a payload parameter. This way you can quickly dive into the relevant traces to determine whether an issue is caused by a timeout (indicated by a particularly slow span), a 5xx internal server error, or another unexpected problem.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot03.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot03.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot03.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot03.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot03.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot03.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot03.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot03.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot03.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot03.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot03.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot03.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot03.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot03.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot03.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"lambda-payload-screenshot03.png\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eYou can search traces with specific payload parameters in Datadog APM to surface relevant Lambda requests.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYou can also set tag-based \u003ca href=\"https://docs.datadoghq.com/tracing/trace_retention_and_ingestion/#retention-filters\"\u003eretention filters\u003c/a\u003e with \u003ca href=\"https://docs.datadoghq.com/tracing/trace_search_and_analytics/#tracing-without-limits-recommended\"\u003eDatadog’s Tracing without Limits™\u003c/a\u003e to \u003ca href=\"https://docs.datadoghq.com/tracing/visualization/#indexed-span\"\u003eindex spans\u003c/a\u003e for critical requests. Then, you can turn your span tags into \u003ca href=\"https://docs.datadoghq.com/tracing/trace_search_and_analytics/query_syntax/#facets\"\u003efacets\u003c/a\u003e, enabling you to use historical data to run quick analysis on Lambda function requests. Using our example from above, you can turn \u003ccode\u003eItemID\u003c/code\u003e into a facet so you can see the latency distribution of all Lambda function requests that include \u003ccode\u003eItemID:12345\u003c/code\u003e, helping you gauge the scope of the issue.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot04.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot04.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot04.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot04.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot04.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot04.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot04.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot04.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot04.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot04.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot04.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot04.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot04.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot04.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda-payload-screenshot04.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"lambda-payload-screenshot04.png\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eTurn payload parameters into facets to filter traces and scope your view to the requests you\u0026#39;re most interest in.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"aws-lambda-function-payloads-right-at-your-fingertips\"\u003e\u003ca href=\"#aws-lambda-function-payloads-right-at-your-fingertips\"\u003eAWS Lambda function payloads right at your fingertips\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog helps speed up your AWS Lambda function troubleshooting by providing you with an in-depth look at request and response payloads as well as tagging function invocation traces with payload attributes. Payload ingestion is currently available for the Python and Node.js runtimes. You can enable it by adding the environment variable \u003ccode\u003eDD_CAPTURE_LAMBDA_PAYLOAD\u003c/code\u003e to your Lambda functions and setting it to \u003ccode\u003etrue\u003c/code\u003e. To learn more about how to set up and configure Datadog payload configuration please see our documentation \u003ca href=\"https://docs.datadoghq.com/serverless/distributed_tracing/collect_lambda_payloads\"\u003ehere\u003c/a\u003e\u003c/p\u003e\u003cp\u003eIf you aren’t already using Datadog, get started today with a 14-day \u003ca href=\"#\"\u003efree trial\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/troubleshoot-lambda-function-request-response-payloads/lambda_payload_hero.png\" width=\"100%\"/\u003eIn a serverless application, AWS Lambda functions are typically invoked by JSON-formatted events from other AWS services—like API Gateway, S3, and DynamoDB—and respond with JSON-formatted payloads. Having visibility into these function request and response payloads can provide context around your function invocations and help you uncover the root causes of Lambda function failures. For example, examining these payloads can help you determine if a function failed due to a misconfigured request or a code issue within the function itself.",
      "date_published": "2021-10-08T00:00:00Z",
      "author": {
        "name": "Jordan Obey"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/template-variable-available-values/",
      "title": "Filter dashboards faster with template variable available values",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eDatadog’s \u003ca href=\"https://docs.datadoghq.com/dashboards/template_variables/\"\u003etemplate variables\u003c/a\u003e help you quickly scope your dashboards to specific contexts using tags, so you can visualize data from only the hosts, containers, services, or any other tagged objects you care about. This helps you build more flexible dashboards so you can access the insights you’re looking for as quickly as possible. We’re proud to announce new features for the template variable workflow that enable you to make highly dynamic, shareable dashboards more efficiently. In this post, we’ll look at the new \u003ca href=\"#manage-template-variables-faster-with-the-new-modal\"\u003etemplate variable modal\u003c/a\u003e for creating and sorting variables, as well as a new \u003ca href=\"#focus-your-dashboards-to-available-values\"\u003e\u003cstrong\u003eavailable values\u003c/strong\u003e field\u003c/a\u003e, which lets you select what values appear in the dropdown to make your dashboards easier to use.\u003c/p\u003e\u003ch2 id=\"manage-template-variables-faster-with-the-new-modal\"\u003e\u003ca href=\"#manage-template-variables-faster-with-the-new-modal\"\u003eManage template variables faster with the new modal\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eThe new template variable modal makes it easier to create and organize variables. When you create a new template variable, you can select the tag or attribute you want to use. Datadog automatically fills in the variable’s name using the tag key.\u003c/p\u003e\u003cp\u003eSetting default values ensures that your dashboard always loads with the same subset of data displayed, so you can easily share it in a default scope across your organization.\u003c/p\u003e\u003cp\u003eYou can also drag variables in the modal to reorder them—this helps you group related variables together to make your variable set easier to parse, especially if you’re using a large number of variables.\u003c/p\u003e\u003ch2 id=\"focus-your-dashboards-to-available-values\"\u003e\u003ca href=\"#focus-your-dashboards-to-available-values\"\u003eFocus your dashboards to available values\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn cases where your new template variable has a large number of possible values, it can be tedious to find the ones you need—often, there’s only a small subset that your team needs to view in the dashboard. And, in cases where your tag values are long strings that are difficult to remember—such as hostnames, container pods, or org IDs—querying for them specifically can be error-prone. This can make it difficult, for example, for stakeholders outside your team to effectively move through scopes in your dashboard.\u003c/p\u003e\u003cp\u003eTo address this, you can now configure \u003cstrong\u003eavailable values\u003c/strong\u003e for each template variable. This means you can specify which values for a tag are available in the dropdown for a template variable in your dashboard.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/available_values.jpg?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/template-variable-available-values/available_values.jpg?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/available_values.jpg?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/template-variable-available-values/available_values.jpg?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/available_values.jpg?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/template-variable-available-values/available_values.jpg?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/available_values.jpg?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/template-variable-available-values/available_values.jpg?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/available_values.jpg?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/template-variable-available-values/available_values.jpg?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/available_values.jpg?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/template-variable-available-values/available_values.jpg?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/available_values.jpg?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/template-variable-available-values/available_values.jpg?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/available_values.jpg?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Select a subset of available values for your template variables\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eThis enables you to focus only on relevant values for your template variables and filter out noise, such as unsupported browsers, deprecated services, and data from older deployments that are no longer reaching customers.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/selected_values.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/template-variable-available-values/selected_values.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/selected_values.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/template-variable-available-values/selected_values.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/selected_values.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/template-variable-available-values/selected_values.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/selected_values.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/template-variable-available-values/selected_values.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/selected_values.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/template-variable-available-values/selected_values.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/selected_values.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/template-variable-available-values/selected_values.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/selected_values.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/template-variable-available-values/selected_values.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/selected_values.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Viewing available values in a dashboard\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eCombining this with \u003ca href=\"https://www.datadoghq.com/blog/dynamic-template-variable-syntax-dashboards/\"\u003edynamic template variable syntax\u003c/a\u003e, you can configure your graphs to query the exact tag values you need from across your environment as quickly and efficiently as possible. And, with \u003ca href=\"https://www.datadoghq.com/blog/template-variable-saved-views/\"\u003esaved views\u003c/a\u003e, you can easily preserve the scope of your dashboard visualizations to share key information across teams.\u003c/p\u003e\u003ch2 id=\"optimize-your-template-variable-workflow\"\u003e\u003ca href=\"#optimize-your-template-variable-workflow\"\u003eOptimize your template variable workflow\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eWith the new optimized template variable workflow, it’s easier than ever to use your dashboards to visualize and monitor the data you need. These new features are now generally available for all Datadog customers—for more information about working with template variables, see our \u003ca href=\"https://docs.datadoghq.com/dashboards/template_variables/\"\u003edocumentation\u003c/a\u003e. Or, if you’re brand new to Datadog, get started with a \u003ca href=\"#\"\u003e14-day free trial\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/template-variable-available-values/tempvar-avail-hero.png\" width=\"100%\"/\u003eDatadog’s template variables help you quickly scope your dashboards to specific contexts using tags, so you can visualize data from only the hosts, containers, services, or any other tagged objects you care about. This helps you build more flexible dashboards so you can access the insights you’re looking for as quickly as possible. We’re proud to announce new features for the template variable workflow that enable you to make highly dynamic, shareable dashboards more efficiently.",
      "date_published": "2021-10-07T00:00:00Z",
      "author": {
        "name": "Stephanie Niu"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/ios-crash-reporting-datadog/",
      "title": "Debug iOS crashes efficiently with Datadog RUM",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eUnsurprisingly, application crashes due to fatal errors can be a major pain point for iOS users. \u003ca href=\"https://www.goodfirms.co/resources/app-download-usage-statistics-to-know\"\u003eRecent research\u003c/a\u003e shows that roughly 20 percent of mobile application uninstalls were due to crashes or other code errors. As a developer, it’s paramount to manage this potential churn by capturing comprehensive crash data in order to track, triage, and debug recurring issues in your iOS apps.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.datadoghq.com/product/real-user-monitoring/\"\u003eDatadog RUM\u003c/a\u003e’s \u003ca href=\"https://docs.datadoghq.com/real_user_monitoring/ios/?tab=us\"\u003eiOS SDK\u003c/a\u003e enables you to collect crash data from your iOS apps so you can correlate them with user metadata and app interactions. This helps you determine the scope of application errors so you can triage the most severe issues and get deeper insight into your application’s performance.\u003c/p\u003e\u003cp\u003eIn this post, we’ll discuss how you can use Datadog to:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"#collect-crash-reports\"\u003eCollect and process crash reports\u003c/a\u003e using the RUM iOS SDK\u003c/li\u003e\u003cli\u003e\u003ca href=\"#triage-and-analyze-crashes-with-error-tracking\"\u003eAnalyze crash data\u003c/a\u003e using dashboards, alerting, and Error Tracking\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"collect-crash-reports\"\u003e\u003ca href=\"#collect-crash-reports\"\u003eCollect crash reports\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eThe \u003ca href=\"https://github.com/DataDog/dd-sdk-ios\"\u003eDatadog iOS SDK\u003c/a\u003e enables you to collect logs, traces, and RUM data from your mobile applications. Now, you can also collect crash reports so that you can visualize crash data in dashboards, analyze symbolicated error reports, and triage error trends with \u003ca href=\"https://www.datadoghq.com/blog/error-tracking/\"\u003eError Tracking\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eTo enable crash report collection, simply modify the SDK’s initialization steps to implement the \u003ccode\u003eenableCrashReporting\u003c/code\u003e method:\u003c/p\u003e\u003cdiv\u003e\u003cp\u003eMyApp.swift\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"swift\"\u003e\u003cspan\u003eimport\u003c/span\u003e \u003cspan\u003eDatadogCrashReporting\u003c/span\u003e \u003cspan\u003e// NEW\u003c/span\u003e\n\n\u003cspan\u003eDatadog\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003einitialize\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\n    \t\t\u003cspan\u003eappContext\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e.\u003c/span\u003e\u003cspan\u003einit\u003c/span\u003e\u003cspan\u003e(),\u003c/span\u003e\n    \t\t\u003cspan\u003etrackingConsent\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003etrackingConsent\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n   \t\t\u003cspan\u003econfiguration\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003eDatadog\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eConfiguration\u003c/span\u003e\n        \t\t\t\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003ebuilderUsing\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\n            \t\t\t\u003cspan\u003erumApplicationID\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;\u0026lt;rum_application_id\u0026gt;\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n            \t\t\t\u003cspan\u003eclientToken\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;\u0026lt;client_token\u0026gt;\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n            \t\t\t\u003cspan\u003eenvironment\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;\u0026lt;environment_name\u0026gt;\u0026#34;\u003c/span\u003e\n        \t\t\t\u003cspan\u003e)\u003c/span\u003e\n \t\t\t\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003etrackUIKitRUMViews\u003c/span\u003e\u003cspan\u003e()\u003c/span\u003e\n        \t\t\t\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003etrackUIKitActions\u003c/span\u003e\u003cspan\u003e()\u003c/span\u003e\n        \t\t\t\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003etrackURLSession\u003c/span\u003e\u003cspan\u003e()\u003c/span\u003e\n        \t\t\t\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eenableCrashReporting\u003c/span\u003e\u003cspan\u003e(\u003c/span\u003e\u003cspan\u003eusing\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003eDDCrashReportingPlugin\u003c/span\u003e\u003cspan\u003e())\u003c/span\u003e \u003cspan\u003e// NEW\u003c/span\u003e\n        \t\t\t\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003ebuild\u003c/span\u003e\u003cspan\u003e()\u003c/span\u003e\n\u003cspan\u003e)\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003ch3 id=\"symbolicate-your-ios-crash-data\"\u003e\u003ca href=\"#symbolicate-your-ios-crash-data\"\u003eSymbolicate your iOS crash data\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eCrash reports from iOS apps are \u003cstrong\u003eunsymbolicated\u003c/strong\u003e—having readable function names in the stacktrace replaced with memory addresses—to reduce file size and provide a security benefit (i.e., the symbols can’t be read by other code running within the same process). You can use \u003ca href=\"https://github.com/DataDog/datadog-ci\"\u003eDatadog’s CLI\u003c/a\u003e to collect and upload mapping files (\u003cstrong\u003e.dSYM\u003c/strong\u003e files) stored in your app’s build directory. Datadog then uses them to replace the memory addresses with meaningful symbols. This way, your stacktraces will appear in Datadog in a readable format.\u003c/p\u003e\u003cp\u003eOnce you’ve begun forwarding crash reports, Datadog will use the data to populate graphs in the out-of-the-box mobile RUM dashboard. This shows you key information about the health of your app, including:\u003c/p\u003e\u003cul\u003e\u003cli\u003eapp resources throwing the most errors\u003c/li\u003e\u003cli\u003emost common error types (HTTP, syntax, runtime exception, etc.)\u003c/li\u003e\u003cli\u003eiOS versions or versions of your application experiencing crashes\u003c/li\u003e\u003c/ul\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/ios-dashboard-2.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/ios-dashboard-2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/ios-dashboard-2.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/ios-dashboard-2.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/ios-dashboard-2.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/ios-dashboard-2.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/ios-dashboard-2.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/ios-dashboard-2.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/ios-dashboard-2.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/ios-dashboard-2.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/ios-dashboard-2.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/ios-dashboard-2.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/ios-dashboard-2.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/ios-dashboard-2.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/ios-dashboard-2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Default RUM Mobile Dashboard\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"triage-and-analyze-crashes-with-error-tracking\"\u003e\u003ca href=\"#triage-and-analyze-crashes-with-error-tracking\"\u003eTriage and analyze crashes with Error Tracking\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDuring heavy usage, your application may generate a large volume of errors that cause it to crash—such as I/O exceptions, runtime exceptions, out-of-memory errors, and more. With potentially thousands of devices emitting this data, it can be difficult to effectively make sense of it all.\u003c/p\u003e\u003cp\u003eDatadog \u003ca href=\"https://www.datadoghq.com/blog/error-tracking/\"\u003eError Tracking\u003c/a\u003e monitors your iOS crash reports and groups similar errors together into issues, so you can view debugging info from your app alongside user session info from RUM. RUM automatically enriches each error with key metadata like customer location, device, code version, and view name. This helps you understand the scope of crashes—how often they occur and which customer locations, releases, and parts of your app are affected—and begin to triage the most severe and frequent crashes to focus your debugging efforts on.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-stacktrace.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-stacktrace.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-stacktrace.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-stacktrace.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-stacktrace.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-stacktrace.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-stacktrace.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-stacktrace.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-stacktrace.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-stacktrace.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-stacktrace.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-stacktrace.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-stacktrace.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-stacktrace.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-stacktrace.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Examining an error stacktrace in Error Tracking\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYou can dive into a specific error to view key context for performing root-cause analysis of your issues. This includes key information from the crash report, such as the error message and a fully symbolicated stacktrace. You can also see any custom attributes you add using the SDK’s included \u003ca href=\"https://docs.datadoghq.com/real_user_monitoring/ios/advanced_configuration/#track-custom-global-attributes\"\u003e\u003ccode\u003esetRUMResourceAttributesProvider\u003c/code\u003e function\u003c/a\u003e—for example, the device location, device type, or the device’s internet connection status.\u003c/p\u003e\u003cp\u003eThe session timeline charts all the view loads, errors, and user actions that occurred during the relevant session that produced the crash. This provides the context you need to reproduce the error, saving time and guesswork. Once you’ve shipped a fix, you can scope your Error Tracking view to the new code version to see if the issue is still showing up.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-timeline.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-timeline.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-timeline.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-timeline.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-timeline.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-timeline.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-timeline.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-timeline.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-timeline.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-timeline.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-timeline.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-timeline.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-timeline.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-timeline.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-timeline.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Examining the session timeline in Error Tracking\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eDatadog emits an \u003ca href=\"https://docs.datadoghq.com/events/\"\u003eevent\u003c/a\u003e each time Error Tracking creates a new issue. Using Datadog’s \u003ca href=\"https://docs.datadoghq.com/real_user_monitoring/error_tracking/explorer/#get-alerted-on-new-errors\"\u003eevent monitors\u003c/a\u003e, you can alert on the first sighting of a new issue in a given environment or view path. This allows you to be informed as soon as a specific part of your app starts crashing, so you can ship a fix for impacted customers as quickly as possible.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/error-tracking-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Configuring an Event Monitor to alert on new issues in Error Tracking\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"practice-ios-crash-safety\"\u003e\u003ca href=\"#practice-ios-crash-safety\"\u003ePractice iOS crash safety\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eWith Datadog’s iOS SDK, you can now use Datadog RUM and Error Tracking to easily track, triage, and debug application crashes in order to manage their impact on users and reduce churn. The new version of the RUM iOS SDK and included crash report symbolication CLI are currently in public beta—for more information on setting up your apps to forward crash reports to Datadog, see our \u003ca href=\"https://docs.datadoghq.com/real_user_monitoring/ios/?tab=us\"\u003edocumentation\u003c/a\u003e. Or, if you’re brand new to Datadog, get started with a \u003ca href=\"#\"\u003e14-day free trial\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/ios-crash-reporting-datadog/ios-crashes-hero.png\" width=\"100%\"/\u003eUnsurprisingly, application crashes due to fatal errors can be a major pain point for iOS users. Recent research shows that roughly 20 percent of mobile application uninstalls were due to crashes or other code errors. As a developer, it’s paramount to manage this potential churn by capturing comprehensive crash data in order to track, triage, and debug recurring issues in your iOS apps.Datadog RUM’s iOS SDK enables you to collect crash data from your iOS apps so you can correlate them with user metadata and app interactions.",
      "date_published": "2021-10-04T00:00:00Z",
      "author": {
        "name": "Thomas Sobolik"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/",
      "title": "How we optimized our Akka application using Datadog’s Continuous Profiler",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003ePerformance bottlenecks are not always (or some might say, never) where you expect them. We have all been there, knowing that there was a latency, but not finding it in any of the expected places. There is nothing worse that seeing that there’s a latency and having to guess at where it is. This is where a profiler comes in - profiling is a form of dynamic program analysis that measures software resource usage, like CPU time or memory allocation, which means you can actually understand your program’s performance rather than guess at what might be slowing it down. At Datadog, we had a perfomance issue (completely unexpectedly) related to a third party framework called \u003ca href=\"https://akka.io/\"\u003eAkka\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eWhen developing in Java or Scala, using frameworks like Akka simplifies writing high-load concurrent, distributed applications and reduces the complexity of writing thread-safe code that is easily parallelized on multi-core machines to maximize application performance. But unfortunately, it abstracts many low-level implementation details. The types of details that can cause performance bottlenecks if used in a sub-optimal way.\u003c/p\u003e\u003cp\u003eOur performance issue was caused by the \u003ccode\u003eForkJoinPool\u003c/code\u003e in our Java application that is based on the Akka framework. We could see that our Java application was using way more CPU than we expected. But it was the type of thing that we didn’t notice right away, it was a gradual realization that our app just shouldn’t be using that much CPU. The issue was responsible for 20-30% of CPU used by this service until we detected it with the Datadog Continuous Profiler. This article explains how we discovered and fixed this issue.\u003c/p\u003e\u003ch2 id=\"how-we-spotted-the-issue\"\u003e\u003ca href=\"#how-we-spotted-the-issue\"\u003eHow we spotted the issue\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eWe use Akka to parallelize the processing of log events. Akka offers a runtime for actor-based concurrent and distributed computation. It is based on binding different units of work, called actors, to a set of dispatchers, which are responsible for scheduling execution of actors’ tasks, and are built on top of various kinds of thread pools.\u003c/p\u003e\u003cp\u003eThere is an Akka dispatcher based on the \u003ccode\u003eForkJoinPool\u003c/code\u003e to handle consecutive stages of our log processing pipelines.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram1.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram1.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram1.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram1.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram1.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram1.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram1.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram1.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram1.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram1.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram1.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram1.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram1.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram1.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram1.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"the flow of a standard logs processing pipeline\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eSo we initially thought the issue was with log processing, and we rolled out what we were confident was going to yield much better performance! While running A/B tests of a new algorithm to optimize log parsing, we expected to see a reduction in CPU usage. However, enabling this optimization showed almost no gain, and in some cases, it even caused performance degradation. We were dissapointed, and so we dug in further, using the \u003ca href=\"https://www.datadoghq.com/blog/code-optimization-datadog-profile-comparison/\"\u003eContinuous Profiler\u003c/a\u003e.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/ab-testing.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/ab-testing.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/ab-testing.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/ab-testing.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/ab-testing.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/ab-testing.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/ab-testing.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/ab-testing.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/ab-testing.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/ab-testing.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/ab-testing.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/ab-testing.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/ab-testing.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/ab-testing.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/ab-testing.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"an image of the issue\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eAfter looking at the flame graphs, the optimization we made helped us reduce CPU time spent on log parsing, as expected. However, we started to spend more CPU time inside of the \u003ccode\u003eForkJoinPool.scan()/Unsafe.park()\u003c/code\u003e methods. It wasn’t clear why this method caused a performance issue. To investigate, we changed the summary table to display the top list of threads consuming the most CPU time.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/thread.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/thread.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/thread.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/thread.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/thread.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/thread.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/thread.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/thread.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/thread.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/thread.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/thread.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/thread.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/thread.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/thread.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/thread.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"the thread causing the issue\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eWe noticed something very odd: in the summary table, the threads from the dedicated “work” pool only spent ~1% of CPU inside of this stack frame. We expected them to be the majority. So we checked the threads from other thread pools and came across the main offender, the threads of the default Akka dispatcher spent most of its CPU time in this method. The default Akka dispatcher is used when no other dispatchers are explicitly set for a given actor and is also based on \u003ccode\u003eForkJoinPool\u003c/code\u003e by default. By diving deeper into the stack frames of these threads, we noticed that many of them were running the same actor – LatencyReportActor, which reported some latency-related metrics for a sample of log events.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/latency-report-actor.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/latency-report-actor.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/latency-report-actor.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/latency-report-actor.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/latency-report-actor.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/latency-report-actor.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/latency-report-actor.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/latency-report-actor.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/latency-report-actor.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/latency-report-actor.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/latency-report-actor.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/latency-report-actor.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/latency-report-actor.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/latency-report-actor.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/latency-report-actor.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"the thread logs of the issue\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"detailed-analysis-of-the-root-cause\"\u003e\u003ca href=\"#detailed-analysis-of-the-root-cause\"\u003eDetailed analysis of the root cause\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eTo find out how this actor could be related to spending more time inside \u003ccode\u003eForkJoinPool.scan()/Unsafe.park()\u003c/code\u003e methods, we needed a deeper understanding of what this method does under the hood.\u003c/p\u003e\u003cp\u003eWe discovered that the \u003ccode\u003eForkJoinPool\u003c/code\u003e attempts to maintain enough active threads by dynamically adding, suspending, or resuming internal worker threads. When there are not enough worker threads, the pool spawns a new thread. When there are no tasks for an active thread, the thread is suspended (by calling \u003ccode\u003eUnsafe.park()\u003c/code\u003e). After being idle for a certain period (60 seconds by default), worker threads get terminated.\u003c/p\u003e\u003cp\u003eIn the method \u003ccode\u003eForkJoinPool.scan()\u003c/code\u003e, a worker thread checks pending tasks, and if there are too many pending tasks compared to the number of active threads, it either resumes a suspended worker thread, if available, by calling \u003ccode\u003eUnsafe.unpark()\u003c/code\u003e, or it spawns an entirely new thread. Also, the set pool parallelism level caps the maximum number of threads.\u003c/p\u003e\u003cp\u003eThe observed behavior is explained by having an \u003cstrong\u003eirregular flow\u003c/strong\u003e of incoming tasks combined with the \u003cstrong\u003ehigh maximum number of threads\u003c/strong\u003e of the underlying thread pool. Because the \u003ccode\u003eForkJoinPool\u003c/code\u003e keeps activating and deactivating worker threads between the periods of stable load, there are short, frequent spikes, which waste CPU time on making expensive \u003ccode\u003eUnsafe.park()/unpark()\u003c/code\u003e native calls.\u003c/p\u003e\u003cp\u003eThis hypothesis perfectly matched \u003ccode\u003eLatencyCheckpointActor\u003c/code\u003e’s behavior, which indeed does not have a regular flow of tasks – it receives a few hundred events every second, reports the latency for them in a matter of milliseconds, and then waits until the next batch of events arrive. The number of actor instances, as well as the size of the underlying thread pool, were limited only by the number of available processor cores. So every second, Akka wakes up all 32 threads (the number of cores) to handle events as fast as possible, and then puts them to sleep once all events have been processed.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram2.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram2.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram2.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram2.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram2.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram2.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram2.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram2.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram2.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram2.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram2.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram2.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram2.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/diagram2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"the flow of logs to the default scheduler\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"how-we-fixed-it\"\u003e\u003ca href=\"#how-we-fixed-it\"\u003eHow we fixed it\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eTo verify this theory, we moved this actor from the default Akka dispatcher to our main “work” dispatcher, which is also based on a \u003ccode\u003eForkJoinPool\u003c/code\u003e, but has a stable flow of log processing tasks, with a single-line config change:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"yaml\"\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003elatency.reporter {\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e        \u003c/span\u003e\u003cspan\u003erouter\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003eround-robin-pool\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e        \u003c/span\u003e\u003cspan\u003enr-of-instances\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e{\u003cspan\u003ethe number of cores}\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e        \u003c/span\u003e\u003cspan\u003edispatcher\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e\u003cspan\u003ework-dispatcher\u003c/span\u003e\u003cspan\u003e\n\u003c/span\u003e\u003cspan\u003e \u003c/span\u003e}\u003cspan\u003e\n\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eAnd the overall CPU usage dropped by 30% on average across different services, and profiles confirmed that this was due to the decrease in CPU time spent inside of \u003ccode\u003eForkJoinPool.scan()\u003c/code\u003e. The default Akka dispatcher’s thread pool also shrank from 32 to 2 threads, confirming our hypothesis.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/cpu-usage.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/cpu-usage.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/cpu-usage.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/cpu-usage.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/cpu-usage.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/cpu-usage.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/cpu-usage.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/cpu-usage.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/cpu-usage.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/cpu-usage.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/cpu-usage.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/cpu-usage.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/cpu-usage.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/cpu-usage.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/cpu-usage.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"the drop in CPU usage\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"conclusion\"\u003e\u003ca href=\"#conclusion\"\u003eConclusion\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIf your application is using \u003ccode\u003eForkJoinPool\u003c/code\u003e, directly or using the Akka framework, keep an eye on how much CPU time is being spent inside the \u003ccode\u003eForkJoinPool.scan()\u003c/code\u003e method. If it is getting too high (over 10-15%), you might need to adjust your thread pool settings to keep the load more or less stable and avoid unnecessary parking and unparking of threads. If this does happen to you, consider trying the following options:\u003c/p\u003e\u003cul\u003e\u003cli\u003elimit the number of actor instances (if you are using Akka)\u003c/li\u003e\u003cli\u003elimit the maximum number of threads in a thread pool\u003c/li\u003e\u003cli\u003ereduce the number of used thread pools to spread the load\u003c/li\u003e\u003cli\u003ebalance the load with some kind of task queues which can accumulate frequent short spikes of tasks\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThe ultimate goal is to keep the number of active threads in a \u003ccode\u003eForkJoinPool\u003c/code\u003e more or less stable, avoiding short-time fluctuations.\u003c/p\u003e\u003cp\u003eThere were a few lessons we learned here:\u003c/p\u003e\u003cp\u003eFirst, don’t trust your intuition when it comes to performance in production. Our initial regression was introduced by a minor, non-critical change (adding an auxiliary reporting actor), which seemed innocent performance-wise. An innocuous change can have dramatic performance impact.\u003c/p\u003e\u003cp\u003eSecond, it’s much easier to overlook performance issues if they happen inside some trustworthy third-party code. Though many of our engineers had seen the CPU usage inside the \u003ccode\u003eForkJoinPool.scan()\u003c/code\u003e, they didn’t take action because it was not directly related to the changes they were making - the stack frame was not linked in any way to our application codebase. Naturally developers tend to trust third-party library code, but tools like continuous profiling can help to spot and debug performance bottlenecks in any part of your application.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/engineering/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler/how-we-optimized-our-akka-application-using-datadogs-continuous-profiler.png\" width=\"100%\"/\u003ePerformance bottlenecks are not always (or some might say, never) where you expect them. We have all been there, knowing that there was a latency, but not finding it in any of the expected places. There is nothing worse that seeing that there\u0026rsquo;s a latency and having to guess at where it is. This is where a profiler comes in - profiling is a form of dynamic program analysis that measures software resource usage, like CPU time or memory allocation, which means you can actually understand your program’s performance rather than guess at what might be slowing it down.",
      "date_published": "2021-09-30T00:00:00Z",
      "author": {
        "name": "Vladimir Zhuk"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/aws-graviton2-lambda-monitoring/",
      "title": "Announcing Support for AWS Lambda Functions running on AWS Graviton2 processors",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003ca href=\"https://aws.amazon.com/ec2/graviton/\"\u003eAWS Graviton2 processors\u003c/a\u003e use the \u003ca href=\"https://www.arm.com/why-arm/architecture/cpu\"\u003eArm architecture\u003c/a\u003e to provide high-efficiency, low-cost computing. AWS already offers the ability to provision \u003ca href=\"https://aws.amazon.com/ec2/graviton/\"\u003eEC2 instances\u003c/a\u003e powered by Graviton2, and Datadog is proud to partner with them for the launch of new \u003ca href=\"https://aws.amazon.com/blogs/aws/aws-lambda-functions-powered-by-aws-graviton2-processor-run-your-functions-on-arm-and-get-up-to-34-better-price-performance\"\u003eGraviton2 compute resources for Lambda functions\u003c/a\u003e. In this post, we’ll discuss how Datadog can provide deep visibility into your Lambda functions across whichever platform you’re using. This enables you to monitor function performance alongside telemetry data from the rest of your stack—and determine whether Graviton2 is a good fit for your serverless workloads.\u003c/p\u003e\u003ch2 id=\"monitor-your-graviton2-powered-functions-out-of-the-box\"\u003e\u003ca href=\"#monitor-your-graviton2-powered-functions-out-of-the-box\"\u003eMonitor your Graviton2-powered functions out of the box\u003c/a\u003e\u003c/h2\u003e\u003cp\u003e\u003ca href=\"https://www.datadoghq.com/blog/datadog-lambda-extension/\"\u003eDatadog’s Lambda extension\u003c/a\u003e \u003ca href=\"https://www.datadoghq.com/blog/datadog-arm-agent/\"\u003efully supports Arm-based architectures\u003c/a\u003e. This means that, once you’ve \u003ca href=\"https://docs.datadoghq.com/serverless/installation#instrument-your-serverless-application\"\u003einstrumented your functions with the appropriate library\u003c/a\u003e, Datadog can collect telemetry from your Lambda functions running on Graviton2.\u003c/p\u003e\u003cp\u003eDatadog automatically tags your functions with key metadata, including architecture, which enables you to visualize and compare their performance across different platforms. For example, you can deploy a \u003ca href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-versions.html\"\u003enew version of an existing function\u003c/a\u003e using Graviton2, and then easily analyze its performance alongside that of its x86-based counterpart. This can help you assess whether it makes sense to continue migrating functions to the new platform.\u003c/p\u003e\u003cp\u003eAWS reports that Graviton2-powered functions can experience up to 34 percent reduced duration, and the cold start time for functions we ran during our testing executed approximately nine percent faster when using Graviton2. This is because our Graviton2 functions compiled into packages that are smaller by about seven to nine percent, which can improve \u003ca href=\"https://www.datadoghq.com/blog/lambda-enhanced-metrics/#avoid-the-chill-of-cold-starts\"\u003ecold start\u003c/a\u003e performance, as Lambda has to pull less data to initialize a function.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-comparison.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-comparison.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-comparison.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-comparison.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-comparison.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-comparison.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-comparison.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-comparison.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-comparison.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-comparison.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-comparison.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-comparison.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-comparison.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-comparison.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-comparison.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"x86 and graviton2 function comparison.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eFaster cold starts can reduce both customer-facing latency and \u003ca href=\"https://aws.amazon.com/blogs/aws/new-for-aws-lambda-1ms-billing-granularity-adds-cost-savings/\"\u003ecosts\u003c/a\u003e. Graviton2 could therefore be an ideal choice for functions that are susceptible to frequent or long cold starts, such as those that are invoked often or have many dependencies. Alternatively, Graviton2 might not be well suited for certain workloads, such as video encoding, which \u003ca href=\"https://docs.aws.amazon.com/lambda/latest/dg/runtimes-avx2.html\"\u003ebenefit from x86 architecture\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"get-full-serverless-visibility\"\u003e\u003ca href=\"#get-full-serverless-visibility\"\u003eGet full serverless visibility\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eOnce you instrument your Lambda functions, Datadog will begin ingesting their metrics, logs, and traces, which you can monitor and correlate with data from the rest of your stack. For instance, you can use the \u003ca href=\"https://www.datadoghq.com/blog/datadog-serverless-view/\"\u003eServerless view\u003c/a\u003e to track function performance alongside metrics from your other serverless resources, such as API Gateway. This makes it easy to surface problems with your functions like long durations or high error rates, which might be related to issues with the services that invoke them.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog serverless view\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eDatadog will also generate \u003ca href=\"https://docs.datadoghq.com/serverless/enhanced_lambda_metrics/\"\u003ereal-time enhanced Lambda metrics\u003c/a\u003e, including the number of cold starts, function memory usage, and estimated cost. You can monitor these metrics using a customizable, out-of-the-box dashboard, giving you even more granular insights into function performance.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-enhanced-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-enhanced-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-enhanced-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-enhanced-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-enhanced-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-enhanced-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-enhanced-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-enhanced-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-enhanced-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-enhanced-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-enhanced-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-enhanced-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-enhanced-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-enhanced-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda-graviton2-enhanced-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog Lambda enhanced metrics dashboard.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"start-today\"\u003e\u003ca href=\"#start-today\"\u003eStart today\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eYou can use Datadog to \u003ca href=\"https://www.datadoghq.com/blog/key-metrics-for-monitoring-aws-lambda/\"\u003emonitor all of your AWS Lambda functions\u003c/a\u003e, whether they are running on x86 or Arm architecture. This makes it easy to visualize performance and determine whether you should continue to \u003ca href=\"https://github.com/aws/aws-graviton-getting-started\"\u003emigrate your serverless applications to this new platform\u003c/a\u003e. See \u003ca href=\"https://docs.datadoghq.com/serverless/\"\u003eour documentation\u003c/a\u003e for more details on getting started. Or, sign up for a free 14-day trial.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/aws-graviton2-lambda-monitoring/lambda_graviton2_210819_FINAL.png\" width=\"100%\"/\u003eAWS Graviton2 processors use the Arm architecture to provide high-efficiency, low-cost computing. AWS already offers the ability to provision EC2 instances powered by Graviton2, and Datadog is proud to partner with them for the launch of new Graviton2 compute resources for Lambda functions. In this post, we\u0026rsquo;ll discuss how Datadog can provide deep visibility into your Lambda functions across whichever platform you\u0026rsquo;re using. This enables you to monitor function performance alongside telemetry data from the rest of your stack—and determine whether Graviton2 is a good fit for your serverless workloads.",
      "date_published": "2021-09-29T00:00:00Z",
      "author": {
        "name": "Alex Cuoci"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/legal/datadog-eea-data-processing-addendum/2021-09-27/",
      "title": "Datadog EEA Data Processing Addendum",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eOther capitalized terms not otherwise defined in this DPA shall have the respective meanings assigned to them in this Section.\u003c/p\u003e\u003cp\u003e“Account Data” means information about Customer that Customer provides to Datadog in connection with the creation or administration of its Datadog accounts, such as first and last name, user name and email address of an Authorized User or Customer’s billing contact. Customer shall ensure that all Account Data is current and accurate at all times during the term of the applicable Order.\u003c/p\u003e\u003cp\u003e“Adequacy” means where the European Commission has decided that the third country, a territory or one or more specified sectors within that third country, or the international organization in question, ensures an adequate level of protection.\u003c/p\u003e\u003cp\u003e“Affiliate” means, unless otherwise defined in the Master Agreement, a business entity that directly or indirectly controls, is controlled by or is under common control with, such Party; “control” means the direct or indirect ownership of more than 50% of the voting securities of a business entity.\u003c/p\u003e\u003cp\u003e“Applicable Laws” means any and all governmental laws, rules, directives, regulations or orders that are applicable to a particular Party’s performance under this DPA, including applicable EU Data Protection Law.\u003c/p\u003e\u003cp\u003e“AUP” means Datadog’s standard Acceptable Use Policy, currently available at \u003ca href=\"https://www.datadoghq.com/legal/acceptable-use/\"\u003ehttps://www.datadoghq.com/legal/acceptable-use/\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e“Authorized User” means an individual employee, agent or contractor of Customer or a Participating Affiliate for whom subscriptions to Services have been purchased pursuant to the terms of the Master Agreement and applicable Order, and who have been supplied user credentials for the Services by Customer or the Participating Affiliate (or by Datadog at Customer’s or a Participating Affiliate’s request).\u003c/p\u003e\u003cp\u003e“Customer Component” means each individual component of Customer’s Environment.\u003c/p\u003e\u003cp\u003e“Customer Credentials” means access passwords, keys, tokens or other credentials used by Customer in connection with the Services.\u003c/p\u003e\u003cp\u003e“Customer Data” means data from Customer’s Environment that are submitted for Processing by the Services. Through Customer’s configuration and use of the Services, Customer has control over the types and amounts of Customer Data.\u003c/p\u003e\u003cp\u003e“Customer’s Environment” means, exclusive of Services, the systems, platforms, services, software, devices, sites and/or networks that Customer uses in its own internal business operations.\u003c/p\u003e\u003cp\u003e“Customer Personal Data” means Customer Data comprising Personal Data of Data Subjects located in the EEA.\u003c/p\u003e\u003cp\u003e“Documentation” means Datadog’s standard user documentation for the Services, currently available at \u003ca href=\"https://docs.datadoghq.com/\"\u003ehttps://docs.datadoghq.com/\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e“EEA” means the European Economic Area, which constitutes the member states of the European Union (“EU”) and Norway, Iceland and Liechtenstein, as well as for purposes of this DPA, the United Kingdom.\u003c/p\u003e\u003cp\u003e“EU Data Protection Law” means the GDPR, and shall include the data protection or privacy laws of the United Kingdom in place after its withdrawal from the EU.\u003c/p\u003e\u003cp\u003e“Order” means a separate order for Services pursuant to the Master Agreement: (a) completed and submitted by Customer online at the Datadog site and accepted by Datadog or (b) executed by Datadog and Customer.\u003c/p\u003e\u003cp\u003e“Participating Affiliate” means an Affiliate of Customer that: (a) has not entered into an Order or other separate agreement directly with Datadog and (b) Customer has authorized to access and use the Services under an existing Order between Datadog and Customer.\u003c/p\u003e\u003cp\u003e“Party” means each of Datadog and Customer.\u003c/p\u003e\u003cp\u003e“Services” means the hosted services to which Customer subscribes through, or otherwise uses following, an Order that are made available by Datadog online via the applicable login page (currently \u003ca href=\"https://app.datadoghq.com/\"\u003ehttps://app.datadoghq.com/\u003c/a\u003e) and other web pages designated by Datadog. Subject to the terms of an Order, the Services will support Customer’s collection, monitoring, management and analysis of Customer Data. For purposes of this DPA, the term Services does not include alpha, beta or other pre-commercial releases of a Datadog product or service (or feature of functionality of a Service).\u003c/p\u003e\u003cp\u003e“Standard Contractual Clauses” means the agreements executed by and between Datadog and Customer and attached to this DPA as Schedule A and Schedule B pursuant to the European Commission’s decision (EU) 2021/914 of 4 June 2021 on Standard Contractual Clauses for the transfer of personal data to processors established in third countries which do not ensure an adequate level of data protection.\u003c/p\u003e\u003cp\u003e“Subprocessor” means any Processor engaged by Datadog or a Datadog Affiliate to Process Customer Personal Data on Datadog’s or its Affiliate’s behalf in the course of providing the Services.\u003c/p\u003e\u003cp\u003e“Subprocessor List” means the list of Subprocessors available at \u003ca href=\"https://www.datadoghq.com/subprocessors/\"\u003ehttps://www.datadoghq.com/subprocessors/\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "This is a reference copy of the Datadog EEA Data Processing Addendum, which may be required for some Datadog customers. For a full copy of Datadog’s EEA Data Processing Addendum, including its attached schedules and the Standard Contractual Clauses effective 9/27/2021, please click here.How to Sign the DPA If you’re ready to sign the Datadog EEA DPA, please reach out to your Datadog CSM or sales representative. If you’re not sure who your CSM or sales representative is, please contact support@datadoghq.",
      "date_published": "2021-09-24T00:00:00Z",
      "author": {
        "name": "Datadog"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/incident-postmortem-process-best-practices/",
      "title": "Best practices for writing incident postmortems",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eAfter you have stopped an incident from affecting your customers, you need a more thorough investigation in order to prevent similar incidents in the future. Postmortems record the root causes of an incident and provide insights for making your systems more resilient. At the same time, postmortems can be difficult to produce, since they require deeper analysis and coordination between teammates who are busy with the next development cycle.\u003c/p\u003e\u003cp\u003eBut with the help of workflows that streamline your data collection, centralize your discussion, and generate interactive postmortem documents automatically, you can let your team spend less time on writing and more time on finding clues—and preventing future incidents.\u003c/p\u003e\u003cp\u003eIn this post, we will explore best practices for writing postmortems as part of your organization’s incident management process, including:\u003c/p\u003e\u003cul\u003e\u003cli\u003eGather data in \u003ca href=\"#centralize-data-as-you-go\"\u003ea shared view\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#generate-your-postmortem-automatically\"\u003eAutomate generation\u003c/a\u003e of postmortems from your shared view\u003c/li\u003e\u003cli\u003eUse your postmortem as a \u003ca href=\"#use-your-postmortem-as-a-thinking-tool\"\u003ethinking tool\u003c/a\u003e that helps you further your investigation\u003c/li\u003e\u003cli\u003eMake your postmortems \u003ca href=\"#make-it-easy-to-find-later\"\u003eeasy to find later\u003c/a\u003e by your team and others\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe will also show you how Datadog builds these best practices into its comprehensive platform to make writing postmortems as seamless as possible.\u003c/p\u003e\u003cp\u003eThroughout this post, we’ll use an example postmortem we wrote for a hypothetical incident where our \u003ccode\u003eweb-store\u003c/code\u003e service returned an elevated rate of 500 (Internal Server Error) response codes to users for a six-hour period.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"The postmortem document we will use as an example throughout this post.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"centralize-data-as-you-go\"\u003e\u003ca href=\"#centralize-data-as-you-go\"\u003eCentralize data as you go\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eTo make coordination easier while writing a postmortem, all team members should gather data in a commonly accessible location—such as a document or message feed—as they investigate. Ideally, this shared view should be the same location they use when responding to the incident. By doing so, team members can then refer to that shared view rather than managing multiple \u003ca href=\"https://www.solutionsiq.com/learning/blog-post/lines-of-communication/\"\u003elines of communication\u003c/a\u003e in order to stay up to date. It also becomes easier to \u003ca href=\"#generate-your-postmortem-automatically\"\u003econvert\u003c/a\u003e the shared view into a postmortem document later on since you don’t have to collect information from multiple sources.\u003c/p\u003e\u003cp\u003eInvestigators should be able to easily export graphs (and other visualizations) from their monitoring platform directly to the shared view with minimal clicks. It’s also useful to be able to export conversations from your organization’s core communication channels, such as Slack. This means that even if incident responders do coordinate outside the shared view, they can easily make their conversations available to other responders as well.\u003c/p\u003e\u003cp\u003eFinally, your shared view should include the ability for team members to leave comments. This way, the discussion about the incident can be visible alongside the data within the shared view. All incident responders can see everything the team has concluded so far about the incident as the discussion develops, making it easier to coordinate and come up with new analysis.\u003c/p\u003e\u003cp\u003eOnce you \u003ca href=\"https://docs.datadoghq.com/monitors/incident_management/#creating-an-incident\"\u003edeclare an incident\u003c/a\u003e in Datadog, for example, you can export any data you gather to the \u003ca href=\"https://docs.datadoghq.com/monitors/incident_management/#updating-the-incident-and-the-incident-timeline\"\u003eincident timeline\u003c/a\u003e. And as you gather more information—such as graphs of additional relevant metrics or \u003ca href=\"https://docs.datadoghq.com/integrations/slack/?tab=slackapplicationus\"\u003eSlack messages\u003c/a\u003e that provide context—you can easily add it, making the timeline a shared view that anyone responding to the incident can review for the full status of the investigation. In the incident shown below, all responders can see the timeseries graph added at 10:46 a.m. to illustrate the issue, as well as the note marking when the customer impact was updated.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Comments within a postmortem in Datadog.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eIf you want to assess the data you collect before you add it to an incident timeline (i.e., to ensure that teammates only see useful information) you can store it temporarily in the \u003ca href=\"https://www.datadoghq.com/blog/datadog-clipboard/\"\u003eDatadog Clipboard\u003c/a\u003e, then review the Clipboard later on to determine what to export. For example, let’s say we’ve noticed in the out-of-the-box \u003ca href=\"https://app.datadoghq.com/dash/integration/30322/kubernetes-pods-overview\"\u003eKubernetes Pods Overview\u003c/a\u003e dashboard that pods for the \u003ccode\u003ead-server\u003c/code\u003e and \u003ccode\u003eproduct-recommendation\u003c/code\u003e services, which \u003ccode\u003eweb-store\u003c/code\u003e depends on, displayed an elevated rate of \u003ccode\u003eCrashLoopBackOff\u003c/code\u003e statuses and OOM kills during the incident, particularly during the first two hours. We copied these graphs to the Clipboard so we can export the most revealing one to the incident timeline after a bit more investigation.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Exporting a graph to an incident timeline in Datadog from the Clipboard.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"generate-your-postmortem-automatically\"\u003e\u003ca href=\"#generate-your-postmortem-automatically\"\u003eGenerate your postmortem automatically\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eWhen it comes time to publish the information in your \u003ca href=\"#centralize-data-as-you-go\"\u003eshared view\u003c/a\u003e as a polished document, you should automate the process as much as possible so investigators can focus on analysis and insights. You can accomplish this by creating templates, checklists, or guidelines that make it easy to start a postmortem. Automating postmortem generation lets your team focus on analysis and understanding rather than copying and pasting incident data, and ensures that no key details are left out. It’s also important to be able to edit your generated postmortems when investigators encounter \u003ca href=\"#use-your-postmortem-as-a-thinking-tool\"\u003enew information\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eDatadog enables you to \u003ca href=\"https://www.datadoghq.com/blog/incident-response-with-datadog/#making-the-most-of-post-incident-reviews\"\u003eautomatically generate\u003c/a\u003e a nearly-complete postmortem from incident metadata with just a few clicks. Your organization can create custom templates that match your current postmortem structure, ensuring that any postmortem you generate contains the right data before you need to start investigating an incident. Templates automatically populate with events from the incident timeline, including live graphs and key details like the causes and customer impact.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Comments in the Datadog incident timeline that we will use to generate a postmortem automatically.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"use-your-postmortem-as-a-thinking-tool\"\u003e\u003ca href=\"#use-your-postmortem-as-a-thinking-tool\"\u003eUse your postmortem as a thinking tool\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAfter you \u003ca href=\"#generate-your-postmortem-automatically\"\u003egenerate\u003c/a\u003e your postmortem, the document should enable responders to get even more insight about the incident. In other words, postmortems need to be living documents that enable readers to have conversations, get additional context, and refine their root-cause analysis. You can achieve this by allowing team members to comment on the postmortem, making it easier to add data and analysis. You can also enable incident responders to access real-time data in the postmortem so they can reach even deeper insights.\u003c/p\u003e\u003cp\u003eFor example, Datadog’s collaborative Notebooks are fully editable and enable you to leave comments so your team can continue to assess the data and gather information even after you have generated your postmortem. In the example below, one investigator uses the earlier insights that \u003ccode\u003eproduct-recommendation\u003c/code\u003e and \u003ccode\u003ead-server\u003c/code\u003e pods were crashing during the incident to suggest a way to prevent similar incidents in the future.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog Notebooks enable you to comment directly in a postmortem document.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYour postmortem should also include (or at least link to) live graphs. Static graphs tie the parameters of a graph—the timeframe, metrics, filters, and aggregation groups—to a specific point in the investigation. With live graphs, on the other hand, responders can modify these parameters so they can draw more information out of a single graph, helping them challenge their assumptions, get more context, and investigate further.\u003c/p\u003e\u003cp\u003eIn Datadog, graphs within Notebooks (including postmortems) are live, meaning that you can expand them to view the \u003ca href=\"https://docs.datadoghq.com/dashboards/querying/#graphing-editor\"\u003egraphing editor\u003c/a\u003e and adjust the timeframe, tags, and other parameters within your metric query. This makes it easier to reveal new dimensions of the graph, such as a previously unforeseen outlier or a broader timeframe that casts new light on a trend.\u003c/p\u003e\u003cp\u003eFor example, by zooming out within one graph in our postmortem, we noticed that error rates had been elevated for at least a week prior to the incident’s recorded start time, even though we had not received support tickets from users. We can then add the zoomed-out graph to our postmortem so readers can have a full view of the data, revise our postmortem to be more accurate, and change the scope of our investigation.\u003c/p\u003e\u003ch2 id=\"make-it-easy-to-find-later\"\u003e\u003ca href=\"#make-it-easy-to-find-later\"\u003eMake it easy to find later\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIt’s important to ensure that the findings included in your postmortems are easy to locate to help team members who may be investigating future incidents or writing a runbook down the road. If readers are searching for postmortems related to a specific service, they should be able to discover yours even if they do not know the ID of the incident you responded to.\u003c/p\u003e\u003cp\u003eYou should include descriptive tags and titles with your incidents and postmortems to make searching easier. Organizing by incident ID or date isn’t enough, for example, if you’re interested in the possible failure modes of a single service. But if you tag your postmortems with their relevant service name as well, it becomes easier to find the ones you need. Datadog enables you to find incidents in the \u003ca href=\"https://app.datadoghq.com/incidents\"\u003eIncidents page\u003c/a\u003e by service, availability zone, and other Datadog tags. In this case, for example, we are searching for all incidents related to the \u003ccode\u003eweb-store\u003c/code\u003e service during the month prior to the one we’re investigating, so we can find a related investigation that we can use as a guide to which data we should explore first.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog enables you to find incidents by tag.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eIf your organization stores postmortems as static files, Datadog enables you to easily \u003ca href=\"https://docs.datadoghq.com/notebooks/#sharing-notebooks\"\u003eexport\u003c/a\u003e a postmortem as a PDF, Markdown document, or formatted text so you can store it with your organization’s preferred method (e.g., adding it to a directory). And if you need to edit a postmortem you have already exported, Datadog Notebooks \u003ca href=\"https://docs.datadoghq.com/notebooks/#graph-snapshots\"\u003eretain a snapshot\u003c/a\u003e of incident-related graphs so you can export your postmortem again even after the \u003ca href=\"https://docs.datadoghq.com/developers/faq/data-collection-resolution-retention/\"\u003edata retention period\u003c/a\u003e has passed.\u003c/p\u003e\u003ch2 id=\"faster-postmortems-with-datadog\"\u003e\u003ca href=\"#faster-postmortems-with-datadog\"\u003eFaster postmortems with Datadog\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn this post, we have seen how Datadog speeds up the process of writing postmortems so you can focus on building more resilient systems, rather than compiling data and coordinating with teammates.\u003c/p\u003e\u003cp\u003eAside from writing postmortems, Datadog \u003ca href=\"https://www.datadoghq.com/blog/incident-response-with-datadog/\"\u003eIncident Management\u003c/a\u003e gives you the visibility you need for every stage of the incident response process, from investigation to mitigation and prevention. \u003ca href=\"https://www.datadoghq.com/product/alerts/\"\u003eAlerts\u003c/a\u003e let you get notified about possible incidents through integrations with technologies like \u003ca href=\"https://docs.datadoghq.com/integrations/pagerduty/\"\u003ePagerDuty\u003c/a\u003e—then declare an incident with data from the alert. You can then speed up your troubleshooting with \u003ca href=\"https://www.datadoghq.com/blog/datadog-watchdog-insights-log-management/\"\u003eWatchdog Insights\u003c/a\u003e and \u003ca href=\"https://www.datadoghq.com/blog/datadog-watchdog-automated-root-cause-analysis/\"\u003eWatchdog RCA\u003c/a\u003e, and contribute to the investigation \u003ca href=\"https://www.datadoghq.com/blog/mobile-incident-management-datadog/\"\u003eon mobile\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIf you haven’t tried Datadog yet and want to start streamlining your postmortems today, you can get started with a \u003ca href=\"#\"\u003efree trial\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/hero.png\" width=\"100%\"/\u003eAfter you have stopped an incident from affecting your customers, you need a more thorough investigation in order to prevent similar incidents in the future. Postmortems record the root causes of an incident and provide insights for making your systems more resilient. At the same time, postmortems can be difficult to produce, since they require deeper analysis and coordination between teammates who are busy with the next development cycle.But with the help of workflows that streamline your data collection, centralize your discussion, and generate interactive postmortem documents automatically, you can let your team spend less time on writing and more time on finding clues—and preventing future incidents.",
      "date_published": "2021-09-17T00:00:00Z",
      "author": {
        "name": "Stephanie Niu"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/code-optimization-datadog-profile-comparison/",
      "title": "Compare and optimize your code with Datadog Profile Comparison",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eCode profilers offer detailed insight into the efficiency of application code by measuring things like the execution time and resource utilization of a service. Datadog’s always-on, low overhead \u003ca href=\"https://www.datadoghq.com/blog/datadog-continuous-profiler/\"\u003eContinuous Profiler\u003c/a\u003e provides snapshots of code performance for a service that are tagged with key metadata (e.g., \u003ccode\u003eregion\u003c/code\u003e, \u003ccode\u003eservice\u003c/code\u003e, \u003ccode\u003erelease\u003c/code\u003e), so you can easily identify and optimize inefficient code. This enables you to manage compute costs and resolve performance bottlenecks that affect your users\u0026#39; experience.\u003c/p\u003e\u003cp\u003eDatadog’s profiler allows you to capture code profiles continuously for all of your production instances. Now you can compare those profiles in the \u003ca href=\"https://docs.datadoghq.com/tracing/profiler/compare_profiles\"\u003eprofile comparison view\u003c/a\u003e to see how the performance and structure of your code change over time. This enables you to answer key questions about code-level performance such as: has a new release improved performance or caused a regression? Is your code more performant in one region, host, or pod versus another? Which functions are consuming the most CPU time for today versus last week?\u003c/p\u003e\u003cp\u003eThe profile comparison view also helps you quantify the changes you’ve made to fix a performance bottleneck, such as optimizing a CPU-intensive method, so you can easily calculate the estimated savings on your production infrastructure costs.\u003c/p\u003e\u003ch2 id=\"quickly-detect-code-performance-regressions-in-production-workloads\"\u003e\u003ca href=\"#quickly-detect-code-performance-regressions-in-production-workloads\"\u003eQuickly detect code performance regressions in production workloads\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAs your application grows in size and complexity, the probability of introducing regressions in code performance also increases. Continuous Profiler enables you to view your application’s code performance in production at a glance, whether it be through an instantaneous sixty-second profile or an aggregate view of a service’s performance bottlenecks within a specific timeframe. But there may still be critical performance blind spots that would otherwise go unnoticed without complete visibility into application code.\u003c/p\u003e\u003cp\u003eWith the profile comparison view, you can efficiently troubleshoot the root cause behind performance blind spots at a method level, including regressions such as:\u003c/p\u003e\u003cul\u003e\u003cli\u003ean increase in a service’s heap memory size over the past two days\u003c/li\u003e\u003cli\u003espikes in service latency since the last deployment\u003c/li\u003e\u003cli\u003eregressions in CPU consumption over the past seven days\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThe profile comparison view automatically highlights changes in production code performance based on a selected profile type (e.g., CPU time, allocations, thread locks, etc.) and a timeframe that you specify. Visibility into these areas of code performance can help you monitor the efficiency of production workloads and detect problematic areas before they become more serious.\u003c/p\u003e\u003cp\u003eFor example, you can compare a service’s live heap memory between two releases to spot potential memory leaks. The screenshot below shows a method that is contributing eight percent more to the heap live size in the newer deployed version (in purple) compared to the previous one (in blue). If the service live heap memory continues to increase over a sustained period of time then it could indicate that there is a memory leak within the service. Methods highlighted in bright red, such as the \u003ccode\u003edoNRequests\u003c/code\u003e method seen below, indicate areas where you can start your investigation.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Use profile comparison to compare heap memory for a service\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"identify-the-cause-of-increased-latency-in-service-endpoints\"\u003e\u003ca href=\"#identify-the-cause-of-increased-latency-in-service-endpoints\"\u003eIdentify the cause of increased latency in service endpoints\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eProfile comparison can also help you identify the root cause of increased latency for a service endpoint, which can affect your end users\u0026#39; experience and be costly if not resolved quickly. But this type of bottleneck is often difficult to detect—it could be the result of issues that resolve on their own (e.g., network latency, noisy neighbor processes) or legitimate performance regressions in your code. With the profile comparison view, you can easily confirm if the latency spike was caused by inefficient code.\u003c/p\u003e\u003cp\u003eFor example, you can compare the elapsed time a service with stable workloads spent executing a method (i.e., wall time) to the previous week’s performance. The screenshot belows shows that the wall time for several methods in a profiled Ruby service increased significantly over several days (highlighted in red).\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Use profile comparison to find the cause of endpoint latency\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYou can filter your view to show the appropriate service controller, enabling you to identify all of the downstream methods that created the spike in latency for the endpoint. Profile comparison identifies the exact methods that need further inspection, down to the line of code associated with the change in performance, so you can troubleshoot further and deploy a fix if needed.\u003c/p\u003e\u003ch2 id=\"compare-code-performance-between-releases\"\u003e\u003ca href=\"#compare-code-performance-between-releases\"\u003eCompare code performance between releases\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eProfile comparison is tightly integrated with \u003ca href=\"https://www.datadoghq.com/blog/datadog-deployment-tracking/\"\u003edeployment tracking\u003c/a\u003e, so you can track code performance for a particular service after a new release by pivoting from a high-level view of a deployment to a more granular view of application code.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Compare a profile from deployment tracking.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eThis enables you to compare code before and after you deploy changes to ensure they improve service performance. For example, the screenshot below compares the CPU time for a specific function (\u003ccode\u003ereadinto\u003c/code\u003e) over two successive releases.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Compare CPU time for a service with profile comparison\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eOn the right, which represents the newer release, you can see that the function consumed 15 percent less CPU time than in the older version, meaning that the deployed optimizations improved performance as expected.\u003c/p\u003e\u003ch2 id=\"better-visibility-into-code-performance\"\u003e\u003ca href=\"#better-visibility-into-code-performance\"\u003eBetter visibility into code performance\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog’s Continuous Profiler enables you to monitor code performance in your production environments in real time, so you can effectively diagnose performance issues, optimize costly lines of code, and deploy fixes to your customers faster. And with the ability to compare profile data side by side, you can better understand how changes to your application code improved or degraded performance over time. Check out our \u003ca href=\"https://docs.datadoghq.com/tracing/profiler/compare_profiles\"\u003edocumentation\u003c/a\u003e to learn more about Datadog’s Continuous Profiler and the profile comparison view. If you don’t already have a Datadog account, you can sign up for a \u003ca href=\"#\"\u003e14-day free trial\u003c/a\u003e today.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-hero.png\" width=\"100%\"/\u003eCode profilers offer detailed insight into the efficiency of application code by measuring things like the execution time and resource utilization of a service. Datadog\u0026rsquo;s always-on, low overhead Continuous Profiler provides snapshots of code performance for a service that are tagged with key metadata (e.g., region, service, release), so you can easily identify and optimize inefficient code. This enables you to manage compute costs and resolve performance bottlenecks that affect your users' experience.",
      "date_published": "2021-09-14T00:00:00Z",
      "author": {
        "name": "Gaurab Aryal"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/npm-best-practices/",
      "title": "Best practices for getting started with Datadog Network Performance Monitoring",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eWhether running on a fully cloud-hosted environment, on-premise servers, or a hybrid solution, modern services and applications are heavily reliant on network and DNS performance. This makes comprehensive visibility into your network a key part of monitoring application health and performance. But as your applications grow in scale and complexity, gaining this visibility is challenging.\u003c/p\u003e\u003cp\u003eTo help identify and troubleshoot problems before they affect your application and users, Datadog \u003ca href=\"https://docs.datadoghq.com/network_monitoring/performance/\"\u003eNetwork Performance Monitoring (NPM)\u003c/a\u003e enables you to visualize and break down data flow across your network. By giving you visibility into network traffic flows, NPM enables you to quickly spot issues that manifest as traffic spikes, drops, or latency between different endpoints in your environment.\u003c/p\u003e\u003cp\u003eOnce you’ve \u003ca href=\"https://docs.datadoghq.com/network_monitoring/performance/setup\"\u003eset up NPM\u003c/a\u003e, Datadog automatically collects key transport-layer (TCP/UDP) and DNS data related to traffic between each endpoint in your environment, including VMs, containers, services, cloud regions or datacenters, and much more.\u003c/p\u003e\u003cp\u003eIn this post, we’ll show you how you can use Datadog to monitor the health and performance of your network dependencies. In particular, we’ll cover how to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eUse our out-of-the-box NPM dashboard to \u003ca href=\"#view-key-network-metrics-with-the-network-overview-dashboard\"\u003eview key network metrics\u003c/a\u003e for insight into the health and performance of your network\u003c/li\u003e\u003cli\u003eQuickly monitor critical dependencies with \u003ca href=\"#quickly-monitor-critical-dependencies-with-saved-views\"\u003eSaved Views\u003c/a\u003e\u003c/li\u003e\u003cli\u003ePinpoint root causes with \u003ca href=\"#correlate-network-data-with-telemetry-from-each-layer-of-your-stack\"\u003ecorrelated\u003c/a\u003e network, application, and infrastructure telemetry data with telemetry from other layers of your stack\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"view-key-network-metrics-with-the-network-overview-dashboard\"\u003e\u003ca href=\"#view-key-network-metrics-with-the-network-overview-dashboard\"\u003eView key network metrics with the Network Overview dashboard\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAs you scale your applications and services, they need to reliably communicate over larger and more complex networks. Without visibility into each aspect of network communication, it can be difficult to determine which is the source of an issue and needs troubleshooting. For instance, monitoring network throughput can help determine whether excessive traffic is overloading your systems and the culprit behind a problem. Similarly, tracking TCP connection metrics and DNS server errors over time helps assess network health since either can negatively impact network communication.\u003c/p\u003e\u003cp\u003eDatadog automatically collects key network traffic and DNS server metrics and populates an out-of-the-box Network Overview dashboard that provides a unified, high-level view of key network health and performance across different facets of your distributed network. This helps you get up and running on NPM quickly to immediately locate problems and drill down to investigate. You can read more about the Network Overview dashboard in \u003ca href=\"https://app.datadoghq.com/notebook/415397/understanding-graphing-network-metrics\"\u003ethis notebook\u003c/a\u003e.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"NPM-dashboard.png\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eUse the Network Overview dashboard to get a high-level view of key network health and performance across your distributed network.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eThe Network Overview dashboard organizes network metrics into the following essential categories to make it easier to troubleshoot problems within different layers of network performance and correlate that data with other telemetry from your environment:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"#network-load-metrics\"\u003e\u003cstrong\u003eNetwork load\u003c/strong\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#tcp-metrics\"\u003e\u003cstrong\u003eTCP traffic performance\u003c/strong\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#dns-metrics\"\u003e\u003cstrong\u003eDNS health\u003c/strong\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#application-overview-metrics\"\u003e\u003cstrong\u003eApplication overview\u003c/strong\u003e\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#cross-regional-traffic-metrics\"\u003e\u003cstrong\u003eCross-regional traffic overview\u003c/strong\u003e\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"network-load-metrics\"\u003e\u003ca href=\"#network-load-metrics\"\u003eNetwork load metrics\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eThe \u003cstrong\u003eNetwork Load\u003c/strong\u003e section visualizes the volume of bytes sent and received between tagged network endpoints (e.g., services and availability zones). Data sent and received are fundamental network metrics because they provide you with an overall view of network traffic and can clue you into sudden data flow stoppages or spikes and which parts of your infrastructure are being affected. If an endpoint is hit with far more traffic than usual, its underlying hosts or containers can become overloaded and start overconsuming resources, leading to higher latencies or outages. Alternatively, if you spot services or infrastructure components that are not sending or receiving any data, you know where to focus your troubleshooting efforts.\u003c/p\u003e\u003ch3 id=\"tcp-metrics\"\u003e\u003ca href=\"#tcp-metrics\"\u003eTCP metrics\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eMost network communication is facilitated by the Transmission Control Protocol (TCP). In order for a client and server to send data packets to each other successfully, they first need to establish a TCP connection. Problems establishing and maintaining these connections can mean that services are unable to communicate with each other. Visibility into TCP metrics can help you identify and mitigate connectivity issues.\u003c/p\u003e\u003cp\u003eThe \u003cstrong\u003eTCP\u003c/strong\u003e section of the Network Overview dashboard visualizes key TCP metrics like the number of established and closed connections, as well as retransmits, so you can pinpoint sources of latency and outages. For example, if you spot a sudden spike in TCP retransmits from a particular service to a destination endpoint alongside a drop in established connections, it could be a sign of a networking issue that needs further investigation\u0026amp;endash;such as traffic congestion, a network misconfiguration, or faulty hardware.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Spikes in TCP retransmits may be a sign of traffic congestion or a network misconfiguration.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch3 id=\"dns-metrics\"\u003e\u003ca href=\"#dns-metrics\"\u003eDNS metrics\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eThe Domain Name System (DNS) is responsible for mapping domain names to their corresponding IP addresses. DNS issues can lead to services and devices being unable to find or connect to endpoints they rely on, which can prevent users from accessing your web applications. DNS communication consists of a client requesting the IP address of a domain name from one or more DNS servers. Since an issue can occur at either end, monitoring key DNS metrics can help you distinguish between client-side issues, like misconfigured requests, and server-side issues, like resource saturation (i.e., overwhelmed by client requests) affecting your DNS servers.\u003c/p\u003e\u003cp\u003eYou can use tags to slice and dice the Network Overview dashboard to quickly look for client- or server-side DNS issues. For example, group DNS metrics by either \u003ccode\u003eapp\u003c/code\u003e or \u003ccode\u003eservice\u003c/code\u003e tags to view the DNS performance of your client applications and services. Then, to look for server-side issues, we recommend grouping by either \u003ccode\u003edns_server\u003c/code\u003e or \u003ccode\u003ecluster\u003c/code\u003e. By visualizing metrics like DNS requests, failures, and timeouts across regions, you can quickly spot issues that you need to dive into.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-6\"\u003eDNS response codes\u003c/a\u003e are another reliable bellwether for DNS health and performance. Two common response errors to look for are \u003ccode\u003eSERVFAIL\u003c/code\u003e errors, which point to server issues, and \u003ccode\u003eNXDOMAIN\u003c/code\u003e errors, which mean clients are making requests to nonexistent domains (likely because of a misconfiguration). The Network Overview dashboard visualizes what percentage these errors make up of all responses, making it easy to identify spikes or worrisome trends that require investigation.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Pay attention to DNS error types to help pinpoint root causes.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch3 id=\"application-overview-metrics\"\u003e\u003ca href=\"#application-overview-metrics\"\u003eApplication overview metrics\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eSince modern applications are highly distributed and vulnerable to networking issues, being able to correlate network and application-level monitoring data is critical for identifying the root cause of issues. For example, customizing the Network Overview dashboard’s \u003cstrong\u003eApplication Overview\u003c/strong\u003e section to visualize network throughput next to application performance data such as service latency that’s available through \u003ca href=\"https://docs.datadoghq.com/tracing/visualization/service/\"\u003eDatadog APM\u003c/a\u003e can help you spot signs that a network issue (e.g., an unexpected drop in bytes sent from a particular service) has negatively impacted application performance (e.g., a spike in latency). You can also correlate network metrics with third-party endpoint health metrics, such as Elastic Load Balancer (ELB) 5xx errors to determine if there is a service-level issue.\u003c/p\u003e\u003ch3 id=\"cross-regional-traffic-metrics\"\u003e\u003ca href=\"#cross-regional-traffic-metrics\"\u003eCross-regional traffic metrics\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eIn order for your cloud-hosted services to be highly available and perform well, it’s often necessary to utilize multiple availability zones and regions. However, when data flows across regions and availability zones, it can drive up costs and create more network vulnerabilities. While some traffic between regions or availability zones might be expected, you should look out for unexpected spikes in interregional traffic. The Network Overview map’s \u003cstrong\u003eCloud Region Overview\u003c/strong\u003e section enables you to view key metrics covered earlier in this post in the context of cross-regional and cross-AZ communication. For instance, you can view the volume of network traffic between availability zones to reveal where you can reconfigure your network to reduce costs. This section also includes a “Top cross-AZ talkers” widget, which identifies source endpoints that send most traffic across availability zones. This means you can quickly spot the source of the spike network communication inefficiencies and begin mitigating the issue.\u003c/p\u003e\u003ch2 id=\"quickly-monitor-critical-dependencies-with-saved-views\"\u003e\u003ca href=\"#quickly-monitor-critical-dependencies-with-saved-views\"\u003eQuickly monitor critical dependencies with Saved Views\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog’s \u003ca href=\"https://app.datadoghq.com/network\"\u003eNetwork page\u003c/a\u003e enables you to use \u003ca href=\"https://docs.datadoghq.com/network_monitoring/performance/network_page/#queries\"\u003equeries\u003c/a\u003e to scope your view to the performance of communication between specific services, pods, cloud resources, and more. When monitoring distributed architectures, you often need to switch your focus between different aspects of network communication to effectively identify issues. For instance, you may be regularly moving back and forth between viewing network traffic between services to network traffic between their underlying pods. Because these are common views to reference when monitoring network performance, writing queries each time means you may lose valuable time needed to troubleshoot. You can use preset \u003ca href=\"https://www.datadoghq.com/blog/template-variable-saved-views/\"\u003eSaved Views\u003c/a\u003e to quickly access useful default and custom queries in the Network view, which enables you to immediately view monitoring data in the scope of your troubleshooting context. For example, the “traffic to external domains” Saved View groups traffic by the \u003ccode\u003eservice\u003c/code\u003e and \u003ccode\u003edomain\u003c/code\u003e tags so you can see network performance metrics related to traffic between a service and an external domain endpoint.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog NPM includes saved views for traffic to external domains.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eDatadog also provides a built-in “cross-availability zone traffic” Saved View, which groups data by the \u003ccode\u003eavailability-zone\u003c/code\u003e tag so you can view traffic that occurs across availability zones which, as we mentioned, can drive up costs and may increase network latency.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog NPM includes saved views for cross-availability zone traffic.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eSaved Views provide you with quick access to relevant network flow data so you can access the information you need and troubleshoot faster.\u003c/p\u003e\u003ch2 id=\"correlate-network-data-with-telemetry-from-each-layer-of-your-stack\"\u003e\u003ca href=\"#correlate-network-data-with-telemetry-from-each-layer-of-your-stack\"\u003eCorrelate network data with telemetry from each layer of your stack\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eBecause applications rely heavily on each other, poor connectivity or slow calls may manifest as errors and latency at the application layer. For example, service latency can be the result of a code-level bug, or it could be an issue with an upstream or downstream service. If, however, you only have visibility into either your network layer or your application layer, it can be challenging to determine which is behind an issue and what team to alert so they can start troubleshooting.\u003c/p\u003e\u003cp\u003eDatadog NPM automatically ties together monitoring data from each layer of your stack so you can correlate them easily. For example, if you see that an availability zone has unexpectedly high TCP retransmits in the Network view, without leaving that view you can open a side panel to explore all correlated logs, traces, and \u003ca href=\"https://docs.datadoghq.com/integrations/process/\"\u003eprocesses\u003c/a\u003e for additional context that helps identify the problem. In the screenshot below, we can see that an \u003ca href=\"https://docs.datadoghq.com/integrations/nginx/?tab=host\"\u003eNGINX\u003c/a\u003e process has saturated the CPU of a host in that availability zone and may be behind the spike in TCP retransmits.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog automatically correlates network data with telemetry from other layers of your service.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eNetwork data is just one piece of the puzzle. By automatically correlating network data with telemetry from the rest of your stack, you can gain a deeper understanding of the health of your environment, enabling you to effectively pinpoint the origins of an issue.\u003c/p\u003e\u003ch2 id=\"get-started-with-network-performance-monitoring-today\"\u003e\u003ca href=\"#get-started-with-network-performance-monitoring-today\"\u003eGet started with Network Performance Monitoring today\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog Network Performance Monitoring helps make troubleshooting problems with your network easier by visualizing key performance metrics, and providing preset Saved Views that let you quickly scope to relevant troubleshooting data. Additionally, Datadog NPM automatically ties network traffic to other key metrics, traces, logs, and processes to help uncover root causes. Datadog NPM uses an \u003ca href=\"http://www.brendangregg.com/blog/2019-01-01/learn-ebpf-tracing.html\"\u003eeBPF-powered\u003c/a\u003e system probe for Linux and a \u003ca href=\"https://www.datadoghq.com/blog/npm-windows-support/\"\u003ecustom driver\u003c/a\u003e for Windows hosts so you can get network-level visibility with minimal overhead regardless of your operating system.\u003c/p\u003e\u003cp\u003eIf you’re already a Datadog customer, you can get started with the out-of-the-box \u003ca href=\"https://app.datadoghq.com/dashboard/pbu-5b3-hrz/network-overview\"\u003enetwork performance dashboard\u003c/a\u003e. Otherwise, sign up for a 14-day \u003ca href=\"#\"\u003efree trial\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-best-practices-hero.png\" width=\"100%\"/\u003eWhether running on a fully cloud-hosted environment, on-premise servers, or a hybrid solution, modern services and applications are heavily reliant on network and DNS performance. This makes comprehensive visibility into your network a key part of monitoring application health and performance. But as your applications grow in scale and complexity, gaining this visibility is challenging.To help identify and troubleshoot problems before they affect your application and users, Datadog Network Performance Monitoring (NPM) enables you to visualize and break down data flow across your network.",
      "date_published": "2021-09-09T00:00:00Z",
      "author": {
        "name": "Jordan Obey"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/amazon-eks-anywhere/",
      "title": "Announcing support for EKS Anywhere",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003ca href=\"https://www.datadoghq.com/blog/eks-cluster-metrics/\"\u003eAmazon Elastic Kubernetes Service\u003c/a\u003e (EKS) is a cloud-based compute platform that includes a \u003ca href=\"https://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html\"\u003efully managed\u003c/a\u003e Kubernetes control plane in order to simplify cluster operations. AWS introduced \u003ca href=\"https://aws.amazon.com/blogs/aws/amazon-eks-anywhere-now-generally-available-to-create-and-manage-kubernetes-clusters-on-premises/\"\u003eEKS Anywhere\u003c/a\u003e to bring the operational ease of EKS to organizations that manage on-premise environments (e.g., to meet \u003ca href=\"https://www.oracle.com/security/saas-security/data-sovereignty\"\u003edata sovereignty\u003c/a\u003e requirements). EKS Anywhere is released as an automation tool that launches an \u003ca href=\"https://aws.amazon.com/eks/eks-distro/\"\u003eEKS Distro\u003c/a\u003e cluster with opinionated defaults on vSphere virtual machines, making it easier to get started with container orchestration.\u003c/p\u003e\u003cp\u003eWith EKS Anywhere, teams can now use consistent tooling to operate and manage both cloud-based and on-premise EKS clusters. This makes EKS Anywhere a good fit for organizations that plan to migrate their on-premise Kubernetes deployments to the cloud, as well as organizations that usually run workloads on premises but want to deploy to AWS in order to handle bursts in traffic.\u003c/p\u003e\u003cp\u003eWe are proud to announce that Datadog is a \u003ca href=\"https://aws.amazon.com/eks/eks-anywhere/partners/\"\u003elaunch partner\u003c/a\u003e for EKS Anywhere. Datadog enables you to get full visibility into the health and performance of EKS Anywhere and cloud-based EKS workloads—and their underlying infrastructure, whether it’s running on premises or in the cloud.\u003c/p\u003e\u003ch2 id=\"full-visibility-into-ekswherever-it-runs\"\u003e\u003ca href=\"#full-visibility-into-ekswherever-it-runs\"\u003eFull visibility into EKS—wherever it runs\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eWhether you deploy your EKS clusters on your own data centers, to the cloud, or both, you need to monitor the resource usage and availability of both environments in order to keep your applications running as expected. With Datadog’s \u003ca href=\"https://docs.datadoghq.com/infrastructure/livecontainers/?tab=helm#kubernetes-resources-view\"\u003eKubernetes resources view\u003c/a\u003e (part of \u003ca href=\"https://www.datadoghq.com/blog/explore-kubernetes-resources-with-datadog/\"\u003eLive Containers\u003c/a\u003e), you can get real-time insights into the resource capacity and usage of your EKS and EKS Anywhere clusters, all in one platform.\u003c/p\u003e\u003cp\u003eIn the example below, we are viewing pods from two EKS clusters: one hosted on premises (\u003ccode\u003eprod-11287-demo-cluster-west\u003c/code\u003e) and the other in the AWS cloud. While this view shows us that CPU and memory utilization for pods in each cluster are similar, if we run into capacity issues in our on-premise data centers, we can scale out our cloud-based EKS cluster until the issue subsides.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"The Clusters view showing EKS clusters hosted in the cloud and on premises.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"get-context-from-your-on-premise-infrastructure\"\u003e\u003ca href=\"#get-context-from-your-on-premise-infrastructure\"\u003eGet context from your on-premise infrastructure\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eWhile EKS Anywhere makes it easier to manage your on-premise Kubernetes deployments, you will still need to monitor your underlying infrastructure to prevent issues with scheduling your application pods. Datadog enables you to explore bespoke views of your EKS Anywhere deployments—and get full context around the vSphere VMs that host them—so you can investigate unavailable nodes, resource saturation, and other conditions that can stop EKS Anywhere from working as expected.\u003c/p\u003e\u003cp\u003eWith Datadog, you can create \u003ca href=\"https://docs.datadoghq.com/dashboards/\"\u003ecustom dashboards\u003c/a\u003e to monitor Kubernetes metrics, such as the \u003ca href=\"https://www.datadoghq.com/blog/eks-cluster-metrics/#metrics-to-alert-on-desired-vs-current-pods\"\u003ecounts\u003c/a\u003e of available and desired pods, as well as \u003ca href=\"https://www.datadoghq.com/blog/vsphere-metrics/\"\u003evSphere metrics\u003c/a\u003e. For example, you can create a dashboard (as shown below) that graphs the number of vSphere VMs by regional data center, then graph the number of available Kubernetes nodes by region. If there are more VMs than Kubernetes nodes, you can investigate whether some \u003ca href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/\"\u003ekubelets\u003c/a\u003e running on your vSphere VMs have crashed—or failed to deploy due to a misconfiguration—causing the API server to register fewer nodes than expected.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"A dashboard that includes vSphere and Kubernetes metrics together, plus a host map and container map.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"eks-is-anywhereand-so-is-datadog\"\u003e\u003ca href=\"#eks-is-anywhereand-so-is-datadog\"\u003eEKS is anywhere—and so is Datadog\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog is well suited for monitoring EKS Anywhere as well as your cloud-based EKS deployments, giving you full visibility into your containerized workloads no matter where they run. You can quickly install Datadog in your EKS Anywhere and EKS clusters using our \u003ca href=\"https://docs.datadoghq.com/agent/kubernetes/?tab=helm\"\u003eHelm chart\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eDatadog integrates with \u003ca href=\"https://docs.datadoghq.com/integrations/vsphere/\"\u003evSphere\u003c/a\u003e—and other infrastructure technologies you might be deploying on Kubernetes, such as \u003ca href=\"https://www.datadoghq.com/blog/monitor-cilium-with-datadog/\"\u003eCilium\u003c/a\u003e and \u003ca href=\"https://www.datadoghq.com/blog/monitor-coredns-with-datadog/\"\u003eCoreDNS\u003c/a\u003e—so you can visualize every layer of your EKS Anywhere environment. And with other features like \u003ca href=\"https://docs.datadoghq.com/network_monitoring/devices/\"\u003eNetwork Device Monitoring\u003c/a\u003e, you can get even deeper insight into the health of your \u003ca href=\"https://www.datadoghq.com/solutions/on-premises-monitoring/\"\u003eon-premise infrastructure\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIf you have not yet signed up for Datadog, you can started today with a \u003ca href=\"#\"\u003efree trial\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/hero.png\" width=\"100%\"/\u003eAmazon Elastic Kubernetes Service (EKS) is a cloud-based compute platform that includes a fully managed Kubernetes control plane in order to simplify cluster operations. AWS introduced EKS Anywhere to bring the operational ease of EKS to organizations that manage on-premise environments (e.g., to meet data sovereignty requirements). EKS Anywhere is released as an automation tool that launches an EKS Distro cluster with opinionated defaults on vSphere virtual machines, making it easier to get started with container orchestration.",
      "date_published": "2021-09-08T00:00:00Z",
      "author": {
        "name": "Paul Gottschling"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/monitor-netlify-with-datadog/",
      "title": "Monitor your Netlify sites with Datadog",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003ca href=\"https://www.netlify.com/\"\u003eNetlify\u003c/a\u003e is a \u003ca href=\"https://jamstack.org/what-is-jamstack/\"\u003eJamstack\u003c/a\u003e web development platform that lets customers build and deploy dynamic, highly performant web apps. By uniting popular JavaScript frameworks, developer tools, and APIs into streamlined workflows, Netlify helps teams rapidly spin up and ship common Jamstack use cases, including e-commerce stores, SaaS applications, and corporate sites. Netlify supports these deployments with an integrated CI/CD tool, global multi-cloud edge network, and serverless backend.\u003c/p\u003e\u003cp\u003eYou can now use Datadog to capture your \u003ca href=\"https://www.netlify.com/blog/2021/09/08/announcing-netlify-log-drains-for-datadog/\"\u003eNetlify web traffic and serverless function logs\u003c/a\u003e for long-term retention and analysis. In this post, we’ll look at how ingesting your Netlify logs into Datadog helps you monitor and visualize key web traffic and function performance data. We’ll also cover how Datadog \u003ca href=\"https://www.datadoghq.com/product/synthetic-monitoring/\"\u003eSynthetic Monitoring\u003c/a\u003e can give you comprehensive visibility into the health and performance of your Netlify sites.\u003c/p\u003e\u003ch2 id=\"send-your-netlify-logs-to-datadog\"\u003e\u003ca href=\"#send-your-netlify-logs-to-datadog\"\u003eSend your Netlify logs to Datadog\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eTo send your logs to Datadog, you can use Netlify’s \u003ca href=\"https://docs.netlify.com/monitor-sites/log-drains/\"\u003eLog Drains\u003c/a\u003e feature, which allows Netlify users to forward logs to third-party monitoring services. Forwarding your Netlify logs to Datadog enables you to retain them beyond the 24-hour window of the Netlify console. Once you set up the integration, your logs will begin streaming into Datadog. Datadog’s built-in \u003ca href=\"https://docs.datadoghq.com/logs/log_configuration/pipelines/\"\u003elog processing pipeline\u003c/a\u003e automatically parses out key attributes from your logs, which you can then use to search, filter, analyze, and generate metrics. Datadog uses your parsed log data to populate an out-of-the-box Netlify dashboard that visualizes key telemetry from your environment, giving you a high-level overview of your Netlify apps.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Default Netlify dashboard\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eNext, we’ll discuss how you can use your Netlify logs to get insights into:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"#capture-and-analyze-serverless-function-logs\"\u003eyour backend functions and business logic\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#use-traffic-logs-to-understand-user-behavior\"\u003etraffic and usage\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"capture-and-analyze-serverless-function-logs\"\u003e\u003ca href=\"#capture-and-analyze-serverless-function-logs\"\u003eCapture and analyze serverless function logs\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eNetlify Functions can be written in JavaScript, TypeScript, or Go and let you add dynamic backend processes to your websites without managing additional infrastructure. Netlify function logs contain key fields including \u003ccode\u003efunction_name\u003c/code\u003e, \u003ccode\u003etimestamp\u003c/code\u003e, and \u003ccode\u003estatus\u003c/code\u003e. Once your logs are streaming into Datadog, you can utilize these attributes in the \u003ca href=\"https://app.datadoghq.com/logs\"\u003eLog Explorer\u003c/a\u003e to filter and sort your logs to surface error-prone or slow functions.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Viewing Netlify function logs in the Log Explorer\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYou can generate metrics from your logs to visualize and alert on things like 4xx/5xx error rates, latency, and request volume. For example, if you’re monitoring an ecommerce payment function, you might want to set an alert on its error rate. This way, you can be notified of issues before they might lead to lost revenue and potential customer churn.\u003c/p\u003e\u003cp\u003eYou can also use your serverless logs to collect key business insights by adding custom information to the \u003ccode\u003elog_message\u003c/code\u003e field at runtime. For example, if you’re monitoring an ecommerce payment function, you can log the dollar value of the transaction, the customer ID, and any relevant product IDs. You can then visualize that information in Datadog to build context for your business analytics.\u003c/p\u003e\u003ch3 id=\"use-traffic-logs-to-understand-user-behavior\"\u003e\u003ca href=\"#use-traffic-logs-to-understand-user-behavior\"\u003eUse traffic logs to understand user behavior\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eYour Netlify application’s web traffic logs are emitted directly from its CDN’s \u003ca href=\"https://www.netlify.com/products/edge/\"\u003eEdge Network\u003c/a\u003e. Traffic logs can provide visibility into your site’s overall performance. Using key attributes like \u003ccode\u003eduration\u003c/code\u003e and \u003ccode\u003estatus_code\u003c/code\u003e, you can generate the standard RED (requests, errors, and duration) metrics for your site and break down errors by status code. Creating alerts for these metrics and visualizing them in your dashboards helps you validate the health and performance of your site in real time and stay ahead of user-facing problems.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Viewing a Netlify function log event\u0026#39;s metadata\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eNetlify traffic logs can also help you analyze your users’ traffic patterns to identify trends and spot anomalous behavior—such as a DDoS attack. For example, you could use the \u003ccode\u003estatus_code\u003c/code\u003e attribute to create a log-based metric counting 504 errors, and then alert on a critical threshold. If the alert triggers you can use the Log Explorer to investigate the relevant logs to determine if they appear to be from a fraudulent source by filtering the logs by the relevant URL path then drilling into log events in the resulting list to see, for example, if a majority of requests are coming from a small group of IPs in a strange location.\u003c/p\u003e\u003ch2 id=\"monitor-your-frontend-performance-with-datadog-synthetic-monitoring\"\u003e\u003ca href=\"#monitor-your-frontend-performance-with-datadog-synthetic-monitoring\"\u003eMonitor your frontend performance with Datadog Synthetic Monitoring\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn addition to logs, \u003ca href=\"https://www.datadoghq.com/digital-experience-monitoring/\"\u003edigital experience monitoring\u003c/a\u003e can provide a deeper view into how your webpages respond to traffic and whether they are working correctly for users. With Datadog Synthetic Monitoring, you can create multistep browser tests that enable you to view the response times of individual content fetches during a page load, alongside the performance of dynamic DOM content. By setting up browser tests for your Netlify application, you can measure the performance of key user flows and quickly spot errors and speed bottlenecks. Each step includes a detailed waterfall timeline of all the static content fetches, client-side JavaScript, and API calls required in a page load, alongside \u003ca href=\"https://www.datadoghq.com/blog/core-web-vitals-monitoring-datadog-rum-synthetics/\"\u003eCore Web Vitals\u003c/a\u003e—such as Largest Contentful Paint and Cumulative Layout Shift—that help you characterize the user experience.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Synthetic browser test\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eBy adding HTTP request steps to your browser tests, you include calls to your Netlify Serverless Functions in your user flows to create a holistic picture of your site’s performance from both frontend and backend data. For example, you could create a checkout flow that includes a call to your payment function via the relevant API endpoint. You can see detailed information about the request, including the overall duration, status code, and request size, along with a waterfall showing a breakdown of the DNS request, SSL handshake, time to first byte, and download, to understand how these processes contribute to the overall latency.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Default Netlify dashboard\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"get-started-with-datadog-and-netlify\"\u003e\u003ca href=\"#get-started-with-datadog-and-netlify\"\u003eGet started with Datadog and Netlify\u003c/a\u003e\u003c/h2\u003e\u003cp\u003e​​With Datadog and Netlify Log Drains, you can easily ingest Netlify logs for full visibility into your serverless functions and site traffic. And, by using Datadog Synthetic Monitoring to track frontend performance, you get a comprehensive solution for monitoring your Netlify-powered applications. Log Drains is available now with Netlify’s \u003ca href=\"https://www.netlify.com/pricing/\"\u003eEnterprise plan\u003c/a\u003e. For more information about the integration, see the \u003ca href=\"https://docs.netlify.com/monitor-sites/log-drains/\"\u003eNetlify Log Drains documentation\u003c/a\u003e and our own \u003ca href=\"https://docs.datadoghq.com/integrations/netlify\"\u003eintegration docs\u003c/a\u003e. Or if you’re brand new to Datadog, sign up for a \u003ca href=\"#\"\u003efree trial\u003c/a\u003e to get started.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-hero.png\" width=\"100%\"/\u003eNetlify is a Jamstack web development platform that lets customers build and deploy dynamic, highly performant web apps. By uniting popular JavaScript frameworks, developer tools, and APIs into streamlined workflows, Netlify helps teams rapidly spin up and ship common Jamstack use cases, including e-commerce stores, SaaS applications, and corporate sites. Netlify supports these deployments with an integrated CI/CD tool, global multi-cloud edge network, and serverless backend.You can now use Datadog to capture your Netlify web traffic and serverless function logs for long-term retention and analysis.",
      "date_published": "2021-09-08T00:00:00Z",
      "author": {
        "name": "Thomas Sobolik"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/amazon-eks-anywhere/",
      "title": "Announcing support for EKS Anywhere",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003ca href=\"https://www.datadoghq.com/blog/eks-cluster-metrics/\"\u003eAmazon Elastic Kubernetes Service\u003c/a\u003e (EKS) is a cloud-based compute platform that includes a \u003ca href=\"https://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html\"\u003efully managed\u003c/a\u003e Kubernetes control plane in order to simplify cluster operations. AWS introduced \u003ca href=\"https://aws.amazon.com/blogs/aws/amazon-eks-anywhere-now-generally-available-to-create-and-manage-kubernetes-clusters-on-premises/\"\u003eEKS Anywhere\u003c/a\u003e to bring the operational ease of EKS to organizations that manage on-premise environments (e.g., to meet \u003ca href=\"https://www.oracle.com/security/saas-security/data-sovereignty\"\u003edata sovereignty\u003c/a\u003e requirements). EKS Anywhere is released as an automation tool that launches an \u003ca href=\"https://aws.amazon.com/eks/eks-distro/\"\u003eEKS Distro\u003c/a\u003e cluster with opinionated defaults on vSphere virtual machines, making it easier to get started with container orchestration.\u003c/p\u003e\u003cp\u003eWith EKS Anywhere, teams can now use consistent tooling to operate and manage both cloud-based and on-premise EKS clusters. This makes EKS Anywhere a good fit for organizations that plan to migrate their on-premise Kubernetes deployments to the cloud, as well as organizations that usually run workloads on premises but want to deploy to AWS in order to handle bursts in traffic.\u003c/p\u003e\u003cp\u003eWe are proud to announce that Datadog is a \u003ca href=\"https://aws.amazon.com/eks/eks-anywhere/partners/\"\u003elaunch partner\u003c/a\u003e for EKS Anywhere. Datadog enables you to get full visibility into the health and performance of EKS Anywhere and cloud-based EKS workloads—and their underlying infrastructure, whether it’s running on premises or in the cloud.\u003c/p\u003e\u003ch2 id=\"full-visibility-into-ekswherever-it-runs\"\u003e\u003ca href=\"#full-visibility-into-ekswherever-it-runs\"\u003eFull visibility into EKS—wherever it runs\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eWhether you deploy your EKS clusters on your own data centers, to the cloud, or both, you need to monitor the resource usage and availability of both environments in order to keep your applications running as expected. With Datadog’s \u003ca href=\"https://docs.datadoghq.com/infrastructure/livecontainers/?tab=helm#kubernetes-resources-view\"\u003eKubernetes resources view\u003c/a\u003e (part of \u003ca href=\"https://www.datadoghq.com/blog/explore-kubernetes-resources-with-datadog/\"\u003eLive Containers\u003c/a\u003e), you can get real-time insights into the resource capacity and usage of your EKS and EKS Anywhere clusters, all in one platform.\u003c/p\u003e\u003cp\u003eIn the example below, we are viewing pods from two EKS clusters: one hosted on premises (\u003ccode\u003eprod-11287-demo-cluster-west\u003c/code\u003e) and the other in the AWS cloud. While this view shows us that CPU and memory utilization for pods in each cluster are similar, if we run into capacity issues in our on-premise data centers, we can scale out our cloud-based EKS cluster until the issue subsides.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"The Clusters view showing EKS clusters hosted in the cloud and on premises.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"get-context-from-your-on-premise-infrastructure\"\u003e\u003ca href=\"#get-context-from-your-on-premise-infrastructure\"\u003eGet context from your on-premise infrastructure\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eWhile EKS Anywhere makes it easier to manage your on-premise Kubernetes deployments, you will still need to monitor your underlying infrastructure to prevent issues with scheduling your application pods. Datadog enables you to explore bespoke views of your EKS Anywhere deployments—and get full context around the vSphere VMs that host them—so you can investigate unavailable nodes, resource saturation, and other conditions that can stop EKS Anywhere from working as expected.\u003c/p\u003e\u003cp\u003eWith Datadog, you can create \u003ca href=\"https://docs.datadoghq.com/dashboards/\"\u003ecustom dashboards\u003c/a\u003e to monitor Kubernetes metrics, such as the \u003ca href=\"https://www.datadoghq.com/blog/eks-cluster-metrics/#metrics-to-alert-on-desired-vs-current-pods\"\u003ecounts\u003c/a\u003e of available and desired pods, as well as \u003ca href=\"https://www.datadoghq.com/blog/vsphere-metrics/\"\u003evSphere metrics\u003c/a\u003e. For example, you can create a dashboard (as shown below) that graphs the number of vSphere VMs by regional data center, then graph the number of available Kubernetes nodes by region. If there are more VMs than Kubernetes nodes, you can investigate whether some \u003ca href=\"https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/\"\u003ekubelets\u003c/a\u003e running on your vSphere VMs have crashed—or failed to deploy due to a misconfiguration—causing the API server to register fewer nodes than expected.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"A dashboard that includes vSphere and Kubernetes metrics together, plus a host map and container map.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"eks-is-anywhereand-so-is-datadog\"\u003e\u003ca href=\"#eks-is-anywhereand-so-is-datadog\"\u003eEKS is anywhere—and so is Datadog\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog is well suited for monitoring EKS Anywhere as well as your cloud-based EKS deployments, giving you full visibility into your containerized workloads no matter where they run. You can quickly install Datadog in your EKS Anywhere and EKS clusters using our \u003ca href=\"https://docs.datadoghq.com/agent/kubernetes/?tab=helm\"\u003eHelm chart\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eDatadog integrates with \u003ca href=\"https://docs.datadoghq.com/integrations/vsphere/\"\u003evSphere\u003c/a\u003e—and other infrastructure technologies you might be deploying on Kubernetes, such as \u003ca href=\"https://www.datadoghq.com/blog/monitor-cilium-with-datadog/\"\u003eCilium\u003c/a\u003e and \u003ca href=\"https://www.datadoghq.com/blog/monitor-coredns-with-datadog/\"\u003eCoreDNS\u003c/a\u003e—so you can visualize every layer of your EKS Anywhere environment. And with other features like \u003ca href=\"https://docs.datadoghq.com/network_monitoring/devices/\"\u003eNetwork Device Monitoring\u003c/a\u003e, you can get even deeper insight into the health of your \u003ca href=\"https://www.datadoghq.com/solutions/on-premises-monitoring/\"\u003eon-premise infrastructure\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIf you have not yet signed up for Datadog, you can started today with a \u003ca href=\"#\"\u003efree trial\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/hero.png\" width=\"100%\"/\u003eAmazon Elastic Kubernetes Service (EKS) is a cloud-based compute platform that includes a fully managed Kubernetes control plane in order to simplify cluster operations. AWS introduced EKS Anywhere to bring the operational ease of EKS to organizations that manage on-premise environments (e.g., to meet data sovereignty requirements). EKS Anywhere is released as an automation tool that launches an EKS Distro cluster with opinionated defaults on vSphere virtual machines, making it easier to get started with container orchestration.",
      "date_published": "2021-09-08T00:00:00Z",
      "author": {
        "name": "Paul Gottschling"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/partner/datadog-for-startups/sequoia-india/",
      "title": "Sequoia India + Datadog for Startups",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003ch2\u003eDatadog for Startup Program Benefits:\u003c/h2\u003e\u003cp\u003eAs a member of the Datadog for Startup program you will have access to resources you need to be successful and grow your business\u003c/p\u003e\u003cdiv\u003e\u003cdiv\u003e\u003csvg width=\"50\" height=\"50\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003ctitle\u003eIcon/integrate\u003c/title\u003e\u003cdesc\u003eCreated with Sketch.\u003c/desc\u003e\u003cg stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\"\u003e\u003cpath d=\"M33.3764336 14.2661605 21.2643837 21.2584019 21.2569486 21.2455228 19.4912488 22.264793 17.4922774 21.1094097 21.1221873 19.0140032 21.124824 19.0296221 26.6576406 15.8355476 26.6555233 15.8230056 33.3636436 11.949338 43.816175 17.9844931V30.0534694L33.3636436 36.0886245 28.1064938 33.0528335V30.7433232 30.7415867L33.3642271 33.7788499 41.816175 28.8988056V19.1391569L33.3764336 14.2661605zM4.51225765 19.4212291 4.012825 19.1328897V7.06392308L14.4641061 1.02873174 24.9166375 7.06388681V13.2504779L22.9166375 14.3335088V8.21855069L14.4641689 3.33820576 6.012825 8.21851442V17.9781728L12.5845983 21.7722799 12.5827495 21.7739016 19.7084938 25.8902687V25.9015534v2.3094377L16.9881393 26.640294 16.9962357 26.6331902 4.51213887 19.4214347 4.51225765 19.4212291zM22.9166375 32.4715599V26.1445599L22.9123625 26.1431001V23.886465l2-1.0830309000000007L24.9166375 22.8011191V39.587225H24.9042875V40.970576L14.4517561 47.0044179 4.000475 40.9705397V28.9015731L9.17326192 25.9144982 11.1717196 27.0699802 6.000475 30.0561644v9.7596584L14.4518189 44.6950696 22.9042875 39.8157865V32.4673425L22.9166375 32.4715599z\" fill=\"#000\" fill-rule=\"nonzero\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/svg\u003e\u003cp\u003e\u003cstrong\u003eDatadog Pro\u003c/strong\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003csvg width=\"50\" height=\"50\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003ctitle\u003eIcon/key\u003c/title\u003e\u003cdesc\u003eCreated with Sketch.\u003c/desc\u003e\u003cg stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\"\u003e\u003cpath d=\"M15.7347263 13.0251099C13.7379154 11.8716985 11.1839716 12.5559578 10.0312589 14.5523224 8.87840737 16.5499718 9.56257805 19.1039077 11.5595694 20.2574234 13.5572135 21.4102718 16.110921 20.7260758 17.2633764 18.7291129 18.4162248 16.7314689 17.7320288 14.1777613 15.7347263 13.0251099zm-5.1751764 8.964353C7.60597842 20.283401 6.59423706 16.5066789 8.29913662 13.5524462 10.0043071 10.5992886 13.7816144 9.58726259 16.7347459 11.2930705 19.6885586 12.9977277 20.7004746 16.7746241 18.9956119 19.728793 17.2909547 22.6826056 13.5140582 23.6945216 10.5595499 21.9894629zM44.216217 31.7156873 23.8062674 19.9322936 23.9872687 19.2019342C25.1183985 14.6377049 23.1069385 9.81500238 18.9721284 7.42814746 13.8805435 4.48841961 7.3680149 6.23336307 4.42827687 11.3249657 1.48854902 16.4165507 3.23349248 22.9290792 8.32520564 25.8688811 12.4600464 28.2569174 17.6416469 27.5878703 21.0289357 24.3257247L21.570876 23.8038063 26.9024703 26.8811874 23.9906418 31.9244743 27.8621331 34.1597464 30.7738978 29.1165699 38.1094653 33.3518861 35.1977006 38.3950625 39.0691919 40.6303347 44.216217 31.7156873zM46.9483007 30.9836303 39.8012081 43.3623948 32.4656405 39.1270786 35.3774052 34.0839022 31.5059139 31.8486301 28.5941492 36.8918065 21.2585817 32.6564904 24.1702826 27.6134244 21.8538083 26.276362C17.8334397 29.7076438 12.0131247 30.3083932 7.32506961 27.6008533 1.27689203 24.1088177-.795787141 16.3731044 2.69624078 10.3249402 6.18827639 4.27676262 13.9239897 2.20408345 19.9720817 5.69606965 24.6601455 8.40229505 27.0499914 13.7437791 26.0890009 18.9408107L46.9483007 30.9836303z\" fill=\"#000\" fill-rule=\"nonzero\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/svg\u003e\u003cp\u003e\u003cstrong\u003eaccess to datadog technical training\u003c/strong\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003csvg width=\"50\" height=\"50\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003ctitle\u003eIcon/colab\u003c/title\u003e\u003cdesc\u003eCreated with Sketch.\u003c/desc\u003e\u003cg stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\"\u003e\u003cpath d=\"M11.3783784 39.0540541H25.7027027v2H9.37837838V25.8648649H11.3783784V39.0540541zM18.8918919 11.5405405V9.54054054H38.6216216V16.7837838h-2V11.5405405H18.8918919zm-4.972973000000001-1C13.9189189 8.58531178 12.3336071 7 10.3783784 7 8.42314961 7 6.83783784 8.58531178 6.83783784 10.5405405 6.83783784 12.4957693 8.42314961 14.0810811 10.3783784 14.0810811 12.3336071 14.0810811 13.9189189 12.4957693 13.9189189 10.5405405zm2 0C15.9189189 13.6003388 13.4381766 16.0810811 10.3783784 16.0810811 7.31858012 16.0810811 4.83783784 13.6003388 4.83783784 10.5405405 4.83783784 7.48074228 7.31858012 5 10.3783784 5 13.4381766 5 15.9189189 7.48074228 15.9189189 10.5405405zM4 25.8648649H2C2 21.237445 5.75095849 17.4864865 10.3783784 17.4864865 15.0057983 17.4864865 18.7567568 21.237445 18.7567568 25.8648649h-2C16.7567568 22.3420145 13.9012288 19.4864865 10.3783784 19.4864865 6.85552799 19.4864865 4 22.3420145 4 25.8648649zm37.1621622.0C41.1621622 23.9096361 39.5768504 22.3243243 37.6216216 22.3243243 35.6663929 22.3243243 34.0810811 23.9096361 34.0810811 25.8648649 34.0810811 27.8200936 35.6663929 29.4054054 37.6216216 29.4054054 39.5768504 29.4054054 41.1621622 27.8200936 41.1621622 25.8648649zm2 0C43.1621622 28.9246631 40.6814199 31.4054054 37.6216216 31.4054054 34.5618234 31.4054054 32.0810811 28.9246631 32.0810811 25.8648649 32.0810811 22.8050666 34.5618234 20.3243243 37.6216216 20.3243243 40.6814199 20.3243243 43.1621622 22.8050666 43.1621622 25.8648649zM31.2432432 41.1891892h-2C29.2432432 36.5617693 32.9942017 32.8108108 37.6216216 32.8108108S46 36.5617693 46 41.1891892H44C44 37.6663388 41.144472 34.8108108 37.6216216 34.8108108 34.0987712 34.8108108 31.2432432 37.6663388 31.2432432 41.1891892z\" fill=\"#000\" fill-rule=\"nonzero\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/svg\u003e\u003cp\u003e\u003cstrong\u003ededicated program manager\u003c/strong\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003csvg width=\"50\" height=\"50\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003ctitle\u003eIcon/event/check\u003c/title\u003e\u003cdesc\u003eCreated with Sketch.\u003c/desc\u003e\u003cg stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\"\u003e\u003cpath d=\"M36.4 9.33333333H44V44.2666667H4V9.33333333h7.6V4h2V9.33333333H34.4V4h2V9.33333333zM6 21.4666667v20.8H42v-20.8H6zm0-2H42V11.3333333H6V19.4666667zM30.8300666 25.7811666 32.2442801 27.1953801 22.0473067 37.3923536 16.9587999 32.3038468 18.3730134 30.8896332 22.0473067 34.5639264 30.8300666 25.7811666z\" fill=\"#000\" fill-rule=\"nonzero\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/svg\u003e\u003cp\u003e\u003cstrong\u003equarterly progress check-ins\u003c/strong\u003e\u003c/p\u003e\u003c/div\u003e\u003cdiv\u003e\u003csvg width=\"50\" height=\"50\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003ctitle\u003eIcon/support\u003c/title\u003e\u003cdesc\u003eCreated with Sketch.\u003c/desc\u003e\u003cg stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\"\u003e\u003cpath d=\"M6.19788894 14.876511C4.76216286 17.6706601 4 20.7790413 4 23.99988 4 27.2866897 4.79268396 30.3881526 6.1972927 33.1235932L10.7097236 30.5182636C9.72258133 28.5101242 9.2 26.2927551 9.2 23.99988 9.2 21.706251 9.72293589 19.4879006 10.7106407 17.4820259L6.19788894 14.876511zm1.00173545-1.7310488L11.7128105 15.7512279C14.249478 11.9761989 18.3941718 9.54279952 23 9.23338857V4.02462245C16.5154703 4.34603028 10.6720887 7.77868236 7.19962439 13.1454622zM41.8024959 33.1236097C43.2383858 30.332001 44 27.2235986 44 23.99988 44 20.7132576 43.2072186 17.6117481 41.8024344 14.8761858L37.290143 17.4814348C38.2772667 19.4873865 38.8 21.7067334 38.8 23.99988 38.8 26.2929067 38.2773496 28.5104174 37.2902422 30.5183824L41.8024959 33.1236097zM40.8005199 34.8545197 36.289149 32.2498021C33.7545705 36.0245369 29.6083506 38.4572478 25 38.7664164V43.975153C31.4863252 43.6538524 37.3296327 40.2214274 40.8005199 34.8545197zM7.1988399 34.8547507C10.5922072 40.0964341 16.371858 43.6489833 23 43.9753185V38.7664165C18.3914737 38.4572375 14.2451252 36.0243737 11.7107606 32.2497157L7.1988399 34.8547507zM40.8008376 13.1450569C37.4074698 7.90365056 31.6280476 4.35081163 25 4.02444432V9.23334693C29.6079147 9.54252262 33.7529898 11.9751374 36.2884191 15.7503794L40.8008376 13.1450569zM24 1.99988C36.1506736 1.99988 46 11.849984 46 23.99988 46 27.9187854 44.9747618 31.6880529 43.0552754 35.0004857 39.1506909 41.7525127 31.9455025 45.99988 24 45.99988 11.8496983 45.99988 2 36.151348 2 23.99988 2 20.0842472 3.02584566 16.3151073 4.944868 12.9990264 8.85196063 6.24712628 16.0569437 1.99988 24 1.99988zM24 36.79988C28.6243973 36.79988 32.8162453 34.3291475 35.0876453 30.3990656 36.204178 28.4693686 36.8 26.279957 36.8 23.99988 36.8 21.7171707 36.2027856 19.5235016 35.084145 17.5960666 32.8102647 13.6679356 28.6216778 11.19988 24 11.19988 19.3800027 11.19988 15.1906326 13.6699291 12.9152892 17.5994429 11.7968774 19.5264823 11.2 21.7177776 11.2 23.99988 11.2 26.279957 11.795822 28.4693686 12.9125996 30.3994891 15.1837547 34.3291475 19.3756027 36.79988 24 36.79988z\" fill=\"#000\" fill-rule=\"nonzero\"\u003e\u003c/path\u003e\u003c/g\u003e\u003c/svg\u003e\u003cp\u003e\u003cstrong\u003ededicated success manager\u003c/strong\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/partner/datadog-for-startups/sequoia-india/combined-landing-page-hero_181211_FINAL.png\" width=\"100%\"/\u003e",
      "date_published": "2021-09-01T00:00:00Z",
      "author": {
        "name": "Datadog"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/feature-monitoring-statsig-datadog-marketplace/",
      "title": "Monitor feature releases with Statsig's offering in the Datadog Marketplace",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003ca href=\"https://www.statsig.com/\"\u003eStatsig\u003c/a\u003e is a modern experimentation platform that provides crucial insight into how new features are received by your users, so you can make informed product decisions and deploy with confidence. Statsig automatically runs A/B tests on features as they’re rolled out, and measures their impact on key business metrics, such as user growth and engagement. This gives both your technical and business teams the context they need to decide whether to ship, abandon, or iterate on a feature—without any lengthy debates or guesswork.\u003c/p\u003e\u003cp\u003eWe’re excited to announce that Statsig is \u003ca href=\"https://app.datadoghq.com/marketplace/app/statsig-statsig/overview\"\u003enow available\u003c/a\u003e in the Datadog Marketplace. Once you’re up and running, you can enable \u003ca href=\"https://app.datadoghq.com/account/settings#integrations/statsig\"\u003ethe Statsig integration\u003c/a\u003e, which allows you to monitor events related to your feature experiments alongside your application’s telemetry data in Datadog. This helps you ensure that the progress you make on business objectives does not come at the expense of reliability or performance.\u003c/p\u003e\u003ch2 id=\"run-feature-experiments-to-drive-product-decisions\"\u003e\u003ca href=\"#run-feature-experiments-to-drive-product-decisions\"\u003eRun feature experiments to drive product decisions\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eStatsig ships with a number of \u003ca href=\"https://docs.statsig.com/console/overview\"\u003eout-of-the-box tools\u003c/a\u003e for conducting experiments that can help you assess which features resonate with your end users. \u003ca href=\"https://docs.statsig.com/console/featureGates/introduction\"\u003eFeature Gates\u003c/a\u003e (also known as feature flags) are a central pillar of the Statsig platform, as they allow you to control which of your users get access to new features as you roll them out. You can use Feature Gates to easily toggle a feature on or off for all of your users, or define \u003ca href=\"https://docs.statsig.com/console/featureGates/rules\"\u003erules and conditions\u003c/a\u003e to only show a feature to a certain subset of your users at a time. For example, you can target users who are part of your beta test cohort or who access your application from a particular country.\u003c/p\u003e\u003cp\u003eStatsig also automatically runs A/B tests for each Feature Gate you create—and shows you how your feature impacts your core business by ingesting, aggregating, and analyzing \u003ca href=\"https://docs.statsig.com/guides/logging-events\"\u003eevents\u003c/a\u003e that occur in your application (e.g., when a user adds an item to their cart or checks out). This requires no additional instrumentation on the user’s part. In the example below, you can see that adding relevance-based sorting to the product catalog yields largely positive effects, such as increased add-to-cart and checkout events and decreased p50 latency.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"statsig-metric-lifts.png\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"monitor-configuration-change-events-alongside-application-telemetry-data\"\u003e\u003ca href=\"#monitor-configuration-change-events-alongside-application-telemetry-data\"\u003eMonitor configuration change events alongside application telemetry data\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eWhen it comes to making product decisions, understanding how new features impact your business is only one part of the equation. It’s equally important to know how they affect your systems, so you can catch and resolve any unexpected issues before you launch. Once enabled, the Statsig integration automatically sends configuration change events, such as when a Feature Gate is created or updated, to Datadog. You can visualize these events—and correlate them with telemetry data from across your stack— by adding the \u003ca href=\"https://docs.datadoghq.com/events/\"\u003eevent stream\u003c/a\u003e widget to any dashboard and filtering it by \u003ccode\u003esources:statsig\u003c/code\u003e. This way, if your system begins to behave anomalously or shows signs of overloading, you can immediately identify the exact configuration change that caused the issue.\u003c/p\u003e\u003cp\u003eIn the screenshot below, you can see that our release of the \u003ccode\u003einstant_search\u003c/code\u003e feature corresponded with a significant spike in CPU utilization. Because we’re able to quickly detect issues like this, we can roll back the change and make adjustments before a wider set of users is affected.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"statsig-in-datadog.png\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"get-started-in-the-datadog-marketplace\"\u003e\u003ca href=\"#get-started-in-the-datadog-marketplace\"\u003eGet started in the Datadog Marketplace\u003c/a\u003e\u003c/h2\u003e\u003cp\u003e\u003ca href=\"https://app.datadoghq.com/marketplace/app/statsig-statsig/overview\"\u003eStatsig\u003c/a\u003e is now available in the Datadog Marketplace. Not sure if Statsig is right for you? Take it for a test drive to experience the benefits of automated A/B testing and analytics. The dev tier is free for up to 5M events per month.\u003c/p\u003e\u003cp\u003eYou can also enable the \u003ca href=\"https://app.datadoghq.com/account/settings#integrations/statsig\"\u003eStatsig integration\u003c/a\u003e right away to monitor feature rollout events alongside your application’s telemetry data in Datadog. If you’re not yet a Datadog customer, you can learn more about the Datadog Marketplace in our \u003ca href=\"https://www.datadoghq.com/blog/datadog-marketplace/\"\u003eblog post\u003c/a\u003e—and sign up for a 14-day \u003ca href=\"#\"\u003efree trial\u003c/a\u003e of Datadog today.\u003c/p\u003e\u003cp\u003eThe ability to promote branded monitoring tools in the Datadog Marketplace is one of the benefits of membership in the \u003ca href=\"https://www.datadoghq.com/partner/\"\u003eDatadog Partner Network\u003c/a\u003e. If you’re interested in developing an integration or application for the Datadog Marketplace, contact us at \u003ca href=\"mailto:marketplace@datadog.com\"\u003emarketplace@datadog.com\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-hero.png\" width=\"100%\"/\u003eStatsig is a modern experimentation platform that provides crucial insight into how new features are received by your users, so you can make informed product decisions and deploy with confidence. Statsig automatically runs A/B tests on features as they\u0026rsquo;re rolled out, and measures their impact on key business metrics, such as user growth and engagement. This gives both your technical and business teams the context they need to decide whether to ship, abandon, or iterate on a feature—without any lengthy debates or guesswork.",
      "date_published": "2021-08-31T00:00:00Z",
      "author": {
        "name": "Kai Xin Tai"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/deploy-dotnet-core-azure-app-service/",
      "title": "Deploy ASP.NET Core applications to Azure App Service",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eThe \u003ca href=\"https://dotnet.microsoft.com/learn/aspnet/what-is-aspnet-core\"\u003eASP.NET Core framework\u003c/a\u003e provides cross-platform support for web development, giving you greater control over how you build and deploy your .NET applications. With the ability to run .NET applications on more platforms, you need to ensure that you have visibility into application performance, regardless of where your applications are hosted.\u003c/p\u003e\u003cp\u003eIn previous posts, we looked at instrumenting and monitoring a .NET application deployed via \u003ca href=\"https://www.datadoghq.com/blog/asp-dotnet-core-monitoring/\"\u003eDocker\u003c/a\u003e and \u003ca href=\"https://www.datadoghq.com/blog/deploy-dotnet-core-aws-fargate/\"\u003eAWS Fargate\u003c/a\u003e. In this post, we’ll show how Datadog can help you get visibility into a .NET Core application on \u003ca href=\"https://azure.microsoft.com/en-us/services/app-service/\"\u003eAzure App Service (AAS)\u003c/a\u003e, a cloud-based platform-as-a-service (PaaS) for deploying web and mobile applications and other resources.\u003c/p\u003e\u003cp\u003eWe’ll walk through:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"#create-a-sample-net-core-application\"\u003ecreating\u003c/a\u003e a sample .NET Core application\u003c/li\u003e\u003cli\u003e\u003ca href=\"#deploy-a-net-core-application-on-azure-app-service\"\u003edeploying\u003c/a\u003e the application to Azure App Services\u003c/li\u003e\u003cli\u003e\u003ca href=\"#enable-datadogs-azure-integration\"\u003eenabling\u003c/a\u003e Datadog’s Azure integration and AAS extension\u003c/li\u003e\u003cli\u003e\u003ca href=\"#monitor-net-core-applications-with-datadog\"\u003emonitoring\u003c/a\u003e application performance with Datadog APM\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eDatadog’s \u003ca href=\"https://docs.datadoghq.com/integrations/azure/?tab=azurecliv20\"\u003eAzure integration\u003c/a\u003e enables you to capture metrics and logs from all of your resources on Azure, giving you visibility into the performance of your workloads and their underlying infrastructure. Datadog’s \u003ca href=\"https://docs.datadoghq.com/serverless/azure_app_services/#overview\"\u003eextension for Azure App Service\u003c/a\u003e provides out-of-the-box instrumentation for .NET applications on AAS as well as support for custom instrumentation, \u003ca href=\"https://docs.datadoghq.com/tracing/#connect-logs-and-distributed-traces\"\u003etrace ID injection\u003c/a\u003e, and application runtime metrics. This enables you to track requests as they move across service and process boundaries, correlate that data with code-level performance, and quickly identify any bottlenecks.\u003c/p\u003e\u003ch2 id=\"create-a-sample-net-core-application\"\u003e\u003ca href=\"#create-a-sample-net-core-application\"\u003eCreate a sample .NET Core application\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eTo get started, make sure that you have at least \u003ca href=\"https://dotnet.microsoft.com/download/dotnet/5.0\"\u003eversion 5 of the .NET Core SDK\u003c/a\u003e installed, which includes the \u003ca href=\"https://docs.microsoft.com/en-us/dotnet/core/tools/\"\u003e.NET CLI\u003c/a\u003e. The CLI lets you generate the sample ASP.NET Core application we’ll use throughout this guide. You will also need the \u003ca href=\"https://docs.microsoft.com/en-us/cli/azure/install-azure-cli\"\u003eAzure CLI\u003c/a\u003e in order to publish the application to Azure App Service.\u003c/p\u003e\u003cp\u003eCreate a new web application project with all of the files needed to run a sample application via the following .NET CLI commands:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003e \ndotnet new sln -n DatadogAasExample\ndotnet new webapp -o DatadogAasExample -n DatadogAasExample\ndotnet sln add DatadogAasExample\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThese commands create a new solution file (i.e.,\u003cstrong\u003eDatadogAasExample.sln\u003c/strong\u003e) and add a new Razor Pages web application project and associated \u003cstrong\u003eDatadogAasExample\u003c/strong\u003e directory to the file. You can build and run the project locally by running the following command:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003e \ndotnet run --project ./DatadogAasExample -- --URLS http://localhost:8000\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eYou can then view your application by navigating to \u003ccode\u003ehttp://localhost:8080/\u003c/code\u003e.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"A sample .NET Core application\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eNext, we’ll show you how to set up Azure App Service to publish your application. Once you’ve done this, you can deploy your application directly to AAS, which will automatically create the runtime environment necessary to run it.\u003c/p\u003e\u003ch2 id=\"deploy-a-net-core-application-on-azure-app-service\"\u003e\u003ca href=\"#deploy-a-net-core-application-on-azure-app-service\"\u003eDeploy a .NET Core application on Azure App Service\u003c/a\u003e\u003c/h2\u003e\u003cp\u003ePublishing applications on AAS requires an App Service, which includes a resource group and host plan. The \u003ca href=\"https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/overview#terminology\"\u003eresource group\u003c/a\u003e is a collection of all of your application resources, such as databases or APIs. The \u003ca href=\"https://docs.microsoft.com/en-us/azure/app-service/overview-hosting-plans\"\u003eAzure App Service host plan\u003c/a\u003e defines the makeup of your application’s compute resources, such as the number of virtual machine instances that should be created along with their operating system, region, and size.\u003c/p\u003e\u003cp\u003eYou can create a new resource group and host plan and publish your application via the Azure CLI. First, \u003ca href=\"https://docs.microsoft.com/en-us/cli/azure/authenticate-azure-cli?view=azure-cli-latest\"\u003elog into your Azure account\u003c/a\u003e, then run the following CLI command in the \u003cstrong\u003eDatadogAasExample\u003c/strong\u003e project folder to create a new App Service, prepare the application, and publish it to AAS:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003e \naz webapp up --sku F1 -n Datadog-MySampleApp --os-type windows -g Datadog-MySampleApp-RG -p Datadog-MySampleApp-AAS\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eYou can append \u003ccode\u003e--dryrun\u003c/code\u003e to the command to view more information about what the command will do before it runs, but we’ll look at each parameter in more detail below.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ccode\u003e--sku F1\u003c/code\u003e: sets the free tier as the \u003ca href=\"https://azure.microsoft.com/en-us/pricing/details/app-service/windows/\"\u003epricing tier\u003c/a\u003e for your host plan\u003c/li\u003e\u003cli\u003e\u003ccode\u003e-n Datadog-MySampleApp\u003c/code\u003e: sets the name of the app\u003c/li\u003e\u003cli\u003e\u003ccode\u003e--os-type windows\u003c/code\u003e: sets Windows as the operating system for the App Service, which is the required OS for installing extensions\u003c/li\u003e\u003cli\u003e\u003ccode\u003e-g Datadog-MySampleApp-RG\u003c/code\u003e: creates and names the new resource group\u003c/li\u003e\u003cli\u003e\u003ccode\u003e-p Datadog-MySampleApp-AAS\u003c/code\u003e: creates and names the new App Service host plan\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eTo learn more about the CLI’s commands and optional parameters, check out \u003ca href=\"https://docs.microsoft.com/en-us/cli/azure/webapp?view=azure-cli-latest#az_webapp_up-optional-parameters\"\u003eAzure’s documentation\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eWhen you run the command, Azure App Service automatically detects that you are deploying a .NET Core application and hosts it on a free-tier shared VM instance with the appropriate OS and runtime. The CLI will provide more details about your deployed application in logs similar to the following output:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003e \nThe webapp \u0026#39;Datadog-MySampleApp\u0026#39; doesn\u0026#39;t exist\nCreating Resource group \u0026#39;Datadog-MySampleApp-RG\u0026#39; ...\nResource group creation complete\nCreating AppServicePlan \u0026#39;Datadog-MySampleApp-AAS\u0026#39; ...\nCreating webapp \u0026#39;Datadog-MySampleApp\u0026#39; ...\nConfiguring default logging for the app, if not already enabled\nCreating zip with contents of dir /app/DatadogAasExample ...\nGetting scm site credentials for zip deployment\nStarting zip deployment. This operation can take a while to complete ...\nDeployment endpoint responded with status code 202\nYou can launch the app at http://datadog-mysampleapp.azurewebsites.net\n{\n  \u0026#34;URL\u0026#34;: \u0026#34;http://datadog-mysampleapp.azurewebsites.net\u0026#34;,\n  \u0026#34;appserviceplan\u0026#34;: \u0026#34;Datadog-MySampleApp-AAS\u0026#34;,\n  \u0026#34;location\u0026#34;: \u0026#34;centralus\u0026#34;,\n  \u0026#34;name\u0026#34;: \u0026#34;Datadog-MySampleApp\u0026#34;,\n  \u0026#34;os\u0026#34;: \u0026#34;Windows\u0026#34;,\n  \u0026#34;resourcegroup\u0026#34;: \u0026#34;Datadog-MySampleApp-RG\u0026#34;,\n  \u0026#34;runtime_version\u0026#34;: \u0026#34;dotnet|5.0\u0026#34;,\n  \u0026#34;runtime_version_detected\u0026#34;: \u0026#34;5.0\u0026#34;,\n  \u0026#34;sku\u0026#34;: \u0026#34;FREE\u0026#34;,\n  \u0026#34;src_path\u0026#34;: \u0026#34;//app//DatadogAasExample\u0026#34;\n}\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eTo view your application on AAS, navigate to the URL in the log output (i.e., \u003ccode\u003ehttp://datadog-mysampleapp.azurewebsites.net\u003c/code\u003e).\u003c/p\u003e\u003cp\u003eNext, we’ll look at how you can get visibility into your Azure environment and .NET application with Datadog’s Azure integration and extension for Azure App Service.\u003c/p\u003e\u003ch2 id=\"enable-datadogs-azure-integration\"\u003e\u003ca href=\"#enable-datadogs-azure-integration\"\u003eEnable Datadog’s Azure integration\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog’s Azure integration collects metrics and logs from your Azure services, including Azure App Service, and is required for the extension. You can \u003ca href=\"https://docs.datadoghq.com/integrations/azure/?tab=azurecliv20#installation\"\u003eenable the integration\u003c/a\u003e via the \u003ca href=\"https://azure.microsoft.com/en-us/features/azure-portal\"\u003eAzure portal\u003c/a\u003e or CLI, but we’ll use the CLI in this guide.\u003c/p\u003e\u003cp\u003eThe Azure integration requires creating an \u003ca href=\"https://docs.microsoft.com/en-us/azure/active-directory/develop/app-objects-and-service-principals#application-registration\"\u003eapp registration\u003c/a\u003e, which uses a \u003ca href=\"https://docs.microsoft.com/en-us/azure/active-directory/develop/app-objects-and-service-principals#service-principal-object\"\u003eservice principal\u003c/a\u003e to generate a set of credentials that grant Datadog monitoring access to your application’s \u003ca href=\"https://docs.microsoft.com/en-us/learn/modules/create-an-azure-account/4-multiple-subscriptions\"\u003esubscription\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eTo create a new service principal, run the following command and replace \u003ccode\u003e{subscription_id}\u003c/code\u003e with your application’s subscription ID, which you can find via the \u003ccode\u003eaz account show\u003c/code\u003e CLI command:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003eaz ad sp create-for-rbac --role \u0026#34;Monitoring Reader\u0026#34; --scopes /subscriptions/{subscription_id} --name datadog-monitor-sp\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThe service principal is configured with the \u003ca href=\"https://docs.microsoft.com/en-us/azure/azure-monitor/roles-permissions-security#monitoring-reader\"\u003e“Monitoring Reader” role\u003c/a\u003e and scoped to your application’s subscription. Once the CLI creates the new service principal, it will display credentials similar to the following output:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"json\"\u003e \n\u003cspan\u003e{\u003c/span\u003e\n  \u003cspan\u003e\u0026#34;appId\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;12c406f7-e9aa-4b43-1234-df0aafd7cf9c\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n  \u003cspan\u003e\u0026#34;displayName\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;datadog-monitor-sp\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n  \u003cspan\u003e\u0026#34;name\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;f12345a1-7e8d-4dcc-8e3e-8f1e12e3db45\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n  \u003cspan\u003e\u0026#34;password\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;XYabcdEFGd3JId.FDSg1234.GRP\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n  \u003cspan\u003e\u0026#34;tenant\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;e12ef3b4-5e67-8b90-b1a0-1234abcd9c787\u0026#34;\u003c/span\u003e\n\u003cspan\u003e}\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eEnter the \u003ccode\u003eappId\u003c/code\u003e, \u003ccode\u003etenant\u003c/code\u003e, and \u003ccode\u003epassword\u003c/code\u003e values into the \u003cstrong\u003eClient ID\u003c/strong\u003e, \u003cstrong\u003eTenant ID\u003c/strong\u003e, and \u003cstrong\u003eClient Secret\u003c/strong\u003e fields respectively in your account’s \u003ca href=\"https://app.datadoghq.com/account/settings?#integrations/azure\"\u003eAzure Integration tile\u003c/a\u003e to grant Datadog access to Azure.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog\u0026#39;s Azure integration tile\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eDatadog will start collecting \u003ca href=\"https://docs.microsoft.com/en-us/azure/azure-monitor/essentials/metrics-supported\"\u003estandard metrics\u003c/a\u003e from Azure Monitor and generate \u003ca href=\"https://www.datadoghq.com/blog/datadog-generated-metrics-azure/\"\u003eadditional metrics and tags\u003c/a\u003e from all of your Azure services, such as service-tier tags (e.g., \u003ccode\u003ebasic\u003c/code\u003e, \u003ccode\u003estandard\u003c/code\u003e, \u003ccode\u003epremium\u003c/code\u003e) and metrics that track the number of hosts on your Azure App Service host plan.\u003c/p\u003e\u003cp\u003eThe Azure integration also enables you to install the extension for Azure App Service, which we’ll look at next.\u003c/p\u003e\u003ch2 id=\"install-the-datadog-extension-for-azure-app-service\"\u003e\u003ca href=\"#install-the-datadog-extension-for-azure-app-service\"\u003eInstall the Datadog extension for Azure App Service\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAzure App Service allows you to add third-party services to your application’s environment via extensions, so you can leverage features such as automatic instrumentation and trace collection for monitoring application performance. The Datadog extension for Azure App Service supports several .NET runtimes running on Windows instances, including the .NET Core framework. Note that AAS does not currently support extensions for Linux-based applications.\u003c/p\u003e\u003ch3 id=\"configure-your-application-to-use-datadogs-extension\"\u003e\u003ca href=\"#configure-your-application-to-use-datadogs-extension\"\u003eConfigure your application to use Datadog’s extension\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eBefore installing the extension, you will need to configure your application with the following environment variables:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ccode\u003eDD_API_KEY\u003c/code\u003e: uses your Datadog account’s \u003ca href=\"https://app.datadoghq.com/account/settings?#api\"\u003eAPI key\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ccode\u003eDD_ENV\u003c/code\u003e, \u003ccode\u003eDD_SERVICE\u003c/code\u003e, \u003ccode\u003eDD_VERSION\u003c/code\u003e: sets the \u003ccode\u003eenv\u003c/code\u003e, \u003ccode\u003eversion\u003c/code\u003e, and \u003ccode\u003eservice\u003c/code\u003e tags on traces for \u003ca href=\"https://docs.datadoghq.com/getting_started/tagging/unified_service_tagging/\"\u003eunified service tagging\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ccode\u003eDD_TRACE_ROUTE_TEMPLATE_RESOURCE_NAME_ENABLED\u003c/code\u003e: enables improved \u003ca href=\"https://docs.datadoghq.com/tracing/setup_overview/setup/dotnet-core/?tab=windows#experimental-features\"\u003eresource names\u003c/a\u003e for ASP.NET Core endpoints\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eYou can add these environment variables to your application \u003ca href=\"https://docs.datadoghq.com/serverless/azure_app_services/#installation\"\u003evia the Azure portal\u003c/a\u003e or by running the following Azure CLI command:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003eaz webapp config appsettings set -g Datadog-MySampleApp-RG -n Datadog-MySampleApp --settings DD_API_KEY={your_API_key} DD_ENV=aas_test DD_SERVICE=MySampleApp DD_VERSION=1.0.0 DD_SITE=datadoghq.com DD_TRACE_ROUTE_TEMPLATE_RESOURCE_NAMES_ENABLED=true\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eCheck out \u003ca href=\"https://docs.datadoghq.com/tracing/setup_overview/setup/dotnet-framework/?tab=environmentvariables#additional-optional-configuration\"\u003eour documentation\u003c/a\u003e to learn more about the available options for customizing the extension’s tracing configuration.\u003c/p\u003e\u003cp\u003eNow that your application is configured with the appropriate Datadog environment variables, you can install the extension via deployment scripts or one of Azure’s UI interfaces.\u003c/p\u003e\u003ch3 id=\"install-the-extension-via-a-powershell-script\"\u003e\u003ca href=\"#install-the-extension-via-a-powershell-script\"\u003eInstall the extension via a Powershell script\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eDatadog provides \u003ca href=\"https://github.com/DataDog/datadog-aas-extension/tree/master/management-scripts/extension\"\u003ePowershell scripts\u003c/a\u003e that enable you to easily install and keep extensions up to date from the command line. This streamlines the setup process and makes it easier to manage installed extensions for each of your Azure App Services and resource groups.\u003c/p\u003e\u003cp\u003eTo install the extension via Powershell, download the \u003ca href=\"https://github.com/DataDog/datadog-aas-extension/blob/master/management-scripts/extension/install-latest-extension.ps1\"\u003e\u003ccode\u003einstall-latest-extension.ps1\u003c/code\u003e script\u003c/a\u003e to the \u003cstrong\u003eDatadogAasExample\u003c/strong\u003e project folder and execute it with the following command:\u003c/p\u003e\u003cdiv\u003e\u003cp\u003e.\\install-latest-extension.ps1\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"powershell\"\u003e \n\u003cspan\u003e.\\\u003c/span\u003e\u003cspan\u003einstall-latest\u003c/span\u003e\u003cspan\u003e-extension\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eps1\u003c/span\u003e \u003cspan\u003e-Username\u003c/span\u003e \u003cspan\u003e$username\u003c/span\u003e \u003cspan\u003e-Password\u003c/span\u003e \u003cspan\u003e$password\u003c/span\u003e \u003cspan\u003e-SubscriptionId\u003c/span\u003e \u003cspan\u003e$subscriptionId\u003c/span\u003e \u003cspan\u003e-ResourceGroup\u003c/span\u003e \u003cspan\u003e$resourceGroupName\u003c/span\u003e \u003cspan\u003e-SiteName\u003c/span\u003e \u003cspan\u003e$webAppName\u003c/span\u003e \u003cspan\u003e-DDApiKey\u003c/span\u003e \u003cspan\u003e$ddApiKey\u003c/span\u003e \u003cspan\u003e-DDSite\u003c/span\u003e \u003cspan\u003e$ddSite\u003c/span\u003e \u003cspan\u003e-DDEnv\u003c/span\u003e \u003cspan\u003e$ddEnv\u003c/span\u003e \u003cspan\u003e-DDService\u003c/span\u003e \u003cspan\u003e$ddService\u003c/span\u003e \u003cspan\u003e-DDVersion\u003c/span\u003e \u003cspan\u003e$ddVersion\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003cp\u003eThe script uses your \u003ca href=\"https://docs.microsoft.com/en-us/azure/app-service/deploy-configure-credentials?tabs=portal#userscope\"\u003euser-scope credentials\u003c/a\u003e and configuration data for your application to install and configure Datadog’s out-of-the-box instrumentation for each of your App Service applications, so you can \u003ca href=\"#monitor-net-core-applications-with-datadog\"\u003eview traces in Datadog APM\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eDatadog’s \u003ca href=\"https://github.com/DataDog/datadog-aas-extension/blob/master/management-scripts/extension/update-all-site-extensions.ps1\"\u003e\u003ccode\u003eupdate-all-site-extensions.ps1\u003c/code\u003e script\u003c/a\u003e can be used to update all existing extensions in a resource group to the latest available version. You can run the following command to execute it:\u003c/p\u003e\u003cdiv\u003e\u003cp\u003e.\\update-all-site-extensions.ps1\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"powershell\"\u003e \n\u003cspan\u003e.\\\u003c/span\u003e\u003cspan\u003eupdate-all\u003c/span\u003e\u003cspan\u003e-site-extensions\u003c/span\u003e\u003cspan\u003e.\u003c/span\u003e\u003cspan\u003eps1\u003c/span\u003e \u003cspan\u003e-SubscriptionId\u003c/span\u003e \u003cspan\u003e$subscriptionId\u003c/span\u003e \u003cspan\u003e-ResourceGroup\u003c/span\u003e \u003cspan\u003e$resourceGroupName\u003c/span\u003e \u003cspan\u003e-Username\u003c/span\u003e \u003cspan\u003e$username\u003c/span\u003e \u003cspan\u003e-Password\u003c/span\u003e \u003cspan\u003e$password\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003cp\u003eYou can also install the extension through one of Azure’s UI interfaces, which provide more visibility into your application’s configuration settings and performance.\u003c/p\u003e\u003ch3 id=\"install-the-extension-via-the-azure-portal\"\u003e\u003ca href=\"#install-the-extension-via-the-azure-portal\"\u003eInstall the extension via the Azure portal\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eThe Azure portal allows you to view and manage all of your applications, extensions, and application resources in one place. To get started, run the following command to fully stop your application, which is required before installing any new extensions for Azure App Service via the UI:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003e \naz webapp stop -n Datadog-MySampleApp -g Datadog-MySampleApp-RG \u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eNext, log into the \u003ca href=\"https://portal.azure.com/\"\u003eportal\u003c/a\u003e and navigate to the “Azure App Services” blade to find and select your application. Click “Extension” under “Development Tools” and click “Add” to see a list of available extensions. Select the \u003cstrong\u003e.NET Datadog APM\u003c/strong\u003e extension to add it to your application.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog\u0026#39;s .NET extension for Azure App Service\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYou can restart your application with the following command to complete the installation process:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003e \naz webapp start -n Datadog-MySampleApp -g Datadog-MySampleApp-RG\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eYou can also view and install extensions via \u003ca href=\"https://docs.microsoft.com/en-us/azure/app-service/resources-kudu\"\u003eKudu\u003c/a\u003e, a source code management (SCM) tool for Azure App Service. Every application on AAS includes a \u003ca href=\"https://github.com/projectkudu/kudu/wiki/Accessing-the-kudu-service\"\u003eKudu SCM portal\u003c/a\u003e, which provides useful information about your application (e.g., environment variables, application settings, server configurations). You can add the Datadog extension by searching for it in the “Gallery” tab on the “Site extensions” page.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog\u0026#39;s .NET extension on Kudu\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eOnce the extension is installed for your application, Datadog will automatically collect application traces and forward them to Datadog, where you can explore them alongside other performance data.\u003c/p\u003e\u003ch2 id=\"monitor-net-core-applications-with-datadog\"\u003e\u003ca href=\"#monitor-net-core-applications-with-datadog\"\u003eMonitor .NET Core applications with Datadog\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog’s Azure integration provides a built-in dashboard for Azure App Service, where you can get a high-level overview of all of your applications and service plans.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog\u0026#39;s Azure App Service dashboard\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYou can also collect additional data from your application, such as \u003ca href=\"https://www.datadoghq.com/blog/monitoring-azure-platform-logs/#collect-and-analyze-azure-platform-logs-with-datadog\"\u003eAzure Platform logs\u003c/a\u003e, and \u003ca href=\"https://docs.datadoghq.com/tracing/connect_logs_and_traces/dotnet/?tab=serilog\"\u003econnect trace IDs to logs\u003c/a\u003e, so you can easily correlate traces with log data. This enables you to view application traces and associated logs in Datadog APM and drill down to specific traces to determine if your application is handling requests as expected.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\".NET Core trace for Azure App Service application\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYour trace and log data provide you with more context for troubleshooting a performance issue with your application and pinpointing its root cause, be it an application bug or a problem with an application resource, such as an overloaded server or a slow database query.\u003c/p\u003e\u003cp\u003eDatadog’s extension also includes support for \u003ca href=\"https://docs.datadoghq.com/serverless/azure_app_services/#custom-metrics-with-dogstatsd\"\u003eDogStatsD\u003c/a\u003e, so you can collect custom metrics that help you measure key performance indicators specific to your application. This data can include anything critical to your business, from the number of completed transactions to the performance of a custom application service.\u003c/p\u003e\u003ch2 id=\"net--azure-app-services\"\u003e\u003ca href=\"#net--azure-app-services\"\u003e.NET + Azure App Services\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn this post, we looked at how you can deploy an ASP.NET Core application on Azure App Service and monitor its performance with Datadog’s Azure integration and extension. Check out our documentation to learn more about \u003ca href=\"https://docs.datadoghq.com/tracing/setup_overview/setup/dotnet-core/?tab=windows\"\u003etracing your .NET Core applications\u003c/a\u003e and getting full visibility into the state of your application and its resources. If you don’t already have a Datadog account, you can sign up for a \u003ca href=\"#\"\u003e14-day free trial\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-azure-app-service-hero.png\" width=\"100%\"/\u003eThe ASP.NET Core framework provides cross-platform support for web development, giving you greater control over how you build and deploy your .NET applications. With the ability to run .NET applications on more platforms, you need to ensure that you have visibility into application performance, regardless of where your applications are hosted.In previous posts, we looked at instrumenting and monitoring a .NET application deployed via Docker and AWS Fargate. In this post, we\u0026rsquo;ll show how Datadog can help you get visibility into a .",
      "date_published": "2021-08-27T00:00:00Z",
      "author": {
        "name": "Andrew Lock"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/video-streaming-performance-monitoring-conviva/",
      "title": "Monitor Conviva with Datadog",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003ca href=\"https://www.conviva.com/streaming-insights-platform/\"\u003eConviva\u003c/a\u003e is a platform that helps businesses gain real-time insight into the overall performance and playback quality of their streaming video content. With video streaming workflows, slow start-up times and playback errors can hinder user experience and ultimately drive customers away. With Conviva, you can view key Quality of Experience (QoE) metrics, including video playback failures, rebuffering ratios, and other business-critical data to help monitor and enhance your viewer experience.\u003c/p\u003e\u003cp\u003eNow, with Datadog’s \u003ca href=\"https://docs.datadoghq.com/integrations/conviva/\"\u003eConviva integration\u003c/a\u003e you can monitor end viewer experience alongside the rest of your infrastructure telemetry, for an end-to-end view of your video supply chain. Once you enable the integration, key Conviva metrics will populate an out-of-the-box \u003ca href=\"%E2%80%8B%E2%80%8Bhttps://app.datadoghq.com/dash/integration/30515/conviva-dashboard\"\u003edashboard\u003c/a\u003e, providing a centralized view of your customers\u0026#39; experience on your streaming service so you can quickly identify issues that need troubleshooting.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog\u0026#39;s Conviva integration comes with an out-of-the-box dashboard for visualizing key metrics.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eDatadog automatically pulls in any \u003cstrong\u003efilters\u003c/strong\u003e and \u003cstrong\u003edimensions\u003c/strong\u003e you have created in your Conviva account as tags. In Datadog, you can then define \u003cstrong\u003eMetricLenses\u003c/strong\u003e using specific combinations of filters and dimensions, which let you scope the dashboard to specific views of your data. For example, you can create a MetricLens that allows you to view metrics from your content delivery networks serving traffic to the state of New York by setting the filter to “New York” and the dimension to “CDNs”.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"metriclens-screenshot.png\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eA new-york-traffic-by-cdn MetricLens lets you quickly view telemetry from the content delivery networks serving traffic to New York.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eWith MetricLenses, you can scope your monitoring and alerting to the exact video streams you need. In this post, we’ll look at how you can use Datadog to:\u003c/p\u003e\u003cul\u003e\u003cli\u003ecorrelate \u003ca href=\"#\"\u003eplayback activity\u003c/a\u003e with telemetry from across your stack\u003c/li\u003e\u003cli\u003emonitor \u003ca href=\"#\"\u003evideo performance\u003c/a\u003e to ensure good end-user experience\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"monitor-playback-activity-alongside-your-infrastructure\"\u003e\u003ca href=\"#monitor-playback-activity-alongside-your-infrastructure\"\u003eMonitor playback activity alongside your infrastructure\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eNot only is it important to know how many users are viewing the content delivered to them, you also have to ensure the health and performance of the underlying infrastructure hosting and delivering that content. Datadog collects key playback activity metrics such as \u003cstrong\u003econcurrent plays\u003c/strong\u003e and \u003cstrong\u003eattempted plays\u003c/strong\u003e. You can easily correlate these user traffic metrics with telemetry from the rest of your infrastructure. For example, if you notice a spike in playback activity in a specific region, you can check resource utilization across your hosts in that region to see if you need to scale up to meet demand. Or, if you notice a drop in playback activity, you may want to check whether your CDN, such as \u003ca href=\"https://docs.datadoghq.com/integrations/akamai_datastream\"\u003eAkamai\u003c/a\u003e, is experiencing elevated error rates.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Viewing concurrent plays by CDN can you identify if a CDN is serving significantly more traffic.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eComparing your Conviva playback with CDN metrics can also help you measure the number of unauthorized users on your platform. If Conviva shows a high number of plays while your CDN indicates normal activity, it could mean there’s been a security breach that allows unauthorized users to view your streams.\u003c/p\u003e\u003ch2 id=\"monitor-quality-of-experience-and-performance-metrics\"\u003e\u003ca href=\"#monitor-quality-of-experience-and-performance-metrics\"\u003eMonitor quality of experience and performance metrics\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eMonitoring video start up times and rebuffering ratios is important for catching potential pain points in your customers\u0026#39; experience. For example, if videos take too long to start or often stall during playback due to network performance issues, viewers are likely to get frustrated, leading to churn and lost revenue. With Datadog, you can surface the slowest video start up times (measured in seconds) by visualizing them as a top list to help you determine where to focus your troubleshooting.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Top lists of slowest video start up times can help you focus your troubleshooting.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eIn addition to monitoring for slow start up times, checking if videos are failing to start or are stopping unexpectedly can prevent customer churn as well. While \u003ca href=\"#monitor-playback-activity\"\u003eattempted plays\u003c/a\u003e tell you how often users tried to view content, it’s important to track what percentage of those attempted video plays resulted in start up and playback failures. The percentage of \u003cstrong\u003evideo start failures (VSFs)\u003c/strong\u003e highlights the portion of attempted videoplays that were aborted before a video is able to start due to an error, pointing to a possible video encoding or packaging problem. Similarly, the percentage of \u003cstrong\u003evideo playback failures (VPFs)\u003c/strong\u003e highlights the portion of videos that abort \u003cem\u003eduring\u003c/em\u003e playback, which could be due to a network issue you can explore with Datadog Network Performance Monitoring. Looking at the percentage of video start and playback failures allows you to gain insight into the overall performance of your streaming service. With Datadog, you can set monitors that alert on high VPF and VSF percentages, so you can quickly be notified of problems and begin troubleshooting.\u003c/p\u003e\u003ch2 id=\"get-full-end-to-end-visibility-with-datadog\"\u003e\u003ca href=\"#get-full-end-to-end-visibility-with-datadog\"\u003eGet full end-to-end visibility with Datadog\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn addition to Conviva’s video performance and QoE metrics, Datadog enables you to visualize and alert on telemetry from over\n450 other services and technologies, including video packaging and storage services like \u003ca href=\"https://docs.datadoghq.com/integrations/?q=elemental\"\u003eAmazon Elemental\u003c/a\u003e and \u003ca href=\"https://docs.datadoghq.com/integrations/amazon_s3/\"\u003eS3\u003c/a\u003e, as well as content delivery networks like \u003ca href=\"https://docs.datadoghq.com/integrations/cloudflare/#overview\"\u003eCloudFlare\u003c/a\u003e \u003ca href=\"https://docs.datadoghq.com/integrations/akamai_datastream/\"\u003eAkamai\u003c/a\u003e, \u003ca href=\"https://docs.datadoghq.com/integrations/amazon_cloudfront/?tab=standardlogs\"\u003eAmazon Cloudfront\u003c/a\u003e and more. This means you get unified end-to-end visibility into your entire video supply chain on a single, unified platform.\u003c/p\u003e\u003cp\u003eTo learn more about how to monitor Conviva with Datadog, check out our \u003ca href=\"https://docs.datadoghq.com/integrations/conviva/\"\u003edocumentation\u003c/a\u003e. If you aren’t already using Datadog, get started today with a 14-day \u003ca href=\"#\"\u003efree trial\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva_hero.png\" width=\"100%\"/\u003eConviva is a platform that helps businesses gain real-time insight into the overall performance and playback quality of their streaming video content. With video streaming workflows, slow start-up times and playback errors can hinder user experience and ultimately drive customers away. With Conviva, you can view key Quality of Experience (QoE) metrics, including video playback failures, rebuffering ratios, and other business-critical data to help monitor and enhance your viewer experience.",
      "date_published": "2021-08-25T00:00:00Z",
      "author": {
        "name": "Jordan Obey"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/pup-culture/datadog-engineering-internship-program-2021/",
      "title": "Datadog's Engineering Internship Program",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv id=\"blog-content\" data-scroll-speed=\"2\"\u003e\u003cp\u003eEvery autumn, we begin our search for aspiring software developers, product managers, and product designers who are interested in participating in our \u003ca href=\"https://www.datadoghq.com/early-careers\"\u003eEngineering Internship Program\u003c/a\u003e. Those who join us are able to spend several months working on meaningful projects, forging professional relationships, and getting the full Datadog experience. The high-growth nature of our company, combined with the maturity and scale of our Engineering organization, enables our interns to have an enormous impact on our product while learning from best-in-class leaders whose work is at the forefront of innovation. And after more than a year of fully remote operations, we’re excited to offer the option for our newest cohort of interns to join us at Datadog offices around the world.\u003c/p\u003e\u003cp\u003e\u003ciframe src=\"https://player.vimeo.com/video/589894585?badge=0\u0026amp;amp;autopause=0\u0026amp;amp;player_id=0\u0026amp;amp;app_id=58479\u0026amp;amp;h=6fd7864e8a\" frameborder=\"0\" webkitallowfullscreen=\"\" mozallowfullscreen=\"\" allowfullscreen=\"\"\u003e\u003c/iframe\u003e\u003c/p\u003e\u003cp\u003eOur primary goal for the internship program has always been to host a supportive learning environment in which interns can hone their skills. All interns participate in weekly one-on-one sessions with managers, mentors, and buddies, and they can also check in with their colleagues throughout the week to ask questions, receive guidance, or simply chat. David Sevilla, a former intern and current Software Engineer on the Website Reliability team, remembered, “There was a large learning curve, but my team was incredibly supportive. By the end of my internship, I participated in on-call rotations, and I learned how to keep cool under pressure, escalate incidents when necessary, and investigate root causes with confidence.”\u003c/p\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 1x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 1x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 1x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 1x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 1x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 1x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 1x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"David Sevilla, Software Engineer\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cblockquote\u003eI participated in on-call rotations, and I learned how to keep cool under pressure, escalate incidents when necessary, and investigate root causes with confidence.\u003cbr/\u003e—\u003cb\u003eDavid Sevilla\u003c/b\u003e, Software Engineer\u003c/blockquote\u003e\u003c/div\u003e\u003c/div\u003e\u003cp\u003eBecause we treat our interns like full-fledged employees, they are able to contribute to—and even drive the development of—features that are used by thousands of customers every day. Conor Branagan, a former intern and current Director of Engineering, noted, “You’re working on the software that customers are interacting with as part of the Datadog product. You’re also working at a scale that’s really unlike any other company out there. In many cases, because of the scale we’re at, we’ve had to roll out our own custom solutions, and interns get the opportunity to work on those solutions. Plus, as an intern, you get to learn alongside incredibly seasoned engineers.”\u003c/p\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 1x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 1x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 1x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 1x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 1x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 1x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 1x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Conor Branagan, Director of Engineering\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cblockquote\u003eIn many cases, because of the scale we\u0026#39;re at, we\u0026#39;ve had to roll out our own custom solutions, and interns get the opportunity to work on those solutions.\u003cbr/\u003e—\u003cb\u003eConor Branagan\u003c/b\u003e, Director of Engineering\u003c/blockquote\u003e\u003c/div\u003e\u003c/div\u003e\u003cp\u003eYiren Wang, a former intern and current Software Engineer based in Paris, had the opportunity to maintain a legacy Elasticsearch database during her internship, and her experience typifies the type of high-impact work that Branagan describes. “I was able to drive the entire process—from ramping up to reviews—and I had a Senior Engineer looking at and advising on my work at every step of the way,” she recalled, adding, “[The database] has grown from the beginning of my internship from about 600 terabytes of data to about 1 petabyte of data.” She also credits Datadog’s culture of blamelessness as one of the key factors that supported her growth. “If I made any mistakes, it could cause a major outage. But I never once felt as if I was at fault or like I couldn’t try out a solution,” she said.\u003c/p\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 1x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 1x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 1x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 1x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 1x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 1x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 1x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Yiren Wang, Software Engineer\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cblockquote\u003eI was able to drive the entire process—from ramping up to reviews—and I had a Senior Engineer looking at and advising on my work at every step of the way.\u003cbr/\u003e—\u003cb\u003eYiren Wang\u003c/b\u003e, Software Engineer\u003c/blockquote\u003e\u003c/div\u003e\u003c/div\u003e\u003cp\u003eHalf the fun of an internship comes with meeting new people and building lasting relationships, and we’re happy that our return to the office will enable our interns to get to know one another better. All Datadog interns are invited to participate in intern-specific lunches, hangout sessions, outings, and fireside chats with leaders, as well as company-wide social events such as Unleash, our annual celebration hosted in New York City. These activities give interns the opportunity to explore, unwind, and catch up with people from different teams. “One of the most memorable events, for me, was when we got to hear from Oli, the CEO and Co-founder. We were able to hear his story and even ask some questions, and, overall, it was a really great experience to be able to interact with someone in senior leadership,” Victoria Kayola, a class of 2020 intern and current Software Engineer, noted.\u003c/p\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 1x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 1x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 1x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 1x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 1x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 1x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 1x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Victoria Kayola, Software Engineer\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv\u003e\u003cblockquote\u003eOne of the most memorable events, for me, was when we got to hear from Oli, the CEO and Co-founder. We were able to hear his story and even ask some questions.\u003cbr/\u003e—\u003cb\u003eVictoria Kayola\u003c/b\u003e, Software Engineer\u003c/blockquote\u003e\u003c/div\u003e\u003c/div\u003e\u003cp\u003eWhether we’re working in the office or from home, we want our interns to leave the program with valuable experiences that will help shape their careers. All interns are offered highly competitive salaries and benefits packages, and we provide them with the equipment and guidance they need to be successful. And we’re proud to say that many graduates from our internship program—including the former interns featured in this post—go on to receive full-time job offers from us. Some are even able to grow into leadership roles at Datadog; for instance, Branagan now manages five teams as a Director of Engineering.\u003c/p\u003e\u003cp\u003eDatadog has become the gold standard for monitoring and security. We’re proud of the success we have achieved, and we’re on the lookout for talented interns to join us in the next phase of our journey. If you would like to be a part of our Engineering Internship Program, please check out our open positions \u003ca href=\"https://www.datadoghq.com/early-careers\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/internship-program-hero.png\" width=\"100%\"/\u003eEvery autumn, we begin our search for aspiring software developers, product managers, and product designers who are interested in participating in our Engineering Internship Program. Those who join us are able to spend several months working on meaningful projects, forging professional relationships, and getting the full Datadog experience. The high-growth nature of our company, combined with the maturity and scale of our Engineering organization, enables our interns to have an enormous impact on our product while learning from best-in-class leaders whose work is at the forefront of innovation.",
      "date_published": "2021-08-24T00:00:00Z",
      "author": {
        "name": "Sara Verdi"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/manage-serverless-logs-datadog/",
      "title": "Best practices for collecting and managing serverless logs with Datadog",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eLogs are an essential part of an effective monitoring strategy, as they provide granular information about activity that occurs anywhere in your system. In serverless environments, however, you have no access to the infrastructure that supports your applications, so you must rely entirely on logs from individual AWS services when troubleshooting performance issues. But serverless applications can generate a massive amount of logs, which introduces storage concerns and makes it difficult to see the forest through the trees.\u003c/p\u003e\u003cp\u003eIn this guide, we’ll discuss some best practices for collecting and managing your logs that will help you maximize their value. More specifically, we’ll cover:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"#standardize-the-format-of-your-logs-with-a-logging-library\"\u003estandardizing the format of your logs\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#log-at-the-appropriate-level-for-your-environment\"\u003esetting an appropriate log level\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#include-useful-information-in-your-logs\"\u003eincluding useful context in your logs\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#centralize-your-aws-serverless-logs-with-datadog\"\u003ecentralizing your logs with Datadog\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#control-your-logging-costs\"\u003econtrolling your logging costs\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"understanding-the-types-of-logs-that-aws-serverless-technologies-generate\"\u003e\u003ca href=\"#understanding-the-types-of-logs-that-aws-serverless-technologies-generate\"\u003eUnderstanding the types of logs that AWS serverless technologies generate\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eBefore we go any further, let’s first examine the types of logs that are emitted by some of the most popular AWS serverless technologies—and how they can help you investigate issues with your applications.\u003c/p\u003e\u003ch3 id=\"aws-lambda-logs\"\u003e\u003ca href=\"#aws-lambda-logs\"\u003eAWS Lambda logs\u003c/a\u003e\u003c/h3\u003e\u003cp\u003e\u003ca href=\"https://aws.amazon.com/lambda/\"\u003eAWS Lambda\u003c/a\u003e functions are the linchpins of serverless applications, as they are responsible for running pieces of code that implement business logic in response to triggers. Lambda generates three types of logs that provide insight into how it operates and processes events: function logs, extension logs, and platform logs.\u003c/p\u003e\u003cp\u003eFunction logs and extension logs are both useful for debugging your code. \u003cstrong\u003eFunction logs\u003c/strong\u003e include any log written by a function to \u003ccode\u003estdout\u003c/code\u003e or \u003ccode\u003estderr\u003c/code\u003e, such as print statements that verify whether your code produces the correct output. Similarly, \u003cstrong\u003eextension logs\u003c/strong\u003e are emitted by your \u003ca href=\"https://aws.amazon.com/blogs/compute/using-aws-lambda-extensions-to-send-logs-to-custom-destinations/\"\u003eLambda extension’s\u003c/a\u003e code, and they can help you identify extension-related issues, such as a failure to subscribe to log streams.\u003c/p\u003e\u003cp\u003eIn contrast, \u003cstrong\u003eplatform logs\u003c/strong\u003e are generated by the Lambda runtime and record invocation- and extension-related events. For example, a function produces a \u003ccode\u003eSTART\u003c/code\u003e, \u003ccode\u003eEND\u003c/code\u003e, and \u003ccode\u003eREPORT\u003c/code\u003e platform log every time it is invoked. \u003ccode\u003eREPORT\u003c/code\u003e platform logs are the most useful of the three, as they contain invocation metrics that can alert you to issues like high latency and cold starts.\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"json\"\u003e \n\u003cspan\u003e{\u003c/span\u003e\n\t\u003cspan\u003e\u0026#39;time\u0026#39;:\u003c/span\u003e \u003cspan\u003e\u0026#39;2021-08-22T10:52:07.294Z\u0026#39;,\u003c/span\u003e \n\t\u003cspan\u003e\u0026#39;type\u0026#39;:\u003c/span\u003e \u003cspan\u003e\u0026#39;platform.report\u0026#39;,\u003c/span\u003e \n\t\u003cspan\u003e\u0026#39;record\u0026#39;:\u003c/span\u003e \u003cspan\u003e{\u003c/span\u003e \u003cspan\u003e\u0026#39;requestId\u0026#39;:\u003c/span\u003e \u003cspan\u003e\u0026#39;79e64213-lp42-47ef-b130-6fd29f30148e\u0026#39;,\u003c/span\u003e \n\t\t\u003cspan\u003e\u0026#39;metrics\u0026#39;:\u003c/span\u003e \u003cspan\u003e{\u003c/span\u003e \u003cspan\u003e\u0026#39;durationMs\u0026#39;:\u003c/span\u003e \u003cspan\u003e4.01,\u003c/span\u003e \n\t\t\t\u003cspan\u003e\u0026#39;billedDurationMs\u0026#39;:\u003c/span\u003e \u003cspan\u003e5,\u003c/span\u003e \n\t\t\t\u003cspan\u003e\u0026#39;memorySizeMB\u0026#39;:\u003c/span\u003e \u003cspan\u003e512,\u003c/span\u003e \n\t\t\t\u003cspan\u003e\u0026#39;maxMemoryUsedMB\u0026#39;:\u003c/span\u003e \u003cspan\u003e87,\u003c/span\u003e \n\t\t\t\u003cspan\u003e\u0026#39;initDurationMs\u0026#39;:\u003c/span\u003e \u003cspan\u003e2.41\u003c/span\u003e\n\t\t\u003cspan\u003e}\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e \n\t\u003cspan\u003e}\u003c/span\u003e\n\u003cspan\u003e}]\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eBy default, Lambda logs are sent asynchronously to Amazon’s built-in log management service, \u003ca href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html\"\u003eCloudWatch Logs\u003c/a\u003e. Each time you create a new function, CloudWatch Logs generates a new log group (\u003ccode\u003e/aws/lambda/your-function-name\u003c/code\u003e) and log stream. If you create more instances of your function to support more concurrent executions, new log streams will be created under the same log group.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"See a list of your Lambda log groups in Amazon CloudWatch\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch3 id=\"amazon-api-gateway-logs\"\u003e\u003ca href=\"#amazon-api-gateway-logs\"\u003eAmazon API Gateway logs\u003c/a\u003e\u003c/h3\u003e\u003cp\u003e\u003ca href=\"https://aws.amazon.com/api-gateway/\"\u003eAmazon API Gateway\u003c/a\u003e allows developers to create APIs that act as the front door to backend services, such as Lambda functions, which are hosted across different machines. API Gateway emits two types of logs: execution logs and access logs. \u003cstrong\u003eExecution logs\u003c/strong\u003e document the steps API Gateway takes to process a request. In these logs, you can see details of requests to APIs along with the responses from \u003ca href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-integration-settings-integration-response.html\"\u003eintegration backends\u003c/a\u003e and \u003ca href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-use-lambda-authorizer.html\"\u003eLambda authorizers\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eOn the other hand, \u003cstrong\u003eaccess logs\u003c/strong\u003e help you identify who accessed your API (e.g., source IP, user) and how they accessed it (e.g., HTTP method, resource path). Unlike execution logs, which are managed by API Gateway, access logs are controlled by the developer. This means that you can flexibly customize the content of your access logs and choose which log group to send them to. We will elaborate on the fields we recommend adding to your access logs \u003ca href=\"#include-useful-information-in-your-logs\"\u003elater in this post\u003c/a\u003e.\u003c/p\u003e\u003ch3 id=\"amazon-dynamodb-logs\"\u003e\u003ca href=\"#amazon-dynamodb-logs\"\u003eAmazon DynamoDB logs\u003c/a\u003e\u003c/h3\u003e\u003cp\u003e\u003ca href=\"https://aws.amazon.com/dynamodb/\"\u003eAmazon DynamoDB\u003c/a\u003e is a popular key-value and document database that provides low-latency data access at scale, which makes it well-suited for serverless applications. DynamoDB captures table modifications in a \u003ca href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html\"\u003estream\u003c/a\u003e, which Lambda polls in order to trigger the appropriate function when a new record is added. DynamoDB integrates out-of-the-box with \u003ca href=\"https://aws.amazon.com/cloudtrail/\"\u003eAWS CloudTrail\u003c/a\u003e, which captures API calls to and from DynamoDB and sends them as logs to an Amazon S3 bucket. You can either view these logs in the CloudTrail console or forward them to CloudWatch Logs.\u003c/p\u003e\u003cp\u003eBy default, CloudTrail only logs \u003ca href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/logging-using-cloudtrail.html#ddb-control-plane-events-in-cloudtrail\"\u003econtrol plane events\u003c/a\u003e, such as when a table is created or deleted. If you’d like to record \u003ca href=\"https://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-data-events-with-cloudtrail.html\"\u003edata plane events\u003c/a\u003e, such as when an item is written or retrieved from a table, you will need to \u003ca href=\"https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-create-a-trail-using-the-console-first-time.html\"\u003ecreate a separate trail\u003c/a\u003e. Each log entry contains details of the activity performed (e.g., event name, table name, key) along with the identity of the user that performed the action (e.g., account ID, ARN). And if a request fails, you can pinpoint whether it was because of an issue with the request itself (4xx error) or with AWS (5xx error).\u003c/p\u003e\u003ch3 id=\"aws-step-functions-logs\"\u003e\u003ca href=\"#aws-step-functions-logs\"\u003eAWS Step Functions logs\u003c/a\u003e\u003c/h3\u003e\u003cp\u003e\u003ca href=\"https://aws.amazon.com/step-functions/?step-functions.sort-by=item.additionalFields.postDateTime\u0026amp;step-functions.sort-order=desc\"\u003eAWS Step Functions\u003c/a\u003e allows you to create more complex workflows (or state machines) that incorporate multiple functions and AWS services, which can be helpful when you begin adding functionality to your serverless applications. As a state machine executes, it transitions between different states, including \u003ca href=\"https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-task-state.html\"\u003eTask\u003c/a\u003e, \u003ca href=\"https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-choice-state.html\"\u003eChoice\u003c/a\u003e, \u003ca href=\"https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-fail-state.html\"\u003eFail\u003c/a\u003e, and \u003ca href=\"https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-pass-state.html\"\u003ePass\u003c/a\u003e. Step Functions logs record the full history of your state machine’s execution, so they are useful for troubleshooting any failures that crop up. For instance, these logs enable you to pinpoint exactly when (i.e., at which state) the failure occurred and whether it was caused by a Lambda function exception, state machine misconfiguration, or a different issue altogether.\u003c/p\u003e\u003ch2 id=\"best-practices-for-aws-serverless-logging\"\u003e\u003ca href=\"#best-practices-for-aws-serverless-logging\"\u003eBest practices for AWS serverless logging\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn this section, we’ll recommend a few best practices for collecting and managing logs to help you get deep visibility into your AWS serverless applications.\u003c/p\u003e\u003ch3 id=\"standardize-the-format-of-your-logs-with-a-logging-library\"\u003e\u003ca href=\"#standardize-the-format-of-your-logs-with-a-logging-library\"\u003eStandardize the format of your logs with a logging library\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eAs we discussed, serverless environments generate many types of logs, which presents several challenges when it comes to standardization. For instance, Lambda function logs that are generated by Python’s \u003ccode\u003eprint()\u003c/code\u003e function are typically unstructured, so they are difficult to query in a systematic way. And while you can parse them with a tool like \u003ca href=\"https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html\"\u003egrok\u003c/a\u003e, it can be cumbersome to define custom regular expressions or filter patterns that apply to every type of log your application generates.\u003c/p\u003e\u003cp\u003eInstead, you should have your application write every log in a structured format like JSON, which is both more human- and machine-readable. Logging in JSON format also ensures that multi-line logs are processed as a single CloudWatch Logs event, which helps you avoid having related information distributed across multiple events. Additionally, JSON supports the addition of custom metadata (e.g., team, environment, request ID) that you can use to search, filter, and aggregate your logs.\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"json\"\u003e \n\u003cspan\u003e{\u003c/span\u003e\n    \u003cspan\u003e\u0026#34;level\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;INFO\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n    \u003cspan\u003e\u0026#34;message\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;Collecting payment\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n    \u003cspan\u003e\u0026#34;timestamp\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;2021-05-03 11:47:12,494+0200\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n    \u003cspan\u003e\u0026#34;service\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;payment\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n    \u003cspan\u003e\u0026#34;team\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;payment-infra\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n    \u003cspan\u003e\u0026#34;cold_start\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003etrue\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n    \u003cspan\u003e\u0026#34;lambda_function_name\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;test\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n    \u003cspan\u003e\u0026#34;lambda_function_memory_size\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e128\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n    \u003cspan\u003e\u0026#34;lambda_function_arn\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;arn:aws:lambda:eu-west-1:12345678910:function:test\u0026#34;\u003c/span\u003e\u003cspan\u003e,\u003c/span\u003e\n    \u003cspan\u003e\u0026#34;lambda_request_id\u0026#34;\u003c/span\u003e\u003cspan\u003e:\u003c/span\u003e \u003cspan\u003e\u0026#34;23fdfc09-2002-154e-183a-5p0f9a611d02\u0026#34;\u003c/span\u003e\n\u003cspan\u003e}\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThere are various logging libraries that you can use to collect logs from your AWS serverless environments, such as \u003ca href=\"https://www.npmjs.com/package/lambda-log\"\u003e\u003ccode\u003elambda-log\u003c/code\u003e\u003c/a\u003e, \u003ca href=\"https://pypi.org/project/aws-lambda-logging/\"\u003e\u003ccode\u003eaws-logging-library\u003c/code\u003e\u003c/a\u003e, and \u003ca href=\"https://logging.apache.org/log4j/2.x/\"\u003eLog4j2\u003c/a\u003e (with the \u003ca href=\"https://github.com/aws/aws-lambda-java-libs/tree/master/aws-lambda-java-log4j2\"\u003e\u003ccode\u003eaws-lambda-java-log4j2\u003c/code\u003e\u003c/a\u003e appender). Many of these libraries are lightweight, which helps reduce cold start times, and write logs in JSON by default. They can also be flexibly configured to route your logs to multiple destinations and log at different levels (which we will discuss in the next section).\u003c/p\u003e\u003ch3 id=\"log-at-the-appropriate-level-for-your-environment\"\u003e\u003ca href=\"#log-at-the-appropriate-level-for-your-environment\"\u003eLog at the appropriate level for your environment\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eLog levels categorize how important a particular log message is. For instance, Log4j2 uses the following levels, in addition to any \u003ca href=\"https://logging.apache.org/log4j/2.x/manual/customloglevels.html\"\u003ecustom levels\u003c/a\u003e you configure, to categorize logs from the most to least severe:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ccode\u003eFATAL\u003c/code\u003e: Indicates a severe issue that might cause the application to terminate\u003c/li\u003e\u003cli\u003e\u003ccode\u003eERROR\u003c/code\u003e: Indicates a serious problem that should be investigated, although the application might still continue to operate\u003c/li\u003e\u003cli\u003e\u003ccode\u003eWARN\u003c/code\u003e: Designates unexpected issues that are potentially adverse\u003c/li\u003e\u003cli\u003e\u003ccode\u003eINFO\u003c/code\u003e: Records information on routine application operations\u003c/li\u003e\u003cli\u003e\u003ccode\u003eDEBUG\u003c/code\u003e: Records granular informational events for debugging purposes\u003c/li\u003e\u003cli\u003e\u003ccode\u003eTRACE\u003c/code\u003e: Designates informational events at an even more granular level than \u003ccode\u003eDEBUG\u003c/code\u003e\u003c/li\u003e\u003cli\u003e\u003ccode\u003eALL\u003c/code\u003e: Collects all logs\u003c/li\u003e\u003cli\u003e\u003ccode\u003eOFF\u003c/code\u003e: Turns off logging\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eEach log level is inclusive of the levels above it; that is, if you choose \u003ccode\u003eWARN\u003c/code\u003e as your logging level, you will receive logs at the \u003ccode\u003eWARN\u003c/code\u003e, \u003ccode\u003eERROR\u003c/code\u003e, and \u003ccode\u003eFATAL\u003c/code\u003e levels. It’s important to choose the logging level that is as selective as possible for the environment you’re operating in. For instance, logging at a low level like \u003ccode\u003eDEBUG\u003c/code\u003e is appropriate for ironing out code-level issues in your local development environment, but it can be too noisy for production and staging environments, where you only want to surface the most critical issues. In those environments, it might be more fitting to set the log level to \u003ccode\u003eINFO\u003c/code\u003e so that you only see logs at the \u003ccode\u003eINFO\u003c/code\u003e, \u003ccode\u003eWARN\u003c/code\u003e, \u003ccode\u003eERROR\u003c/code\u003e, and \u003ccode\u003eFATAL\u003c/code\u003e levels.\u003c/p\u003e\u003ch3 id=\"include-useful-information-in-your-logs\"\u003e\u003ca href=\"#include-useful-information-in-your-logs\"\u003eInclude useful information in your logs\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eAnother best practice is to include sufficient context in your logs so that anyone on your team can easily understand and analyze them. At the very minimum, each log should include a timestamp, log level, identifier (e.g., request ID, customer ID), and descriptive message. As we discussed above, Log4j2 makes it easy to add log levels, and it also includes an appender that adds request IDs to your Lambda logs by default. This enables you to quickly drill down to entries generated, for example, by a specific Lambda invocation or API request.\u003c/p\u003e\u003cp\u003eIt’s also worth noting that of the types of logs we discussed \u003ca href=\"#understanding-the-types-of-logs-that-aws-serverless-technologies-generate\"\u003eearlier in this post\u003c/a\u003e, API Gateway access logs are unique in that they are managed by the developer, instead of Amazon. API Gateway provides more than 80 \u003ca href=\"https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-mapping-template-reference.html\"\u003e$context variables\u003c/a\u003e, which you can use to flexibly customize the content of your access logs. There are three main categories of information you should include, and we list some of the most useful variables for each category below:\u003c/p\u003e\u003ch4 id=\"requests\"\u003e\u003ca href=\"#requests\"\u003eRequests\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eThe first category is related to requests made to API Gateway. These fields can help you pinpoint problematic endpoints that could be causing issues, such as a spike in API Gateway response errors.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ccode\u003erequestTime\u003c/code\u003e: The timestamp of the request\u003c/li\u003e\u003cli\u003e\u003ccode\u003erequestId\u003c/code\u003e: The API request ID given by API Gateway\u003c/li\u003e\u003cli\u003e\u003ccode\u003ehttpMethod\u003c/code\u003e: The HTTP method used (e.g., DELETE, GET, POST, PUT)\u003c/li\u003e\u003cli\u003e\u003ccode\u003eresourcePath\u003c/code\u003e: The path to your resource (e.g., \u003ccode\u003e/root/child\u003c/code\u003e)\u003c/li\u003e\u003cli\u003e\u003ccode\u003estatus\u003c/code\u003e: The status code of the response\u003c/li\u003e\u003cli\u003e\u003ccode\u003eresponseLatency\u003c/code\u003e: The amount of time API Gateway took to respond to the request (in milliseconds)\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThe next category records information about the client and Lambda authorizers, which are functions that control access to your APIs. When a client makes an API request, API Gateway calls your Lambda authorizer, which authenticates the client and returns an IAM policy. You can use the fields below as a starting point when you need to investigate whether a request failed because the client lacked the necessary permissions or the authorizer was not properly functioning.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ccode\u003eauthorizer.requestId\u003c/code\u003e: The Lambda invocation request ID\u003c/li\u003e\u003cli\u003e\u003ccode\u003eauthorizer.status\u003c/code\u003e: The status code returned by an authorizer, which indicates whether the authorizer responded successfully\u003c/li\u003e\u003cli\u003e\u003ccode\u003eauthorize.status\u003c/code\u003e: The status code returned from an authorization attempt, which indicates whether the authorizer allowed or denied the request\u003c/li\u003e\u003cli\u003e\u003ccode\u003eauthorizer.latency\u003c/code\u003e: The amount of time the authorizer took (in milliseconds) to run\u003c/li\u003e\u003cli\u003e\u003ccode\u003eidentity.user\u003c/code\u003e: The principal identifier of the IAM user that made the request\u003c/li\u003e\u003cli\u003e\u003ccode\u003eidentity.sourceIP\u003c/code\u003e: The source IP address of the TCP connection making the request to API Gateway endpoint\u003c/li\u003e\u003c/ul\u003e\u003ch4 id=\"integration\"\u003e\u003ca href=\"#integration\"\u003eIntegration\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eLast but not least, it is important to log about your integration endpoints, which process requests to API Gateway. Each API method integrates with an endpoint in the backend, which can be a Lambda function, a different AWS service, or a HTTP web page.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ccode\u003eintegration.requestId\u003c/code\u003e: The integration’s request ID\u003c/li\u003e\u003cli\u003e\u003ccode\u003eintegration.status\u003c/code\u003e: The status code returned by the integration’s code\u003c/li\u003e\u003cli\u003e\u003ccode\u003eintegration.integrationStatus\u003c/code\u003e: The status code returned by the integration service\u003c/li\u003e\u003cli\u003e\u003ccode\u003eintegration.error\u003c/code\u003e: The error message returned by the integration\u003c/li\u003e\u003cli\u003e\u003ccode\u003eintegration.latency\u003c/code\u003e: The amount of time the integration took (in milliseconds) to run\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"centralize-your-aws-serverless-logs-with-datadog\"\u003e\u003ca href=\"#centralize-your-aws-serverless-logs-with-datadog\"\u003eCentralize your AWS serverless logs with Datadog\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eAs your serverless applications become more complex and generate more logs over time, it can be challenging to find what you need to troubleshoot an issue. By centralizing all of your logs in one platform, you can easily analyze and correlate them with other types of monitoring data in order to identify the root cause. CloudWatch Logs provides quick insight into logs from \u003ca href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/aws-services-sending-logs.html\"\u003emany AWS services\u003c/a\u003e by default, but third-party observability tools like Datadog enable you to perform more sophisticated visualization, alerting, and analysis.\u003c/p\u003e\u003cp\u003eYou can send Lambda logs directly to Datadog—without having to forward them from CloudWatch Logs—by deploying the \u003ca href=\"https://docs.datadoghq.com/serverless/libraries_integrations/extension/\"\u003eDatadog Lambda extension\u003c/a\u003e as a Lambda Layer across all of your Python and Node.js functions. To submit logs from your Lambda integrations to Datadog, you’ll need to install the Datadog Forwarder Lambda function and subscribe it to your CloudWatch Logs log groups, as detailed in our \u003ca href=\"https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-lambda-function/?tab=awsconsole\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eOnce you’ve configured Datadog to collect logs from your serverless environment, you can begin exploring and analyzing them in real time in the \u003ca href=\"https://app.datadoghq.com/logs\"\u003eLog Explorer\u003c/a\u003e. Datadog’s built-in log processing pipelines automatically extract metadata from your logs and turn them into tags, which you can use to slice and dice your data.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"View and explore all your AWS serverless logs in the Log Explorer\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYou can also use the \u003ca href=\"https://app.datadoghq.com/functions\"\u003eServerless view\u003c/a\u003e to see all the logs generated during a specific function invocation.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"View logs for each function invocation in the Serverless view\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eDatadog correlates your logs with distributed traces and metrics, including those from your containerized and on-premise workloads, to give you a full picture of your application’s performance. For example, if your traces reveal that a request is slow because of an error in API Gateway, you can pivot seamlessly to the corresponding logs to further investigate the issue.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Correlate logs with traces in the Serverless view\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch3 id=\"control-your-logging-costs\"\u003e\u003ca href=\"#control-your-logging-costs\"\u003eControl your logging costs\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eLogs stored in CloudWatch Logs are retained indefinitely by default, which can become prohibitively expensive as your application grows. It is possible to adjust their retention period, but it can be difficult to know ahead of time which logs you will need and which ones are safe to discard. Datadog’s \u003ca href=\"https://www.datadoghq.com/blog/logging-without-limits/\"\u003eLogging without Limits™\u003c/a\u003e eliminates this tradeoff between cost and visibility by enabling you to ingest all of your logs and dynamically decide later on which ones to index.\u003c/p\u003e\u003cp\u003eFor instance, when you’re investigating the cause of high latency in your application, you can use Log Patterns to help you identify noisy log types that might be complicating your efforts, as shown in the example below. You can then add these logs to an exclusion filter to stop them from being indexed.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Use Log Patterns to identify noisy logs\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYou can still leverage the information in the logs you’ve chosen not to index by turning them into \u003ca href=\"https://www.datadoghq.com/blog/log-based-metrics/\"\u003emetrics\u003c/a\u003e, which can be tracked over the long term. This enables you to continue monitoring performance trends at the log level without incurring unnecessary indexing costs. And just like any other metric in Datadog, you can graph, alert on, and correlate log-based metrics with the rest of your application’s telemetry data.\u003c/p\u003e\u003ch2 id=\"start-monitoring-your-aws-serverless-logs-with-datadog\"\u003e\u003ca href=\"#start-monitoring-your-aws-serverless-logs-with-datadog\"\u003eStart monitoring your AWS serverless logs with Datadog\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn this post, we’ve seen how logs are indispensable for investigating issues in your AWS serverless applications. We’ve also shared some best practices for collecting and managing your logs to help you get deep visibility into your applications. Additionally, we showed you how you can cost-effectively send your serverless logs to Datadog—and correlate them with the rest of your telemetry data, all in one place. If you’re an existing Datadog customer, start monitoring your \u003ca href=\"https://docs.datadoghq.com/serverless/\"\u003eserverless applications\u003c/a\u003e today. Otherwise, sign up for a 14-day \u003ca href=\"#\"\u003efree trial\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-logs_best-practices_210720_FINAL.png\" width=\"100%\"/\u003eLogs are an essential part of an effective monitoring strategy, as they provide granular information about activity that occurs anywhere in your system. In serverless environments, however, you have no access to the infrastructure that supports your applications, so you must rely entirely on logs from individual AWS services when troubleshooting performance issues. But serverless applications can generate a massive amount of logs, which introduces storage concerns and makes it difficult to see the forest through the trees.",
      "date_published": "2021-08-23T00:00:00Z",
      "author": {
        "name": "Kai Xin Tai"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/linux-security-threat-detection-datadog/",
      "title": "How to detect security threats in your systems' Linux processes",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eAlmost all tasks within a Linux system, whether it’s an application, system daemon, or certain types of user activity, are executed by one or more \u003ca href=\"https://tldp.org/LDP/tlk/kernel/processes.html\"\u003eprocesses\u003c/a\u003e. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we’ll look at:\u003c/p\u003e\u003cul\u003e\u003cli\u003ehow \u003ca href=\"#a-primer-on-the-process-tree\"\u003eunderstanding the Linux process tree\u003c/a\u003e can help you identify security threats\u003c/li\u003e\u003cli\u003ewhat \u003ca href=\"#use-process-data-to-determine-the-scope-of-an-attack\"\u003eprocess information\u003c/a\u003e can help you determine the scope of a breach\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe’ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.\u003c/p\u003e\u003ch2 id=\"a-primer-on-the-process-tree\"\u003e\u003ca href=\"#a-primer-on-the-process-tree\"\u003eA primer on the process tree\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn Linux, each process is generated by a preceding \u003cstrong\u003eparent\u003c/strong\u003e process and can generate one or more \u003cstrong\u003echild\u003c/strong\u003e processes. Following this parent/child structure, active processes form a \u003cstrong\u003eprocess tree\u003c/strong\u003e that starts with the \u003ccode\u003esystemd\u003c/code\u003e process that runs when Linux first boots and ends with the most recently generated processes. This parent/child structure is particularly useful for revealing security threats because, unlike simple indicators of compromise (IOCs) like adversarial IP addresses or file hashes, it’s difficult to fake or change. For instance, while attackers can change an IP address, it’s much harder to hide that an application has spawned a new suspicious child process.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"process-tree.png\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eActive processes are structured as a process tree which can be used to help you spot signs of a security breach.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"identify-suspicious-processes\"\u003e\u003ca href=\"#identify-suspicious-processes\"\u003eIdentify suspicious processes\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAs you monitor your applications, it’s important to look out for any launched shells or utilities (e.g., \u003ccode\u003ebash\u003c/code\u003e or \u003ccode\u003ecurl\u003c/code\u003e) that are children of key processes in your environment. For example, if a Java application process generates a shell you aren’t anticipating, it could indicate that a malicious actor has infiltrated your app and launched a \u003ca href=\"https://us-cert.cisa.gov/ncas/alerts/TA15-314A\"\u003eweb shell attack\u003c/a\u003e. When these attacks are successful, they can create backdoors to your infrastructure that allow attackers to access sensitive data and execute commands without authorization.\u003c/p\u003e\u003cp\u003eLikewise, you should check if a process spawned utilities like \u003ccode\u003enmap\u003c/code\u003e, which an attacker can use to survey your network for further vulnerabilities to exploit, or \u003ccode\u003epasswd\u003c/code\u003e, which can be used to change user passwords and grant attackers higher privileges.\u003c/p\u003e\u003cp\u003eOnce you’ve identified a malicious process, it’s important to investigate the scope of the attack, including what information the attacker has potentially gained access to.\u003c/p\u003e\u003ch2 id=\"use-process-data-to-determine-the-scope-of-an-attack\"\u003e\u003ca href=\"#use-process-data-to-determine-the-scope-of-an-attack\"\u003eUse process data to determine the scope of an attack\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eLinux processes include metadata that can help you determine the scope of an attack. The key types of information to look at are:\u003c/p\u003e\u003cul\u003e\u003cli\u003eenvironment variables\u003c/li\u003e\u003cli\u003ecommand-line arguments\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"environment-variables\"\u003e\u003ca href=\"#environment-variables\"\u003eEnvironment variables\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eDue to their \u003ca href=\"#a-primer-on-the-process-tree\"\u003erelationship\u003c/a\u003e, child processes inherit access to any environment variables available to the parent process. Though it’s not considered best practice, environment variables are often used to store sensitive data like API and GitHub keys, or even database credentials. Using our example of an attacker successfully creating a web shell from a Java application process, the shell would be able to see any environment variables associated with your application process, such as database credentials for a SQL server containing sensitive customer data.\u003c/p\u003e\u003cp\u003eExamining what environment variables a process includes can help you determine the full scope of a threat. You can quickly view a list of a process’s environment variables by using the Linux command \u003ccode\u003eps faux\u003c/code\u003e to get its PID and then running the following:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003ecat /proc/\u0026lt;PROCESS_PID\u0026gt;/environ \u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003ePlease note, however, that this detection method only works while the process is running. This makes it challenging to view potential attacks without a \u003ca href=\"#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003econtinuous monitoring\u003c/a\u003e tool.\u003c/p\u003e\u003ch3 id=\"command-line-arguments\"\u003e\u003ca href=\"#command-line-arguments\"\u003eCommand-line arguments\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eIn addition to environment variables, it’s important to know what command-line arguments an attacker used when starting a malicious process. Command-line arguments hold information that’s critical to determining the nature of a security threat. Arguments may include identifying data like the IP address an attacker used when they issued a \u003ccode\u003ecurl\u003c/code\u003e command to download a malicious payload, as well as activity data like \u003ca href=\"https://stackabuse.com/encoding-and-decoding-base64-strings-in-python\"\u003eencoded Python scripts\u003c/a\u003e that were run directly in the command line. Insight into a process’s command-line arguments can help you view what occurred during an attack so you can plan how to respond.\u003c/p\u003e\u003cp\u003eFor a quick look at a process’s command line arguments, get its PID and run a command like the following:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003eps -p \u0026lt;PROCESS_PID\u0026gt; -o args\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThis approach, however, is limited because you need to be able to catch the process before it terminates. Next, we’ll look at how Datadog’s Cloud Workload Security helps you detect attacks and view relevant metadata.\u003c/p\u003e\u003ch2 id=\"detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003e\u003ca href=\"#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003eDetect threats in your Linux processes with Datadog Cloud Workload Security\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/\"\u003eCloud Workload Security (CWS)\u003c/a\u003e analyzes the full process tree across all your Linux hosts and containers in real time to automatically detect the kind of threats we’ve looked at. Datadog includes \u003ca href=\"https://docs.datadoghq.com/security_platform/default_rules/#cat-workload-security\"\u003eout-of-the-box workload threat detection rules\u003c/a\u003e that help you immediately respond to potential security threats by flagging suspicious behavior like the execution of \u003ccode\u003epasswd\u003c/code\u003e and \u003ccode\u003enmap\u003c/code\u003e utilities.\u003c/p\u003e\u003cp\u003eIn addition to out-of-the-box workload security rules, Datadog enables you to write your own custom rules. Security rules are constructed with \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/agent_expressions/\"\u003e\u003cstrong\u003eAgent Expressions\u003c/strong\u003e\u003c/a\u003e that enable you to define what process activity to look for with as much specificity as you want. For example, you can instruct Datadog to detect if a Java process generated a \u003ccode\u003ebash\u003c/code\u003e shell, or even watch for processes run with specific command-line arguments. To learn more about how to construct your own custom workload security rules, check out our \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/workload_security_rules/\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIf Datadog detects any processes that match a rule, it will generate a \u003ca href=\"https://docs.datadoghq.com/security_platform/security_monitoring/getting_started/#explore-security-signals\"\u003eSecurity Signal\u003c/a\u003e. Security Signals include full context around the suspicious process, including environment variable keys (without collecting the associated values), command-line arguments, and other metadata. You can use this information to quickly determine the scope of an attack before planning your response.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Security signals include environment variables and command-line arguments which can help you determine the scope of security attacks.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"start-today\"\u003e\u003ca href=\"#start-today\"\u003eStart today\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eNo matter which distribution you work with, processes are at the heart of any Linux system. In this post, we looked at how understanding processes and their relationships can help you spot suspicious behavior and determine the severity of a security breach. Datadog Cloud Workload Security monitors process activity throughout your infrastructure at the kernel level in real time to reveal any suspicious or malicious behavior. Read our \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/getting_started/?tab=kubernetes\"\u003edocumentation\u003c/a\u003e to learn more or sign up today for a 14-day \u003ca href=\"#\"\u003efree trial.\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/linux-process-hero.png\" width=\"100%\"/\u003eAlmost all tasks within a Linux system, whether it\u0026rsquo;s an application, system daemon, or certain types of user activity, are executed by one or more processes. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we\u0026rsquo;ll look at: how understanding the Linux process tree can help you identify security threats what process information can help you determine the scope of a breach We\u0026rsquo;ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.",
      "date_published": "2021-08-19T00:00:00Z",
      "author": {
        "name": "Jordan Obey"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/linux-security-threat-detection-datadog/",
      "title": "How to detect security threats in your systems' Linux processes",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eAlmost all tasks within a Linux system, whether it’s an application, system daemon, or certain types of user activity, are executed by one or more \u003ca href=\"https://tldp.org/LDP/tlk/kernel/processes.html\"\u003eprocesses\u003c/a\u003e. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we’ll look at:\u003c/p\u003e\u003cul\u003e\u003cli\u003ehow \u003ca href=\"#a-primer-on-the-process-tree\"\u003eunderstanding the Linux process tree\u003c/a\u003e can help you identify security threats\u003c/li\u003e\u003cli\u003ewhat \u003ca href=\"#use-process-data-to-determine-the-scope-of-an-attack\"\u003eprocess information\u003c/a\u003e can help you determine the scope of a breach\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe’ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.\u003c/p\u003e\u003ch2 id=\"a-primer-on-the-process-tree\"\u003e\u003ca href=\"#a-primer-on-the-process-tree\"\u003eA primer on the process tree\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn Linux, each process is generated by a preceding \u003cstrong\u003eparent\u003c/strong\u003e process and can generate one or more \u003cstrong\u003echild\u003c/strong\u003e processes. Following this parent/child structure, active processes form a \u003cstrong\u003eprocess tree\u003c/strong\u003e that starts with the \u003ccode\u003esystemd\u003c/code\u003e process that runs when Linux first boots and ends with the most recently generated processes. This parent/child structure is particularly useful for revealing security threats because, unlike simple indicators of compromise (IOCs) like adversarial IP addresses or file hashes, it’s difficult to fake or change. For instance, while attackers can change an IP address, it’s much harder to hide that an application has spawned a new suspicious child process.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"process-tree.png\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eActive processes are structured as a process tree which can be used to help you spot signs of a security breach.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"identify-suspicious-processes\"\u003e\u003ca href=\"#identify-suspicious-processes\"\u003eIdentify suspicious processes\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAs you monitor your applications, it’s important to look out for any launched shells or utilities (e.g., \u003ccode\u003ebash\u003c/code\u003e or \u003ccode\u003ecurl\u003c/code\u003e) that are children of key processes in your environment. For example, if a Java application process generates a shell you aren’t anticipating, it could indicate that a malicious actor has infiltrated your app and launched a \u003ca href=\"https://us-cert.cisa.gov/ncas/alerts/TA15-314A\"\u003eweb shell attack\u003c/a\u003e. When these attacks are successful, they can create backdoors to your infrastructure that allow attackers to access sensitive data and execute commands without authorization.\u003c/p\u003e\u003cp\u003eLikewise, you should check if a process spawned utilities like \u003ccode\u003enmap\u003c/code\u003e, which an attacker can use to survey your network for further vulnerabilities to exploit, or \u003ccode\u003epasswd\u003c/code\u003e, which can be used to change user passwords and grant attackers higher privileges.\u003c/p\u003e\u003cp\u003eOnce you’ve identified a malicious process, it’s important to investigate the scope of the attack, including what information the attacker has potentially gained access to.\u003c/p\u003e\u003ch2 id=\"use-process-data-to-determine-the-scope-of-an-attack\"\u003e\u003ca href=\"#use-process-data-to-determine-the-scope-of-an-attack\"\u003eUse process data to determine the scope of an attack\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eLinux processes include metadata that can help you determine the scope of an attack. The key types of information to look at are:\u003c/p\u003e\u003cul\u003e\u003cli\u003eenvironment variables\u003c/li\u003e\u003cli\u003ecommand-line arguments\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"environment-variables\"\u003e\u003ca href=\"#environment-variables\"\u003eEnvironment variables\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eDue to their \u003ca href=\"#a-primer-on-the-process-tree\"\u003erelationship\u003c/a\u003e, child processes inherit access to any environment variables available to the parent process. Though it’s not considered best practice, environment variables are often used to store sensitive data like API and GitHub keys, or even database credentials. Using our example of an attacker successfully creating a web shell from a Java application process, the shell would be able to see any environment variables associated with your application process, such as database credentials for a SQL server containing sensitive customer data.\u003c/p\u003e\u003cp\u003eExamining what environment variables a process includes can help you determine the full scope of a threat. You can quickly view a list of a process’s environment variables by using the Linux command \u003ccode\u003eps faux\u003c/code\u003e to get its PID and then running the following:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003ecat /proc/\u0026lt;PROCESS_PID\u0026gt;/environ \u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003ePlease note, however, that this detection method only works while the process is running. This makes it challenging to view potential attacks without a \u003ca href=\"#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003econtinuous monitoring\u003c/a\u003e tool.\u003c/p\u003e\u003ch3 id=\"command-line-arguments\"\u003e\u003ca href=\"#command-line-arguments\"\u003eCommand-line arguments\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eIn addition to environment variables, it’s important to know what command-line arguments an attacker used when starting a malicious process. Command-line arguments hold information that’s critical to determining the nature of a security threat. Arguments may include identifying data like the IP address an attacker used when they issued a \u003ccode\u003ecurl\u003c/code\u003e command to download a malicious payload, as well as activity data like \u003ca href=\"https://stackabuse.com/encoding-and-decoding-base64-strings-in-python\"\u003eencoded Python scripts\u003c/a\u003e that were run directly in the command line. Insight into a process’s command-line arguments can help you view what occurred during an attack so you can plan how to respond.\u003c/p\u003e\u003cp\u003eFor a quick look at a process’s command line arguments, get its PID and run a command like the following:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003eps -p \u0026lt;PROCESS_PID\u0026gt; -o args\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThis approach, however, is limited because you need to be able to catch the process before it terminates. Next, we’ll look at how Datadog’s Cloud Workload Security helps you detect attacks and view relevant metadata.\u003c/p\u003e\u003ch2 id=\"detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003e\u003ca href=\"#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003eDetect threats in your Linux processes with Datadog Cloud Workload Security\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/\"\u003eCloud Workload Security (CWS)\u003c/a\u003e analyzes the full process tree across all your Linux hosts and containers in real time to automatically detect the kind of threats we’ve looked at. Datadog includes \u003ca href=\"https://docs.datadoghq.com/security_platform/default_rules/#cat-workload-security\"\u003eout-of-the-box workload threat detection rules\u003c/a\u003e that help you immediately respond to potential security threats by flagging suspicious behavior like the execution of \u003ccode\u003epasswd\u003c/code\u003e and \u003ccode\u003enmap\u003c/code\u003e utilities.\u003c/p\u003e\u003cp\u003eIn addition to out-of-the-box workload security rules, Datadog enables you to write your own custom rules. Security rules are constructed with \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/agent_expressions/\"\u003e\u003cstrong\u003eAgent Expressions\u003c/strong\u003e\u003c/a\u003e that enable you to define what process activity to look for with as much specificity as you want. For example, you can instruct Datadog to detect if a Java process generated a \u003ccode\u003ebash\u003c/code\u003e shell, or even watch for processes run with specific command-line arguments. To learn more about how to construct your own custom workload security rules, check out our \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/workload_security_rules/\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIf Datadog detects any processes that match a rule, it will generate a \u003ca href=\"https://docs.datadoghq.com/security_platform/security_monitoring/getting_started/#explore-security-signals\"\u003eSecurity Signal\u003c/a\u003e. Security Signals include full context around the suspicious process, including environment variable keys (without collecting the associated values), command-line arguments, and other metadata. You can use this information to quickly determine the scope of an attack before planning your response.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Security signals include environment variables and command-line arguments which can help you determine the scope of security attacks.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"start-today\"\u003e\u003ca href=\"#start-today\"\u003eStart today\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eNo matter which distribution you work with, processes are at the heart of any Linux system. In this post, we looked at how understanding processes and their relationships can help you spot suspicious behavior and determine the severity of a security breach. Datadog Cloud Workload Security monitors process activity throughout your infrastructure at the kernel level in real time to reveal any suspicious or malicious behavior. Read our \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/getting_started/?tab=kubernetes\"\u003edocumentation\u003c/a\u003e to learn more or sign up today for a 14-day \u003ca href=\"#\"\u003efree trial.\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/linux-process-hero.png\" width=\"100%\"/\u003eAlmost all tasks within a Linux system, whether it\u0026rsquo;s an application, system daemon, or certain types of user activity, are executed by one or more processes. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we\u0026rsquo;ll look at: how understanding the Linux process tree can help you identify security threats what process information can help you determine the scope of a breach We\u0026rsquo;ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.",
      "date_published": "2021-08-19T00:00:00Z",
      "author": {
        "name": "Jordan Obey"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/linux-security-threat-detection-datadog/",
      "title": "How to detect security threats in your systems' Linux processes",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eAlmost all tasks within a Linux system, whether it’s an application, system daemon, or certain types of user activity, are executed by one or more \u003ca href=\"https://tldp.org/LDP/tlk/kernel/processes.html\"\u003eprocesses\u003c/a\u003e. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we’ll look at:\u003c/p\u003e\u003cul\u003e\u003cli\u003ehow \u003ca href=\"#a-primer-on-the-process-tree\"\u003eunderstanding the Linux process tree\u003c/a\u003e can help you identify security threats\u003c/li\u003e\u003cli\u003ewhat \u003ca href=\"#use-process-data-to-determine-the-scope-of-an-attack\"\u003eprocess information\u003c/a\u003e can help you determine the scope of a breach\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe’ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.\u003c/p\u003e\u003ch2 id=\"a-primer-on-the-process-tree\"\u003e\u003ca href=\"#a-primer-on-the-process-tree\"\u003eA primer on the process tree\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn Linux, each process is generated by a preceding \u003cstrong\u003eparent\u003c/strong\u003e process and can generate one or more \u003cstrong\u003echild\u003c/strong\u003e processes. Following this parent/child structure, active processes form a \u003cstrong\u003eprocess tree\u003c/strong\u003e that starts with the \u003ccode\u003esystemd\u003c/code\u003e process that runs when Linux first boots and ends with the most recently generated processes. This parent/child structure is particularly useful for revealing security threats because, unlike simple indicators of compromise (IOCs) like adversarial IP addresses or file hashes, it’s difficult to fake or change. For instance, while attackers can change an IP address, it’s much harder to hide that an application has spawned a new suspicious child process.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"process-tree.png\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eActive processes are structured as a process tree which can be used to help you spot signs of a security breach.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"identify-suspicious-processes\"\u003e\u003ca href=\"#identify-suspicious-processes\"\u003eIdentify suspicious processes\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAs you monitor your applications, it’s important to look out for any launched shells or utilities (e.g., \u003ccode\u003ebash\u003c/code\u003e or \u003ccode\u003ecurl\u003c/code\u003e) that are children of key processes in your environment. For example, if a Java application process generates a shell you aren’t anticipating, it could indicate that a malicious actor has infiltrated your app and launched a \u003ca href=\"https://us-cert.cisa.gov/ncas/alerts/TA15-314A\"\u003eweb shell attack\u003c/a\u003e. When these attacks are successful, they can create backdoors to your infrastructure that allow attackers to access sensitive data and execute commands without authorization.\u003c/p\u003e\u003cp\u003eLikewise, you should check if a process spawned utilities like \u003ccode\u003enmap\u003c/code\u003e, which an attacker can use to survey your network for further vulnerabilities to exploit, or \u003ccode\u003epasswd\u003c/code\u003e, which can be used to change user passwords and grant attackers higher privileges.\u003c/p\u003e\u003cp\u003eOnce you’ve identified a malicious process, it’s important to investigate the scope of the attack, including what information the attacker has potentially gained access to.\u003c/p\u003e\u003ch2 id=\"use-process-data-to-determine-the-scope-of-an-attack\"\u003e\u003ca href=\"#use-process-data-to-determine-the-scope-of-an-attack\"\u003eUse process data to determine the scope of an attack\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eLinux processes include metadata that can help you determine the scope of an attack. The key types of information to look at are:\u003c/p\u003e\u003cul\u003e\u003cli\u003eenvironment variables\u003c/li\u003e\u003cli\u003ecommand-line arguments\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"environment-variables\"\u003e\u003ca href=\"#environment-variables\"\u003eEnvironment variables\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eDue to their \u003ca href=\"#a-primer-on-the-process-tree\"\u003erelationship\u003c/a\u003e, child processes inherit access to any environment variables available to the parent process. Though it’s not considered best practice, environment variables are often used to store sensitive data like API and GitHub keys, or even database credentials. Using our example of an attacker successfully creating a web shell from a Java application process, the shell would be able to see any environment variables associated with your application process, such as database credentials for a SQL server containing sensitive customer data.\u003c/p\u003e\u003cp\u003eExamining what environment variables a process includes can help you determine the full scope of a threat. You can quickly view a list of a process’s environment variables by using the Linux command \u003ccode\u003eps faux\u003c/code\u003e to get its PID and then running the following:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003ecat /proc/\u0026lt;PROCESS_PID\u0026gt;/environ \u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003ePlease note, however, that this detection method only works while the process is running. This makes it challenging to view potential attacks without a \u003ca href=\"#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003econtinuous monitoring\u003c/a\u003e tool.\u003c/p\u003e\u003ch3 id=\"command-line-arguments\"\u003e\u003ca href=\"#command-line-arguments\"\u003eCommand-line arguments\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eIn addition to environment variables, it’s important to know what command-line arguments an attacker used when starting a malicious process. Command-line arguments hold information that’s critical to determining the nature of a security threat. Arguments may include identifying data like the IP address an attacker used when they issued a \u003ccode\u003ecurl\u003c/code\u003e command to download a malicious payload, as well as activity data like \u003ca href=\"https://stackabuse.com/encoding-and-decoding-base64-strings-in-python\"\u003eencoded Python scripts\u003c/a\u003e that were run directly in the command line. Insight into a process’s command-line arguments can help you view what occurred during an attack so you can plan how to respond.\u003c/p\u003e\u003cp\u003eFor a quick look at a process’s command line arguments, get its PID and run a command like the following:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003eps -p \u0026lt;PROCESS_PID\u0026gt; -o args\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThis approach, however, is limited because you need to be able to catch the process before it terminates. Next, we’ll look at how Datadog’s Cloud Workload Security helps you detect attacks and view relevant metadata.\u003c/p\u003e\u003ch2 id=\"detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003e\u003ca href=\"#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003eDetect threats in your Linux processes with Datadog Cloud Workload Security\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/\"\u003eCloud Workload Security (CWS)\u003c/a\u003e analyzes the full process tree across all your Linux hosts and containers in real time to automatically detect the kind of threats we’ve looked at. Datadog includes \u003ca href=\"https://docs.datadoghq.com/security_platform/default_rules/#cat-workload-security\"\u003eout-of-the-box workload threat detection rules\u003c/a\u003e that help you immediately respond to potential security threats by flagging suspicious behavior like the execution of \u003ccode\u003epasswd\u003c/code\u003e and \u003ccode\u003enmap\u003c/code\u003e utilities.\u003c/p\u003e\u003cp\u003eIn addition to out-of-the-box workload security rules, Datadog enables you to write your own custom rules. Security rules are constructed with \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/agent_expressions/\"\u003e\u003cstrong\u003eAgent Expressions\u003c/strong\u003e\u003c/a\u003e that enable you to define what process activity to look for with as much specificity as you want. For example, you can instruct Datadog to detect if a Java process generated a \u003ccode\u003ebash\u003c/code\u003e shell, or even watch for processes run with specific command-line arguments. To learn more about how to construct your own custom workload security rules, check out our \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/workload_security_rules/\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIf Datadog detects any processes that match a rule, it will generate a \u003ca href=\"https://docs.datadoghq.com/security_platform/security_monitoring/getting_started/#explore-security-signals\"\u003eSecurity Signal\u003c/a\u003e. Security Signals include full context around the suspicious process, including environment variable keys (without collecting the associated values), command-line arguments, and other metadata. You can use this information to quickly determine the scope of an attack before planning your response.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Security signals include environment variables and command-line arguments which can help you determine the scope of security attacks.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"start-today\"\u003e\u003ca href=\"#start-today\"\u003eStart today\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eNo matter which distribution you work with, processes are at the heart of any Linux system. In this post, we looked at how understanding processes and their relationships can help you spot suspicious behavior and determine the severity of a security breach. Datadog Cloud Workload Security monitors process activity throughout your infrastructure at the kernel level in real time to reveal any suspicious or malicious behavior. Read our \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/getting_started/?tab=kubernetes\"\u003edocumentation\u003c/a\u003e to learn more or sign up today for a 14-day \u003ca href=\"#\"\u003efree trial.\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/linux-process-hero.png\" width=\"100%\"/\u003eAlmost all tasks within a Linux system, whether it\u0026rsquo;s an application, system daemon, or certain types of user activity, are executed by one or more processes. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we\u0026rsquo;ll look at: how understanding the Linux process tree can help you identify security threats what process information can help you determine the scope of a breach We\u0026rsquo;ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.",
      "date_published": "2021-08-19T00:00:00Z",
      "author": {
        "name": "Jordan Obey"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/faulty-deployment-detection/",
      "title": "Release code confidently with Automatic Faulty Deployment Detection",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eModern software development teams use CI/CD tools to ship features quickly and rely on best practices like \u003ca href=\"https://www.datadoghq.com/blog/shift-left-testing-best-practices/\"\u003eshift-left testing\u003c/a\u003e to find application errors before they become user-facing bugs. But you still face the risk that any code you deploy could contain errors that your testing did not surface. To help you deploy with confidence and mitigate the effects of a bad deployment, \u003ca href=\"https://www.datadoghq.com/knowledge-center/distributed-tracing/\"\u003eDatadog APM\u003c/a\u003e now provides Automatic Faulty Deployment Detection.\u003c/p\u003e\u003cp\u003eThis post will show you how Automatic Faulty Deployment Detection helps you prevent faulty deployments from affecting the performance of your application. We’ll explain how you can:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"#automatically-detect-faulty-deployments\"\u003eSpot a deployment that appears to be faulty\u003c/a\u003e (even if the deployment itself didn’t fail)\u003c/li\u003e\u003cli\u003e\u003ca href=\"#troubleshoot-faulty-deployments-quickly\"\u003eTroubleshoot faulty deployments\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#proactively-set-alerts-to-monitor-future-deployments\"\u003eCreate alerts to notify your team\u003c/a\u003e of a faulty deployment\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"automatically-detect-faulty-deployments\"\u003e\u003ca href=\"#automatically-detect-faulty-deployments\"\u003eAutomatically detect faulty deployments\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAutomatic Faulty Deployment Detection uses \u003ca href=\"https://www.datadoghq.com/blog/watchdog/\"\u003eWatchdog’s machine learning algorithms\u003c/a\u003e to spot faulty deployments within minutes, reducing your mean time to detection (MTTD). As your team continuously deploys code to production, Watchdog compares the performance of each new version of a service with its previous versions to spot new types of errors introduced in a deployment (instead of an increase in the rate of an existing error that you might expect with a new deployment). If Watchdog determines that a new deployment is faulty, you’ll see details about the affected service in the service-level dashboard, including error types, error rates, request rates, and latency metrics for each version you’ve deployed.\u003c/p\u003e\u003cp\u003eIn the screenshot below, the yellow banner at the top of the page indicates that the most recent deployment of the \u003ccode\u003einventory-api\u003c/code\u003e service may be faulty, and a previously unseen error is affecting this serivce’s \u003ccode\u003ehttp.request\u003c/code\u003e operation. The \u003cstrong\u003eDeployments\u003c/strong\u003e table at the bottom of the screen shows a history of the service’s deployments and indicates an error rate of 100 percent for the most recently deployed version, indicating that you may need to roll back the deployment and investigate the source of the errors.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"The Services page shows service-level information including rate of requests, rate of errors, and latency. A yellow banner states that the most recent deployment of the service may be faulty.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYou can click \u003cstrong\u003eView Details\u003c/strong\u003e—or any deployment listed in the \u003cstrong\u003eDeployments\u003c/strong\u003e table—to open up the \u003ca href=\"https://www.datadoghq.com/blog/datadog-deployment-tracking/\"\u003eDeployment Tracking\u003c/a\u003e view, shown in the screenshot below. This view provides details about the faulty deployment, including the new type of error detected (\u003ccode\u003edb.utils.OperationalError\u003c/code\u003e), the affected endpoint (\u003ccode\u003e/inventory\u003c/code\u003e), and the HTTP status code (\u003ccode\u003e500\u003c/code\u003e), which can help you understand how the error is affecting your service. In this case, the application is trying to create the \u003ccode\u003eproducts\u003c/code\u003e table each time it calls the endpoint, rather than executing an \u003ccode\u003eUPDATE\u003c/code\u003e statement against the existing table.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"A detailed view of the faulty deployment shows the time it was detected, the error type, the relevant endpoint, and the HTTP status code.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"troubleshoot-faulty-deployments-quickly\"\u003e\u003ca href=\"#troubleshoot-faulty-deployments-quickly\"\u003eTroubleshoot faulty deployments quickly\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eWhen Automatic Faulty Deployment Detection spots an error in a deployment, you can start troubleshooting by exploring the service’s \u003ca href=\"https://docs.datadoghq.com/tracing/\"\u003etraces\u003c/a\u003e, which visualize your application’s activity and surface details that can help you understand the source of the error.\u003c/p\u003e\u003cp\u003eTo see the traces for a service affected by a faulty deployment, click the \u003cstrong\u003eTraces\u003c/strong\u003e tab on the service-level dashboard or the \u003cstrong\u003epreviously unseen errors\u003c/strong\u003e table in the Deployment Tracking view.\u003c/p\u003e\u003cp\u003eYou can view your trace data as a \u003ca href=\"https://www.datadoghq.com/knowledge-center/distributed-tracing/flame-graph/\"\u003eflame graph\u003c/a\u003e, which shows the performance of each of your services as your application processes a request. The screenshot below shows a flame graph corresponding to the error shown earlier in the Deployment Tracking view. The \u003ccode\u003e200 OK\u003c/code\u003e response at the top indicates that the request was successful overall. But the purple span shows the response from the \u003ccode\u003einventory\u003c/code\u003e service, which took 166 microseconds and resulted in a \u003ccode\u003e500\u003c/code\u003e error, whose details are shown in the bottom half of the screen.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"A flame graph shows four requests. The final request, in purple, represents the HTTP request to the inventory service which resulted in a 500 error.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eAs you gain an understanding of the error that was detected in the deployment, you can collaborate with your team to troubleshoot and resolve the issue. You can easily share what you learn by creating a \u003ca href=\"https://www.datadoghq.com/blog/collaborative-notebooks-datadog/\"\u003enotebook\u003c/a\u003e that your team can use to collaborate, or you can declare an \u003ca href=\"https://www.datadoghq.com/blog/incident-response-with-datadog/\"\u003eincident\u003c/a\u003e to initiate your team’s defined process for responding to an error in production. The screenshot below highlights the buttons you can use to start your collaboration with just a single click.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"A highlighted area of the faulty deployment detailed view shows buttons to create a Notebook and an incident.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eIf you click the \u003cstrong\u003eCreate Incident\u003c/strong\u003e button, Datadog will automatically generate an incident that your team can use to troubleshoot the faulty deployment. The incident automatically includes a link to the relevant service dashboard to provide context that can help collaborators quickly identify and mitigate the impact of the incident.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"The new incident form includes fields to designate incident severity, incident commander, team members to be notified, and a link to the APM page that describes the faulty deployment.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eSee the documentation for more information about \u003ca href=\"https://docs.datadoghq.com/monitors/incident_management/\"\u003eDatadog Incident Management\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"proactively-set-alerts-to-monitor-future-deployments\"\u003e\u003ca href=\"#proactively-set-alerts-to-monitor-future-deployments\"\u003eProactively set alerts to monitor future deployments\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eTo further support your team’s ability to release features rapidly, you can create alerts that automatically page you if a release appears to be faulty. Automatic Faulty Deployment Detection suggests monitors that you can enable with a single click to proactively address any errors that affect your most critical services. These automated alerts can help your team react quickly and mitigate faulty deployments before they degrade your user experience.\u003c/p\u003e\u003cp\u003eIn the screenshot below, the \u003ccode\u003einventory-api\u003c/code\u003e service dashboard shows a faulty deployment and includes a \u003cstrong\u003eSuggested Monitor\u003c/strong\u003e button that allows you to create an alert that will automatically notify you if the same service exhibits new errors in a future deployment. Once you’ve set the alert, Datadog will monitor your deployments so your team can focus on shipping your next release.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"A highlighted area on the service page shows the Suggested Monitor button.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"deploy-safely-with-datadog\"\u003e\u003ca href=\"#deploy-safely-with-datadog\"\u003eDeploy safely with Datadog\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAlong with best practices like \u003ca href=\"https://www.datadoghq.com/blog/introducing-synthetic-monitoring/\"\u003esynthetic monitoring\u003c/a\u003e and automated \u003ca href=\"https://www.datadoghq.com/blog/datadog-synthetic-ci-cd-testing/\"\u003eCI/CD pipeline testing\u003c/a\u003e, Automatic Faulty Deployment Detection can help you maintain both the velocity of your development and the quality of your service. To get started, enable \u003ca href=\"https://docs.datadoghq.com/tracing/setup_overview/\"\u003eAPM\u003c/a\u003e and then enable \u003ca href=\"https://docs.datadoghq.com/tracing/deployment_tracking/\"\u003eDeployment Tracking\u003c/a\u003e by tagging your deployments with a \u003ca href=\"https://docs.datadoghq.com/getting_started/tagging/unified_service_tagging/\"\u003e\u003ccode\u003eversion\u003c/code\u003e tag\u003c/a\u003e—which may be provided \u003ca href=\"https://www.datadoghq.com/blog/unified-service-tagging/#use-the-version-tag-to-identify-problematic-deployments\"\u003eautomatically\u003c/a\u003e by your CI/CD tool. If you’re not already using Datadog, you can start today with a \u003ca href=\"#\"\u003efree 14-day trial\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/automatic_faulty_deployment_detection.png\" width=\"100%\"/\u003eModern software development teams use CI/CD tools to ship features quickly and rely on best practices like shift-left testing to find application errors before they become user-facing bugs. But you still face the risk that any code you deploy could contain errors that your testing did not surface. To help you deploy with confidence and mitigate the effects of a bad deployment, Datadog APM now provides Automatic Faulty Deployment Detection.",
      "date_published": "2021-08-19T00:00:00Z",
      "author": {
        "name": "David Asker"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/linux-security-threat-detection-datadog/",
      "title": "How to detect security threats in your systems' Linux processes",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eAlmost all tasks within a Linux system, whether it’s an application, system daemon, or certain types of user activity, are executed by one or more \u003ca href=\"https://tldp.org/LDP/tlk/kernel/processes.html\"\u003eprocesses\u003c/a\u003e. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we’ll look at:\u003c/p\u003e\u003cul\u003e\u003cli\u003ehow \u003ca href=\"#a-primer-on-the-process-tree\"\u003eunderstanding the Linux process tree\u003c/a\u003e can help you identify security threats\u003c/li\u003e\u003cli\u003ewhat \u003ca href=\"#use-process-data-to-determine-the-scope-of-an-attack\"\u003eprocess information\u003c/a\u003e can help you determine the scope of a breach\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe’ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.\u003c/p\u003e\u003ch2 id=\"a-primer-on-the-process-tree\"\u003e\u003ca href=\"#a-primer-on-the-process-tree\"\u003eA primer on the process tree\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn Linux, each process is generated by a preceding \u003cstrong\u003eparent\u003c/strong\u003e process and can generate one or more \u003cstrong\u003echild\u003c/strong\u003e processes. Following this parent/child structure, active processes form a \u003cstrong\u003eprocess tree\u003c/strong\u003e that starts with the \u003ccode\u003esystemd\u003c/code\u003e process that runs when Linux first boots and ends with the most recently generated processes. This parent/child structure is particularly useful for revealing security threats because, unlike simple indicators of compromise (IOCs) like adversarial IP addresses or file hashes, it’s difficult to fake or change. For instance, while attackers can change an IP address, it’s much harder to hide that an application has spawned a new suspicious child process.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"process-tree.png\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eActive processes are structured as a process tree which can be used to help you spot signs of a security breach.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"identify-suspicious-processes\"\u003e\u003ca href=\"#identify-suspicious-processes\"\u003eIdentify suspicious processes\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAs you monitor your applications, it’s important to look out for any launched shells or utilities (e.g., \u003ccode\u003ebash\u003c/code\u003e or \u003ccode\u003ecurl\u003c/code\u003e) that are children of key processes in your environment. For example, if a Java application process generates a shell you aren’t anticipating, it could indicate that a malicious actor has infiltrated your app and launched a \u003ca href=\"https://us-cert.cisa.gov/ncas/alerts/TA15-314A\"\u003eweb shell attack\u003c/a\u003e. When these attacks are successful, they can create backdoors to your infrastructure that allow attackers to access sensitive data and execute commands without authorization.\u003c/p\u003e\u003cp\u003eLikewise, you should check if a process spawned utilities like \u003ccode\u003enmap\u003c/code\u003e, which an attacker can use to survey your network for further vulnerabilities to exploit, or \u003ccode\u003epasswd\u003c/code\u003e, which can be used to change user passwords and grant attackers higher privileges.\u003c/p\u003e\u003cp\u003eOnce you’ve identified a malicious process, it’s important to investigate the scope of the attack, including what information the attacker has potentially gained access to.\u003c/p\u003e\u003ch2 id=\"use-process-data-to-determine-the-scope-of-an-attack\"\u003e\u003ca href=\"#use-process-data-to-determine-the-scope-of-an-attack\"\u003eUse process data to determine the scope of an attack\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eLinux processes include metadata that can help you determine the scope of an attack. The key types of information to look at are:\u003c/p\u003e\u003cul\u003e\u003cli\u003eenvironment variables\u003c/li\u003e\u003cli\u003ecommand-line arguments\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"environment-variables\"\u003e\u003ca href=\"#environment-variables\"\u003eEnvironment variables\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eDue to their \u003ca href=\"#a-primer-on-the-process-tree\"\u003erelationship\u003c/a\u003e, child processes inherit access to any environment variables available to the parent process. Though it’s not considered best practice, environment variables are often used to store sensitive data like API and GitHub keys, or even database credentials. Using our example of an attacker successfully creating a web shell from a Java application process, the shell would be able to see any environment variables associated with your application process, such as database credentials for a SQL server containing sensitive customer data.\u003c/p\u003e\u003cp\u003eExamining what environment variables a process includes can help you determine the full scope of a threat. You can quickly view a list of a process’s environment variables by using the Linux command \u003ccode\u003eps faux\u003c/code\u003e to get its PID and then running the following:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003ecat /proc/\u0026lt;PROCESS_PID\u0026gt;/environ \u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003ePlease note, however, that this detection method only works while the process is running. This makes it challenging to view potential attacks without a \u003ca href=\"#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003econtinuous monitoring\u003c/a\u003e tool.\u003c/p\u003e\u003ch3 id=\"command-line-arguments\"\u003e\u003ca href=\"#command-line-arguments\"\u003eCommand-line arguments\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eIn addition to environment variables, it’s important to know what command-line arguments an attacker used when starting a malicious process. Command-line arguments hold information that’s critical to determining the nature of a security threat. Arguments may include identifying data like the IP address an attacker used when they issued a \u003ccode\u003ecurl\u003c/code\u003e command to download a malicious payload, as well as activity data like \u003ca href=\"https://stackabuse.com/encoding-and-decoding-base64-strings-in-python\"\u003eencoded Python scripts\u003c/a\u003e that were run directly in the command line. Insight into a process’s command-line arguments can help you view what occurred during an attack so you can plan how to respond.\u003c/p\u003e\u003cp\u003eFor a quick look at a process’s command line arguments, get its PID and run a command like the following:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003eps -p \u0026lt;PROCESS_PID\u0026gt; -o args\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThis approach, however, is limited because you need to be able to catch the process before it terminates. Next, we’ll look at how Datadog’s Cloud Workload Security helps you detect attacks and view relevant metadata.\u003c/p\u003e\u003ch2 id=\"detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003e\u003ca href=\"#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003eDetect threats in your Linux processes with Datadog Cloud Workload Security\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/\"\u003eCloud Workload Security (CWS)\u003c/a\u003e analyzes the full process tree across all your Linux hosts and containers in real time to automatically detect the kind of threats we’ve looked at. Datadog includes \u003ca href=\"https://docs.datadoghq.com/security_platform/default_rules/#cat-workload-security\"\u003eout-of-the-box workload threat detection rules\u003c/a\u003e that help you immediately respond to potential security threats by flagging suspicious behavior like the execution of \u003ccode\u003epasswd\u003c/code\u003e and \u003ccode\u003enmap\u003c/code\u003e utilities.\u003c/p\u003e\u003cp\u003eIn addition to out-of-the-box workload security rules, Datadog enables you to write your own custom rules. Security rules are constructed with \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/agent_expressions/\"\u003e\u003cstrong\u003eAgent Expressions\u003c/strong\u003e\u003c/a\u003e that enable you to define what process activity to look for with as much specificity as you want. For example, you can instruct Datadog to detect if a Java process generated a \u003ccode\u003ebash\u003c/code\u003e shell, or even watch for processes run with specific command-line arguments. To learn more about how to construct your own custom workload security rules, check out our \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/workload_security_rules/\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIf Datadog detects any processes that match a rule, it will generate a \u003ca href=\"https://docs.datadoghq.com/security_platform/security_monitoring/getting_started/#explore-security-signals\"\u003eSecurity Signal\u003c/a\u003e. Security Signals include full context around the suspicious process, including environment variable keys (without collecting the associated values), command-line arguments, and other metadata. You can use this information to quickly determine the scope of an attack before planning your response.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Security signals include environment variables and command-line arguments which can help you determine the scope of security attacks.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"start-today\"\u003e\u003ca href=\"#start-today\"\u003eStart today\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eNo matter which distribution you work with, processes are at the heart of any Linux system. In this post, we looked at how understanding processes and their relationships can help you spot suspicious behavior and determine the severity of a security breach. Datadog Cloud Workload Security monitors process activity throughout your infrastructure at the kernel level in real time to reveal any suspicious or malicious behavior. Read our \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/getting_started/?tab=kubernetes\"\u003edocumentation\u003c/a\u003e to learn more or sign up today for a 14-day \u003ca href=\"#\"\u003efree trial.\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/linux-process-hero.png\" width=\"100%\"/\u003eAlmost all tasks within a Linux system, whether it\u0026rsquo;s an application, system daemon, or certain types of user activity, are executed by one or more processes. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we\u0026rsquo;ll look at: how understanding the Linux process tree can help you identify security threats what process information can help you determine the scope of a breach We\u0026rsquo;ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.",
      "date_published": "2021-08-19T00:00:00Z",
      "author": {
        "name": "Jordan Obey"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/linux-security-threat-detection-datadog/",
      "title": "How to detect security threats in your systems' Linux processes",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eAlmost all tasks within a Linux system, whether it’s an application, system daemon, or certain types of user activity, are executed by one or more \u003ca href=\"https://tldp.org/LDP/tlk/kernel/processes.html\"\u003eprocesses\u003c/a\u003e. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we’ll look at:\u003c/p\u003e\u003cul\u003e\u003cli\u003ehow \u003ca href=\"#a-primer-on-the-process-tree\"\u003eunderstanding the Linux process tree\u003c/a\u003e can help you identify security threats\u003c/li\u003e\u003cli\u003ewhat \u003ca href=\"#use-process-data-to-determine-the-scope-of-an-attack\"\u003eprocess information\u003c/a\u003e can help you determine the scope of a breach\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe’ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.\u003c/p\u003e\u003ch2 id=\"a-primer-on-the-process-tree\"\u003e\u003ca href=\"#a-primer-on-the-process-tree\"\u003eA primer on the process tree\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn Linux, each process is generated by a preceding \u003cstrong\u003eparent\u003c/strong\u003e process and can generate one or more \u003cstrong\u003echild\u003c/strong\u003e processes. Following this parent/child structure, active processes form a \u003cstrong\u003eprocess tree\u003c/strong\u003e that starts with the \u003ccode\u003esystemd\u003c/code\u003e process that runs when Linux first boots and ends with the most recently generated processes. This parent/child structure is particularly useful for revealing security threats because, unlike simple indicators of compromise (IOCs) like adversarial IP addresses or file hashes, it’s difficult to fake or change. For instance, while attackers can change an IP address, it’s much harder to hide that an application has spawned a new suspicious child process.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"process-tree.png\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eActive processes are structured as a process tree which can be used to help you spot signs of a security breach.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"identify-suspicious-processes\"\u003e\u003ca href=\"#identify-suspicious-processes\"\u003eIdentify suspicious processes\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAs you monitor your applications, it’s important to look out for any launched shells or utilities (e.g., \u003ccode\u003ebash\u003c/code\u003e or \u003ccode\u003ecurl\u003c/code\u003e) that are children of key processes in your environment. For example, if a Java application process generates a shell you aren’t anticipating, it could indicate that a malicious actor has infiltrated your app and launched a \u003ca href=\"https://us-cert.cisa.gov/ncas/alerts/TA15-314A\"\u003eweb shell attack\u003c/a\u003e. When these attacks are successful, they can create backdoors to your infrastructure that allow attackers to access sensitive data and execute commands without authorization.\u003c/p\u003e\u003cp\u003eLikewise, you should check if a process spawned utilities like \u003ccode\u003enmap\u003c/code\u003e, which an attacker can use to survey your network for further vulnerabilities to exploit, or \u003ccode\u003epasswd\u003c/code\u003e, which can be used to change user passwords and grant attackers higher privileges.\u003c/p\u003e\u003cp\u003eOnce you’ve identified a malicious process, it’s important to investigate the scope of the attack, including what information the attacker has potentially gained access to.\u003c/p\u003e\u003ch2 id=\"use-process-data-to-determine-the-scope-of-an-attack\"\u003e\u003ca href=\"#use-process-data-to-determine-the-scope-of-an-attack\"\u003eUse process data to determine the scope of an attack\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eLinux processes include metadata that can help you determine the scope of an attack. The key types of information to look at are:\u003c/p\u003e\u003cul\u003e\u003cli\u003eenvironment variables\u003c/li\u003e\u003cli\u003ecommand-line arguments\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"environment-variables\"\u003e\u003ca href=\"#environment-variables\"\u003eEnvironment variables\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eDue to their \u003ca href=\"#a-primer-on-the-process-tree\"\u003erelationship\u003c/a\u003e, child processes inherit access to any environment variables available to the parent process. Though it’s not considered best practice, environment variables are often used to store sensitive data like API and GitHub keys, or even database credentials. Using our example of an attacker successfully creating a web shell from a Java application process, the shell would be able to see any environment variables associated with your application process, such as database credentials for a SQL server containing sensitive customer data.\u003c/p\u003e\u003cp\u003eExamining what environment variables a process includes can help you determine the full scope of a threat. You can quickly view a list of a process’s environment variables by using the Linux command \u003ccode\u003eps faux\u003c/code\u003e to get its PID and then running the following:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003ecat /proc/\u0026lt;PROCESS_PID\u0026gt;/environ \u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003ePlease note, however, that this detection method only works while the process is running. This makes it challenging to view potential attacks without a \u003ca href=\"#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003econtinuous monitoring\u003c/a\u003e tool.\u003c/p\u003e\u003ch3 id=\"command-line-arguments\"\u003e\u003ca href=\"#command-line-arguments\"\u003eCommand-line arguments\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eIn addition to environment variables, it’s important to know what command-line arguments an attacker used when starting a malicious process. Command-line arguments hold information that’s critical to determining the nature of a security threat. Arguments may include identifying data like the IP address an attacker used when they issued a \u003ccode\u003ecurl\u003c/code\u003e command to download a malicious payload, as well as activity data like \u003ca href=\"https://stackabuse.com/encoding-and-decoding-base64-strings-in-python\"\u003eencoded Python scripts\u003c/a\u003e that were run directly in the command line. Insight into a process’s command-line arguments can help you view what occurred during an attack so you can plan how to respond.\u003c/p\u003e\u003cp\u003eFor a quick look at a process’s command line arguments, get its PID and run a command like the following:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003eps -p \u0026lt;PROCESS_PID\u0026gt; -o args\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThis approach, however, is limited because you need to be able to catch the process before it terminates. Next, we’ll look at how Datadog’s Cloud Workload Security helps you detect attacks and view relevant metadata.\u003c/p\u003e\u003ch2 id=\"detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003e\u003ca href=\"#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003eDetect threats in your Linux processes with Datadog Cloud Workload Security\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/\"\u003eCloud Workload Security (CWS)\u003c/a\u003e analyzes the full process tree across all your Linux hosts and containers in real time to automatically detect the kind of threats we’ve looked at. Datadog includes \u003ca href=\"https://docs.datadoghq.com/security_platform/default_rules/#cat-workload-security\"\u003eout-of-the-box workload threat detection rules\u003c/a\u003e that help you immediately respond to potential security threats by flagging suspicious behavior like the execution of \u003ccode\u003epasswd\u003c/code\u003e and \u003ccode\u003enmap\u003c/code\u003e utilities.\u003c/p\u003e\u003cp\u003eIn addition to out-of-the-box workload security rules, Datadog enables you to write your own custom rules. Security rules are constructed with \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/agent_expressions/\"\u003e\u003cstrong\u003eAgent Expressions\u003c/strong\u003e\u003c/a\u003e that enable you to define what process activity to look for with as much specificity as you want. For example, you can instruct Datadog to detect if a Java process generated a \u003ccode\u003ebash\u003c/code\u003e shell, or even watch for processes run with specific command-line arguments. To learn more about how to construct your own custom workload security rules, check out our \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/workload_security_rules/\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIf Datadog detects any processes that match a rule, it will generate a \u003ca href=\"https://docs.datadoghq.com/security_platform/security_monitoring/getting_started/#explore-security-signals\"\u003eSecurity Signal\u003c/a\u003e. Security Signals include full context around the suspicious process, including environment variable keys (without collecting the associated values), command-line arguments, and other metadata. You can use this information to quickly determine the scope of an attack before planning your response.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Security signals include environment variables and command-line arguments which can help you determine the scope of security attacks.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"start-today\"\u003e\u003ca href=\"#start-today\"\u003eStart today\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eNo matter which distribution you work with, processes are at the heart of any Linux system. In this post, we looked at how understanding processes and their relationships can help you spot suspicious behavior and determine the severity of a security breach. Datadog Cloud Workload Security monitors process activity throughout your infrastructure at the kernel level in real time to reveal any suspicious or malicious behavior. Read our \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/getting_started/?tab=kubernetes\"\u003edocumentation\u003c/a\u003e to learn more or sign up today for a 14-day \u003ca href=\"#\"\u003efree trial.\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/linux-process-hero.png\" width=\"100%\"/\u003eAlmost all tasks within a Linux system, whether it\u0026rsquo;s an application, system daemon, or certain types of user activity, are executed by one or more processes. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we\u0026rsquo;ll look at: how understanding the Linux process tree can help you identify security threats what process information can help you determine the scope of a breach We\u0026rsquo;ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.",
      "date_published": "2021-08-19T00:00:00Z",
      "author": {
        "name": "Jordan Obey"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/linux-security-threat-detection-datadog/",
      "title": "How to detect security threats in your systems' Linux processes",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eAlmost all tasks within a Linux system, whether it’s an application, system daemon, or certain types of user activity, are executed by one or more \u003ca href=\"https://tldp.org/LDP/tlk/kernel/processes.html\"\u003eprocesses\u003c/a\u003e. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we’ll look at:\u003c/p\u003e\u003cul\u003e\u003cli\u003ehow \u003ca href=\"#a-primer-on-the-process-tree\"\u003eunderstanding the Linux process tree\u003c/a\u003e can help you identify security threats\u003c/li\u003e\u003cli\u003ewhat \u003ca href=\"#use-process-data-to-determine-the-scope-of-an-attack\"\u003eprocess information\u003c/a\u003e can help you determine the scope of a breach\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe’ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.\u003c/p\u003e\u003ch2 id=\"a-primer-on-the-process-tree\"\u003e\u003ca href=\"#a-primer-on-the-process-tree\"\u003eA primer on the process tree\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn Linux, each process is generated by a preceding \u003cstrong\u003eparent\u003c/strong\u003e process and can generate one or more \u003cstrong\u003echild\u003c/strong\u003e processes. Following this parent/child structure, active processes form a \u003cstrong\u003eprocess tree\u003c/strong\u003e that starts with the \u003ccode\u003esystemd\u003c/code\u003e process that runs when Linux first boots and ends with the most recently generated processes. This parent/child structure is particularly useful for revealing security threats because, unlike simple indicators of compromise (IOCs) like adversarial IP addresses or file hashes, it’s difficult to fake or change. For instance, while attackers can change an IP address, it’s much harder to hide that an application has spawned a new suspicious child process.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"process-tree.png\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eActive processes are structured as a process tree which can be used to help you spot signs of a security breach.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"identify-suspicious-processes\"\u003e\u003ca href=\"#identify-suspicious-processes\"\u003eIdentify suspicious processes\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAs you monitor your applications, it’s important to look out for any launched shells or utilities (e.g., \u003ccode\u003ebash\u003c/code\u003e or \u003ccode\u003ecurl\u003c/code\u003e) that are children of key processes in your environment. For example, if a Java application process generates a shell you aren’t anticipating, it could indicate that a malicious actor has infiltrated your app and launched a \u003ca href=\"https://us-cert.cisa.gov/ncas/alerts/TA15-314A\"\u003eweb shell attack\u003c/a\u003e. When these attacks are successful, they can create backdoors to your infrastructure that allow attackers to access sensitive data and execute commands without authorization.\u003c/p\u003e\u003cp\u003eLikewise, you should check if a process spawned utilities like \u003ccode\u003enmap\u003c/code\u003e, which an attacker can use to survey your network for further vulnerabilities to exploit, or \u003ccode\u003epasswd\u003c/code\u003e, which can be used to change user passwords and grant attackers higher privileges.\u003c/p\u003e\u003cp\u003eOnce you’ve identified a malicious process, it’s important to investigate the scope of the attack, including what information the attacker has potentially gained access to.\u003c/p\u003e\u003ch2 id=\"use-process-data-to-determine-the-scope-of-an-attack\"\u003e\u003ca href=\"#use-process-data-to-determine-the-scope-of-an-attack\"\u003eUse process data to determine the scope of an attack\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eLinux processes include metadata that can help you determine the scope of an attack. The key types of information to look at are:\u003c/p\u003e\u003cul\u003e\u003cli\u003eenvironment variables\u003c/li\u003e\u003cli\u003ecommand-line arguments\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"environment-variables\"\u003e\u003ca href=\"#environment-variables\"\u003eEnvironment variables\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eDue to their \u003ca href=\"#a-primer-on-the-process-tree\"\u003erelationship\u003c/a\u003e, child processes inherit access to any environment variables available to the parent process. Though it’s not considered best practice, environment variables are often used to store sensitive data like API and GitHub keys, or even database credentials. Using our example of an attacker successfully creating a web shell from a Java application process, the shell would be able to see any environment variables associated with your application process, such as database credentials for a SQL server containing sensitive customer data.\u003c/p\u003e\u003cp\u003eExamining what environment variables a process includes can help you determine the full scope of a threat. You can quickly view a list of a process’s environment variables by using the Linux command \u003ccode\u003eps faux\u003c/code\u003e to get its PID and then running the following:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003ecat /proc/\u0026lt;PROCESS_PID\u0026gt;/environ \u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003ePlease note, however, that this detection method only works while the process is running. This makes it challenging to view potential attacks without a \u003ca href=\"#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003econtinuous monitoring\u003c/a\u003e tool.\u003c/p\u003e\u003ch3 id=\"command-line-arguments\"\u003e\u003ca href=\"#command-line-arguments\"\u003eCommand-line arguments\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eIn addition to environment variables, it’s important to know what command-line arguments an attacker used when starting a malicious process. Command-line arguments hold information that’s critical to determining the nature of a security threat. Arguments may include identifying data like the IP address an attacker used when they issued a \u003ccode\u003ecurl\u003c/code\u003e command to download a malicious payload, as well as activity data like \u003ca href=\"https://stackabuse.com/encoding-and-decoding-base64-strings-in-python\"\u003eencoded Python scripts\u003c/a\u003e that were run directly in the command line. Insight into a process’s command-line arguments can help you view what occurred during an attack so you can plan how to respond.\u003c/p\u003e\u003cp\u003eFor a quick look at a process’s command line arguments, get its PID and run a command like the following:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003eps -p \u0026lt;PROCESS_PID\u0026gt; -o args\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThis approach, however, is limited because you need to be able to catch the process before it terminates. Next, we’ll look at how Datadog’s Cloud Workload Security helps you detect attacks and view relevant metadata.\u003c/p\u003e\u003ch2 id=\"detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003e\u003ca href=\"#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security\"\u003eDetect threats in your Linux processes with Datadog Cloud Workload Security\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/\"\u003eCloud Workload Security (CWS)\u003c/a\u003e analyzes the full process tree across all your Linux hosts and containers in real time to automatically detect the kind of threats we’ve looked at. Datadog includes \u003ca href=\"https://docs.datadoghq.com/security_platform/default_rules/#cat-workload-security\"\u003eout-of-the-box workload threat detection rules\u003c/a\u003e that help you immediately respond to potential security threats by flagging suspicious behavior like the execution of \u003ccode\u003epasswd\u003c/code\u003e and \u003ccode\u003enmap\u003c/code\u003e utilities.\u003c/p\u003e\u003cp\u003eIn addition to out-of-the-box workload security rules, Datadog enables you to write your own custom rules. Security rules are constructed with \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/agent_expressions/\"\u003e\u003cstrong\u003eAgent Expressions\u003c/strong\u003e\u003c/a\u003e that enable you to define what process activity to look for with as much specificity as you want. For example, you can instruct Datadog to detect if a Java process generated a \u003ccode\u003ebash\u003c/code\u003e shell, or even watch for processes run with specific command-line arguments. To learn more about how to construct your own custom workload security rules, check out our \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/workload_security_rules/\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIf Datadog detects any processes that match a rule, it will generate a \u003ca href=\"https://docs.datadoghq.com/security_platform/security_monitoring/getting_started/#explore-security-signals\"\u003eSecurity Signal\u003c/a\u003e. Security Signals include full context around the suspicious process, including environment variable keys (without collecting the associated values), command-line arguments, and other metadata. You can use this information to quickly determine the scope of an attack before planning your response.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Security signals include environment variables and command-line arguments which can help you determine the scope of security attacks.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"start-today\"\u003e\u003ca href=\"#start-today\"\u003eStart today\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eNo matter which distribution you work with, processes are at the heart of any Linux system. In this post, we looked at how understanding processes and their relationships can help you spot suspicious behavior and determine the severity of a security breach. Datadog Cloud Workload Security monitors process activity throughout your infrastructure at the kernel level in real time to reveal any suspicious or malicious behavior. Read our \u003ca href=\"https://docs.datadoghq.com/security_platform/cloud_workload_security/getting_started/?tab=kubernetes\"\u003edocumentation\u003c/a\u003e to learn more or sign up today for a 14-day \u003ca href=\"#\"\u003efree trial.\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/linux-process-hero.png\" width=\"100%\"/\u003eAlmost all tasks within a Linux system, whether it\u0026rsquo;s an application, system daemon, or certain types of user activity, are executed by one or more processes. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we\u0026rsquo;ll look at: how understanding the Linux process tree can help you identify security threats what process information can help you determine the scope of a breach We\u0026rsquo;ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.",
      "date_published": "2021-08-19T00:00:00Z",
      "author": {
        "name": "Jordan Obey"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/anomaly-detection-rules-datadog/",
      "title": "Detect security threats with anomaly detection rules",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eSecuring your environment requires being able to quickly detect abnormal activity that could represent a threat. But today’s modern cloud infrastructure is large, complex, and can generate vast volumes of logs. This makes it difficult to determine what activity is normal and harder to identify anomalous behavior. Now, in addition to \u003ca href=\"https://docs.datadoghq.com/security_platform/security_monitoring/log_detection_rules/?tab=threshold#define-a-search-query\"\u003ethreshold\u003c/a\u003e and \u003ca href=\"https://www.datadoghq.com/blog/new-term-detection-method-datadog/#security-on-your-terms\"\u003enew term\u003c/a\u003e–based \u003ca href=\"https://docs.datadoghq.com/security_platform/detection_rules/\"\u003eThreat Detection Rules\u003c/a\u003e, Datadog Security Monitoring provides the ability to create \u003ca href=\"https://docs.datadoghq.com/security_platform/security_monitoring/log_detection_rules/?tab=anomaly\"\u003eanomaly\u003c/a\u003e detection rules. With this detection method, Datadog will analyze relevant logs for the specific entities you query—hosts, IP addresses, users, etc.—to identify historical trends and determine baseline behavior. Then, when it detects any type of deviation from this baseline, Datadog will create a \u003ca href=\"https://www.datadoghq.com/blog/announcing-security-monitoring/#correlate-and-triage-security-signals\"\u003eSecurity Signal\u003c/a\u003e that includes a timeseries graph to illustrate what happened, enabling you to triage the event and take any necessary action.\u003c/p\u003e\u003ch2 id=\"spot-anomalies-in-dynamic-activity\"\u003e\u003ca href=\"#spot-anomalies-in-dynamic-activity\"\u003eSpot anomalies in dynamic activity\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eThreshold-based detection rules can notify you if the frequency of certain activity exceeds a specific value (e.g., there are more than 100 access-denied requests from a user within a one-hour timeframe). For situations where you’re not able to establish a set threshold, you can use anomaly detection rules to dynamically generate thresholds based on historical behavior. This can be particularly helpful for monitoring unusual behavior across events like unique API calls, an influx in access denied requests, and more. In these cases, baseline activity is different entity to entity, so it can be difficult to define a set threshold that won’t potentially result in many false positives.\u003c/p\u003e\u003cp\u003eLet’s say you are monitoring your organization’s \u003ca href=\"https://docs.datadoghq.com/integrations/google_cloud_platform/\"\u003eGoogle Cloud Platform\u003c/a\u003e service accounts. Service accounts connect to APIs to access the resources they need to run their workloads, so you expect to see API calls made regularly. If, however, a service account makes an unusual amount of API calls, it could mean that an account has been compromised and an attacker is attempting to access sensitive data. You can create an anomaly-based rule that monitors your audit logs for API activity and alerts you if an unusual volume of calls have been made.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"anomaly-detection01.png\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eAn anomaly detection rule that looks for an unusual number of API calls from a GCP service account.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eSimilarly, if you’re monitoring \u003ca href=\"https://www.datadoghq.com/blog/monitor-salesforce-logs-datadog/#monitor-salesforce-user-activity-in-real-time\"\u003eSalesforce user activity\u003c/a\u003e, Datadog provides an out-of-the-box Threat Detection Rule that notifies you of any anomalous \u003ca href=\"https://docs.datadoghq.com/security_platform/default_rules/salesforce-large-volume-of-query-activity/\"\u003espikes in query results\u003c/a\u003e. While there may be periods when spikes in Salesforce user activity is the norm, anomalous spikes can signal that an unauthorized user may be attempting to access protected data and may require further investigation.\u003c/p\u003e\u003ch2 id=\"analyze-security-signals\"\u003e\u003ca href=\"#analyze-security-signals\"\u003eAnalyze Security Signals\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIf Datadog ingests logs that trigger an anomaly detection rule, Datadog will generate a Security Signal, notifying you of the nature of the anomaly as well as the window of time it occurred in so you can investigate further. Security Signals include key event data like IP addresses and usernames so you can, for instance, look at the user ID associated with an anomalous spike in Salesforce query results to determine if it is a recognized account or an attacker.\u003c/p\u003e\u003cp\u003eAny Security Signals that Datadog generates based on anomaly detection rules will remain “open” (i.e., continue to report data about the anomaly) as long as analyzed logs indicate the same anomalous behavior over a set interval, or until the anomaly exceeds a specified maximum signal duration (e.g., 24 hours), and has become the new baseline. This helps you determine when an anomaly first occurred, and whether it is still ongoing or has concluded.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Security signals can be generated by triggered anomaly detection rules.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"get-started-today\"\u003e\u003ca href=\"#get-started-today\"\u003eGet started today\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog Security Monitoring’s anomaly-based detection rules identify and alert on anomalous behavior in your dynamic environment, making it easier to identify and investigate suspicious behavior when it appears. If you’re currently a Datadog customer, you can learn more about creating security rules \u003ca href=\"https://docs.datadoghq.com/security_platform/security_monitoring/log_detection_rules/?tab=anomaly\"\u003ehere\u003c/a\u003e. Otherwise, get started today with a 14-day \u003ca href=\"#\"\u003efree trial.\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/security-monitoring-anomaly-detection-hero.png\" width=\"100%\"/\u003eSecuring your environment requires being able to quickly detect abnormal activity that could represent a threat. But today\u0026rsquo;s modern cloud infrastructure is large, complex, and can generate vast volumes of logs. This makes it difficult to determine what activity is normal and harder to identify anomalous behavior. Now, in addition to threshold and new term–based Threat Detection Rules, Datadog Security Monitoring provides the ability to create anomaly detection rules. With this detection method, Datadog will analyze relevant logs for the specific entities you query—hosts, IP addresses, users, etc.",
      "date_published": "2021-08-18T00:00:00Z",
      "author": {
        "name": "Jordan Obey"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/about/latest-news/press-releases/datadog-announces-deep-database-monitoring/",
      "title": "Datadog Announces Deep Database Monitoring",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cstrong\u003eNEW YORK\u003c/strong\u003e – \u003ca href=\"http://www.datadoghq.com\"\u003eDatadog\u003c/a\u003e, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced the general availability of Database Monitoring (DBM). With insights into query performance and explain plans, as well as automatic correlation of query metrics with application and infrastructure metrics, Database Monitoring provides engineers and database administrators the visibility they need to quickly find and fix application performance issues that arise from slow running database queries. \u003c/p\u003e\u003cp\u003eDatabase queries are often the root cause of incidents and application performance issues. When applications make unnecessary queries or fail to use indices, they burden the entire database, causing performance degradation for all applications using the database. Databases do not store historical query performance metrics, which makes it extremely difficult to understand the context around an issue and identify trends. This becomes even harder as engineers typically need to dig into each database individually to investigate, which prolongs downtime and exacerbates the impact on the customer experience.\u003c/p\u003e\u003cp\u003eDatadog Database Monitoring builds on the existing ability to monitor the general health and availability of the database and underlying infrastructure by allowing users to pinpoint the exact queries that impact application performance and user experience. With DBM, users can see the performance of database queries, troubleshoot slow queries with detailed execution breakdowns, and analyze historical trends in query latencies and overhead. This allows organizations to unlock improvements not only in database performance, but also in the performance of the upstream applications, APIs, and microservices that the database underpins.\u003c/p\u003e\u003cp\u003eDBM users are also able to automatically correlate query performance data with Datadog infrastructure metrics to easily identify resource bottlenecks. This allows engineers to quickly understand whether performance issues are at the database or infrastructure level, without needing to manually export and reconcile information from multiple, disconnected point solutions. Datadog’s unified data model makes it easy to search and filter information at scale with the same tags that are used everywhere in Datadog.\u003c/p\u003e\u003cp\u003e“Databases underpin today’s digital experiences. Consequently, a disruption in database uptime and performance can quickly have dramatic effects on business operations,” said Renaud Boutet, Senior Vice President, Product Management, Datadog. “The Datadog platform now enables database administrators and application engineers to detect and act on database issues by sharing the same data. This allows organizations to discover and implement improvements while saving time communicating and reconciling information.”\u003c/p\u003e\u003cp\u003e“The biggest observability challenge we face is proactively monitoring our databases\u0026#39; performance,” said Chris Seltzer, Engineering Manager, Compass. “Datadog Database Monitoring enables our engineers on both the Product and Infrastructure teams to pinpoint query performance issues and ultimately avoid prolonged downtime that disrupts the end-user experience. The best part is that it’s all within a single tool.”\u003c/p\u003e\u003cp\u003eDatadog DBM delivers deep visibility into databases and enables organizations to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eQuickly detect and isolate drops in performance. Users can track the performance of normalized queries across their entire fleet of databases, see which types of queries are executed the most and where they run, and get alerts for long running or expensive queries. For each query, they can drill down further to the hosts that are running that query, and leverage log and network information to understand host performance.\u003c/li\u003e\u003cli\u003ePinpoint the root cause of performance drops. DBM provides quick access to explain plans, so users can view the sequence of steps that make up a query. This allows them to localize bottlenecks and identify opportunities to optimize performance and resource efficiency. \u003c/li\u003e\u003cli\u003eImprove and maintain database health, preventing incidents and saving costs. DBM enables organizations to keep historical query performance data for up to three months, so they can understand changes over time and prevent regressions. \u003c/li\u003e\u003cli\u003eProvide engineers access to database performance telemetry, without compromising data security. DBM offers a centralized view of database performance data, automatically correlated with infrastructure and application metrics, without requiring direct user access to database instances.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eDatadog DBM for Postgres and MySQL starts at $70 per database server. For more information, please visit \u003ca href=\"https://www.datadoghq.com/product/database-monitoring/\"\u003ehttps://www.datadoghq.com/product/database-monitoring/\u003c/a\u003e\u003c/p\u003e\u003cdiv\u003e\u003cp\u003e\u003cstrong\u003eAbout Datadog\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eDatadog is the monitoring and security platform for cloud applications. Our SaaS platform integrates and automates infrastructure monitoring, application performance monitoring and log management to provide unified, real-time observability of our customers’ entire technology stack. Datadog is used by organizations of all sizes and across a wide range of industries to enable digital transformation and cloud migration, drive collaboration among development, operations, security and business teams, accelerate time to market for applications, reduce time to problem resolution, secure applications and infrastructure, understand user behavior and track key business metrics.\u003c/p\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003eForward-Looking Statements\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eThis press release may include certain “forward-looking statements” within the meaning of Section 27A of the Securities Act of 1933, as amended, or the Securities Act, and Section 21E of the Securities Exchange Act of 1934, as amended. These forward-looking statements reflect our current views about our plans, intentions, expectations, strategies and prospects, which are based on the information currently available to us and on assumptions we have made. Actual results may differ materially from those described in the forward-looking statements and are subject to a variety of assumptions, uncertainties, risks and factors that are beyond our control, including those risks detailed under the caption “Risk Factors” and elsewhere in our Securities and Exchange Commission filings and reports, including the Quarterly Report on Form 10-Q filed with the Securities and Exchange Commission on August 6, 2021, as well as future filings and reports by us. Except as required by law, we undertake no duty or obligation to update any forward-looking statements contained in this release as a result of new information, future events, changes in expectations or otherwise.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "NEW YORK \u0026ndash; Datadog, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced the general availability of Database Monitoring (DBM). With insights into query performance and explain plans, as well as automatic correlation of query metrics with application and infrastructure metrics, Database Monitoring provides engineers and database administrators the visibility they need to quickly find and fix application performance issues that arise from slow running database queries.",
      "date_published": "2021-08-17T21:43:00Z",
      "author": {
        "name": "Datadog"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/blackhat-2021-highlights-datadog/",
      "title": "Highlights from Black Hat USA 2021",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003ca href=\"https://www.blackhat.com/us-21/\"\u003eBlack Hat USA\u003c/a\u003e is one of the industry’s oldest and most well-established security events. Last year, the conference was held virtually for the first time in its history. This year’s conference brought together the best of both worlds, with a hybrid event that was held virtually and in person in Las Vegas.\u003c/p\u003e\u003cp\u003eHistorically, Black Hat has seen \u003ca href=\"https://www.crn.com/slide-shows/security/black-hat-is-back-scenes-from-the-show\"\u003eabout 20,000 attendees\u003c/a\u003e at its in-person conference. This year’s Black Hat was no different from a numbers perspective, but the bulk of attendees actually attended virtually. \u003ca href=\"https://www.businesswire.com/news/home/20210809005548/en/Black-Hat-USA-2021-Closes-on-the-Industry%E2%80%99s-First-and-Largest-Hybrid-Event\"\u003eBlack Hat reported\u003c/a\u003e that nearly 14,600 attendees logged into Swapcard (the platform that hosted the virtual event), which likely makes it the largest hybrid conference in cybersecurity since the shift to virtual.\u003c/p\u003e\u003cp\u003eThe Datadog team was excited to participate in this year’s conference as both an exhibitor and speaker. In this post, we’ll share highlights from the show floor, major themes from the conference, and our picks for noteworthy Briefings.\u003c/p\u003e\u003ch2 id=\"notes-from-the-show-floor\"\u003e\u003ca href=\"#notes-from-the-show-floor\"\u003eNotes from the show floor\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eThis year’s conference marked Datadog’s first time participating in the Black Hat Business Hall. Even though attendance was a little lower in person this year, we were especially excited to share our \u003ca href=\"https://www.datadoghq.com/blog/cloud-security-posture-management/\"\u003eCloud Security Posture Management\u003c/a\u003e product with this particular audience. We also announced the general availability of \u003ca href=\"https://www.datadoghq.com/blog/datadog-workload-security/\"\u003eDatadog Cloud Workload Security\u003c/a\u003e, which monitors real-time file, process, and kernel activity in hosts and containers across your environment. Both are part of the \u003ca href=\"https://www.datadoghq.com/product/security-platform/\"\u003eDatadog Cloud Security Platform\u003c/a\u003e, which protects an organization’s production environment with a full-stack offering providing threat detection and posture management, as well as workload and application security.\u003c/p\u003e\u003cp\u003eWe were not surprised to see a good number of threat detection solutions on the show floor. SIEM (Security Information Event Management) has been a hot-ticket item for years now, and this event made it clear that it is still very much in high demand. Regardless of your choice of SIEM vendor, it’s clear that companies are increasingly seeking solutions that are cloud native, managed, and integrated with other security tooling, which can be key for maximizing usage.\u003c/p\u003e\u003cp\u003eBlack Hat was also a treat for swag seekers everywhere. Whether you wanted to find a new T-shirt, socks, or even shop for an XDR solution, you’d find it all in the Black Hat Business Hall.\u003c/p\u003e\u003ch2 id=\"black-hat-keynotes\"\u003e\u003ca href=\"#black-hat-keynotes\"\u003eBlack Hat keynotes\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eWith more than half of attendees joining the conference virtually, Black Hat’s keynotes were enhanced by an especially lively chat. Whether you attended a keynote from \u003ca href=\"https://www.blackhat.com/us-21/briefings/schedule/#keynote-hacking-the-cybersecurity-puzzle-25068\"\u003eJen Easterly\u003c/a\u003e (Director of the Cybersecurity and Infrastructure Security Agency), \u003ca href=\"https://www.blackhat.com/us-21/briefings/schedule/index.html#keynote-secretary-alejandro-mayorkas-25100\"\u003eAlejandro N. Mayorkas\u003c/a\u003e (Secretary, Department of Homeland Security), \u003ca href=\"https://www.blackhat.com/us-21/briefings/schedule/#supply-chain-infections-and-the-future-of-contactless-deliveries-24987\"\u003eMatt Tait\u003c/a\u003e (Chief Operating Officer, Corellium), or all of the above, you would have seen a ton of great questions coming in from the audience.\u003c/p\u003e\u003cp\u003eAcross all three keynotes, the message was clear: collaboration will be key for moving our security efforts forward. DevOps has heralded breaking down barriers since its inception. With the rapid evolution of DevSecOps, the industry is now placing even greater emphasis on driving collaboration among development, security, and operations teams. We also expect that external government partnerships like CISA will help catapult private and public security to the next level.\u003c/p\u003e\u003ch2 id=\"black-hat-briefings\"\u003e\u003ca href=\"#black-hat-briefings\"\u003eBlack Hat Briefings\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eEvery year, it seems like the breadth of material covered in Black Hat Briefings grows. It was refreshing to see a mixture of Black Hat veteran speakers and new faces. This year, two of the briefings stood out to us:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://www.blackhat.com/us-21/briefings/schedule/index.html#cloudy-with-a-chance-of-apt-novel-microsoft--attacks-in-the-wild-23682\"\u003eCloudy with a Chance of APT: Novel Microsoft 365 Attacks in the Wild\u003c/a\u003e was a great Briefing on the rise of cloud-targeted attacks. It’s worth noting that advanced nation-state threat actors are specifically targeting SaaS applications such as Microsoft 365. If you want to learn more about securing your Microsoft 365 environment, check out our \u003ca href=\"https://www.datadoghq.com/blog/microsoft-365-integration/\"\u003eblog post\u003c/a\u003e.\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://www.blackhat.com/us-21/briefings/schedule/#im-a-hacker-get-me-out-of-here-breaking-network-segregation-using-esoteric-command--control-channels-22851\"\u003eI’m a Hacker Get Me Out of Here! Breaking Network Segregation Using Esoteric Command \u0026amp; Control Channels\u003c/a\u003e was one of the few Briefings that focused on privilege escalation and lateral movements. These topics often don’t get as much attention as they deserve in the cybersecurity space, as there is a lot of focus on infiltration. A \u003ca href=\"https://www.datadoghq.com/product/security-platform/cloud-security-posture-management/\"\u003eCSPM solution\u003c/a\u003e can help with applying the principles of least privilege, while a \u003ca href=\"https://www.datadoghq.com/product/security-platform/cloud-workload-security/\"\u003ecloud workload security solution\u003c/a\u003e can detect lateral movements.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eDatadog’s team of researchers also spoke at \u003ca href=\"https://defcon.org/\"\u003eDEF CON\u003c/a\u003e and Black Hat on the relative attack surface of eBPF. We also shared \u003ca href=\"https://github.com/Gui774ume/ebpfkit-monitor\"\u003eebpfkit-monitor\u003c/a\u003e, an ethical hacking toolkit that detects and protects against suspicious eBPF activity at runtime. More information about our Black Hat Briefing is available \u003ca href=\"https://www.blackhat.com/us-21/briefings/schedule/index.html#with-friends-like-ebpf-who-needs-enemies-23619\"\u003ehere\u003c/a\u003e, and you can watch our DEF CON talk \u003ca href=\"https://www.youtube.com/watch?v=5zixNDolLrg\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"full-stack-security-with-datadog\"\u003e\u003ca href=\"#full-stack-security-with-datadog\"\u003eFull-stack security with Datadog\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eThis year’s Black Hat conference gave us an invaluable opportunity to connect with the rest of the cybersecurity community, and we look forward to participating in more Black Hat events in the future. \u003ca href=\"https://docs.datadoghq.com/security_platform/\"\u003eCheck out our docs\u003c/a\u003e to learn more about how Datadog’s Cloud Security Platform can help break down barriers by helping every team across your organization leverage detailed observability data. If you’re not yet using Datadog, you can sign up for a \u003ca href=\"#\"\u003efree trial\u003c/a\u003e today.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/blackhat-2021-highlights-datadog/black_hat_event_recap_210809_FINAL.png\" width=\"100%\"/\u003eBlack Hat USA is one of the industry\u0026rsquo;s oldest and most well-established security events. Last year, the conference was held virtually for the first time in its history. This year’s conference brought together the best of both worlds, with a hybrid event that was held virtually and in person in Las Vegas.Historically, Black Hat has seen about 20,000 attendees at its in-person conference. This year’s Black Hat was no different from a numbers perspective, but the bulk of attendees actually attended virtually.",
      "date_published": "2021-08-17T00:00:00Z",
      "author": {
        "name": "Huxley Barbee"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/database-performance-monitoring-datadog/",
      "title": "Monitor and visualize database performance with Datadog Database Monitoring",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eWhen you’re running databases at scale, finding performance bottlenecks can often feel like looking for a needle in a haystack. In any troubleshooting scenario, you need to know the exact state of your database at the onset of an issue, as well as its behavior leading up to it. But databases themselves do not store historical performance metrics, which makes it extremely difficult to identify trends and determine whether the issue is caused by inefficient queries, suboptimal database design, or resource saturation. Developers also typically need to dig into each database individually to investigate, which prolongs downtime and other customer-facing issues.\u003c/p\u003e\u003cp\u003eToday, we’re excited to announce the release of \u003ca href=\"https://app.datadoghq.com/databases\"\u003eDatabase Monitoring\u003c/a\u003e, which delivers deep visibility into databases across all of your hosts. With historical query performance metrics, explain plans, and host-level metrics all in one place, developers and database administrators can easily understand the health and performance of their databases and quickly troubleshoot any issues that arise.\u003c/p\u003e\u003cp\u003eIn this post, we’ll show you how Database Monitoring enables you to:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"#see-the-performance-of-normalized-queries-at-a-glance\"\u003eSee the performance of normalized queries at a glance\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#troubleshoot-slow-queries-with-detailed-explain-plans\"\u003eTroubleshoot slow queries with detailed explain plans\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#analyze-historical-trends-in-query-performance\"\u003eAnalyze historical trends in query performance\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#explore-and-visualize-sampled-queries\"\u003eExplore and visualize sampled queries\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#detect-infrastructure-level-issues-impacting-your-database\"\u003eDetect infrastructure-level issues impacting your database\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"see-the-performance-of-normalized-queries-at-a-glance\"\u003e\u003ca href=\"#see-the-performance-of-normalized-queries-at-a-glance\"\u003eSee the performance of normalized queries at a glance\u003c/a\u003e\u003c/h2\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Track the performance of normalized queries with Datadog Database Monitoring\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eInefficient queries can deplete your database’s resources and block other queries from running, so it’s important to identify and optimize them in order to ensure your application remains performant. Databases aggregate similar query statements into \u003ca href=\"https://dev.mysql.com/doc/refman/8.0/en/performance-schema-statement-digests.html\"\u003enormalized queries\u003c/a\u003e—in which literal values, such as names, passwords, and dates, are replaced with question marks—to generate statistics that help database administrators troubleshoot issues with query execution. But because databases do not provide a way to sort or filter normalized queries, it can be challenging to identify the most problematic ones.\u003c/p\u003e\u003cp\u003eDatabase Monitoring enables you to track the performance of normalized queries across all of your hosts in a summary graph and sortable list, so you can see at a glance which types of queries are executed the most, how long they’re taking, how many rows are returned, and more. This helps you identify, for instance, if there are any long-running queries that return only a small number of rows, which could be a sign that your data is not indexed properly. You can also drill down to a smaller subset of queries using tags like \u003ccode\u003eservice\u003c/code\u003e, \u003ccode\u003ehost\u003c/code\u003e, and \u003ccode\u003ecluster_name\u003c/code\u003e to create a more focused view for your investigation.\u003c/p\u003e\u003ch2 id=\"troubleshoot-slow-queries-with-detailed-explain-plans\"\u003e\u003ca href=\"#troubleshoot-slow-queries-with-detailed-explain-plans\"\u003eTroubleshoot slow queries with detailed explain plans\u003c/a\u003e\u003c/h2\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"View more details for each normalized query\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eIf you notice that a particular normalized query is taking a long time to execute, you can click on it to open the Query Details panel, which includes detailed \u003ca href=\"https://dev.mysql.com/doc/refman/8.0/en/execution-plan-information.html\"\u003eexplain plans\u003c/a\u003e (also known as execution plans) for that particular query. An explain plan uses a node tree to map the sequence of steps chosen by the query planner to execute the query. Each node in the tree represents a single operation such as a table scan, sort, join, or aggregation.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"See explain plans used to execute each query\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eIn Database Monitoring, you can see the estimated cost of running each node, as well as the number of rows and bytes expected to be returned, which can help you identify operation hotspots. For instance, if your plan includes a costly sequential scan, you might want to consider creating indexes on important columns to encourage the database to use an index scan instead. Explain plans also show you how table joins are performed (i.e., which joins are used and in which order) so you can adjust your query if the query planner has selected a suboptimal plan.\u003c/p\u003e\u003ch2 id=\"analyze-historical-trends-in-query-performance\"\u003e\u003ca href=\"#analyze-historical-trends-in-query-performance\"\u003eAnalyze historical trends in query performance\u003c/a\u003e\u003c/h2\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"View timeseries graphs for key database performance metrics in the Metrics tab\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eHistorical performance data provides crucial insight into changes in database behavior and the efficacy of your optimizations, but the database itself can only report statistics on its present state. Database Monitoring addresses this issue by providing timeseries graphs for key performance indicators of normalized queries, such as total execution time, number of requests, and shared block activity. These metrics, which are available in the Metrics tab of the Query Details panel, are stored at full granularity for three months, allowing you to track performance trends over the long term. You can easily add these graphs to any dashboard, such as your \u003ca href=\"https://app.datadoghq.com/dash/integration/30404/mysql\"\u003eMySQL\u003c/a\u003e or \u003ca href=\"https://app.datadoghq.com/dash/integration/235/postgres---overview\"\u003ePostgreSQL\u003c/a\u003e dashboards, and correlate them with higher-level metrics like throughput, replication, and connections for a more comprehensive view of your database’s performance.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Creating an anomaly monitor to notify us if any of our queries take abnormally long to execute\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYou can also set up automated alerts on any query metric to stay ahead of potential issues. For instance, you can create an \u003ca href=\"https://docs.datadoghq.com/monitors/monitor_types/anomaly/\"\u003eanomaly monitor\u003c/a\u003e that will notify you if any query to your production cluster takes unusually long to execute, as shown in the screenshot above.\u003c/p\u003e\u003ch2 id=\"explore-and-visualize-sampled-queries\"\u003e\u003ca href=\"#explore-and-visualize-sampled-queries\"\u003eExplore and visualize sampled queries\u003c/a\u003e\u003c/h2\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Explore query samples from all of your databases\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eWhile normalized queries give you a high-level overview of database performance, sampled queries provide more granular insights. Datadog periodically collects a random sample of queries from all your databases—and enables you to see where each sample query was executed (i.e., on which host or application), along with other details such as its duration, cost, and explain plan. Datadog also converts sample query metadata into tags, which you can use to search, filter, and visualize individual queries when troubleshooting an issue or performing open-ended exploration. For example, you can use a table to group your most expensive queries by application in order to determine which ones you should optimize first.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Visualizing the execution plan cost of queries for each application in a table\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"detect-infrastructure-level-issues-impacting-your-database\"\u003e\u003ca href=\"#detect-infrastructure-level-issues-impacting-your-database\"\u003eDetect infrastructure-level issues impacting your database\u003c/a\u003e\u003c/h2\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Database Monitoring brings host metrics into the same view as your queries\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eQuery optimization can resolve some database issues, but others may be rooted in the underlying infrastructure. Database Monitoring automatically correlates normalized queries with host metrics to help you easily identify resource bottlenecks that degrade the performance of your databases. In the Query Details panel, you can see which of your hosts are running that normalized query, along with throughput and client connection metrics that indicate how busy those hosts are. If you see that a particular host is handling a disproportionate amount of traffic, you may need to adjust your load balancer or scale up your resources. To gather more context, you can click on the host and navigate to its default dashboard, which can be customized to include data from any part of your stack. Similarly, as you’re performing analysis in Query Samples, you can click on a sampled query and pivot to its host’s dashboard, logs, and network data for lower-level insights.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Seamlessly pivot from a sampled query to its host\u0026#39;s dashboard, logs, and network data\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"start-using-database-monitoring-today\"\u003e\u003ca href=\"#start-using-database-monitoring-today\"\u003eStart using Database Monitoring today\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog Database Monitoring tracks historical query performance metrics, explain plans, and host-level metrics from every database in your environment, so you can better understand their performance and troubleshoot issues effectively. Database Monitoring currently supports MySQL 5.6+ and PostgreSQL 9.6+ databases, regardless of whether they’re self-hosted or fully managed. Check out our \u003ca href=\"https://docs.datadoghq.com/database_monitoring/\"\u003edocumentation\u003c/a\u003e to learn how to get started. And if you’re not yet using Datadog, sign up for a 14-day \u003ca href=\"#\"\u003efree trial\u003c/a\u003e today.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/database_monitoring_feature_announcement_210716_v3a.png\" width=\"100%\"/\u003eWhen you’re running databases at scale, finding performance bottlenecks can often feel like looking for a needle in a haystack. In any troubleshooting scenario, you need to know the exact state of your database at the onset of an issue, as well as its behavior leading up to it. But databases themselves do not store historical performance metrics, which makes it extremely difficult to identify trends and determine whether the issue is caused by inefficient queries, suboptimal database design, or resource saturation.",
      "date_published": "2021-08-17T00:00:00Z",
      "author": {
        "name": "Kai Xin Tai"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/case-studies/marketplacer/",
      "title": "Tracking Cloud Security Posture in a Dynamic Environment",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003ch2 id=\"about-marketplacer\"\u003eAbout Marketplacer\u003c/h2\u003e\u003cp\u003eEstablished in 2017 in Australia, Marketplacer is a global technology platform-as-a-service (PaaS) company equipped with all the tools and functionality needed to build a successful and scalable online marketplace at speed. The Marketplacer platform exists to make growth simple. To date, the company has helped over 90 businesses execute their own successful marketplace strategies and connected over 20,000 businesses worldwide.\u003c/p\u003e\u003cspan\u003e\u003chr/\u003e\u003ch2 id=\"key-results\"\u003eKey Results\u003c/h2\u003e\u003ch4 id=\"reduced-mttd-and-mttr\"\u003eReduced MTTD and MTTR\u003c/h4\u003e\u003cp\u003eDatadog helps Marketplacer reduce the time it takes to identify and mitigate compliance issues via easy filtering and remediation guidance.\u003c/p\u003e\u003ch4 id=\"unified-platform\"\u003eUnified platform\u003c/h4\u003e\u003cp\u003eCSPM is built on the unified Datadog agent and cloud integrations, increasing cost and operational efficiency.\u003c/p\u003e\u003ch4 id=\"600-resources-audited\"\u003e600+ resources audited\u003c/h4\u003e\u003cp\u003eWith Datadog, Marketplacer gets live configuration check results on the 600+ resources so they can track their compliance over time.\u003c/p\u003e\u003chr/\u003e\u003ch2 id=\"challenge\"\u003eChallenge\u003c/h2\u003e\u003cp\u003eMarketplacer is pursuing ISO:27001 certification and needed a solution to help them identify issues and track their progress along that journey. They needed visibility into the state of their compliance across their dynamic environment, and across different points in time. With a small security team, they wanted an easy-to-use solution that wouldn’t induce alert fatigue or require a high barrier to entry.\u003c/p\u003e\u003chr/\u003e\u003ch2 id=\"why-datadog\"\u003eWhy Datadog?\u003c/h2\u003e\u003cp\u003eDatadog offers Marketplacer a fully integrated Cloud Security Posture Management solution that enables everyone on their team to easily drill down into security posture issues and get actionable links to resources for mitigation.\u003c/p\u003e\u003chr/\u003e\u003c/span\u003e\u003c/div\u003e\u003cdiv\u003e\u003cspan\u003e\u003cp\u003eUnderstanding the state of your cloud security posture and the steps you need to take to mitigate misconfigurations is crucial for maintaining a strong security posture. At Marketplacer, keeping up to date with the state of their infrastructure compliance as they progressed toward an ISO:27001 certification was proving to be a challenge.\u003c/p\u003e\u003cp\u003eAs Marketplacer began to expand internationally and work with larger customers, the infrastructure and security team organized around the goal of becoming compliant with ISO:27001 in order to meet the requirements of these new customers. As a cloud-native organization running on AWS, cloud security posture was a core element they needed to track and maintain. However, visibility into this area was limited—developers were working in silos when it came to configuring resources, and lacked a centralized way to manage configurations across the organization.\u003c/p\u003e\u003cblockquote\u003e\u003cp\u003e\u003cem\u003e“ Building a compliant and secure platform is a high priority for our customers. We want to be proactive with our security.”\u003c/em\u003e\u003c/p\u003e\u003cp\u003eChristian Kornacker\u003cbr/\u003eDevOps Lead, Marketplacer\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003eMarketplacer increasingly saw the need for a solution that could help them detect and remediate misconfigurations and other issues quickly in a rapidly changing environment. Furthermore, as big proponents of infrastructure as code, they could easily provision large swathes of resources with a single command—but they needed guardrails in place to help them understand how each deployment would affect both their security posture and adherence to ISO:27001.\u003c/p\u003e\u003cp\u003eThey set out to find a Cloud Security Posture Management solution that could meet their growing needs, but they didn’t like the high expertise requirements, noisy alerting, and complexity of the first few platforms they explored.\u003c/p\u003e\u003cp\u003eMarketplacer ultimately chose Datadog because it gives the engineers on the infrastructure and security team the ability to drill down into security posture issues as they crop up, with links to resources on how to remediate them. Additionally, Datadog allows them to track the results of their configuration checks each time they deploy, so they can better compare their security posture status across releases, and find ways to move closer to ISO:27001 compliance.\u003c/p\u003e\u003cblockquote\u003e\u003cp\u003e\u003cem\u003e“ Datadog is easy to use, but at the same time, very comprehensive. What I like about Datadog is that you don’t need to be a security or compliance expert to go through your misconfigurations and fix them across the team.”\u003c/em\u003e\u003c/p\u003e\u003cp\u003eChristian Kornacker\u003cbr/\u003eDevOps Lead, Marketplacer\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003eMarketplacer leverages Datadog’s dashboards and executive reporting to get summaries and track conformance to specific industry benchmarking criteria. The out-of-the-box cloud configuration rules map to various benchmarks and relevant controls, making it easy for everyone across the company to understand and get value out of the platform. For a small but growing team, the dashboards and mitigation advice help reduce complexity. Marketplacer also sets up bespoke, actionable alerts for each team, enabling everyone to maximize the impact of time spent on monitoring and maintaining their security posture.\u003c/p\u003e\u003cp\u003eEach time Markerplacer updates or deploys new resources, the team can check their security posture dashboard in Datadog to see which resource configurations don’t match the available rules. Because Datadog provides rich context around those resources, the team can easily go back to their infrastructure as code definitions to mitigate any issues that arise that may impact their compliance.\u003c/p\u003e\u003cblockquote\u003e\u003cp\u003e\u003cem\u003e“ Datadog is the best I’ve seen when it comes to alerting. We can drill down to only see the issues that matter and reduce the noise. Each alert tells us why it exists and what to do about it—which is particularly helpful if you’re a junior infrastructure engineer.”\u003c/em\u003e\u003c/p\u003e\u003cp\u003eChristian Kornacker\u003cbr/\u003eDevOps Lead, Marketplacer\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003eAdditionally, Datadog continuously scans and surveys every resource, no matter how short-lived, so Marketplacer can answer tough questions and identify the state of their security posture down to specific resources and time frames.\u003c/p\u003e\u003cp\u003eCloud Security Posture Management is part of the Datadog Cloud Security Platform, which helps an organization protect its production environment with a full-stack offering providing threat detection, posture management, workload security, and application security.\u003c/p\u003e\u003cp\u003eBecause Datadog Cloud Security Posture Management is fully integrated with the rest of the Datadog platform as well, the Marketplacer team can get a single unified view of their environment. They also leverage Datadog for APM and logging, with a focus on finding problems before they impact customers. With the addition of Cloud Security Posture Management, Datadog lets them bring that same focus to security.\u003c/p\u003e\u003cp\u003eWith a Cloud Security Posture Management solution that not only gives them visibility into their security posture, but also enables them to find actionable industry recommendations for resolving issues, Marketplacer is seeing significant reductions in their MTTD and MTTR. As they move closer to ISO:27001 certification, Marketplacer has also been able to proactively address any issues that arise before they impact customers.\u003c/p\u003e\u003cblockquote\u003e\u003cp\u003e\u003cem\u003e“ The speed and number of new configuration checks that Datadog adds on a regular basis is incredible. The trajectory of the product is so impressive.”\u003c/em\u003e\u003c/p\u003e\u003cp\u003eChristian Kornacker\u003cbr/\u003eDevOps Lead, Marketplacer\u003c/p\u003e\u003c/blockquote\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "About Marketplacer Established in 2017 in Australia, Marketplacer is a global technology platform-as-a-service (PaaS) company equipped with all the tools and functionality needed to build a successful and scalable online marketplace at speed. The Marketplacer platform exists to make growth simple. To date, the company has helped over 90 businesses execute their own successful marketplace strategies and connected over 20,000 businesses worldwide. Key Results Reduced MTTD and MTTR Datadog helps Marketplacer reduce the time it takes to identify and mitigate compliance issues via easy filtering and remediation guidance.",
      "date_published": "2021-08-13T00:00:00Z",
      "author": {
        "name": "Datadog"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/datadog-serverless-view/",
      "title": "Monitor your entire serverless stack in the Serverless view",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eServerless event-driven architectures are composed of AWS Lambda functions that regularly interact with databases, APIs, message queues, and other resources to facilitate complex workflows and functionalities. It is therefore crucial to monitor every component of your stack to ensure your applications perform optimally at scale. But traditionally, telemetry data for AWS resources has lived in silos, making it difficult to quickly get the context you need to debug issues. For instance, if the end-to-end latency of a customer request to your application’s backend suddenly spiked, you would need to dig into each resource’s Amazon CloudWatch metrics and logs to figure out whether an overloaded database, throttled Lambda function, or misconfigured API Gateway endpoint was to blame.\u003c/p\u003e\u003cp\u003eAs today’s serverless applications become increasingly complex, we’re excited to announce that we’ve fully redesigned the \u003ca href=\"https://app.datadoghq.com/functions\"\u003eServerless view\u003c/a\u003e to meet our customers\u0026#39; need for a more seamless debugging experience. The new Serverless view unifies telemetry data from Lambda functions and other AWS resources to give you a full overview of your entire serverless stack—making it the ideal starting point for monitoring, debugging, and optimizing your applications.\u003c/p\u003e\u003ch2 id=\"create-a-logical-view-of-your-serverless-application\"\u003e\u003ca href=\"#create-a-logical-view-of-your-serverless-application\"\u003eCreate a logical view of your serverless application\u003c/a\u003e\u003c/h2\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"See all your serverless resources, grouped by service, in the newly-redesigned Serverless view\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eBy default, the Serverless view groups your serverless resources by service to help you easily visualize how each part of your application is performing. For each service, you will see the functions that belong to it, along with the resources (Amazon API Gateway, SNS, SQS, DynamoDB, S3, EventBridge, Kinesis) that invoked them.\u003c/p\u003e\u003cp\u003eWhile grouping by service is the default, you can also group your resources by AWS CloudFormation stack name, as well as any other tags you’ve configured (e.g., team, project, or environment). Additionally, \u003ca href=\"https://docs.datadoghq.com/logs/explorer/saved_views/\"\u003eSaved Views\u003c/a\u003e allows you to preserve your preferred way of grouping, so you don’t need to manually enter it every time you visit the page.\u003c/p\u003e\u003ch2 id=\"detect-and-debug-performance-issues-across-your-stack\"\u003e\u003ca href=\"#detect-and-debug-performance-issues-across-your-stack\"\u003eDetect and debug performance issues across your stack\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eThe Serverless view enables you to correlate high-level metrics from AWS resources with those of Lambda functions, so you can quickly spot issues and jump-start your investigation. In the example below, we can see that one of our Lambda functions is frequently invoked, which is causing our cloud costs to increase. But the age of the oldest message in the SQS queue that invokes the function is 0 seconds, which indicates that SQS is not under heavy load.\u003c/p\u003e\u003cp\u003eBy clicking on the queue, we can seamlessly pivot to the default dashboard for SQS and view additional statistics on message and queue activity. As our application is not latency-sensitive, we can increase the \u003ca href=\"https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html#events-sqs-eventsource\"\u003equeue’s batch size\u003c/a\u003e, such that more requests are processed by each Lambda invocation—reducing invocation count and costs.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Increased traffic to a SQS queue is causing a Lambda function to be frequently invoked\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eOr, say that in a different case, a monitor alerts us of elevated latency in API Gateway. In the Serverless view, we can immediately see that the \u003ccode\u003etheme-park-initstate\u003c/code\u003e function, which is invoked by our API, is experiencing increased throttling.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Correlated error rates in API Gateway and Lambda\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eTo investigate, we can click on the problematic Lambda function to view a full list of its invocations, along with key metrics, traces, and logs. Datadog APM visualizes Lambda functions and the AWS resources they invoke all in one trace, so we can track the flow of requests across our distributed architecture and determine whether the issue has propagated to downstream resources.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Visualize the full lifespan of a request with Datadog APM\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"start-monitoring-your-serverless-applications-in-the-serverless-view\"\u003e\u003ca href=\"#start-monitoring-your-serverless-applications-in-the-serverless-view\"\u003eStart monitoring your serverless applications in the Serverless view\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAll customers can now group their serverless resources using any tag in the new \u003ca href=\"https://app.datadoghq.com/functions\"\u003eServerless view\u003c/a\u003e. At this time, only Python and Node.js functions are tied to their related resources, but we plan to add support for more runtimes in the future. To get started, \u003ca href=\"https://docs.datadoghq.com/serverless/installation\"\u003eenable Datadog APM for tracing\u003c/a\u003e and ensure you’re running Lambda Library v28+ for \u003ca href=\"https://github.com/DataDog/datadog-lambda-python/releases\"\u003ePython\u003c/a\u003e and v49+ for Node.js. Or if you’re already using AWS X-Ray to trace your applications, all you need to do is \u003ca href=\"https://docs.datadoghq.com/serverless/troubleshooting/connect_invoking_resources\"\u003eadd the Lambda Library to your functions\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eNew to Datadog? Get started with a 14-day \u003ca href=\"#\"\u003efree trial\u003c/a\u003e today.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/datadog-serverless-view/Serverless-view_Feature-Announcement_210729_v4a.png\" width=\"100%\"/\u003eServerless event-driven architectures are composed of AWS Lambda functions that regularly interact with databases, APIs, message queues, and other resources to facilitate complex workflows and functionalities. It is therefore crucial to monitor every component of your stack to ensure your applications perform optimally at scale. But traditionally, telemetry data for AWS resources has lived in silos, making it difficult to quickly get the context you need to debug issues. For instance, if the end-to-end latency of a customer request to your application\u0026rsquo;s backend suddenly spiked, you would need to dig into each resource\u0026rsquo;s Amazon CloudWatch metrics and logs to figure out whether an overloaded database, throttled Lambda function, or misconfigured API Gateway endpoint was to blame.",
      "date_published": "2021-08-06T00:00:00Z",
      "author": {
        "name": "Alex Cuoci"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/amazon-efs-monitoring-datadog/",
      "title": "EFS Monitoring with Datadog",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eIn \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-metrics\"\u003ePart 1\u003c/a\u003e of this series, we looked at the key EFS metrics you should monitor, and in \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-monitoring-tools\"\u003ePart 2\u003c/a\u003e we showed you how you can use tools from AWS and Linux to collect and alert on EFS metrics and logs. Monitoring EFS in isolation, however, can lead to visibility gaps as you try to understand the full context of your application’s health and performance. To meet the challenge of monitoring this dynamic storage system and its heterogeneous clients, you need to explore and alert on metrics and logs from EFS alongside data from your clients, related AWS services, and other key technologies.\u003c/p\u003e\u003cp\u003eDatadog provides complete EFS visibility, allowing you to monitor the size of your file systems and the behavior of the many different clients—EC2 instances, EKS pods, Lambda functions, and more—that access your data. In this post, we’ll show you how to:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"#integrate-efs-with-datadog\"\u003eIntegrate EFS with Datadog\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#bring-on-the-metrics\"\u003eVisualize EFS metrics\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#alert-on-efs-activity-and-performance\"\u003eAlert on EFS activity and performance\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#collect-efs-logs\"\u003eCollect EFS logs\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"The out-of-the-box EFS dashboard shows metrics that describe I/O, operation size, and configuration of multiple EFS file systems.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"integrate-efs-with-datadog\"\u003e\u003ca href=\"#integrate-efs-with-datadog\"\u003eIntegrate EFS with Datadog\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog’s AWS integration gives you deep visibility into EFS and the other AWS services you’re using, all in a single platform. In this section, we’ll show you how to add EFS to your AWS monitoring—or how to enable the AWS integration if you’re just getting started—so you can visualize, analyze, and alert on the performance of the AWS services you rely on.\u003c/p\u003e\u003ch3 id=\"add-efs-to-your-aws-monitoring\"\u003e\u003ca href=\"#add-efs-to-your-aws-monitoring\"\u003eAdd EFS to your AWS monitoring\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eIf you’re already monitoring some AWS services, you can add EFS to the mix by clicking the \u003cstrong\u003eConfiguration\u003c/strong\u003e tab on the \u003ca href=\"https://app.datadoghq.com/account/settings#integrations/amazon-web-services\"\u003eAWS Integration tile\u003c/a\u003e. Check the “EFS” box under the “Limit metric collection by AWS Service” list, as well as the boxes for any other AWS services you want to add to your monitoring. If you’re using Lambda with EFS, check the “Lambda” box and follow the steps for \u003ca href=\"https://docs.datadoghq.com/integrations/amazon_efs/#amazon-efs-for-lambda\"\u003eenabling EFS for Lambda\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eOnce you’ve checked the boxes for all the AWS services you want to monitor, click the “Update Configuration” button. Metrics will begin flowing into your Datadog account within a few minutes so you can quickly get started using EFS \u003ca href=\"#bring-on-the-metrics\"\u003edashboards, tags, and alerts\u003c/a\u003e.\u003c/p\u003e\u003ch3 id=\"start-monitoring-efs-and-other-aws-services\"\u003e\u003ca href=\"#start-monitoring-efs-and-other-aws-services\"\u003eStart monitoring EFS and other AWS services\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eIf you’re not yet monitoring AWS services with Datadog, you can start by installing the AWS integration with our \u003ca href=\"https://www.datadoghq.com/blog/aws-1-click-integration/\"\u003e1-click installation\u003c/a\u003e process. The 1-click process is based on CloudFormation, and you’ll need to create an IAM role and an associated policy. Once you’ve completed the installation steps described in our \u003ca href=\"https://www.datadoghq.com/blog/aws-1-click-integration/#click-here\"\u003eblog post\u003c/a\u003e, Datadog will begin automatically \u003ca href=\"#bring-on-the-metrics\"\u003ecollecting EFS metrics\u003c/a\u003e, as well as metrics from the other AWS services in your stack.\u003c/p\u003e\u003ch2 id=\"bring-on-the-metrics\"\u003e\u003ca href=\"#bring-on-the-metrics\"\u003eBring on the metrics\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eThe \u003ca href=\"https://app.datadoghq.com/screen/integration/30330/aws-efs\"\u003ebuilt-in EFS dashboard\u003c/a\u003e—shown in the screenshot at the beginning of this post—brings together I/O metrics, throughput metrics, and burst credit balance data for all of the file systems in your account, so you can understand each file system’s health and performance at a glance.\u003c/p\u003e\u003cp\u003eYou can easily \u003ca href=\"https://docs.datadoghq.com/getting_started/dashboards/#start-by-reusing-other-dashboards\"\u003ecustomize the dashboard\u003c/a\u003e to graph EFS metrics alongside metrics from other AWS services. For example, \u003ca href=\"https://docs.datadoghq.com/agent/amazon_ecs/?tab=awscli\"\u003eAmazon ECS\u003c/a\u003e Auto Scaling metrics could explain changes in the number of clients connecting to your file system and \u003ca href=\"https://docs.datadoghq.com/integrations/amazon_sqs/\"\u003eAmazon SQS\u003c/a\u003e metrics might reveal a backlog of work your clients need to process. And you can add even more context to your EFS metrics by correlating them with data from any of Datadog’s more than\n450 other integrations.\u003c/p\u003e\u003cp\u003eYou can also leverage Datadog’s tagging system to organize, filter, and explore specific subsets of your data, such as the performance of an individual file system or even a specific client. Datadog automatically tags your EFS metrics to show the AWS account, file system, and region where they came from, and you can also add custom tags (for example, to identify the application for which a file system provides storage) from within the EFS console or by including them in a \u003ca href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/quickref-efs.html\"\u003eCloudFormation template\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eYou can even \u003ca href=\"https://docs.datadoghq.com/getting_started/tagging/\"\u003ecreate common tags\u003c/a\u003e across your metrics, logs, and traces so you can correlate them to understand the context of what you see on your dashboards. For example, if EFS metrics show that a file system’s burst credits are exhausted, you can seamlessly navigate to APM to see if any of your application’s services shows a corresponding increase in latency.\u003c/p\u003e\u003ch2 id=\"alert-on-efs-activity-and-performance\"\u003e\u003ca href=\"#alert-on-efs-activity-and-performance\"\u003eAlert on EFS activity and performance\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDashboards let you visualize real-time metrics, but you can also create alerts to automatically notify you if the value of a metric crosses a threshold that could affect your file systems\u0026#39; performance and your EFS costs.\u003c/p\u003e\u003cp\u003eFor example, you may want to be notified if your file system is running out of \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-metrics#metric-to-alert-on-i-o-utilization\"\u003eIOPS\u003c/a\u003e (by creating an alert on the \u003ccode\u003eaws.efs.percent_iolimit\u003c/code\u003e metric) or \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-metrics#metric-to-alert-on-burst-credit-balance\"\u003eburst credits\u003c/a\u003e (\u003ccode\u003eaws.efs.burst_credit_balance\u003c/code\u003e) so you can proactively address an issue before it causes your application to slow down. And if you want to watch your file system for changes that could indicate cost anomalies or security concerns, you can create alerts to notify you of any unusual changes in metrics like \u003ccode\u003eaws.efs.data_write_iobytes*\u003c/code\u003e or \u003ccode\u003eaws.efs.storage_bytes\u003c/code\u003e, as shown in the screenshot below.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog\u0026#39;s New Monitor screen defines an alert with a warning threshold of 180 GB and an alert threshold of 200 GB.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eAn alert based on a threshold can keep you informed of unexpected changes in your metrics, but it can be hard to determine the value you should use for the threshold. \u003ca href=\"https://docs.datadoghq.com/monitors/monitor_types/anomaly/\"\u003eAnomaly-based monitors\u003c/a\u003e can notify you automatically of changes that are out of line with a metric’s history so you don’t have to choose a threshold value to define what’s normal and expected. For example, the number of \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-metrics#metric-to-alert-on-client-connections\"\u003eclients connected\u003c/a\u003e to your file system may be dynamic, but if it drops due to a configuration error that prevents new instances from connecting, an anomaly monitor can notify you of the unexpected change. In the screenshot below, the recent history of the \u003ccode\u003eaws.efs.client_connections\u003c/code\u003e metric appears on the left, and the expected future values of this metric appear in the gray band in the graph on the right.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"The New Monitor screen for an Anomaly Monitor shows the history and the expected range of values of the connected clients metric.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"collect-efs-logs\"\u003e\u003ca href=\"#collect-efs-logs\"\u003eCollect EFS logs\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn Part 2 of this series, we showed you how you can publish \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-monitoring-tools#mount-helper-logs\"\u003emount helper logs\u003c/a\u003e and \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-monitoring-tools#vpc-flow-logs\"\u003eflow logs\u003c/a\u003e to CloudWatch. In this section, we’ll show you how to forward those logs from CloudWatch to Datadog so you can explore and correlate them with logs from other technologies in your stack.\u003c/p\u003e\u003ch3 id=\"enable-log-collection\"\u003e\u003ca href=\"#enable-log-collection\"\u003eEnable log collection\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eOnce you’re sending your EFS logs to CloudWatch Logs, you can \u003ca href=\"https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination/\"\u003eroute them to Datadog\u003c/a\u003e by way of a \u003ca href=\"https://docs.aws.amazon.com/firehose/latest/dev/what-is-this-service.html\"\u003eKinesis Data Firehose delivery stream\u003c/a\u003e. Sending logs from EFS—and other AWS services—through Kinesis allows you to leverage AWS’s managed service for streaming logs and frees you from the challenges of managing concurrency and throttling that come with deploying your own \u003ca href=\"https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-lambda-function/\"\u003eLambda forwarder\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIf you’re already collecting AWS service logs into a delivery stream in Firehose, you can add your EFS logs to the same stream. They’ll be delivered to Datadog alongside your other logs, but they’ll be distinguished by \u003ccode\u003eservice\u003c/code\u003e and \u003ccode\u003esource\u003c/code\u003e values that show the name of the \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-monitoring-tools#mount-helper-logs\"\u003eCloudWatch log\u003c/a\u003e group you configured to collect them.\u003c/p\u003e\u003cp\u003eIf you’re not yet collecting AWS service logs through Firehose, create a delivery stream and \u003ca href=\"https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination\"\u003econfigure Datadog as the destination\u003c/a\u003e. Then, \u003ca href=\"https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination/?tab=kinesisfirehosedeliverystream#send-aws-logs-to-your-kinesis-stream\"\u003eadd a subscription filter\u003c/a\u003e to the CloudWatch log group where you’re collecting your EFS logs and set your Kinesis Data Firehose delivery stream as the filter’s destination. See the \u003ca href=\"https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination/\"\u003edocumentation\u003c/a\u003e for more information about sending AWS service logs into Datadog via Kinesis.\u003c/p\u003e\u003ch3 id=\"explore-and-analyze-your-logs\"\u003e\u003ca href=\"#explore-and-analyze-your-logs\"\u003eExplore and analyze your logs\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eDatadog brings together logs from AWS services—including EFS—and many other technologies into a single platform, where you can explore and analyze them with the help of tags. Just as with \u003ca href=\"#bring-on-the-metrics\"\u003emetrics\u003c/a\u003e, Datadog automatically tags your EFS logs to show the AWS account, region, and file system where they originated, and you can apply custom tags by adding parameters when you configure Datadog as the \u003ca href=\"https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination\"\u003edestination\u003c/a\u003e for your delivery stream.\u003c/p\u003e\u003cp\u003eYou can also add \u003ca href=\"https://docs.datadoghq.com/logs/explorer/facets/\"\u003efacets\u003c/a\u003e to your tags to make it easy to group logs from related sources and present a fuller picture of activity across your stack. For example, if you apply an \u003ccode\u003eapplication\u003c/code\u003e tag to identify EFS logs originating from a specific application, you can apply the same tag to logs from your clients and related AWS services (e.g., an ELB that distributes incoming requests to your EC2 fleet). Then, you can \u003ca href=\"https://docs.datadoghq.com/logs/explorer/facets/#create-facets\"\u003ecreate a facet\u003c/a\u003e based on that tag to group logs from all layers of your application.\u003c/p\u003e\u003cp\u003eIn the screenshot below, we’ve created a facet on the \u003ccode\u003edatadog_app\u003c/code\u003e tag to isolate logs from a single application, and we’ve grouped them by \u003ccode\u003eregion\u003c/code\u003e to show relative amounts of EFS traffic by geography. We’ve also filtered the logs using a \u003ca href=\"https://docs.datadoghq.com/logs/explorer/facets/#quantitative-facets\"\u003emeasure\u003c/a\u003e—a type of facet based on the value of a log field—to reveal logs that represent a large amount of write activity.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"An area graph shows the rate of bytes written by EFS clients in each AWS region.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"gain-full-visibility-into-efs-with-datadog\"\u003e\u003ca href=\"#gain-full-visibility-into-efs-with-datadog\"\u003eGain full visibility into EFS with Datadog\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eEFS can serve a key role in your application, supporting simultaneous access across numerous clients, including \u003ca href=\"https://docs.datadoghq.com/integrations/amazon_ec2/\"\u003eEC2\u003c/a\u003e instances, \u003ca href=\"https://docs.datadoghq.com/integrations/amazon_lambda/\"\u003eLambda\u003c/a\u003e functions, and \u003ca href=\"https://www.datadoghq.com/blog/amazon-ecs-metrics/\"\u003eAmazon Elastic Container Service (ECS)\u003c/a\u003e tasks. Datadog gives you full visibility into each of these services, in addition to more than\n450 other technologies, so you can monitor the health and performance of your file systems in context. If you’re not already using Datadog, start today with a \u003ca href=\"#\"\u003e14-day free trial\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cem\u003eSource Markdown for this post is available \u003ca href=\"https://github.com/DataDog/the-monitor/blob/master/efs/amazon-efs-monitoring-datadog.md\"\u003eon GitHub\u003c/a\u003e. Questions, corrections, additions, etc.? Please \u003ca href=\"https://github.com/DataDog/the-monitor/issues\"\u003elet us know\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/amazon_efs_longform_part-3v2.png\" width=\"100%\"/\u003eIn Part 1 of this series, we looked at the key EFS metrics you should monitor, and in Part 2 we showed you how you can use tools from AWS and Linux to collect and alert on EFS metrics and logs. Monitoring EFS in isolation, however, can lead to visibility gaps as you try to understand the full context of your application\u0026rsquo;s health and performance. To meet the challenge of monitoring this dynamic storage system and its heterogeneous clients, you need to explore and alert on metrics and logs from EFS alongside data from your clients, related AWS services, and other key technologies.",
      "date_published": "2021-08-05T00:00:00Z",
      "author": {
        "name": "David M. Lentz"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/amazon-efs-metrics/",
      "title": "Key metrics for monitoring Amazon EFS",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003ca href=\"https://aws.amazon.com/efs/\"\u003eAmazon Elastic File System (EFS)\u003c/a\u003e provides shared, persistent, and elastic storage in the AWS cloud. Like \u003ca href=\"https://aws.amazon.com/s3/\"\u003eAmazon S3\u003c/a\u003e, EFS is a highly available managed service that scales with your storage needs, and it also enables you to mount a file system to an EC2 instance, similar to \u003ca href=\"https://aws.amazon.com/ebs/\"\u003eAmazon Elastic Block Store (EBS)\u003c/a\u003e. But EFS offers other features—like simultaneous access from multiple clients and \u003ca href=\"https://aws.amazon.com/blogs/compute/using-amazon-efs-for-aws-lambda-in-your-serverless-applications/\"\u003eAWS Lambda integration\u003c/a\u003e—that make it well-suited for use cases such as big data workloads, machine learning, and serving web content.\u003c/p\u003e\u003cp\u003eIt’s important to monitor EFS latency, I/O, throughput, and connections in order to ensure the performance of the services and applications that access your file systems. Monitoring EFS can also help you understand costs, which are determined in part by the size and settings of your file systems. In this post, we’ll show you which Amazon EFS metrics are important to monitor, but first, let’s look at how EFS works.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format\u0026amp;w=1140 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format\u0026amp;w=1140\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format\u0026amp;w=942 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format\u0026amp;w=942\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format\u0026amp;w=847\" alt=\"I/O, throughput, and connection graphs shown on a Datadog built-in dashboard are useful in monitoring Amazon EFS.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"an-overview-of-efs\"\u003e\u003ca href=\"#an-overview-of-efs\"\u003eAn overview of EFS\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eEFS is based on the \u003ca href=\"https://en.wikipedia.org/wiki/Network_File_System\"\u003eNetwork File System (NFS)\u003c/a\u003e protocol, and it automatically handles \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html#consistency\"\u003edata consistency\u003c/a\u003e and manages \u003ca href=\"https://en.wikipedia.org/wiki/File_locking\"\u003efile locking\u003c/a\u003e to safely allow for parallel access from multiple clients. You can access EFS from EC2 instances, Lambda functions, \u003ca href=\"https://aws.amazon.com/sagemaker/\"\u003eAmazon SageMaker\u003c/a\u003e notebook instances, and AWS \u003ca href=\"https://aws.amazon.com/blogs/storage/best-practices-for-using-amazon-efs-for-container-storage/\"\u003econtainer services\u003c/a\u003e (ECS tasks and EKS pods running on EC2 or Fargate). If you’re using Direct Connect, you can also connect to EFS from on-premise hosts. This flexibility makes EFS appropriate for a variety of use cases: for example, you can store static website data in EFS and serve it from a fleet of EC2 instances or ECS tasks, or run a big data application comprised of Lambda functions that read the data, normalize it, and write it back to the file system.\u003c/p\u003e\u003cp\u003eBy default, EFS stores copies of your data in multiple availability zones (AZs) and provides access to clients via \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/accessing-fs.html\"\u003e\u003cstrong\u003emount targets\u003c/strong\u003e\u003c/a\u003e. When you create a mount target, AWS creates an \u003ca href=\"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_ElasticNetworkInterfaces.html\"\u003eElastic Network Interface (ENI)\u003c/a\u003e in a subnet you specify, providing a local endpoint for all clients in that subnet (or clients that can \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/manage-fs-access-vpc-peering.html\"\u003eroute to it\u003c/a\u003e). AWS recommends creating a mount target in each AZ to minimize latency and avoid cross-zone data transfer charges.\u003c/p\u003e\u003cp\u003eThe diagram below shows an EFS file system that stores its data across two availability zones. A subnet in each AZ contains a mount target, and EC2 instances within the subnet communicate with the local mount target. The diagram also shows a Lambda function accessing the mount target in each subnet via ENIs that are \u003ca href=\"https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html\"\u003ecreated automatically\u003c/a\u003e when the function is connected to the VPC.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"A diagram of EFS architecture shows a file system inside a VPC. Two availability zones in the VPC contain EC2 instances connected to EFS mount targets. From outside the VPC, a Lambda function connects to the mount targets.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003e\u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/efs-access-points.html\"\u003e\u003cstrong\u003eAccess points\u003c/strong\u003e\u003c/a\u003e enable you to limit a client’s access to a subset of a file system by specifying a path for the client to use as its root directory. You can create multiple access points to give different applications access to different subdirectories, and you can optionally configure an access point to \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/efs-access-points.html#enforce-identity-access-points\"\u003eenforce a user identity\u003c/a\u003e so that all clients access the data as a single user. You can also create a \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/iam-access-control-nfs-efs.html\"\u003e\u003cstrong\u003efile system policy\u003c/strong\u003e\u003c/a\u003e to allow or deny connections to an access point.\u003c/p\u003e\u003cp\u003eA file system must have an access point in order for Lambda functions to connect to it. Other clients—EC2 instances, ECS tasks, EKS pods, and SageMaker notebooks—can mount a file system without using an access point if the file system policy will allow it, but this may give your applications \u003ca href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#grant-least-privilege\"\u003egreater access than necessary\u003c/a\u003e.\u003c/p\u003e\u003ch3 id=\"performance-modes\"\u003e\u003ca href=\"#performance-modes\"\u003ePerformance modes\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eEFS operates in one of two \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/performance.html#performancemodes\"\u003e\u003cstrong\u003eperformance modes\u003c/strong\u003e\u003c/a\u003e, which influence the file system’s latency and I/O operations per second (IOPS). General Purpose mode is the default, and it provides the lowest latency for most use cases. Max I/O mode provides higher IOPS, although it adds some \u003ca href=\"https://aws.amazon.com/premiumsupport/knowledge-center/linux-efs-performance-modes/\"\u003elatency\u003c/a\u003e to each operation. If your workload’s data access is parallelized across a large number of clients or processes—for example, training a machine learning algorithm—Max I/O can improve your application’s data storage and retrieval performance.\nYou can choose either performance mode without affecting your EFS costs, but you can’t change the performance mode of a file system after you’ve created it.\u003c/p\u003e\u003ch3 id=\"throughput-modes\"\u003e\u003ca href=\"#throughput-modes\"\u003eThroughput modes\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eYou can also choose your file system’s \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/performance.html#throughput-modes\"\u003e\u003cstrong\u003ethroughput mode\u003c/strong\u003e\u003c/a\u003e, which determines the amount of data your clients can read and write in each disk operation.\nBursting Throughput is the default mode. It provides a consistent baseline level of throughput that is proportional to your file system’s size, but it also allows you to burst above the baseline for relatively short periods of time. Your baseline throughput scales up as your file system grows, and your ability to burst increases (i.e., you accrue \u003cstrong\u003eburst credits\u003c/strong\u003e) as your file system operates below the baseline throughput rate.\u003c/p\u003e\u003cp\u003eIf your application consistently requires throughput above the baseline level provided by Bursting Throughput mode, you can choose to use Provisioned Throughput mode instead. This mode allows you to specify a level of throughput that is always available regardless of the size of your file system. Provisioned Throughput mode carries an additional cost, but if the amount of data your application uses is small relative to your throughput needs—for example, a static website with high traffic—it can help you ensure that your file system is not a bottleneck for your application’s performance.\u003c/p\u003e\u003ch3 id=\"storage-classes\"\u003e\u003ca href=\"#storage-classes\"\u003eStorage classes\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eEach file system you create in EFS keeps your data in one or more \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/storage-classes.html\"\u003e\u003cstrong\u003estorage classes\u003c/strong\u003e\u003c/a\u003e, which provide different levels of availability and performance, and which incur different costs. The Standard storage class keeps data in multiple availability zones within the VPC where you created your file system. In contrast, the One Zone class stores data in a single AZ, which reduces both the \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/storage-classes.html#sc-compare\"\u003eavailability\u003c/a\u003e of your data and the costs associated with storing it. These tradeoffs make the One Zone class most appropriate for storing temporary data that can be easily recreated, such as staging or build environments.\u003c/p\u003e\u003cp\u003eYou can configure EFS to automatically move data from either of these classes to an infrequent access (IA) class—Standard-Infrequent Access or One Zone-Infrequent Access—if it is not accessed within a \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/lifecycle-management-efs.html\"\u003etime frame you specify\u003c/a\u003e. It’s less expensive to use IA classes, so storing unused data there can help you manage your EFS costs. But you must pay a per-access charge any time you retrieve data from IA, and the latency is higher, so it may or may not be your preferred storage option, depending on your data access patterns.\u003c/p\u003e\u003ch2 id=\"key-amazon-efs-metrics-to-monitor\"\u003e\u003ca href=\"#key-amazon-efs-metrics-to-monitor\"\u003eKey Amazon EFS metrics to monitor\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eSo far in this post, we’ve shown you how EFS provides shared storage to a variety of clients, and we’ve looked at the configuration options that let you balance availability, performance, and cost. In this section, we’ll walk you through the key metrics you should monitor to fully understand the health and performance of your file system. We’ll show you metrics from the following categories:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"#storage-metrics\"\u003estorage\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#latency-metrics\"\u003elatency\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#io-metrics\"\u003eI/O\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#throughput-metrics\"\u003ethroughput\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#connection-metrics\"\u003eclient connections\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eTerminology in this section comes from our \u003ca href=\"https://www.datadoghq.com/blog/monitoring-101-collecting-data/\"\u003eMonitoring 101\u003c/a\u003e series. Most of the metrics in this section are available from \u003ca href=\"https://aws.amazon.com/cloudwatch/\"\u003eAmazon CloudWatch\u003c/a\u003e, but some come from Linux utilities. We’ll explore these and some other tools you can use to collect Amazon EFS metrics in \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-monitoring-tools\"\u003ePart 2\u003c/a\u003e of this series.\u003c/p\u003e\u003ch3 id=\"storage-metrics\"\u003e\u003ca href=\"#storage-metrics\"\u003eStorage metrics\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eEFS is elastic and will scale to provide more storage as your needs increase. But the size of your file system affects your EFS costs, so it’s important to track how much data you’re storing—overall and in each storage class—in order to understand and anticipate your monthly charges.\u003c/p\u003e\u003ctable\u003e\u003cthead\u003e\u003ctr\u003e\u003cth\u003eName\u003c/th\u003e\u003cth\u003eDescription\u003c/th\u003e\u003cth\u003eMetric type\u003c/th\u003e\u003cth\u003eAvailability\u003c/th\u003e\u003c/tr\u003e\u003c/thead\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003eFile size\u003c/td\u003e\u003ctd\u003eStorage space used by a single file or directory\u003c/td\u003e\u003ctd\u003eResource: Utilization\u003c/td\u003e\u003ctd\u003eLinux utilities\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eFile system size\u003c/td\u003e\u003ctd\u003eAggregate storage space used by a file system\u003c/td\u003e\u003ctd\u003eResource: Utilization\u003c/td\u003e\u003ctd\u003eCloudWatch, Linux utilities\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003ch4 id=\"metric-to-watch-file-size\"\u003e\u003ca href=\"#metric-to-watch-file-size\"\u003eMetric to watch: File size\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eMonitoring the size of individual files or directories can give you granular insight into your EFS usage. You should track the growth of files that contribute significantly to your overall usage—for example, fast-growing log files—to understand and accurately predict your application’s storage needs.\u003c/p\u003e\u003ch4 id=\"metric-to-watch-file-system-size\"\u003e\u003ca href=\"#metric-to-watch-file-system-size\"\u003eMetric to watch: File system size\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eA typical disk utilization metric doesn’t apply in the case of EFS, which has no fixed upper limit on the amount of data you can store. But monitoring your file system size over time can show you how your application is storing and accessing data in three dimensions: the Standard storage classes, the IA storage classes, and in total.\nIf you’re using \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/lifecycle-management-efs.html\"\u003elifecycle management\u003c/a\u003e, this metric will provide insight into how data shifts from Standard to IA storage classes. Seeing the rate of that shift can illustrate patterns in how your application accesses existing data.\u003c/p\u003e\u003ch3 id=\"latency-metrics\"\u003e\u003ca href=\"#latency-metrics\"\u003eLatency metrics\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eYour file system’s performance mode and storage class can influence its latency, so you’ll want to keep an eye on your latency metrics to ensure that you’ve chosen the most optimal configuration. Because EFS is based on NFS, you can use the \u003ccode\u003enfsiostat\u003c/code\u003e tool on an EC2 instance, ECS task (via \u003ca href=\"https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/execute-command.html\"\u003e\u003ccode\u003eexecute-command\u003c/code\u003e\u003c/a\u003e), or EKS pod (via \u003ca href=\"https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html\"\u003e\u003ccode\u003ekubectl\u003c/code\u003e\u003c/a\u003e) to see the round-trip time required for that client to access data on any attached EFS file system. If you’re using EFS with Lambda, \u003ca href=\"https://aws.amazon.com/codeguru/\"\u003eAmazon CodeGuru Profiler\u003c/a\u003e can help you visualize the time your application spends \u003ca href=\"https://docs.aws.amazon.com/codeguru/latest/profiler-ug/working-with-visualizations-summary-page.html\"\u003ewaiting for disk operations\u003c/a\u003e to complete.\u003c/p\u003e\u003ctable\u003e\u003cthead\u003e\u003ctr\u003e\u003cth\u003eName\u003c/th\u003e\u003cth\u003eDescription\u003c/th\u003e\u003cth\u003eMetric type\u003c/th\u003e\u003cth\u003eAvailability\u003c/th\u003e\u003c/tr\u003e\u003c/thead\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003eRead round-trip time\u003c/td\u003e\u003ctd\u003eThe time between when the client sends a request to read data and when it receives the reply from EFS\u003c/td\u003e\u003ctd\u003eWork: Performance\u003c/td\u003e\u003ctd\u003eLinux utilities\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eWrite round-trip time\u003c/td\u003e\u003ctd\u003eThe time between when the client sends a request to write data and when it receives the reply from EFS\u003c/td\u003e\u003ctd\u003eWork: Performance\u003c/td\u003e\u003ctd\u003eLinux utilities\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003ch4 id=\"metric-to-watch-readwrite-round-trip-time\"\u003e\u003ca href=\"#metric-to-watch-readwrite-round-trip-time\"\u003eMetric to watch: Read/write round-trip time\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eYou can monitor EFS’s round-trip time (RTT) to understand how storage access contributes to your application’s overall latency. You may be able to reduce average RTT across all of your clients by ensuring that they are connecting to \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html\"\u003emount targets in their local availability zone\u003c/a\u003e and by minimizing any competing network traffic within the VPC. If only some clients have a slow RTT, you should optimize the network performance of the relevant nodes—for example, by scaling up to a larger instance size—to prevent sporadic latency in your application. You should also ensure that your file system is using the optimal performance mode and storage class, as Infrequent Access storage classes and Max I/O performance mode generally have higher latencies.\u003c/p\u003e\u003ch3 id=\"io-metrics\"\u003e\u003ca href=\"#io-metrics\"\u003eI/O metrics\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eYour I/O rate will increase as more clients access a shared file system, and your application’s access to storage could get throttled if your clients collectively require more IOPS than your file system can provide. It’s therefore important for you to monitor I/O utilization, especially if you’ve parallelized storage access across a large number of clients or processes.\u003c/p\u003e\u003cp\u003eYou can use CloudWatch to monitor the I/O utilization of file systems that use General Purpose mode, but this metric isn’t available if you’re using Max I/O mode.\u003c/p\u003e\u003ctable\u003e\u003cthead\u003e\u003ctr\u003e\u003cth\u003eName\u003c/th\u003e\u003cth\u003eDescription\u003c/th\u003e\u003cth\u003eMetric type\u003c/th\u003e\u003cth\u003eAvailability\u003c/th\u003e\u003c/tr\u003e\u003c/thead\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003eI/O utilization\u003c/td\u003e\u003ctd\u003eThe percentage of the file system’s available IOPS that is in use\u003c/td\u003e\u003ctd\u003eResource: Utilization\u003c/td\u003e\u003ctd\u003eAvailability: CloudWatch\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003ch4 id=\"metric-to-alert-on-io-utilization\"\u003e\u003ca href=\"#metric-to-alert-on-io-utilization\"\u003eMetric to alert on: I/O utilization\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eIf your file system reaches its IOPS limit, your application could slow down as it waits to read and write data. You should create an alert that triggers when your file system approaches a specified percentage of its IOPS limit to give your team time to refactor or re-architect your application (e.g., to introduce a caching layer) before its performance degrades. Alternatively, you should consider moving to a new file system configured to use \u003ca href=\"#performance-modes\"\u003eMax I/O mode\u003c/a\u003e.\u003c/p\u003e\u003ch3 id=\"throughput-metrics\"\u003e\u003ca href=\"#throughput-metrics\"\u003eThroughput metrics\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eA file system’s throughput limit is determined by its performance mode, size, and level of activity. In Bursting Mode, the throughput limit changes based on the file system’s size and burst credit balance. In Provisioned Throughput mode, you specify the limit in the file system’s configuration. Monitoring the metrics described in this section can help you see whether insufficient throughput presents a risk to your application’s performance—or whether you’ve provisioned more throughput than your application requires.\u003c/p\u003e\u003ctable\u003e\u003cthead\u003e\u003ctr\u003e\u003cth\u003eName\u003c/th\u003e\u003cth\u003eDescription\u003c/th\u003e\u003cth\u003eMetric type\u003c/th\u003e\u003cth\u003eAvailability\u003c/th\u003e\u003c/tr\u003e\u003c/thead\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003eBurst credit balance\u003c/td\u003e\u003ctd\u003eThe number of bytes of bursting throughput the file system has available\u003c/td\u003e\u003ctd\u003eResource: Utilization\u003c/td\u003e\u003ctd\u003eCloudWatch\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003ePermitted throughput\u003c/td\u003e\u003ctd\u003eThe amount of throughput available to the file system, in bytes per second\u003c/td\u003e\u003ctd\u003eWork: Throughput\u003c/td\u003e\u003ctd\u003eCloudWatch\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003eMetered I/O bytes\u003c/td\u003e\u003ctd\u003eThe number of bytes used in reads, writes, and metadata operations on the file system\u003c/td\u003e\u003ctd\u003eResource: Utilization\u003c/td\u003e\u003ctd\u003eCloudWatch\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003ch4 id=\"metric-to-alert-on-burst-credit-balance\"\u003e\u003ca href=\"#metric-to-alert-on-burst-credit-balance\"\u003eMetric to alert on: Burst credit balance\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eIn Bursting Throughput mode, your file system can temporarily attain throughput rates above the baseline. The more burst credits you have, the longer you can sustain a higher throughput.\u003c/p\u003e\u003cp\u003eYou accrue burst credits when you’re operating below the baseline throughput, and you spend burst credits when you’re operating above the baseline (i.e., bursting). If your burst credit balance reaches zero, your application’s access to your file system will be limited to the baseline throughput, which could cause user-facing latency.\u003c/p\u003e\u003cp\u003eMonitor burst credit balance to ensure that you have sufficient credits to support the data access patterns of your workloads. If you find that you are consistently running out of burst credits, you should consider switching to \u003ca href=\"#throughput-modes\"\u003eProvisioned Throughput mode\u003c/a\u003e, which will enable you to define the amount of throughput you require.\u003c/p\u003e\u003ch4 id=\"metric-to-watch-permitted-throughput\"\u003e\u003ca href=\"#metric-to-watch-permitted-throughput\"\u003eMetric to watch: Permitted throughput\u003c/a\u003e\u003c/h4\u003e\u003cp\u003ePermitted throughput illustrates the throughput available to you at any moment, and it is calculated differently depending on which performance mode you’re using. In Bursting Throughput mode, this metric changes along with burst credit balance and file system size. If no burst credits are available, permitted throughput will be equal to the file system’s baseline throughput. In Provisioned Throughput mode, the value of this metric will equal the larger of your provisioned amount of throughput or the baseline throughput. If its value is lower than you expected, it could help explain any errors or latency in your application.\u003c/p\u003e\u003ch4 id=\"metric-to-alert-on-meterediobytes\"\u003e\u003ca href=\"#metric-to-alert-on-meterediobytes\"\u003eMetric to alert on: MeteredIOBytes\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eCloudWatch aggregates the data used on read, write, and metadata operations into a \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/efs-metrics.html\"\u003e\u003ccode\u003eMeteredIOBytes\u003c/code\u003e\u003c/a\u003e metric. If the value of this metric reaches your file system’s permitted throughput, your application’s access will be limited, which could cause user-facing latency. Create an alert on \u003ccode\u003eMeteredIOBytes\u003c/code\u003e as a percentage of permitted throughput so you can \u003ca href=\"#throughput-modes\"\u003eprovision\u003c/a\u003e enough throughput to meet your application’s requirements and prevent application latency.\u003c/p\u003e\u003ch3 id=\"connection-metrics\"\u003e\u003ca href=\"#connection-metrics\"\u003eConnection metrics\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eEFS supports \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/limits.html#limits-efs-resources-per-account-per-region\"\u003ethousands of connections per file system\u003c/a\u003e, but even if you’re not at risk of surpassing that limit, it can be helpful to monitor each file system’s connection count to watch for unexpected changes. Fewer connections than usual could indicate a problem with an application or the network. And if you see more connections than you expect, you could have a security issue or an auto-scaling anomaly that you need to investigate.\u003c/p\u003e\u003ctable\u003e\u003cthead\u003e\u003ctr\u003e\u003cth\u003eName\u003c/th\u003e\u003cth\u003eDescription\u003c/th\u003e\u003cth\u003eMetric type\u003c/th\u003e\u003cth\u003eAvailability\u003c/th\u003e\u003c/tr\u003e\u003c/thead\u003e\u003ctbody\u003e\u003ctr\u003e\u003ctd\u003eClient connections\u003c/td\u003e\u003ctd\u003eA count of all the clients connected to the file system\u003c/td\u003e\u003ctd\u003eResource: Utilization\u003c/td\u003e\u003ctd\u003eCloudWatch\u003c/td\u003e\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\u003ch4 id=\"metric-to-alert-on-client-connections\"\u003e\u003ca href=\"#metric-to-alert-on-client-connections\"\u003eMetric to alert on: Client connections\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eYour file system’s I/O is a limited resource—especially if you’re using General Purpose mode—and an upward trend in your connection count could be one cause of an increase in \u003ca href=\"#io-metrics\"\u003eIOPS\u003c/a\u003e. If your application typically has a steady number of clients accessing your file system, you should create an alert to notify you if the client connections metric rises above normal so you can evaluate whether you’re at risk of running out of IOPS.\u003c/p\u003e\u003ch2 id=\"monitor-efs-performance-for-healthy-storage\"\u003e\u003ca href=\"#monitor-efs-performance-for-healthy-storage\"\u003eMonitor EFS performance for healthy storage\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn this post, we’ve shown you how EFS works and which EFS metrics you can track to understand your file system’s performance. It’s important to monitor your file system’s latency, I/O, and throughput, as well as your usage, to ensure the health of your application and troubleshoot any bottlenecks that arise. Coming up in \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-monitoring-tools\"\u003ePart 2\u003c/a\u003e, we’ll show you some of the tools you can use to gather logs and metrics from EFS.\u003c/p\u003e\u003ch2 id=\"acknowledgments\"\u003e\u003ca href=\"#acknowledgments\"\u003eAcknowledgments\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eWe’d like to thank Ray Zaman at AWS for their technical review of this post.\u003c/p\u003e\u003cp\u003e\u003cem\u003eSource Markdown for this post is available \u003ca href=\"https://github.com/DataDog/the-monitor/blob/master/efs/amazon-efs-metrics.md\"\u003eon GitHub\u003c/a\u003e. Questions, corrections, additions, etc.? Please \u003ca href=\"https://github.com/DataDog/the-monitor/issues\"\u003elet us know\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/amazon_efs_longform_part-1.png\" width=\"100%\"/\u003eAmazon Elastic File System (EFS) provides shared, persistent, and elastic storage in the AWS cloud. Like Amazon S3, EFS is a highly available managed service that scales with your storage needs, and it also enables you to mount a file system to an EC2 instance, similar to Amazon Elastic Block Store (EBS). But EFS offers other features—like simultaneous access from multiple clients and AWS Lambda integration—that make it well-suited for use cases such as big data workloads, machine learning, and serving web content.",
      "date_published": "2021-08-05T00:00:00Z",
      "author": {
        "name": "David M. Lentz"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/amazon-efs-monitoring-tools/",
      "title": "Amazon EFS monitoring tools",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eIn \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-metrics\"\u003ePart 1\u003c/a\u003e of this series, we looked at EFS metrics from several different categories—storage, latency, I/O, throughput, and client connections. In this post, we’ll show you how you can collect those metrics—as well as EFS logs—using built-in and external tools. We’ll look at how to:\u003c/p\u003e\u003cul\u003e\u003cli\u003eview metrics in \u003ca href=\"#the-efs-console\"\u003ethe EFS console\u003c/a\u003e\u003c/li\u003e\u003cli\u003euse the \u003ca href=\"#cloudwatch\"\u003eCloudWatch\u003c/a\u003e console and API\u003c/li\u003e\u003cli\u003ecollect metrics with \u003ca href=\"#linux-tools\"\u003eLinux tools\u003c/a\u003e\u003c/li\u003e\u003cli\u003ecollect EFS logs with \u003ca href=\"#aws-logging-services\"\u003eAWS logging services\u003c/a\u003e and \u003ca href=\"#non-aws-logging-tools\"\u003eLinux logging tools\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"collect-efs-metrics\"\u003e\u003ca href=\"#collect-efs-metrics\"\u003eCollect EFS metrics\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eCollecting and analyzing EFS metrics can help you understand your file systems\u0026#39; role in the health and performance of your applications. Because EFS is a managed service, some standard approaches to monitoring, such as monitoring server resource metrics, are not applicable. In this section, we’ll look at some tools provided by AWS and some that are built into Linux that let you collect and visualize key EFS metrics.\u003c/p\u003e\u003ch3 id=\"the-efs-console\"\u003e\u003ca href=\"#the-efs-console\"\u003eThe EFS console\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eYou can use the EFS console, which is available from within the \u003ca href=\"https://console.aws.amazon.com/\"\u003eAWS Management Console\u003c/a\u003e, to create and delete file systems, define their settings, and manage mount targets and access points. You can also see graphs of key metrics we looked at in \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-metrics\"\u003ePart 1\u003c/a\u003e of this series, such as throughput, I/O, client connections, and storage, to visualize the performance of each file system over time.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Graphs of file system metrics shown on the EFS console include throughput, IOPS, connection, and storage data.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch3 id=\"cloudwatch\"\u003e\u003ca href=\"#cloudwatch\"\u003eCloudWatch\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eWhile the EFS console is a good way to quickly begin monitoring your EFS file systems, \u003ca href=\"https://aws.amazon.com/cloudwatch/\"\u003eAmazon CloudWatch\u003c/a\u003e allows you to monitor, correlate, and alert on the performance of EFS and the other AWS services you use. In this section, we’ll show you how to use the CloudWatch console to visualize the data that CloudWatch collects, and we’ll introduce you to the CloudWatch API, which allows you to retrieve EFS metrics programmatically.\u003c/p\u003e\u003ch4 id=\"cloudwatch-console\"\u003e\u003ca href=\"#cloudwatch-console\"\u003eCloudWatch console\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eThe CloudWatch console for EFS—shown in the screenshot below—includes a built-in dashboard that expands on the data shown in the \u003ca href=\"#the-efs-console\"\u003eEFS console\u003c/a\u003e and visualizes connections, IOPS, burst credits, and throughput data from multiple file systems at once.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"The CloudWatch service dashboard for EFS graphs data from multiple file systems, visualizing connection, IOPS, burst credit, and throughput data.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYou can open any one of these graphs in \u003ca href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/working_with_metrics.html\"\u003eCloudWatch metrics\u003c/a\u003e, where you can modify it and add it to a custom dashboard. Custom dashboards allow you to graph metrics from multiple AWS services in a single view or even on the same graph, so you can quickly explore possible causes of an issue you need to troubleshoot.\nFor example, the graph in the screenshot below shows the \u003ccode\u003eBurstCreditBalance\u003c/code\u003e value for an EFS file system decreasing as the rate of a Lambda function’s \u003ccode\u003eInvocations\u003c/code\u003e rises. This correlation suggests that the Lambda function’s increased disk activity could be consuming the available burst credits, which, as discussed in the section on \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-metrics#throughput-metrics\"\u003ethroughput metrics\u003c/a\u003e in Part 1 of this series, could ultimately cause user-facing latency.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"A CloudWatch graph shows the burst credit balance metric for a file system declining while the rate of invocations of a Lambda function increases.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYou can create an \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/creating_alarms.html\"\u003ealarm\u003c/a\u003e for any metric you see in the CloudWatch console by defining a threshold value for the metric and an \u003ca href=\"https://aws.amazon.com/sns/\"\u003eSNS topic\u003c/a\u003e to which AWS will automatically send a message if the metric breaches that value. You can also create anomaly-based CloudWatch Alarms to automatically notify you, for example, if the number of clients connected to your file system changes significantly from its historical range of values.\u003c/p\u003e\u003ch4 id=\"cloudwatch-api\"\u003e\u003ca href=\"#cloudwatch-api\"\u003eCloudWatch API\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eIn the previous section, we discussed how the CloudWatch console lets you visualize and alert on EFS metrics. You can also fetch EFS metrics programmatically from the \u003ca href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/making-api-requests.html\"\u003eCloudWatch API\u003c/a\u003e via AWS SDKs or the AWS command-line interface (CLI). The AWS \u003ca href=\"https://aws.amazon.com/tools/\"\u003eSDKs\u003c/a\u003e enable you to call the API with Python, Ruby, Go, and \u003ca href=\"https://aws.amazon.com/tools/#SDKs\"\u003emany other languages\u003c/a\u003e, so you can integrate EFS monitoring into your processes or applications. In contrast, the \u003ca href=\"https://aws.amazon.com/cli/\"\u003eCLI\u003c/a\u003e is useful for manually executing ad hoc queries or creating scripts that automatically collect metrics.\u003c/p\u003e\u003cp\u003eTo use the AWS CLI, you’ll first need to \u003ca href=\"https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html\"\u003einstall it\u003c/a\u003e on the host where you’ll execute the API calls. You’ll also need to configure the necessary authentication, for example by using an \u003ca href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html\"\u003eEC2 instance profile\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eTo get CloudWatch metrics through the CLI, you use the \u003ccode\u003ecloudwatch\u003c/code\u003e subcommand. The example below uses the \u003ca href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_GetMetricStatistics.html\"\u003e\u003ccode\u003eget-metric-statistics\u003c/code\u003e\u003c/a\u003e action to retrieve the value of the \u003ccode\u003eStorageBytes\u003c/code\u003e metric from the \u003ccode\u003eAWS/EFS\u003c/code\u003e \u003ca href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Namespace\"\u003enamespace\u003c/a\u003e. The command includes \u003ccode\u003estart-time\u003c/code\u003e and \u003ccode\u003eend-time\u003c/code\u003e parameters to scope the request to a one-hour time frame, a \u003ccode\u003eperiod\u003c/code\u003e parameter to aggregate the metrics every 15 minutes, and a \u003ccode\u003estatistics\u003c/code\u003e parameter to request a sum of the collected metric values. The \u003ccode\u003edimensions\u003c/code\u003e parameter holds key-value pairs to define the file system (\u003ccode\u003eFileSystemId\u003c/code\u003e) and the \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-metrics#metric-to-watch-file-system-size\"\u003estorage class\u003c/a\u003e (\u003ccode\u003eStorageClass\u003c/code\u003e) to query.\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003eaws cloudwatch get-metric-statistics \\\n--metric-name StorageBytes \\\n--start-time 2021-04-02T16:35:00 \\\n--end-time 2021-04-02T17:35:00 \\\n--period 900 \\\n--statistics Sum \\\n--namespace AWS/EFS \\\n--dimensions Name=FileSystemId,Value=\u0026lt;MY-FILE-SYSTEM-ID\u0026gt; Name=StorageClass,Value=Total\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThe \u003ccode\u003eget-metric-statistics\u003c/code\u003e action returns a JSON object like the one shown below. This example result contains four records, one every 15 minutes over the one-hour time frame specified in the request. Note that CloudWatch does not guarantee that records returned by \u003ccode\u003eget-metric-statistics\u003c/code\u003e will appear in chronological order.\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003e{\n    \u0026#34;Label\u0026#34;: \u0026#34;StorageBytes\u0026#34;,\n    \u0026#34;Datapoints\u0026#34;: [\n        {\n            \u0026#34;Timestamp\u0026#34;: \u0026#34;2021-04-02T16:50:00+00:00\u0026#34;,\n            \u0026#34;Sum\u0026#34;: 4220928.0,\n            \u0026#34;Unit\u0026#34;: \u0026#34;Bytes\u0026#34;\n        },\n        {\n            \u0026#34;Timestamp\u0026#34;: \u0026#34;2021-04-02T17:05:00+00:00\u0026#34;,\n            \u0026#34;Sum\u0026#34;: 4220928.0,\n            \u0026#34;Unit\u0026#34;: \u0026#34;Bytes\u0026#34;\n        },\n        {\n            \u0026#34;Timestamp\u0026#34;: \u0026#34;2021-04-02T16:35:00+00:00\u0026#34;,\n            \u0026#34;Sum\u0026#34;: 2123776.0,\n            \u0026#34;Unit\u0026#34;: \u0026#34;Bytes\u0026#34;\n        },\n        {\n            \u0026#34;Timestamp\u0026#34;: \u0026#34;2021-04-02T17:20:00+00:00\u0026#34;,\n            \u0026#34;Sum\u0026#34;: 4220928.0,\n            \u0026#34;Unit\u0026#34;: \u0026#34;Bytes\u0026#34;\n        }\n    ]\n}\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eSee the \u003ca href=\"https://awscli.amazonaws.com/v2/documentation/api/latest/reference/efs/index.html\"\u003eAWS CLI documentation\u003c/a\u003e to learn more about interacting with the \u003ca href=\"https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudwatch/index.html\"\u003eCloudWatch API\u003c/a\u003e. And to find more information on the CloudWatch metrics available in the EFS namespace, see the \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/efs-metrics.html\"\u003eEFS documentation\u003c/a\u003e.\u003c/p\u003e\u003ch3 id=\"linux-tools\"\u003e\u003ca href=\"#linux-tools\"\u003eLinux tools\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eIf your EFS client is a Linux-based EC2 instance (EFS does not support Windows), you can use Linux utilities to collect metrics that describe the file system and the performance of the client. In this section, we’ll show you how to query an instance to see the size of its mounted file systems, as well as per-client metrics that aren’t available in CloudWatch: the \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-metrics#latency-metrics\"\u003elatency\u003c/a\u003e, \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-metrics#throughput-metrics\"\u003ethroughput\u003c/a\u003e, and error rate of its EFS read and write operations.\nTo execute the commands shown in this section, you can SSH to your instance’s command line or use \u003ca href=\"https://docs.aws.amazon.com/systems-manager/latest/userguide/execute-remote-commands.html\"\u003eAWS Systems Manager Run Command\u003c/a\u003e. On EKS, you can use \u003ca href=\"https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html\"\u003e\u003ccode\u003ekubectl\u003c/code\u003e\u003c/a\u003e to execute these commands, and on ECS, you can use \u003ca href=\"https://aws.amazon.com/blogs/containers/new-using-amazon-ecs-exec-access-your-containers-fargate-ec2/\"\u003eECS Exec\u003c/a\u003e. And although Lambda doesn’t provide a CLI, we’ll show you an example of how you can query a file system’s size from within a Lambda function.\u003c/p\u003e\u003ch4 id=\"determine-the-storage-used-by-a-file-system\"\u003e\u003ca href=\"#determine-the-storage-used-by-a-file-system\"\u003eDetermine the storage used by a file system\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eAWS calculates and charges for EFS storage based on \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/metered-sizes.html\"\u003e\u003cstrong\u003emetered size\u003c/strong\u003e\u003c/a\u003e—the space required to store your objects and metadata. Knowing the size of your file system can help you spot unexpected changes in the amount of data your application is storing and can even help you estimate your EFS costs. On a Linux host, you can use the \u003ca href=\"https://en.wikipedia.org/wiki/Df_(Unix)\"\u003e\u003ccode\u003edf\u003c/code\u003e\u003c/a\u003e tool to see the total space used by a mounted file system, which means you can use \u003ccode\u003edf\u003c/code\u003e to view the metered size of your EFS file systems. It’s important to note, however, that because the data \u003ccode\u003edf\u003c/code\u003eprovides is \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/metered-sizes.html#metered-sizes-fs\"\u003eeventually consistent\u003c/a\u003e, you should not rely on it for real-time data.\u003c/p\u003e\u003cp\u003eIn addition to viewing the aggregate size of your file system, you may also need to track the sizes of individual objects. Log files, for example, accumulate data over time and can influence your overall storage needs. You can use the \u003ca href=\"https://en.wikipedia.org/wiki/Du_(Unix)\"\u003e\u003ccode\u003edu\u003c/code\u003e\u003c/a\u003e and \u003ccode\u003estat\u003c/code\u003e tools to view the size of any single file you’ve stored in EFS. The command below allows you to see the size of the file \u003cstrong\u003emyFile\u003c/strong\u003e located in the file system mounted at \u003cstrong\u003e/mnt/myFileSystem\u003c/strong\u003e:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003estat /mnt/myFileSystem/myFile\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eAs shown below, \u003ccode\u003estat\u003c/code\u003e’s output includes additional information beyond the file’s size, such as the number of blocks used by the file, its inode, its permissions, and the file’s creation and modification history.\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003e  File: ‘/mnt/myFileSystem/myFile’\n  Size: 3048448000\tBlocks: 5954000    IO Block: 1048576 regular file\nDevice: 26h/38d\tInode: 16195615950234888882  Links: 1\nAccess: (0664/-rw-rw-r--)  Uid: ( 1000/ec2-user)   Gid: ( 1000/ec2-user)\nAccess: 2021-04-27 21:48:50.398000000 +0000\nModify: 2021-04-27 21:48:50.398000000 +0000\nChange: 2021-04-27 21:48:50.398000000 +0000\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eSee the \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/metered-sizes.html\"\u003eAWS documentation\u003c/a\u003e for more information about how to view the metered size of both your file system and the individual objects it contains.\u003c/p\u003e\u003ch4 id=\"see-the-aggregate-size-of-a-file-system-from-a-lambda-function\"\u003e\u003ca href=\"#see-the-aggregate-size-of-a-file-system-from-a-lambda-function\"\u003eSee the aggregate size of a file system from a Lambda function\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eIf your EFS client is a Lambda function, you don’t have access to a command line, but some Lambda runtimes allow you to include code in your function that can collect storage metrics. For example, Python’s \u003ca href=\"https://docs.python.org/3/library/index.html\"\u003estandard library\u003c/a\u003e includes a \u003ca href=\"https://docs.python.org/3/library/shutil.html\"\u003e\u003ccode\u003eshutil\u003c/code\u003e\u003c/a\u003e package that you can use to check the size of a file system. The following function uses the \u003ccode\u003edisk_usage\u003c/code\u003e method to check the disk space used by the file system mounted at \u003cstrong\u003e/mnt/myFileSystem\u003c/strong\u003e:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003eimport shutil\n\ndef lambda_handler(event, context):\n    return {\n        \u0026#39;output\u0026#39;: shutil.disk_usage(\u0026#34;/mnt/myFileSystem\u0026#34;)\n    }\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThis function returns a JSON object like the one shown below. In our case, it shows that the file system is using slightly less than 3,600 MB of storage space.\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003e{\n  \u0026#34;output\u0026#34;: {\n    \u0026#34;total\u0026#34;: 9223372036853727000,\n    \u0026#34;used\u0026#34;: 3598712832,\n    \u0026#34;free\u0026#34;: 9223372033255014000\n  }\n}\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch4 id=\"measure-efs-performance-with-nfsiostat\"\u003e\u003ca href=\"#measure-efs-performance-with-nfsiostat\"\u003eMeasure EFS performance with \u003ccode\u003enfsiostat\u003c/code\u003e\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eTo attach your EC2 instance to EFS, AWS recommends that you install the \u003ca href=\"https://github.com/aws/efs-utils\"\u003e\u003ccode\u003eamazon-efs-utils\u003c/code\u003e\u003c/a\u003e package, which includes an NFS client. This means you can use the \u003ccode\u003enfsiostat\u003c/code\u003e utility to view some of the key metrics covered in \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-metrics\"\u003ePart 1\u003c/a\u003e of this series, including throughput (\u003ccode\u003ekB/s\u003c/code\u003e) and latency (\u003ccode\u003eavg RTT\u003c/code\u003e). For example, to see metrics from the file system mounted at \u003cstrong\u003e/mnt/myFileSystem\u003c/strong\u003e, you can use this command:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003enfsiostat /mnt/myFileSystem\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThe output, shown below, details the client’s read and write activity since the file system was mounted or since \u003ccode\u003enfsiostat\u003c/code\u003e was last executed.\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003e   op/s\t\trpc bklog\n   2.81\t   \t0.00\nread:\tops/s\tkB/s\t \tkB/op\t\tretrans\tavg RTT (ms)\tavg exe (ms)\n0.000\t0.000\t \t0.000\t\t0 (0.0%)\t0.000\t\t0.000\nwrite:\tops/s\tkB/s\t \tkB/op\t\tretrans\tavg RTT (ms)\tavg exe (ms)\n2.266\t2284.646\t1008.283\t0 (0.0%)\t129.606\t356.155\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"collect-efs-logs\"\u003e\u003ca href=\"#collect-efs-logs\"\u003eCollect EFS logs\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eTo gain even deeper insight into the performance of your file systems, you can collect logs from your EFS clients. Logs reveal details of each client’s activity—such as when a given client mounted an EFS file system and how much data it sent to the mount target—that can be useful when you need to analyze and troubleshoot EFS performance. In this section, we’ll show you how you can collect and view EFS logs using AWS services and Linux tools.\u003c/p\u003e\u003ch3 id=\"aws-logging-services\"\u003e\u003ca href=\"#aws-logging-services\"\u003eAWS logging services\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eAWS provides logging services that allow you to gather EFS logs from \u003ca href=\"#mount-helper-logs\"\u003eEC2 instances\u003c/a\u003e, as well as \u003ca href=\"#vpc-flow-logs\"\u003enetwork logs\u003c/a\u003e that show connection activity to your EFS mount targets. You can analyze and alert on these logs using Amazon \u003ca href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html\"\u003eCloudWatch Logs\u003c/a\u003e and query them with \u003ca href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html\"\u003eCloudWatch Logs Insights\u003c/a\u003e.\u003c/p\u003e\u003ch4 id=\"mount-helper-logs\"\u003e\u003ca href=\"#mount-helper-logs\"\u003eMount helper logs\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eThe \u003ca href=\"https://github.com/aws/efs-utils\"\u003eEFS client software\u003c/a\u003e includes a \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/efs-mount-helper.html\"\u003emount helper\u003c/a\u003e tool which allows you to collect \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/efs-mount-helper.html#mount-helper-logs\"\u003elogs\u003c/a\u003e from your EC2 instances and forward them to \u003ca href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html\"\u003eCloudWatch Logs\u003c/a\u003e. To collect logs from an instance, \u003ca href=\"https://github.com/aws/efs-utils#step-1-install-botocore\"\u003einstall botocore\u003c/a\u003e—the foundation of the \u003ca href=\"https://aws.amazon.com/sdk-for-python/\"\u003eAWS SDK for Python\u003c/a\u003e—onto the instance, attach the necessary \u003ca href=\"https://github.com/aws/efs-utils#step-3-attach-the-cloudwatch-logs-policy-to-the-iam-role-attached-to-instance\"\u003eIAM policy\u003c/a\u003e to the instance’s role, and then install the \u003ca href=\"https://docs.aws.amazon.com/efs/latest/ug/using-amazon-efs-utils.html\"\u003eEFS client software\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eLogging is disabled by default, so you need to \u003ca href=\"https://github.com/aws/efs-utils#step-2-enable-cloudwatch-log-feature-in-efs-utils-config-file-etcamazonefsefs-utilsconf\"\u003eupdate\u003c/a\u003e the client’s configuration file (\u003ca href=\"https://github.com/aws/efs-utils/blob/master/dist/efs-utils.conf\"\u003e\u003cstrong\u003e/etc/amazon/efs/efs-utils.conf\u003c/strong\u003e\u003c/a\u003e) to enable logging and configure the helper to forward logs to CloudWatch Logs. The \u003cstrong\u003eefs-utils.conf\u003c/strong\u003e excerpt shown below sets \u003ccode\u003eenabled = true\u003c/code\u003e in the \u003ccode\u003e[cloudwatch-log]\u003c/code\u003e section of the configuration file. As a result, this instance will automatically forward its mount helper logs to the CloudWatch Logs group named \u003ccode\u003e/aws/my-efs-mount-helper-logs\u003c/code\u003e.\u003c/p\u003e\u003cdiv\u003e\u003cp\u003eefs-utils.conf\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003e[cloudwatch-log]\nenabled = true\nlog_group_name = /aws/my-efs-mount-helper-logs\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003cp\u003eOnce you’ve aggregated your mount helper logs in CloudWatch Logs, you can explore the status and history of mount activity across all of the EC2 instances that connect to your file system. You can also use CloudWatch Logs Insights to search and filter your logs, which can reveal patterns and trends in EFS performance and client activity. For example, the CloudWatch Logs Insights query in the screenshot below searches the \u003ccode\u003e/aws/my-efs-mount-helper-logs\u003c/code\u003e logs group and displays the timestamp, message, and log stream identifier fields from the 20 most recent logs across all of the streams in the group. The timeseries graph above the results visualizes the rate at which the logs occur.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"A CloudWatch Logs Insights query searches across all logs streams in the log group and returns three records, each from different log streams.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch4 id=\"vpc-flow-logs\"\u003e\u003ca href=\"#vpc-flow-logs\"\u003eVPC Flow Logs\u003c/a\u003e\u003c/h4\u003e\u003cp\u003e\u003ca href=\"https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html\"\u003eVPC Flow Logs\u003c/a\u003e allow you to monitor traffic on the network interfaces your AWS resources use. The clients connected to an EFS file system interact with it by sending requests to port 2049 on the \u003ca href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html\"\u003eElastic Network Interface (ENI)\u003c/a\u003e of one of its \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-metrics#an-overview-of-efs\"\u003emount targets\u003c/a\u003e. By capturing these requests in a flow log, you can aggregate network activity from multiple clients in a single log, which you can then \u003ca href=\"https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs-cwl.html\"\u003epublish to Cloudwatch Logs\u003c/a\u003e. This allows you to see, for example, the IP addresses of all the \u003ca href=\"https://aws.amazon.com/premiumsupport/knowledge-center/list-instances-connected-to-efs/\"\u003eclients that have connected\u003c/a\u003e to your file system. You can also \u003ca href=\"https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html\"\u003efilter\u003c/a\u003e your results based on the values contained in fields you identify. For example, the screenshot below illustrates a CloudWatch Logs Insights query that finds flow logs showing data transfers greater than 102,400 bytes to and from the file system’s mount targets.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"A CloudWatch Logs Insights query shows logs from all logs streams in the log group where the bytes field is greater than 102.4 kilobytes.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eSee \u003ca href=\"https://aws.amazon.com/premiumsupport/knowledge-center/list-instances-connected-to-efs/\"\u003ethe AWS documentation\u003c/a\u003e for more examples about collecting and querying VPC Flow Logs in CloudWatch Logs.\u003c/p\u003e\u003ch3 id=\"non-aws-logging-tools\"\u003e\u003ca href=\"#non-aws-logging-tools\"\u003eNon-AWS logging tools\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eIf your EFS clients are running on EC2 instances, including EC2-backed EKS or ECS clusters, their log activity can reveal important details about changes within the file systems they mount. In this section, we’ll show you Linux utilities you can use to log the activity of clients making changes to the EFS file system.\nThe \u003ca href=\"https://aws.amazon.com/premiumsupport/knowledge-center/ec2-monitor-file-system-changes#Short_description\"\u003eLinux auditing system\u003c/a\u003e provides tools that allow you to monitor your Linux hosts for changes that could indicate security concerns. Linux security is a topic that extends beyond file system monitoring, but you can use these tools to \u003ca href=\"https://aws.amazon.com/premiumsupport/knowledge-center/ec2-monitor-file-system-changes/\"\u003eincrease your visibility into EFS\u003c/a\u003e by logging file creation, deletion, modification, and access.\n\u003ccode\u003eauditd\u003c/code\u003e is the process that monitors and logs activity on the host, and \u003ccode\u003eauditctl\u003c/code\u003e is the program you use to configure \u003ccode\u003eauditd\u003c/code\u003e. To log changes to your file system, you create rules that tell \u003ccode\u003eauditd\u003c/code\u003e which directories to monitor and which activities to watch for. When a change takes place in the file system that aligns with a rule you’ve defined—for example, when a client writes to a file that’s being monitored—\u003ccode\u003eauditd\u003c/code\u003e will create a new log in \u003cstrong\u003e/var/log/audit/audit.log\u003c/strong\u003e.\u003c/p\u003e\u003cp\u003eYou can then use two complementary utilities—\u003ccode\u003eausearch\u003c/code\u003e to filter the log contents and \u003ccode\u003eaureport\u003c/code\u003e to format the output—to view the contents of \u003cstrong\u003eaudit.log\u003c/strong\u003e and see the activity on the file system. The command below searches for logs created by the \u003ccode\u003emykeyname\u003c/code\u003e rule. It includes the \u003ccode\u003e-i\u003c/code\u003e flag to interpret the \u003ca href=\"https://man7.org/linux/man-pages/man8/aureport.8.html\"\u003eoutput\u003c/a\u003e and the \u003ccode\u003e-f\u003c/code\u003e flag to return log entries related to file activity.\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003esudo ausearch -k mykeyname | aureport -f -i\n\n\nFile Report\n===============================================\n# date time file syscall success exe auid event\n===============================================\n1. 04/16/2021 16:50:27 /mnt/myFileSystem/myFile openat yes /usr/bin/bash ec2-user 124\n2. 04/16/2021 16:50:43 /mnt/myFileSystem/myOtherFile openat yes /usr/bin/bash ec2-user 125\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eYou can also use the \u003ccode\u003erpcdebug\u003c/code\u003e tool to log an instance’s interactions with an EFS file system, which includes creating, modifying, reading, and executing files. For example, if your application creates and writes to a file named \u003cstrong\u003emyNewFile\u003c/strong\u003e in the root directory of an EFS file system, \u003ccode\u003erpcdebug\u003c/code\u003e will add the following messages to the instance’s system log:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003eApr  5 22:17:06 ip-172-31-46-92 kernel: NFS: open file(/myNewFile)\nApr  5 22:17:06 ip-172-31-46-92 kernel: NFS: flush(/myNewFile)\nApr  5 22:17:06 ip-172-31-46-92 kernel: NFS: fsync file(/myNewFile) datasync 0\nApr  5 22:17:06 ip-172-31-46-92 kernel: NFS: write(/myNewFile, 5@0)\nApr  5 22:17:06 ip-172-31-46-92 kernel: NFS: flush(/myNewFile)\nApr  5 22:17:06 ip-172-31-46-92 kernel: NFS: fsync file(/myNewFile) datasync 0\nApr  5 22:17:06 ip-172-31-46-92 kernel: NFS: release(/myNewFile)\nApr  5 22:18:31 ip-172-31-46-92 dhclient[2818]: XMT: Solicit on eth0, interval 121000ms.\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"monitor-efs-and-your-whole-stack\"\u003e\u003ca href=\"#monitor-efs-and-your-whole-stack\"\u003eMonitor EFS and your whole stack\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn this post, we’ve looked at how you can collect and alert on EFS metrics and logs using AWS and Linux tools. In \u003ca href=\"https://www.datadoghq.com/blog/amazon-efs-monitoring-datadog\"\u003ePart 3\u003c/a\u003e of this series, we’ll show you how Datadog enables you to visualize and analyze this data alongside telemetry from more than 450 other technologies, so you can gain full visibility into your EFS file systems and the applications they support.\u003c/p\u003e\u003ch2 id=\"acknowledgments\"\u003e\u003ca href=\"#acknowledgments\"\u003eAcknowledgments\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eWe’d like to thank Ray Zaman at AWS for their technical review of this post.\u003c/p\u003e\u003cp\u003e\u003cem\u003eSource Markdown for this post is available \u003ca href=\"https://github.com/DataDog/the-monitor/blob/master/efs/amazon-efs-monitoring-tools.md\"\u003eon GitHub\u003c/a\u003e. Questions, corrections, additions, etc.? Please \u003ca href=\"https://github.com/DataDog/the-monitor/issues\"\u003elet us know\u003c/a\u003e\u003c/em\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/amazon_efs_longform_part-2.png\" width=\"100%\"/\u003eIn Part 1 of this series, we looked at EFS metrics from several different categories—storage, latency, I/O, throughput, and client connections. In this post, we\u0026rsquo;ll show you how you can collect those metrics—as well as EFS logs—using built-in and external tools. We\u0026rsquo;ll look at how to: view metrics in the EFS console use the CloudWatch console and API collect metrics with Linux tools collect EFS logs with AWS logging services and Linux logging tools Collect EFS metricsCollecting and analyzing EFS metrics can help you understand your file systems' role in the health and performance of your applications.",
      "date_published": "2021-08-05T00:00:00Z",
      "author": {
        "name": "David M. Lentz"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/monitor-containers-with-npm/",
      "title": "How to monitor containerized and service-meshed network communication with Datadog NPM",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003ca href=\"https://www.datadoghq.com/container-report/\"\u003eContainers\u003c/a\u003e are lightweight, portable, easily scalable, and enable you to run multiple workloads on the same host efficiently, particularly when using an orchestration platform like Kubernetes or Amazon ECS. But containers also introduce monitoring challenges. Containerized environments may comprise vast webs of distributed endpoints and dependencies that rely on complex network communication. Adding further complexity, you need to ensure that each node in your cluster maintains contact with almost every other node. And containers are highly ephemeral, which makes IP-level connection data unreliable for tracking network traffic between these components, especially in the cloud.\u003c/p\u003e\u003cp\u003eDatadog \u003ca href=\"https://docs.datadoghq.com/network_monitoring/performance/\"\u003eNetwork Performance Monitoring\u003c/a\u003e visualizes network traffic between objects within your entire containerized environment. This makes it easy to monitor network dependencies across all of your containers, services, and deployments so you can spot architectural and performance issues quickly. If you’re using a service mesh in your environment, Datadog NPM also enables you to analyze service mesh traffic to help identify traffic management misconfigurations and ensure the services in your mesh communicate efficiently.\u003c/p\u003e\u003cp\u003eIn this post we’ll look at how you can use Datadog NPM to help you:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"#visualize-your-containerized-architecture-with-the-network-map\"\u003evisualize\u003c/a\u003e network communication across your dynamic containerized infrastructure\u003c/li\u003e\u003cli\u003e\u003ca href=\"#get-full-visibility-into-each-layer-of-your-containerized-applications\"\u003etroubleshoot\u003c/a\u003e performance issues in containerized applications\u003c/li\u003e\u003cli\u003e\u003ca href=\"#analyze-service-mesh-and-proxied-traffic-health\"\u003eanalyze\u003c/a\u003e service mesh traffic health\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"visualize-your-containerized-architecture-with-the-network-map\"\u003e\u003ca href=\"#visualize-your-containerized-architecture-with-the-network-map\"\u003eVisualize your containerized architecture with the Network Map\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eContainerized environments are highly distributed and can quickly grow in size and complexity, making them especially vulnerable to network issues. And, because each service may have many dependencies, an isolated problem can have an outsize impact on the rest of your application. This means visibility into network communication across your containerized workloads is key to monitoring the health and performance of your applications. But because containers churn often, tracking communication between them can be difficult.\u003c/p\u003e\u003cp\u003eDatadog’s \u003ca href=\"https://docs.datadoghq.com/network_monitoring/performance/network_map/\"\u003eNetwork Map\u003c/a\u003e uses directional arrows, or \u003cstrong\u003eedges\u003c/strong\u003e, to visualize traffic flows between containers, pods, deployments, or other tagged objects in your environment, regardless of whether their constituent containers change. This gives you a real-time view of your network’s topology do you can spot architectural inefficiencies and misconfigurations. Visualizing traffic with edges can quickly reveal, for example, if Kubernetes pods in the same cluster are communicating through an \u003ca href=\"https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/\"\u003eingress controller\u003c/a\u003e rather than directly to each other. Since you’d expect an ingress controller to be used for traffic between different clusters, intra-cluster ingress traffic indicates misconfiguration which can lead to increased latency.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"npm-for-containers00.png\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eUse the Network Map to ensure there\u0026#39;s expected traffic between pods. If there are no edges between pods, it could indicate a misconfiguration.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eThe Network Map’s visualization options enable you to tie issues like high TCP retransmits and latency to objects within your containerized infrastructure, like ECS tasks or Kubernetes deployments and pods. This enables you to determine at which layer of your environment network problems are occurring. Let’s say you use the Network Map to visualize the TCP latency across your services and see that there’s high latency between two services. You can inspect one of the services and then break the map down further by selecting \u003ccode\u003epod_name\u003c/code\u003e in the View dropdown menu, enabling you to dig deeper by viewing latency in the context of your services\u0026#39; underlying pods. This way, you can see if a particular pod is contributing to latency, indicated by thicker lines connected to a pod’s node.\u003c/p\u003e\u003cp\u003eOnce you’ve identified a pod to investigate, you can view it in the \u003ca href=\"https://app.datadoghq.com/orchestration/overview/pod\"\u003eOrchestration Center\u003c/a\u003e and see its specs (including status), resource consumption down to the process level, logs, and more. If the pod’s CPU usage is high, that is likely the culprit behind the latency you observed. Now that you’ve pinpointed the root cause, you can start taking mitigating steps to reduce latency, like scaling the pod.\u003c/p\u003e\u003ch2 id=\"get-full-visibility-into-each-layer-of-your-containerized-applications\"\u003e\u003ca href=\"#get-full-visibility-into-each-layer-of-your-containerized-applications\"\u003eGet full visibility into each layer of your containerized applications\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn containerized environments, requests can propagate across a number of components in your infrastructure. Because of this, it can be difficult to determine whether problems are due to network issues or possible code-level bugs. For example, pod connectivity problems can manifest as application latency or errors if your service can’t reach a dependency.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://docs.datadoghq.com/tracing/\"\u003eDatadog APM\u003c/a\u003e provides insight into issues at the application layer of your containerized environment in order to help determine the root cause of a problem. For instance, if you’ve identified a container running on EC2 that’s experiencing high request latency, you can dig into its traces to try to establish whether the cause is a code-level issue. If not, you can then easily pivot to the “Network” tab to view all network connections that are related to that service and identify if the problem stems from an upstream service (i.e., one application’s pods are overwhelmed with traffic from another application and can no longer respond to requests).\u003c/p\u003e\u003cp\u003eDatadog NPM also supports \u003ca href=\"https://www.datadoghq.com/blog/monitor-dns-with-datadog/\"\u003eDNS monitoring\u003c/a\u003e, which means you can view the health of the communication between your pods and DNS servers to determine if a service discovery issue is preventing your client pod from finding the pods it needs to reach. You can easily identify which DNS servers (such as CoreDNS pods) may be contributing to the high response time or error rate of incoming DNS requests. Or, you can look for spikes in \u003ccode\u003eNXDOMAIN\u003c/code\u003e DNS responses. This can help determine whether a DNS server’s latency is a consequence of a client-side issue, like a pod making multiple invalid requests for every valid request, which may be overloading the DNS server.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog NPM supports DNS montiroing so you can view the health of the traffic between pods and DNS servers.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"analyze-service-mesh-and-proxied-traffic-health\"\u003e\u003ca href=\"#analyze-service-mesh-and-proxied-traffic-health\"\u003eAnalyze service mesh and proxied traffic health\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eService meshes like \u003ca href=\"https://istio.io/\"\u003eIstio\u003c/a\u003e help manage the access parameters and routing of microservice communication. But they also introduce further monitoring challenges by adding a layer of abstraction across your environment, making it challenging to get visibility into container communication. With Datadog Network Performance Monitoring, you can easily visualize traffic flow across \u003ca href=\"https://www.datadoghq.com/blog/monitor-istio-with-npm/\"\u003eIstio-managed networks\u003c/a\u003e. And, Datadog’s \u003ca href=\"https://docs.datadoghq.com/integrations/istio/#pagetitle\"\u003eIstio integration\u003c/a\u003e provides full visibility into every other aspect of your Istio environment. Datadog collects key \u003ca href=\"https://docs.datadoghq.com/integrations/istio/#metrics\"\u003eIstio metrics\u003c/a\u003e to monitor bandwidth and request performance, \u003ca href=\"https://docs.datadoghq.com/integrations/istio/#log-collection\"\u003elogs\u003c/a\u003e to investigate control plane health, and distributed \u003ca href=\"https://docs.datadoghq.com/tracing/setup_overview/proxy_setup/?tab=istio\"\u003etraces\u003c/a\u003e from application requests propagating across your mesh.\u003c/p\u003e\u003cp\u003eAdditionally, Datadog supports \u003ca href=\"https://istio.io/latest/docs/ops/deployment/architecture/#envoy\"\u003eEnvoy\u003c/a\u003e monitoring, enabling you to easily correlate Istio monitoring data with data from its Envoy proxy mesh. Because application containers route traffic through Envoy \u003cstrong\u003esidecars\u003c/strong\u003e installed on their local pods to sidecars on separate pods, latency between pods could either be due to latency between application containers and their local Envoy sidecar or to latency between sidecars themselves. Datadog NPM tags Envoy sidecars as containers, which means if you do see latency between pods, you can use the Network Map to visualize the underlying container traffic and determine if it’s a service mesh issue.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"npm-for-containers04.png\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eVisualize service mesh traffic by container_name to look at network communication between Envoy sidecars.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"start-monitoring-your-containerized-workloads-with-npm-today\"\u003e\u003ca href=\"#start-monitoring-your-containerized-workloads-with-npm-today\"\u003eStart monitoring your containerized workloads with NPM today\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eWhether you’re using orchestration tools like Kubernetes and Amazon ECS, relying on an Istio service mesh, or migrating to any of these platforms, Datadog Network Performance Monitoring provides you with full visibility into your containerized applications and their communication. To get started with NPM, follow the installation instructions \u003ca href=\"https://docs.datadoghq.com/network_monitoring/performance/setup/?tab=agent#setup\"\u003ehere\u003c/a\u003e. And, to learn about how \u003ca href=\"https://www.deliveryhero.com/\"\u003eDelivery Hero\u003c/a\u003e was able to safely scale to meet 2X their orders in 2020 using Datadog NPM for visibility into their Kubernetes network, \u003ca href=\"https://www.datadoghq.com/case-studies/deliveryhero-2021/\"\u003esee the case study\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIf you’re new to Datadog, sign up today for a 14-day \u003ca href=\"#\"\u003efree trial.\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers-hero.png\" width=\"100%\"/\u003eContainers are lightweight, portable, easily scalable, and enable you to run multiple workloads on the same host efficiently, particularly when using an orchestration platform like Kubernetes or Amazon ECS. But containers also introduce monitoring challenges. Containerized environments may comprise vast webs of distributed endpoints and dependencies that rely on complex network communication. Adding further complexity, you need to ensure that each node in your cluster maintains contact with almost every other node.",
      "date_published": "2021-08-05T00:00:00Z",
      "author": {
        "name": "Jordan Obey"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/about/latest-news/press-releases/datadog-launches-cloud-security-platform-to-provide-security-teams-with-unprecedented-observability-capabilities/",
      "title": "Datadog Launches Cloud Security Platform to Provide Security Teams with Unprecedented Observability Capabilities",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cstrong\u003eNEW YORK\u003c/strong\u003e – \u003ca href=\"https://www.datadoghq.com/\"\u003eDatadog\u003c/a\u003e, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced the launch of the Datadog Cloud Security Platform, adding full-stack security context to Datadog’s deep observability capabilities. This new offering enables organizations to use a single platform to correlate security insights with monitoring data across infrastructure, network and application tiers, providing Security teams with the visibility they need to understand and respond to potential threats faster. \u003c/p\u003e\u003cp\u003eIn recent years, security attacks have increasingly focused on the application level, prompting DevOps and Security teams to work more closely together to “shift left” and infuse security into the full software development life cycle. Traditionally, this has been difficult because of siloed tools and processes, which has been further exacerbated as organizations move to the cloud and security teams are left with even less visibility.\u003c/p\u003e\u003cp\u003eDatadog’s Cloud Security Platform addresses these challenges by enabling DevOps and Security teams to access a shared source of truth supported by a common data model. With Datadog, in parallel to detecting potential threats, Security leaders now have access to the underlying infrastructure, network and application data at the time of an attack, meaning they have deeper insights that enable more accurate threat detection and accelerated incident response. And, unlike point solutions, Datadog’s platform approach ensures that this data is automatically correlated and presented in context, without requiring manual analysis.\u003c/p\u003e\u003cp\u003e“As organizations embark on their digital transformation journey, unifying once disparate security, compliance and engineering practices has become a key requirement to deliver best-in-class customer experiences,” said Amit Agarwal, Chief Product Officer, Datadog. “Built for cloud scale, the Datadog Cloud Security Platform supports organizations in adopting a modern DevSecOps practice that will enable a more holistic and, ultimately, a more robust approach to security, without increasing the operational burden of deploying and maintaining multiple, disconnected point solutions.”\u003c/p\u003e\u003cp\u003e“With Lemonade’s growth, cloud security has become a primary focus,” said Jonathan Jaffe, Chief Information Security Officer, Lemonade. “Within the first week of an easy integration, Datadog’s security offerings helped my team manage potential threats faster, with less effort, and with higher fidelity and accuracy. What’s more, collaboration with our DevOps colleagues became easier and has helped tie security to the business. We have many security tools and services; Datadog Cloud Security Platform has become one of our top-three tools. We see it supporting our current and future growth with security, and in lockstep with DevOps.” \u003c/p\u003e\u003cp\u003eForrester’s State of Application Security report notes that “Applications remain a top cause of external breaches, and the prevalence of open source, API, and containers only adds complexity to the security team. Happily, organizations have started to recognize the importance of application security and are embedding security more tightly into the development phase.” \u003c/p\u003e\u003cp\u003eThe Datadog Cloud Security Platform includes:\u003c/p\u003e\u003cul\u003e\u003cli\u003eCloud Security Posture Management (CSPM) makes it easy to track whether your production environment complies with industry standards, such as PCI DSS, SOC 2 and HIPAA, and catches misconfigurations that leave your organization vulnerable to potential attacks.\u003c/li\u003e\u003cli\u003eCloud Workload Security (CWS) detects threats to your production workloads by monitoring file and process activity across your environments to help catch host and infrastructure-based attacks.\u003c/li\u003e\u003cli\u003eSecurity Monitoring identifies threats to your cloud environments by analyzing operational and security logs. As an easy-to-use cloud-native SIEM, Security Monitoring provides out-of-the-box security integrations and threat detection rules that are easy to extend and customize.\u003c/li\u003e\u003cli\u003eApplication Security, currently in beta, provides protection against application-level threats by identifying and blocking attacks that target code-level vulnerabilities, such as SQL injections and cross-site scripting (XSS) exploits.\u003c/li\u003e\u003cli\u003eUnified Observability and Security Reporting allows seamless pivots between DevOps telemetry and security insights. This unified experience enables Security teams to understand the operational and business impact of security incidents, and DevOps teams to see security signals alongside the metrics, traces and logs of their services.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cbr/\u003eFor more information and to get started with the Datadog Cloud Security Platform, please visit \u003ca href=\"https://www.datadoghq.com/product/security-platform/\"\u003ehttps://www.datadoghq.com/product/security-platform/\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eDatadog will be at Black Hat’s USA Summit—both in person and virtually. To listen in on our session, With Friends Like eBPF, Who Needs Enemies? please visit \u003ca href=\"https://www.blackhat.com/us-21/briefings/schedule/index.html#with-friends-like-ebpf-who-needs-enemies-23619\"\u003eBlack Hat speaker sessions\u003c/a\u003e. \u003c/p\u003e\u003cdiv\u003e\u003cp\u003e\u003cstrong\u003eAbout Datadog\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eDatadog is the monitoring and security platform for cloud applications. Our SaaS platform integrates and automates infrastructure monitoring, application performance monitoring and log management to provide unified, real-time observability of our customers’ entire technology stack. Datadog is used by organizations of all sizes and across a wide range of industries to enable digital transformation and cloud migration, drive collaboration among development, operations, security and business teams, accelerate time to market for applications, reduce time to problem resolution, secure applications and infrastructure, understand user behavior and track key business metrics.\u003c/p\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003eForward-Looking Statements\u003c/strong\u003e \u003c/p\u003e\u003cp\u003eThis press release may include certain “forward-looking statements” within the meaning of Section 27A of the Securities Act of 1933, as amended, or the Securities Act, and Section 21E of the Securities Exchange Act of 1934, as amended. These forward-looking statements reflect our current views about our plans, intentions, expectations, strategies and prospects, which are based on the information currently available to us and on assumptions we have made. Actual results may differ materially from those described in the forward-looking statements and are subject to a variety of assumptions, uncertainties, risks and factors that are beyond our control, including those risks detailed under the caption “Risk Factors” and elsewhere in our Securities and Exchange Commission filings and reports, including the Quarterly Report on Form 10-Q filed with the Securities and Exchange Commission on May 7, 2021, as well as future filings and reports by us. Except as required by law, we undertake no duty or obligation to update any forward-looking statements contained in this release as a result of new information, future events, changes in expectations or otherwise.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "NEW YORK \u0026ndash; Datadog, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced the launch of the Datadog Cloud Security Platform, adding full-stack security context to Datadog’s deep observability capabilities. This new offering enables organizations to use a single platform to correlate security insights with monitoring data across infrastructure, network and application tiers, providing Security teams with the visibility they need to understand and respond to potential threats faster.",
      "date_published": "2021-08-04T20:30:44Z",
      "author": {
        "name": "Datadog"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/cloud-migration-monitoring/",
      "title": "Best practices for monitoring a cloud migration",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eWhen you migrate workloads from on-premise infrastructure into a public cloud, you can improve the performance, reliability, and security of your application, and you might also lower your costs. To execute a successful cloud migration, you need a detailed inventory of your current deployments, visibility into your application’s performance as you shift traffic to the cloud, and confirmation that—once you’ve landed in the cloud—you’re still providing a high-quality user experience.\u003c/p\u003e\u003cp\u003eIn this post, we’ll explore best practices for monitoring your cloud migration and show you how Datadog can give you visibility throughout every phase. We’ll show you how to:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"#take-inventory-to-plan-your-migration\"\u003ePlan what cloud resources you need\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#prepare-create-and-test-your-new-environment\"\u003eBuild visibility into your cloud environment\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#cut-over-and-watch-your-cloud-migration-metrics\"\u003eMonitor your newly migrated application\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"take-inventory-to-plan-your-migration\"\u003e\u003ca href=\"#take-inventory-to-plan-your-migration\"\u003eTake inventory to plan your migration\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn order to plan a cloud environment that’s capable of supporting your applications, you’ll need a deep understanding of your current environment. In this section, we’ll show you how Datadog can help you plan your migration by understanding the topology and resource requirements of your application in its current state.\u003c/p\u003e\u003ch3 id=\"map-your-application-and-infrastructure\"\u003e\u003ca href=\"#map-your-application-and-infrastructure\"\u003eMap your application and infrastructure\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eThe \u003ca href=\"https://www.datadoghq.com/blog/service-map/\"\u003eService Map\u003c/a\u003e helps you gain a complete understanding of your services, their dependencies, and the rate of requests between them. In the screenshot below, the Service Map highlights the \u003ccode\u003eweb-store\u003c/code\u003e service and shows its request, latency, and error rates as well as its request traffic to and from other services. From here, you can click any service to drill down to view request data gathered by \u003ca href=\"https://www.datadoghq.com/knowledge-center/distributed-tracing/\"\u003eApplication Performance Monitoring (APM) and distributed tracing\u003c/a\u003e.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"The Service Map shows the request, latency, and error rate of the web store service, and maps its requests to and from other services.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eThe \u003ca href=\"https://www.datadoghq.com/blog/introducing-host-maps-know-thy-infrastructure/\"\u003ehost map\u003c/a\u003e visualizes your current environment and uses colors to represent the real-time value of a metric your hosts are reporting. You can use metadata from your hosts to aggregate, explore, and better understand your infrastructure. The screenshot below shows hosts grouped by environment and color coded to show hosts with high CPU usage in red and low CPU usage in green.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"The Host map shows hosts grouped by availability zone and uses red to indicate a host with high CPU usage and green to show low CPU usage.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eThe host map can reveal resource-utilization hotspots that help you decide the number, size, and type of the VMs you launch in the cloud. You can click any node on the map to see a dashboard that shows you detailed resource usage patterns. This data can help you understand your infrastructure needs and \u003ca href=\"https://aws.amazon.com/aws-cost-management/aws-cost-optimization/right-sizing/\"\u003eright-size\u003c/a\u003e your new cloud infrastructure. For example, if the host map shows you that a specific application is running on a large number of underutilized instances, you may be able to save money by migrating it to fewer cloud instances. You could also choose a less expensive instance type, such as one that features fewer CPU cores or provides general-purpose capabilities rather than a compute-optimized instance.\u003c/p\u003e\u003ch3 id=\"analyze-your-network\"\u003e\u003ca href=\"#analyze-your-network\"\u003eAnalyze your network\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eTo ensure that your new cloud environment can accommodate the volume and type of network traffic your application generates, you’ll need to take a close look at the behavior of your current network. \u003ca href=\"https://www.datadoghq.com/blog/network-performance-monitoring/\"\u003eDatadog Network Performance Monitoring (NPM)\u003c/a\u003e gives you visibility into the traffic within and between your on-premise data centers, so you can design the \u003ca href=\"https://en.wikipedia.org/wiki/Virtual_private_cloud\"\u003eVPCs\u003c/a\u003e, \u003ca href=\"https://en.wikipedia.org/wiki/Subnetwork\"\u003esubnets\u003c/a\u003e, and other network constructs in your cloud environment to support your application’s traffic.\u003c/p\u003e\u003cp\u003eThe \u003ca href=\"https://docs.datadoghq.com/network_monitoring/performance/network_map/\"\u003eNetwork Map\u003c/a\u003e visualizes the traffic between the hosts, pods, containers, and other components of your environment. This can help you spot bottlenecks as you migrate—and provision appropriate cloud network resources to resolve them. The screenshot below shows a Network Map of a testing-related application that generates a small amount of traffic. An application like this could be a preferred, lower-risk candidate for migrating first, ahead of higher-traffic applications.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"The network map shows an application called test comprised of only two services.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003e\u003ca href=\"https://www.datadoghq.com/blog/cloud-service-autodetection-datadog/\"\u003eIn the cloud\u003c/a\u003e, your network can dynamically scale to include new hosts, subnets, and VPCs. As these cloud resources come and go, you can continue to rely on the Network Map and \u003ca href=\"https://docs.datadoghq.com/network_monitoring/performance/network_page/\"\u003eNetwork Overview\u003c/a\u003e to track network flows within your cloud environment. You can sort your NPM data by geography to identify traffic between regions or availability zones. Using this information, you may be able to revise your network traffic flows so you can minimize latency and transit costs in the cloud.\u003c/p\u003e\u003ch3 id=\"understand-your-storage\"\u003e\u003ca href=\"#understand-your-storage\"\u003eUnderstand your storage\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eAs you plan to provide storage for your application in the cloud (e.g., managed databases, file storage, and object storage), you should have a detailed inventory of the types and amounts of storage required. Our \u003ca href=\"https://docs.datadoghq.com/integrations/#cat-data-store\"\u003edata store integrations\u003c/a\u003e provide out-of-the-box dashboards that visualize usage metrics like:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ccode\u003epostgresql.total_size\u003c/code\u003e: the total disk space used by a PostgreSQL table, in bytes\u003c/li\u003e\u003cli\u003e\u003ccode\u003eibm_db2.tablespace.size\u003c/code\u003e: the total disk space used by an IBM DB2 table, in bytes\u003c/li\u003e\u003cli\u003e\u003ccode\u003esap_hana.disk.used\u003c/code\u003e: the total disk space used by SAP HANA to persist data, in bytes\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eAnd to estimate your future storage costs, you can apply a \u003ca href=\"https://docs.datadoghq.com/dashboards/functions/algorithms/#forecast\"\u003eforecast function\u003c/a\u003e when you graph these metrics to see where your data storage needs are headed.\u003c/p\u003e\u003ch2 id=\"prepare-create-and-test-your-new-environment\"\u003e\u003ca href=\"#prepare-create-and-test-your-new-environment\"\u003ePrepare, create, and test your new environment\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eOnce you’ve identified the resources to include in your cloud environment, you should make plans to ensure that you’ll have the visibility you need. In this section, we’ll describe steps you can take to leverage monitoring throughout the process of creating your cloud environment. We’ll look at three phases of moving an application to the cloud: preparation, setup, and validation.\u003c/p\u003e\u003ch3 id=\"prepare-your-slos-and-dashboards\"\u003e\u003ca href=\"#prepare-your-slos-and-dashboards\"\u003ePrepare your SLOs and dashboards\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eYou should expect the cloud-based version of your application to be at least as reliable as the on-premise version, so you can continue to use the same \u003ca href=\"https://www.datadoghq.com/blog/slo-monitoring-tracking/\"\u003eservice level objectives (SLOs)\u003c/a\u003e—performance and reliability targets for the services you operate—across the old and new versions. But you may need to adjust what you measure—your service level indicators (SLIs)—to include performance metrics from your newly migrated workloads.\u003c/p\u003e\u003cp\u003eFor example, let’s say you’re planning to move a Redis cache to the managed version that AWS provides—Amazon ElastiCache for Redis—and you’ve created an SLO to ensure that your cache hit rate stays above 90 percent over each seven-day period. You may need to operate that cache temporarily as a hybrid while you transition to the cloud. During this hybrid phase, your SLOs should be based on a combination of SLIs from both the legacy infrastructure (on-premise Redis) and the target infrastructure (ElastiCache). In this case, you could update your SLO to track metrics that reflect cache hits and misses from both services. As you phase out your legacy infrastructure, the legacy Redis deployment will eventually stop reporting any data, and you can remove the \u003ccode\u003eredis.stats.keyspace_*\u003c/code\u003e metrics from your SLIs.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"An SLO shows a numerator of Redis cache hits plus Elasticache hits and a denominator of hits from both caches added to misses from both caches.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eTo ensure that you have visibility into your cloud infrastructure from day one, you can leverage the dashboards and alerts you already use to track the health of your application. Export any of your \u003ca href=\"https://docs.datadoghq.com/dashboards/#copy-import-or-export-dashboard-json\"\u003edashboards\u003c/a\u003e or \u003ca href=\"https://docs.datadoghq.com/monitors/monitor_types/#import\"\u003ealerts\u003c/a\u003e to JSON and edit the file to revise the metric names to align with your cloud services. Then import the modified JSON to begin monitoring your application in the cloud.\u003c/p\u003e\u003ch3 id=\"set-up-a-cloud-environment-with-monitoring-built-in\"\u003e\u003ca href=\"#set-up-a-cloud-environment-with-monitoring-built-in\"\u003eSet up a cloud environment with monitoring built in\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eWhen you launch your cloud environment, you can use your cloud provider’s resource management service (e.g., AWS CloudFormation) to automatically enable the integrations that will help you track the performance of your cloud services and infrastructure. For example, you can create a CloudFormation template that defines the necessary AWS resources and also enables the Datadog AWS integration that allows you to \u003ca href=\"https://www.datadoghq.com/blog/monitoring-as-code-with-datadog-and-cloudformation/#automatically-enable-datadogs-aws-integration\"\u003emonitor them\u003c/a\u003e. You can even \u003ca href=\"https://github.com/DataDog/datadog-cloudformation-resources#resources-available\"\u003eautomatically deploy Datadog resources\u003c/a\u003e—such as \u003ca href=\"#prepare-your-slos-and-dashboards\"\u003edashboards, monitors, and SLOs\u003c/a\u003e—as part of your migration to the cloud. This way, you can have monitoring in place before you even begin shifting traffic to your new cloud infrastructure.\u003c/p\u003e\u003cp\u003eResource management tools also make it easy to apply tags to the infrastructure and services you launch in your cloud environment. For example, you could apply an \u003ccode\u003eenv:production_cloud\u003c/code\u003e tag that allows you to monitor the new version of your application separately from the legacy version. You can add a tag like this automatically by specifying it in the templates or commands you use in \u003ca href=\"https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/tag-resources\"\u003eAzure Resource Manager\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deployment-manager/docs/creating-managing-labels\"\u003eGoogle Cloud Platform\u003c/a\u003e, and \u003ca href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-resource-tags.html\"\u003eAWS CloudFormation\u003c/a\u003e.\u003c/p\u003e\u003ch3 id=\"validate-test-and-protect-your-cloud-architecture\"\u003e\u003ca href=\"#validate-test-and-protect-your-cloud-architecture\"\u003eValidate, test, and protect your cloud architecture\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eWhen you migrate your application to the cloud, you could be subject to data-protection regulations such as HIPAA, PCI, and GDPR. Datadog \u003ca href=\"https://www.datadoghq.com/product/security-platform/cloud-security-posture-management/\"\u003eCloud Security Posture Management (CSPM)\u003c/a\u003e helps you track the compliance posture of your cloud environment to ensure that your application meets the applicable regulations. CSPM provides \u003ca href=\"https://docs.datadoghq.com/security_platform/cspm/frameworks_and_benchmarks/\"\u003eout-of-the-box rules\u003c/a\u003e that are automatically enabled to continuously evaluate your cloud environment against compliance standards and industry benchmarks. For example, if you’re migrating to Azure Kubernetes Service, Datadog provides a built-in rule to help you confirm that \u003ca href=\"https://docs.datadoghq.com/security_platform/default_rules/cis-azure-1.3.0-8.5/\"\u003eRBAC is enabled\u003c/a\u003e at all times.\u003c/p\u003e\u003cp\u003eAs you shift traffic to your cloud environment, Datadog \u003ca href=\"https://www.datadoghq.com/product/security-platform/security-monitoring/\"\u003eSecurity Monitoring\u003c/a\u003e can help you spot security threats by automatically analyzing application and infrastructure logs in real time. Security Monitoring provides threat detection rules so you can get started quickly. You can also \u003ca href=\"https://docs.datadoghq.com/security_platform/detection_rules/#creating-and-managing-rules\"\u003ecreate custom rules\u003c/a\u003e to watch for specific security concerns.\u003c/p\u003e\u003cp\u003eOnce you’ve created your cloud environment and deployed your application there, you can use \u003ca href=\"https://www.datadoghq.com/product/synthetic-monitoring/\"\u003eSynthetic Monitoring\u003c/a\u003e to automatically test the availability of your API endpoints and key user workflows within your application. It can simulate user journeys—even ones that include \u003ca href=\"https://www.datadoghq.com/blog/mfa-synthetic-testing-datadog/\"\u003emulti-factor authentication\u003c/a\u003e—and execute simple or \u003ca href=\"https://www.datadoghq.com/blog/monitor-apis-with-datadog/\"\u003emultistep API tests\u003c/a\u003e to help you proactively identify issues before your users do.\u003c/p\u003e\u003cp\u003eOnce you start running Synthetic tests on your cloud environment, that traffic will appear in the \u003ca href=\"#map-your-application-and-infrastructure\"\u003eService Map\u003c/a\u003e. You can compare this to the Service Map of your legacy environment to check for any missing or unexpected request paths in your newly migrated workloads.\u003c/p\u003e\u003ch2 id=\"cut-over-and-watch-your-cloud-migration-metrics\"\u003e\u003ca href=\"#cut-over-and-watch-your-cloud-migration-metrics\"\u003eCut over and watch your cloud migration metrics\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAs you shift traffic to the cloud, you can use Datadog to verify that your application’s performance and end user experience remain optimal. In this section, we’ll describe how to use SLOs, dashboards, RUM, and APM to monitor your new cloud environment while you complete your migration.\u003c/p\u003e\u003ch3 id=\"track-slos-and-migration-progress-on-dashboards\"\u003e\u003ca href=\"#track-slos-and-migration-progress-on-dashboards\"\u003eTrack SLOs and migration progress on dashboards\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eTo ensure that your migration is not affecting the performance of your application, you can continue to rely on the SLOs you’ve already created. You can \u003ca href=\"https://www.datadoghq.com/blog/define-and-manage-slos/\"\u003eshare SLO information\u003c/a\u003e by displaying \u003ca href=\"https://docs.datadoghq.com/dashboards/widgets/slo/\"\u003eSLO widgets\u003c/a\u003e and other curated monitoring data on your \u003ca href=\"https://docs.datadoghq.com/dashboards/\"\u003edashboards\u003c/a\u003e. These dashboards enable you to easily share a real-time status report of your migration-in-progress—both internally and with stakeholders \u003ca href=\"https://www.datadoghq.com/blog/dashboard-sharing/\"\u003eoutside of your organization\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eDatadog also provides \u003ca href=\"https://docs.datadoghq.com/getting_started/dashboards/#explore-out-of-the-box-dashboards\"\u003eout-of-the-box dashboards\u003c/a\u003e for cloud services like \u003ca href=\"https://docs.datadoghq.com/agent/amazon_ecs/\"\u003eAmazon ECS\u003c/a\u003e, \u003ca href=\"https://docs.datadoghq.com/integrations/google_cloud_functions/\"\u003eGoogle Cloud Functions\u003c/a\u003e, and \u003ca href=\"https://docs.datadoghq.com/integrations/azure_sql_database/\"\u003eAzure SQL Database\u003c/a\u003e to give you real-time information about the health and performance of the services that run your application. You can expect some metrics to rise steadily as you send more traffic to the cloud—for example, the rate of requests and the size of your data stores. And you can watch to ensure that other metrics—such as latency and error rates—hold steady or even decrease as the cloud version of your application begins to outperform the legacy version. To be fully prepared, of course, you should create \u003ca href=\"https://docs.datadoghq.com/monitors/\"\u003ealerts\u003c/a\u003e to notify you if those metrics increase unexpectedly.\u003c/p\u003e\u003ch3 id=\"monitor-end-to-end-with-rum-and-apm\"\u003e\u003ca href=\"#monitor-end-to-end-with-rum-and-apm\"\u003eMonitor end-to-end with RUM and APM\u003c/a\u003e\u003c/h3\u003e\u003cp\u003e\u003ca href=\"https://www.datadoghq.com/blog/real-user-monitoring-with-datadog/\"\u003eReal User Monitoring (RUM)\u003c/a\u003e gives you visibility into the experience of your users by measuring their interactions with your application. For example, the \u003ccode\u003eview.first_input_delay\u003c/code\u003e metric tracks how long your users are waiting for the app to react to their first action on a page, and \u003ccode\u003eview.largest_contentful_paint\u003c/code\u003e measures how long it takes before the largest object in the DOM is rendered. RUM also shows you data on the rate of errors and crashes in your \u003ca href=\"https://www.datadoghq.com/blog/datadog-mobile-rum/\"\u003emobile apps\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eRUM collects your application’s frontend data—metrics, events, and browser information—and links automatically with Datadog \u003ca href=\"https://www.datadoghq.com/blog/announcing-apm/\"\u003eAPM\u003c/a\u003e to provide \u003ca href=\"https://www.datadoghq.com/blog/unify-apm-rum-datadog/\"\u003eend-to-end visibility\u003c/a\u003e. If RUM metrics and error rates reveal that your shift to the cloud has caused crashes or introduced latency, you can use APM to pinpoint the source of the problem. \u003ca href=\"https://www.datadoghq.com/knowledge-center/distributed-tracing/flame-graph/\"\u003eFlame graphs\u003c/a\u003e visualize the sequence of service calls your application executes to fulfill each request, making it easy to spot services that are returning errors or adding latency.\u003c/p\u003e\u003cp\u003eAPM can also help you understand whether the cloud-based version of your application is resource-constrained—for example, running on VMs that are too small or serverless functions that are underprovisioned. If a flame graph reveals a bottleneck in a request, you can click the \u003ca href=\"https://docs.datadoghq.com/tracing/visualization/#spans\"\u003espan\u003c/a\u003e that represents the slow service call to see resource utilization metrics from the relevant host. In the screenshot below, the \u003ccode\u003echeck-token\u003c/code\u003e call took 3.43 seconds. The \u003cstrong\u003eMetrics\u003c/strong\u003e tab below the flame graph shows high CPU usage on the host that received the request, indicating that the slow response could be due to insufficient resources.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"A flame graph shows one call taking 3.43 seconds or 97.6 percent of the execution time, along with CPU utilization near 100 percent.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch3 id=\"finalizing\"\u003e\u003ca href=\"#finalizing\"\u003eFinalizing\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eBefore you call your migration complete, you should confirm that all traffic has shifted and that it’s safe to decommission your legacy infrastructure. The screenshot below shows an example of a graph that you can create to verify the progress of your traffic shift. This \u003ca href=\"https://www.datadoghq.com/blog/timeseries-metric-graphs-101/#stacked-area-graphs\"\u003earea graph\u003c/a\u003e shows that the combined volume of requests to our legacy and cloud infrastructure has remained consistent throughout the migration. It also indicates that the new cloud environment (represented by the darker area on the bottom and tagged \u003ccode\u003eenv:production_cloud\u003c/code\u003e) has been servicing an increasing share of the traffic, while the on-premise environment’s share (the lighter area on top) has decreased.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"An area graph shows an static total of overall requests, with requests to \u0026#39;production cloud\u0026#39; increasing over 45 minutes.\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYou should also confirm that all sessions have been drained from on-premise servers, and that message queues (e.g., ActiveMQ or RabbitMQ) and data streams (e.g., Kafka or Apache Flink) no longer hold any records.\u003c/p\u003e\u003cp\u003eWhen you’ve completed your migration, you can continue to use RUM and APM—along with your SLOs, dashboards, and alerts—to give you ongoing visibility as you operate your applications in the cloud. And as the new version of your application establishes traffic patterns in the cloud, you can take advantage of features like \u003ca href=\"https://www.datadoghq.com/blog/watchdog/\"\u003eWatchdog\u003c/a\u003e and \u003ca href=\"https://www.datadoghq.com/blog/introducing-anomaly-detection-datadog/\"\u003eanomaly detection\u003c/a\u003e to help you spot and troubleshoot anomalies in your application’s performance.\u003c/p\u003e\u003ch2 id=\"migrate-and-monitor\"\u003e\u003ca href=\"#migrate-and-monitor\"\u003eMigrate and monitor\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eBy building monitoring into your cloud migration process, you’ll have the visibility you need to confirm a successful launch and take advantage of the increased performance and reliability of the cloud. Datadog provides integrations with more than\n450 technologies to ensure that you can always monitor all the layers of your application. If you’re not yet using Datadog, you can start today with a \u003ca href=\"#\"\u003e14-day free trial\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration_monitoring_210628_FINAL.png\" width=\"100%\"/\u003eWhen you migrate workloads from on-premise infrastructure into a public cloud, you can improve the performance, reliability, and security of your application, and you might also lower your costs. To execute a successful cloud migration, you need a detailed inventory of your current deployments, visibility into your application\u0026rsquo;s performance as you shift traffic to the cloud, and confirmation that—once you\u0026rsquo;ve landed in the cloud—you\u0026rsquo;re still providing a high-quality user experience.",
      "date_published": "2021-08-04T00:00:00Z",
      "author": {
        "name": "David M. Lentz"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/deploy-dotnet-core-aws-fargate/",
      "title": "Monitor containerized ASP.NET Core applications on AWS Fargate",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eThe \u003ca href=\"https://dotnet.microsoft.com/learn/aspnet/what-is-aspnet-core\"\u003eASP.NET Core framework\u003c/a\u003e enables you to build and deploy .NET applications on a wide variety of platforms, each of which has different observability concerns. \u003ca href=\"https://www.datadoghq.com/blog/asp-dotnet-core-monitoring/\"\u003eIn a previous post\u003c/a\u003e, we looked at monitoring a containerized ASP.NET Core application. In this guide, we’ll show how Datadog provides visibility into ASP.NET Core applications running on \u003ca href=\"https://aws.amazon.com/fargate/\"\u003eAWS Fargate\u003c/a\u003e. We’ll walk through:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"#package-an-instrumented-application-with-docker\"\u003einstrumenting and packaging a sample .NET application\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#publish-your-image-to-docker-hub\"\u003epublishing the application\u003c/a\u003e to Docker Hub\u003c/li\u003e\u003cli\u003e\u003ca href=\"#deploy-a-containerized-net-application-with-aws-fargate\"\u003edeploying the instrumented .NET application\u003c/a\u003e using AWS Fargate\u003c/li\u003e\u003cli\u003e\u003ca href=\"#monitor-application-performance-with-datadog\"\u003emonitoring\u003c/a\u003e application performance with Datadog APM\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eInstrumenting your application enables you to track requests as they move across the application’s service and process boundaries, so you can identify performance bottlenecks and resolve them before they affect end users. Datadog offers out-of-the-box instrumentation for .NET Core and other .NET frameworks with the \u003ca href=\"https://docs.datadoghq.com/tracing/setup_overview/setup/dotnet-core/?tab=windows\"\u003e.NET tracer\u003c/a\u003e, which submits trace data to Datadog via the Datadog Agent. The Agent can also collect performance data from your Fargate resources, giving you complete visibility into your application and its underlying infrastructure.\u003c/p\u003e\u003ch3 id=\"get-started-with-a-sample-application\"\u003e\u003ca href=\"#get-started-with-a-sample-application\"\u003eGet started with a sample application\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eTo get started, make sure you have at least \u003ca href=\"https://dotnet.microsoft.com/download/dotnet/5.0\"\u003eversion 5 of the .NET Core SDK\u003c/a\u003e installed, which includes \u003ca href=\"https://docs.microsoft.com/en-us/dotnet/core/tools/\"\u003ethe .NET CLI\u003c/a\u003e. This will let you generate the sample ASP.NET Core application we’ll use throughout this guide. We’ll also use \u003ca href=\"https://hub.docker.com/\"\u003eDocker Hub\u003c/a\u003e to publish the containerized application, though you can use other container registry services such as \u003ca href=\"https://aws.amazon.com/ecr/\"\u003eAmazon ECR\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eYou can create a new web application project with all of the files needed to run a sample application via the following .NET CLI commands:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003e \ndotnet new sln -n DatadogFargateExample\ndotnet new webapp -o DatadogFargateExample -n DatadogFargateExample\ndotnet sln add DatadogFargateExample\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThese commands create a new solution file (i.e., \u003cstrong\u003eDatadogFargateExample.sln\u003c/strong\u003e) and add a new \u003ca href=\"https://docs.microsoft.com/en-us/aspnet/core/razor-pages/?view=aspnetcore-5.0\u0026amp;tabs=visual-studio\"\u003eRazor Pages\u003c/a\u003e web application project and associated \u003cstrong\u003eDatadogFargateExample\u003c/strong\u003e directory to the file. Next, we’ll instrument the application with Datadog’s .NET tracer and publish it on Docker Hub as a Linux container.\u003c/p\u003e\u003ch2 id=\"package-an-instrumented-application-with-docker\"\u003e\u003ca href=\"#package-an-instrumented-application-with-docker\"\u003ePackage an instrumented application with Docker\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDocker enables you to easily package applications and their dependencies together in a single container, which you can then deploy to any environment, such as a Fargate cluster. AWS Fargate currently only supports Linux-based containers, so we will use a Linux container to package the application. To create a container, add the following Dockerfile to your project’s \u003cstrong\u003eDatadogFargateExample\u003c/strong\u003e directory:\u003c/p\u003e\u003cdiv\u003e\u003cp\u003e./DatadogFargateExample/Dockerfile\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003e#See https://aka.ms/containerfastmode to understand how Visual Studio uses this Dockerfile to build your images for faster debugging.\n \nFROM mcr.microsoft.com/dotnet/aspnet:5.0 AS base\nWORKDIR /app\nEXPOSE 80\nEXPOSE 443\n \nFROM mcr.microsoft.com/dotnet/sdk:5.0 AS build\n \n# Download the latest version of the tracer but don\u0026#39;t install yet\nRUN TRACER_VERSION=$(curl -s \\https://api.github.com/repos/DataDog/dd-trace-dotnet/releases/latest | grep tag_name | cut -d \u0026#39;\u0026#34;\u0026#39; -f 4 | cut -c2-) \\\n    \u0026amp;\u0026amp; curl -Lo /tmp/datadog-dotnet-apm.deb https://github.com/DataDog/dd-trace-dotnet/releases/download/v${TRACER_VERSION}/datadog-dotnet-apm_${TRACER_VERSION}_amd64.deb\n \nWORKDIR /src\nCOPY [\u0026#34;DatadogFargateExample/DatadogFargateExample.csproj\u0026#34;, \u0026#34;DatadogFargateExample/\u0026#34;]\nRUN dotnet restore \u0026#34;DatadogFargateExample/DatadogFargateExample.csproj\u0026#34;\nCOPY . .\nWORKDIR \u0026#34;/src/DatadogFargateExample\u0026#34;\nRUN dotnet build \u0026#34;DatadogFargateExample.csproj\u0026#34; -c Release -o /app/build\n \nFROM build AS publish\nRUN dotnet publish \u0026#34;DatadogFargateExample.csproj\u0026#34; -c Release -o /app/publish\n \nFROM base AS final\n \n# Copy the tracer from build target\nCOPY --from=build /tmp/datadog-dotnet-apm.deb /tmp/datadog-dotnet-apm.deb\n# Install the tracer\nRUN mkdir -p /opt/datadog \\\n    \u0026amp;\u0026amp; mkdir -p /var/log/datadog \\\n    \u0026amp;\u0026amp; dpkg -i /tmp/datadog-dotnet-apm.deb \\\n    \u0026amp;\u0026amp; rm /tmp/datadog-dotnet-apm.deb\n \n# Enable the tracer\nENV CORECLR_ENABLE_PROFILING=1\nENV CORECLR_PROFILER={846F5F1C-F9AE-4B07-969E-05C26BC060D8}\nENV CORECLR_PROFILER_PATH=/opt/datadog/Datadog.Trace.ClrProfiler.Native.so\nENV DD_DOTNET_TRACER_HOME=/opt/datadog\nENV DD_INTEGRATIONS=/opt/datadog/integrations.json\n \nWORKDIR /app\nCOPY --from=publish /app/publish .\nENTRYPOINT [\u0026#34;dotnet\u0026#34;, \u0026#34;DatadogFargateExample.dll\u0026#34;]\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003cp\u003eThe Dockerfile uses \u003ca href=\"https://docs.docker.com/develop/develop-images/multistage-build/\"\u003emulti-stage builds\u003c/a\u003e to optimize the build process and ensure compatibility with Visual Studio so you can debug issues locally via Visual Studio’s container tools. You can check out \u003ca href=\"https://docs.microsoft.com/visualstudio/containers/container-build\"\u003eMicrosoft’s documentation\u003c/a\u003e for details.\u003c/p\u003e\u003cp\u003eThere are four build stages in the Dockerfile above: \u003ccode\u003ebase\u003c/code\u003e, \u003ccode\u003ebuild\u003c/code\u003e, \u003ccode\u003epublish\u003c/code\u003e, and \u003ccode\u003efinal\u003c/code\u003e. The \u003ccode\u003emcr.microsoft.com/dotnet/aspnet:5.0\u003c/code\u003e Docker image in the \u003ccode\u003ebase\u003c/code\u003e stage is based on the Debian operating system and serves as the main image to run the application in the \u003ccode\u003efinal\u003c/code\u003e stage.\u003c/p\u003e\u003cp\u003eIn the \u003ccode\u003ebuild\u003c/code\u003e stage, the Dockerfile uses the \u003ccode\u003emcr.microsoft.com/dotnet/sdk:5.0\u003c/code\u003e Docker image to first download the latest version of the Datadog .NET tracer (this image has the \u003ccode\u003ecurl\u003c/code\u003e utility needed to download the tracer) then build the \u003ca href=\"#get-started-with-a-sample-application\"\u003e\u003cstrong\u003eDatadogFargateExample\u003c/strong\u003e project\u003c/a\u003e. To use a specific version of the tracer, you can remove the \u003ccode\u003eRUN TRACER_VERSION\u003c/code\u003e step from the Dockerfile and set the \u003ccode\u003eTRACER_VERSION\u003c/code\u003e environment variable via \u003ca href=\"https://docs.docker.com/engine/reference/builder/#arg\"\u003ea build argument\u003c/a\u003e instead.\u003c/p\u003e\u003cp\u003eThe \u003ccode\u003epublish\u003c/code\u003e stage publishes the project and its dependencies to the \u003cstrong\u003e/app/publish\u003c/strong\u003e directory for deployment, and the \u003ccode\u003efinal\u003c/code\u003e stage installs and enables the tracer with the necessary file configurations and environment variables to auto-instrument your application. This allows the tracer to submit data to the Agent, which we will install via \u003ca href=\"#create-an-ecs-task-definition\"\u003ean ECS task definition\u003c/a\u003e in a later section.\u003c/p\u003e\u003cp\u003eYou can build your Docker image and launch the container locally using the following commands:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003edocker build -t test/datadog-fargate-example -f ./DatadogFargateExample/Dockerfile .\ndocker run --rm --name datadog-test -p 8080:80 datadog-fargate-example\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThe \u003ccode\u003etest/datadog-fargate-example\u003c/code\u003e tag allows you to easily push the image to a container registry platform or pull it as a source image for a container deployed via Fargate. Once your container spins up, you can view your instrumented application by navigating to \u003ccode\u003ehttp://localhost:8080/\u003c/code\u003e.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"A sample .NET Core appliction\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch3 id=\"publish-your-image-to-docker-hub\"\u003e\u003ca href=\"#publish-your-image-to-docker-hub\"\u003ePublish your image to Docker Hub\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eYou can push the Docker image to a container registry platform like Docker Hub using the following command:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003edocker image push test/datadog-fargate-example\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThis publishes the image to the registry so you can use it in other environments or platforms. We’ll look at how to use the published image to deploy your .NET application via Fargate next.\u003c/p\u003e\u003ch2 id=\"deploy-a-containerized-net-application-with-aws-fargate\"\u003e\u003ca href=\"#deploy-a-containerized-net-application-with-aws-fargate\"\u003eDeploy a containerized .NET application with AWS Fargate\u003c/a\u003e\u003c/h2\u003e\u003cp\u003e\u003ca href=\"https://www.datadoghq.com/blog/aws-fargate-metrics/\"\u003eAWS Fargate\u003c/a\u003e is a service that enables you to run Amazon Elastic Container Service (Amazon ECS) tasks or Amazon Elastic Kubernetes Service (Amazon EKS) containers without needing to manage any underlying infrastructure. For this guide, we’ll look at leveraging Fargate with ECS by creating:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"#create-an-amazon-ecs-cluster\"\u003ea new ECS cluster\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#create-an-ecs-task-definition\"\u003ean ECS task definition\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#create-an-application-load-balancer\"\u003ean application load balancer\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#create-an-ecs-service\"\u003ean ECS service\u003c/a\u003e for the cluster\u003c/li\u003e\u003c/ul\u003e\u003ch3 id=\"create-an-amazon-ecs-cluster\"\u003e\u003ca href=\"#create-an-amazon-ecs-cluster\"\u003eCreate an Amazon ECS cluster\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eA core part of the ECS infrastructure is \u003ca href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_clusters.html\"\u003ethe cluster\u003c/a\u003e, which is a group of tasks and services necessary for deploying an application. You can \u003ca href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/create_cluster.html\"\u003ecreate an ECS cluster\u003c/a\u003e by navigating to the \u003ca href=\"https://console.aws.amazon.com/ecs/\"\u003eAmazon ECS console\u003c/a\u003e in your AWS account. Select “Networking Only” as the cluster template and use the default values for the remaining configuration settings. Once provisioned, you can view your new cluster by clicking the “View Cluster” button on the “Launch status” page.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"The cluster\u0026#39;s configuration settings\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eNext, we’ll walk through how to add the Datadog Agent and the application container you \u003ca href=\"#publish-your-image-to-docker-hub\"\u003epublished to Docker Hub\u003c/a\u003e to the new cluster.\u003c/p\u003e\u003ch3 id=\"create-an-ecs-task-definition\"\u003e\u003ca href=\"#create-an-ecs-task-definition\"\u003eCreate an ECS task definition\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eECS clusters use \u003ca href=\"https://docs.aws.amazon.com/AmazonECS/latest/userguide/task_definitions.html\"\u003etask definitions\u003c/a\u003e to specify which containers should be created as part of a deployment. For this guide, we will add two containers to the task definition. The first will run the containerized Datadog Agent and the second your instrumented application. You can \u003ca href=\"https://docs.datadoghq.com/integrations/ecs_fargate/#web-ui\"\u003echeck out our documentation\u003c/a\u003e for detailed steps on creating a new task definition with a Datadog Agent container, but we will highlight some of the key container configurations below.\u003c/p\u003e\u003ch4 id=\"create-the-datadog-agent-container\"\u003e\u003ca href=\"#create-the-datadog-agent-container\"\u003eCreate the Datadog Agent container\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eThe first container uses the \u003ccode\u003edatadog/agent:latest\u003c/code\u003e image to run the Agent, which will gather data from the .NET tracer and host and submit it to Datadog. The Agent image uses environment variables (seen below) to enable APM and listen for non-local traffic, which is required when the Agent and application are running in different containers. It also uses a \u003ccode\u003eDD_API_KEY\u003c/code\u003e environment variable for connecting the Agent to your Datadog account—your unique API key can be found in \u003ca href=\"https://app.datadoghq.com/account/settings?#api\"\u003eyour account’s settings\u003c/a\u003e.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Environment variables for the Datadog Agent\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch4 id=\"create-the-application-container\"\u003e\u003ca href=\"#create-the-application-container\"\u003eCreate the application container\u003c/a\u003e\u003c/h4\u003e\u003cp\u003eYou can use \u003ca href=\"https://docs.datadoghq.com/integrations/ecs_fargate/#web-ui\"\u003ethe same steps\u003c/a\u003e to create the second container, which will launch the instrumented application and use the Agent container as a startup dependency. Make sure that you set the image name to the name of the application container on Docker Hub (e.g., \u003ccode\u003edatadog-fargate-example\u003c/code\u003e) and, under “Port mappings,” add port 80 over TCP, which is the port we defined in the application’s Dockerfile. There are also a few environment variables that you will need to add to the “Advanced container configuration” section, as seen in the screenshot below.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Environment variables for the application container\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eThese variables configure the Agent to collect the following data from your application:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ccode\u003eDD_ENV\u003c/code\u003e, \u003ccode\u003eDD_VERSION\u003c/code\u003e, \u003ccode\u003eDD_SERVICE\u003c/code\u003e: sets the \u003ccode\u003eenv\u003c/code\u003e, \u003ccode\u003eversion\u003c/code\u003e, and \u003ccode\u003eservice\u003c/code\u003e tags on traces for \u003ca href=\"https://docs.datadoghq.com/getting_started/tagging/unified_service_tagging/?tab=kubernetes\"\u003eUnified Service Tagging\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ccode\u003eDD_TRACE_ROUTE_TEMPLATE_RESOURCE_NAMES_ENABLED\u003c/code\u003e: enables \u003ca href=\"https://docs.datadoghq.com/tracing/setup_overview/setup/dotnet-core/?tab=windows#experimental-features\"\u003eimproved resource names\u003c/a\u003e for ASP.NET Core endpoints\u003c/li\u003e\u003cli\u003e\u003ccode\u003eDD_RUNTIME_METRICS_ENABLED\u003c/code\u003e: enables \u003ca href=\"https://www.datadoghq.com/blog/monitor-dotnet-runtime-metrics/\"\u003eruntime metrics for the .NET runtime\u003c/a\u003e like thread counts and garbage collection (GC) pressure\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eFinally, in the “Startup Dependency Ordering” section, add the Agent container as a dependency by setting the “Container name” to \u003ccode\u003edatadog-agent\u003c/code\u003e and the “Condition” to “START”.\u003c/p\u003e\u003cp\u003eIn the next section, we will create an application load balancer (ALB) that can automatically route public network traffic to our Agent and application containers.\u003c/p\u003e\u003ch3 id=\"create-an-application-load-balancer\"\u003e\u003ca href=\"#create-an-application-load-balancer\"\u003eCreate an application load balancer\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eFargate supports \u003ca href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/load-balancer-types.html\"\u003eseveral different types\u003c/a\u003e of load balancers for ECS, but we’ll use \u003ca href=\"https://docs.amazonaws.cn/en_us/AmazonECS/latest/developerguide/create-load-balancer.html\"\u003ean ALB\u003c/a\u003e for this guide. Create a new load balancer by following steps in \u003ca href=\"https://docs.aws.amazon.com/AmazonECS/latest/userguide/create-application-load-balancer.html\"\u003ethe AWS documentation\u003c/a\u003e. You can use the default values for most of the available configuration options, but there are a few new security group rules that you will need to create.\u003c/p\u003e\u003cp\u003eLoad balancer security groups determine what traffic is allowed to access the load balancer. On the “Assign Security Groups” page, \u003ca href=\"https://docs.aws.amazon.com/AmazonECS/latest/userguide/create-application-load-balancer.html#alb-configure-security-groups\"\u003ecreate a new security group\u003c/a\u003e with a rule that uses the TCP protocol on port 80 and \u003ccode\u003e0.0.0.0/0, ::/0\u003c/code\u003e as a custom source. This ensures that the ALB is accessible from the public internet.\u003c/p\u003e\u003cp\u003eNext, on the “Configure Routing” page, \u003ca href=\"https://docs.aws.amazon.com/AmazonECS/latest/userguide/create-application-load-balancer.html#alb-configure-routing\"\u003ecreate a new target group\u003c/a\u003e that uses the “IP address” target type and the HTTP protocol on port 80. You can use \u003ccode\u003e/\u003c/code\u003e as the health check path. Complete the remaining steps to create your load balancer.\u003c/p\u003e\u003cp\u003eOnce the ALB is created, make note of its DNS name (found in the “Description” tab for the load balancer) as you will need it to access your application. Next, we will create a service to launch the application and all of its resources.\u003c/p\u003e\u003ch3 id=\"create-an-ecs-service\"\u003e\u003ca href=\"#create-an-ecs-service\"\u003eCreate an ECS service\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eThe final step for deploying the Agent and .NET application is to create a new \u003ca href=\"https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html\"\u003eECS service\u003c/a\u003e for the cluster. We can use this service to schedule and launch all of the necessary components to run the application, such as the load balancer we created previously and the containers defined in our task definition.\u003c/p\u003e\u003cp\u003eYou can \u003ca href=\"https://docs.aws.amazon.com/AmazonECS/latest/userguide/create-service-console-v2.html\"\u003ecreate a new service\u003c/a\u003e on the “Clusters” page of the Amazon ECS console. Select your ECS cluster and click the “Create” button in the “Services” tab. There are a few settings that you will need to configure for the service. First, make sure the service uses “Fargate” as the launch type and the task definition you created earlier. In the “VPC and security groups” section, use your application load balancer’s VPC, subnets, and security group. In the “Load balancing” section of the “Configure network” page, select the \u003ca href=\"#create-an-application-load-balancer\"\u003eload balancer you created earlier\u003c/a\u003e and add the application container in the “Container to load balance” section. Finally, the “Production listener port” needs to use the existing “80:HTTP” listener and the “Target group name” needs to use the name of your application container that you defined in your task definition.\u003c/p\u003e\u003cp\u003eOnce the service launches successfully, navigate to the service’s “Details” tab to view the security group and add a new inbound rule. The new rule should use “All TCP\u0026#39;\u0026#39; as the type and your ALB security group as the custom source. This setting allows the ALB to route traffic to your cluster; without it, your cluster may restart repeatedly due to “failed health checks”.\u003c/p\u003e\u003cp\u003eAfter finishing these steps, you can use the DNS name associated with the ALB you created earlier to navigate to your application and generate traffic. Since the application is instrumented with the .NET tracer and configured to submit traces via the Agent, you will start seeing real-time performance data for your ECS cluster and .NET application in Datadog.\u003c/p\u003e\u003ch2 id=\"monitor-application-performance-with-datadog\"\u003e\u003ca href=\"#monitor-application-performance-with-datadog\"\u003eMonitor application performance with Datadog\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog provides full visibility into the \u003ca href=\"https://www.datadoghq.com/blog/aws-fargate-monitoring-with-datadog/\"\u003ehealth and performance\u003c/a\u003e of your Fargate resources, such as the memory and CPU utilization of your ECS tasks. You can use the built-in integration dashboard to get a high-level overview of your Fargate environment and ensure that the underlying infrastructure supporting your .NET application is performing optimally.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog\u0026#39;s built-in AWS Fargate dashboard\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eThe dashboard can alert you to significant changes in container performance, such as a sudden increase in memory usage for your application’s container, which you can troubleshoot further using Datadog APM.\u003c/p\u003e\u003ch3 id=\"visualize-traces-with-datadog\"\u003e\u003ca href=\"#visualize-traces-with-datadog\"\u003eVisualize traces with Datadog\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eDatadog APM enables you to track distributed traces from your .NET application so you can get a better understanding of how application services process requests. To view your application’s traces, navigate to the \u003ca href=\"https://app.datadoghq.com/apm/services/\"\u003eservice page\u003c/a\u003e in your Datadog account and locate the \u003ccode\u003eDatadogFargateExample\u003c/code\u003e service under the \u003ccode\u003emy-container-test\u003c/code\u003e environment, which reflects the values you set for your \u003ca href=\"#create-the-application-container\"\u003eapplication container’s \u003ccode\u003eDD_SERVICE\u003c/code\u003e and \u003ccode\u003eDD_ENV\u003c/code\u003e environment variables\u003c/a\u003e. You can select that service to see a high-level overview of application performance and visualizations for key metrics, such as the total number of requests, errors, and request latency.\u003c/p\u003e\u003cp\u003eYou can also view your application’s runtime metrics alongside trace data in order to troubleshoot common performance issues, such as \u003ca href=\"https://www.datadoghq.com/blog/monitor-dotnet-runtime-metrics/#monitor-first-chance-exceptions\"\u003efirst-chance exceptions\u003c/a\u003e, so you have more context for resolving the problem before it becomes more serious.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Runtime metrics for a .NET Core application service\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eFor even greater visibility into your application, you can \u003ca href=\"https://docs.datadoghq.com/tracing/connect_logs_and_traces/dotnet/\"\u003econnect .NET logs to your traces\u003c/a\u003e by automatically injecting trace and span IDs into your logs. This enables you to quickly pivot between your traces and .NET logs to get a better picture of what is going on in your application. You can also add \u003ca href=\"https://docs.datadoghq.com/tracing/setup_overview/custom_instrumentation/dotnet/\"\u003ecustom instrumentation\u003c/a\u003e to your application’s business logic to monitor critical services, such as those that process payments, and ensure they are performing optimally.\u003c/p\u003e\u003ch2 id=\"net-core--aws-fargate\"\u003e\u003ca href=\"#net-core--aws-fargate\"\u003e.NET Core + AWS Fargate\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIn this post, we’ve shown how you can instrument a .NET Core application with Datadog’s .NET tracer and deploy it as a container via AWS Fargate. We also looked at how you can use Datadog to monitor application and infrastructure performance in one place. Check out our documentation for more information about \u003ca href=\"https://docs.datadoghq.com/tracing/setup_overview/\"\u003etracing your applications\u003c/a\u003e and getting visibility into application performance, regardless of the environment or platform. If you don’t already have a Datadog account, you can sign up for a \u003ca href=\"#\"\u003efree trial\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-hero.png\" width=\"100%\"/\u003eThe ASP.NET Core framework enables you to build and deploy .NET applications on a wide variety of platforms, each of which has different observability concerns. In a previous post, we looked at monitoring a containerized ASP.NET Core application. In this guide, we\u0026rsquo;ll show how Datadog provides visibility into ASP.NET Core applications running on AWS Fargate. We\u0026rsquo;ll walk through: instrumenting and packaging a sample .NET application publishing the application to Docker Hub deploying the instrumented .",
      "date_published": "2021-08-03T00:00:00Z",
      "author": {
        "name": "Andrew Lock"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/amazon-fsx-audit-logs-monitoring/",
      "title": "Monitor AWS FSx audit logs with Datadog",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003ca href=\"https://aws.amazon.com/fsx/windows/\"\u003eAmazon FSx for Windows File Server\u003c/a\u003e is a fully managed file storage service built on Windows Server. Migrating on-premise Windows file systems to a managed service like FSx enables organizations to reduce operational overhead and take advantage of the flexibility and scalability of the cloud. But having visibility into file access activity across their environment is key for security and compliance requirements, particularly in sectors such as financial services and healthcare. In order to provide this visibility, \u003ca href=\"https://aws.amazon.com/blogs/aws/file-access-auditing-is-now-available-for-amazon-fsx-for-windows-file-server/\"\u003eAWS recently added file access auditing to the Amazon FSx service\u003c/a\u003e. With this update, Amazon FSx now publishes and stores audit event logs that summarize file system access activity at user-level for all files, folders, and file shares.\u003c/p\u003e\u003cp\u003eAs an \u003ca href=\"https://partners.amazonaws.com/partners/001E000000Rp57sIAB/Datadog%20Inc\"\u003eAWS Partner solution\u003c/a\u003e, you can use Datadog as an endpoint to send Amazon FSx audit event logs for retention and real-time analysis. You can use Datadog’s \u003ca href=\"https://app.datadoghq.com/logs\"\u003eLog Explorer\u003c/a\u003e to easily search for file access events of interest or use \u003ca href=\"https://www.datadoghq.com/blog/announcing-security-monitoring/\"\u003eDatadog Security Monitoring\u003c/a\u003e to look for and alert you to any unusual activity. This way, in addition to monitoring FSx metrics via \u003ca href=\"https://docs.datadoghq.com/integrations/amazon_fsx/\"\u003eDatadog’s integration\u003c/a\u003e, your teams can audit any suspicious or unauthorized activity and take immediate steps to address any detected violations.\u003c/p\u003e\u003cp\u003eIn this post, we’ll look at what information these logs contain and how you can use Datadog to:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"#analyze-and-monitor-amazon-fsx-audit-event-logs-in-datadog\"\u003eMonitor access activity\u003c/a\u003e across your file systems\u003c/li\u003e\u003cli\u003e\u003ca href=\"#automatically-detect-security-threats-to-your-fsx-file-system\"\u003eCreate security rules\u003c/a\u003e to alert you to possible threats\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"analyze-and-monitor-amazon-fsx-audit-event-logs-in-datadog\"\u003e\u003ca href=\"#analyze-and-monitor-amazon-fsx-audit-event-logs-in-datadog\"\u003eAnalyze and monitor Amazon FSx audit event logs in Datadog\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAmazon FSx audit event logs record all user attempts to access, create, modify, or delete a \u003ca href=\"https://docs.aws.amazon.com/fsx/latest/WindowsGuide/using-file-shares.html\"\u003efile share\u003c/a\u003e or individual file or folder object. Each log follows the standard Windows event log format and contains important information regarding the access event, including:\u003c/p\u003e\u003cul\u003e\u003cli\u003ethe type of event (indicated by the \u003ccode\u003eEventID\u003c/code\u003e)\u003c/li\u003e\u003cli\u003ethe user who performed the action (\u003ccode\u003eSubjectUserName\u003c/code\u003e)\u003c/li\u003e\u003cli\u003ethe object being accessed (\u003ccode\u003eObjectName\u003c/code\u003e or \u003ccode\u003eShareName\u003c/code\u003e)\u003c/li\u003e\u003cli\u003ewhether it was successful (\u003ccode\u003eKeywords\u003c/code\u003e)\u003c/li\u003e\u003cli\u003ein the case of file shares, the access action performed (\u003ccode\u003eAccessMask\u003c/code\u003e).\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eDatadog’s built-in \u003ca href=\"https://docs.datadoghq.com/logs/processing/pipelines/\"\u003elog processing pipeline\u003c/a\u003e parses and extracts these key fields from your logs as \u003ca href=\"https://docs.datadoghq.com/logs/processing/attributes_naming_convention/\"\u003eattributes\u003c/a\u003e, which you can then use to query, sort, and filter your logs. This enables you to perform complex analysis of user and file activity across your logs. For example, you can easily search for activity related to particularly sensitive folders.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog parses AWS FSx logs\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eDatadog parses out key data from your Amazon FSx event audit logs.\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eIt’s also important to track overall trends in file system activity to surface any unusual behavior. For example, aggregating logs by file access event type, like create, modify, or delete, makes it easy to spot anomalous spikes in certain activity. You can then dive into the relevant logs to look at the users behind the spikes.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog AWS FSx audit log analytics\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eUsing the \u003ccode\u003eKeywords\u003c/code\u003e attribute, you can further break down events by whether they were successful or not. This can help you identify spikes in failed operations, which might indicate an unauthorized user trying to access files.\u003c/p\u003e\u003ch2 id=\"automatically-detect-security-threats-to-your-fsx-file-system\"\u003e\u003ca href=\"#automatically-detect-security-threats-to-your-fsx-file-system\"\u003eAutomatically detect security threats to your FSx file system\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eReal-time knowledge of potentially suspicious activity across your file system is key to ensuring the security of your sensitive data. Datadog Security Monitoring provides out-of-the-box Threat Detection Rules to notify you when Datadog identifies specific activity. For example, the rule below looks for more than 10 failed file access attempts from a single user, which might indicate someone attempting to access files they don’t have permissions for.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Datadog AWS FSx logs threat detection rule\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYou can easily create custom rules for your specific environment. For example, if you have particularly important file shares (\u003ccode\u003eShareName\u003c/code\u003e), or even entire file systems (\u003ccode\u003eComputer\u003c/code\u003e), you can create rules to monitor them for any delete or modify attempts. You might also want to be alerted to any file share event from an IP address outside your organization. You can create a \u003ca href=\"https://www.datadoghq.com/blog/new-term-detection-method-datadog/\"\u003enew term–based\u003c/a\u003e rule that notifies you of any activity from an address that Datadog hasn’t seen before, helping alert you to a possible threat.\u003c/p\u003e\u003cp\u003eWhenever a rule is triggered, Datadog generates a Security Signal that includes key metadata about the relevant event, so you can determine if you need to take further action, such as adjusting security policy settings to modify who can access certain files.\u003c/p\u003e\u003ch2 id=\"get-deeper-insight-into-your-amazon-fsx-file-systems\"\u003e\u003ca href=\"#get-deeper-insight-into-your-amazon-fsx-file-systems\"\u003eGet deeper insight into your Amazon FSx file systems\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAmazon FSx’s file access audit event logs give your teams immediate visibility into activity across your Windows Server file directory that, when paired with Datadog’s log management and security platforms, helps ensure that your files are secure. You can send your Amazon FSx logs to Datadog either with our \u003ca href=\"https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-lambda-function/\"\u003eForwarder Lambda function\u003c/a\u003e or by using a \u003ca href=\"https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination/\"\u003eKinesis Firehose data stream\u003c/a\u003e. See our \u003ca href=\"https://docs.datadoghq.com/integrations/amazon_fsx/#log-collection\"\u003edocumentation\u003c/a\u003e to get started. Or, if you’re not a Datadog customer, sign up today for a \u003ca href=\"#\"\u003efree 14-day trial\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/AWS-FSx_integration_FINAL.png\" width=\"100%\"/\u003eAmazon FSx for Windows File Server is a fully managed file storage service built on Windows Server. Migrating on-premise Windows file systems to a managed service like FSx enables organizations to reduce operational overhead and take advantage of the flexibility and scalability of the cloud. But having visibility into file access activity across their environment is key for security and compliance requirements, particularly in sectors such as financial services and healthcare.",
      "date_published": "2021-07-30T00:00:00Z",
      "author": {
        "name": "Jonathan Epstein"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/about/latest-news/press-releases/datadog-announces-availability-on-google-cloud-marketplace-to-support-customers-cloud-migrations/",
      "title": "Datadog Announces Availability on Google Cloud Marketplace to Support Customers’ Cloud Migrations",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003e\u003cstrong\u003eNEW YORK\u003c/strong\u003e – \u003ca href=\"https://www.datadoghq.com/\"\u003eDatadog\u003c/a\u003e, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced its availability on \u003ca href=\"https://console.cloud.google.com/marketplace/product/datadog-public/datadog\"\u003eGoogle Cloud Marketplace\u003c/a\u003e, deepening its partnership with Google Cloud. Google Cloud customers can now purchase Datadog with just a few clicks on the Google Cloud Marketplace, allowing them to quickly and easily monitor the health of their applications and infrastructure across their Google Cloud and hybrid cloud environments. \u003c/p\u003e\u003cp\u003eGoogle Cloud Marketplace offers integrated solutions vetted by Google Cloud, to support customers’ enterprise IT needs. Customers rely on Google Cloud Marketplace to identify and purchase the third-party tools that help them move to, build on and work in Google Cloud. In addition to easier access, customers who purchase Datadog through Google Cloud Marketplace will benefit from consolidated billing and streamlined procurement. Datadog usage will appear directly on customers’ Google Cloud invoices, and customers will be able to pay for a portion of this usage with their committed Google Cloud spend.\u003c/p\u003e\u003cp\u003e“By making Datadog available on Google Cloud via Marketplace, customers will have access to Datadog’s advanced monitoring and security capabilities,” said Amy Bray, Global Head, Google Cloud Marketplace, Google. “With Datadog on Google Cloud, customers can quickly begin leveraging its capabilities in application monitoring and security, ultimately helping them accelerate their cloud migrations and digital transformations.”\u003c/p\u003e\u003cp\u003e“We’re excited that Datadog is now available in the Google Cloud Marketplace,” said Marc Weisman, Vice President, Product Management, Datadog. “Monitoring and security are crucial for companies as they move their infrastructure and applications to the cloud, and we look forward to supporting Google Cloud customers as they undertake these initiatives.”\u003c/p\u003e\u003cp\u003eDatadog’s existing partnership and support for Google Cloud includes:\u003c/p\u003e\u003cul\u003e\u003cli\u003eAccess to Datadog’s 450+ integrations on Google Cloud’s scalable and secure infrastructure, including integrations with Google Cloud services such as Compute Engine, Cloud Storage, BigQuery and more.\u003c/li\u003e\u003cli\u003eThe ability to deploy the Datadog Agent directly on hosts and compute instances in Google Cloud, to collect metrics with greater granularity.\u003c/li\u003e\u003cli\u003eExtended go-to-market collaboration and deeper sales alignment with Google Cloud and Datadog sales teams.\u003c/li\u003e\u003cli\u003eContinued investment into product co-innovation with more native joint solutions around Anthos, Open Telemetry and the Google Cloud operations suite.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eFor more information and to get started with Datadog, visit \u003ca href=\"https://console.cloud.google.com/marketplace/product/datadog-public/datadog\"\u003eDatadog in Google Cloud Marketplace\u003c/a\u003e.\u003c/p\u003e\u003cdiv\u003e\u003cp\u003e\u003cstrong\u003eAbout Datadog\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eDatadog is the monitoring and security platform for cloud applications. Our SaaS platform integrates and automates infrastructure monitoring, application performance monitoring and log management to provide unified, real-time observability of our customers’ entire technology stack. Datadog is used by organizations of all sizes and across a wide range of industries to enable digital transformation and cloud migration, drive collaboration among development, operations, security and business teams, accelerate time to market for applications, reduce time to problem resolution, secure applications and infrastructure, understand user behavior and track key business metrics.\u003c/p\u003e\u003c/div\u003e\u003cp\u003e\u003cstrong\u003eForward-Looking Statements\u003c/strong\u003e\u003c/p\u003e\u003cp\u003eThis press release may include certain “forward-looking statements” within the meaning of Section 27A of the Securities Act of 1933, as amended, or the Securities Act, and Section 21E of the Securities Exchange Act of 1934, as amended. These forward-looking statements reflect our current views about our plans, intentions, expectations, strategies and prospects, which are based on the information currently available to us and on assumptions we have made. Actual results may differ materially from those described in the forward-looking statements and are subject to a variety of assumptions, uncertainties, risks and factors that are beyond our control, including those risks detailed under the caption “Risk Factors” and elsewhere in our Securities and Exchange Commission filings and reports, including the Quarterly Report on Form 10-Q filed with the Securities and Exchange Commission on May 7, 2021, as well as future filings and reports by us. Except as required by law, we undertake no duty or obligation to update any forward-looking statements contained in this release as a result of new information, future events, changes in expectations or otherwise.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "NEW YORK \u0026ndash; Datadog, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced its availability on Google Cloud Marketplace, deepening its partnership with Google Cloud. Google Cloud customers can now purchase Datadog with just a few clicks on the Google Cloud Marketplace, allowing them to quickly and easily monitor the health of their applications and infrastructure across their Google Cloud and hybrid cloud environments. Google Cloud Marketplace offers integrated solutions vetted by Google Cloud, to support customers’ enterprise IT needs.",
      "date_published": "2021-07-29T20:30:00Z",
      "author": {
        "name": "Datadog"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/session-replay-datadog/",
      "title": "Use Datadog Session Replay to view real-time user journeys",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eWhen developing large, customer-facing applications, it’s paramount to have visibility into real user behavior in order to optimize your UX. Without a direct view into what users are actually doing when navigating your app, it can be difficult to reproduce bugs and understand how aspects of your frontend design are causing user frustration and churn. With Datadog RUM’s Session Replay feature, currently available in beta, you can watch individual user sessions using a video-like interface. This allows you to view exactly how your users interact with your website, saving you time and guesswork recreating bugs and helping you understand patterns in your users’ behavior. In this post, we’ll discuss how Session Replay can help you \u003ca href=\"#reproduce-bugs-and-troubleshoot-faster\"\u003espeed up your debugging\u003c/a\u003e and \u003ca href=\"#understand-user-behavior\"\u003efind patterns in your users’ behavior\u003c/a\u003e.\u003c/p\u003e\u003ch2 id=\"reproduce-bugs-and-troubleshoot-faster\"\u003e\u003ca href=\"#reproduce-bugs-and-troubleshoot-faster\"\u003eReproduce bugs and troubleshoot faster\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAs a frontend or support engineer, an essential—and often time-consuming—part of the debugging process is reproducing bugs. But it can be difficult to do so without a clear understanding of the actions a user took before your application threw an error. By recording real user journeys, Session Replay effectively reproduces the bug for you, saving time and eliminating any guesswork.\u003c/p\u003e\u003cp\u003eFor example, let’s say you’re a frontend engineer monitoring a recent release and notice a new issue pop up in \u003ca href=\"https://www.datadoghq.com/blog/error-tracking/\"\u003eError Tracking\u003c/a\u003e. After viewing key information about the error, such as the error message, stacktrace, and browser info, you can immediately pivot directly from the issue summary to a live reproduction of the most recent session that experienced the error.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Pivot to a Session Replay from Error Tracking\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eWhen viewing a replay, you can see a video-like reproduction of the entire user journey. Datadog also displays an event timeline that breaks the session down into every page load and DOM change resulting from the user’s actions so you can jump to individual events. The timeline flags any user interaction that results in an error so you can pinpoint when and where issues occurred.\u003c/p\u003e\u003cp\u003eFor example, let’s say you notice a rise in timeout errors on a particular page load. With Session Replay, you can easily identify the exact user action that’s causing the timeout, without needing to guess about how users are triggering the error.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Session Replay\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eOnce you’ve found the user action or page load triggering the timeout error, you can see more details to start troubleshooting. For example, you can see a \u003ca href=\"https://docs.datadoghq.com/real_user_monitoring/browser/monitoring_page_performance\"\u003ewaterfall\u003c/a\u003e of the resources loaded—along with \u003ca href=\"https://www.datadoghq.com/blog/core-web-vitals-monitoring-datadog-rum-synthetics/\"\u003ekey performance metrics\u003c/a\u003e. This helps you determine, for example, if there is a particularly slow asset that is causing a bottleneck for users. For further context, you can pivot to relevant \u003ca href=\"https://www.datadoghq.com/blog/unify-apm-rum-datadog/\"\u003etraces, logs, and errors\u003c/a\u003e to continue investigating whether, for instance, the root cause of the timeouts is a backend problem like a hanging API call.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"RUM waterfall\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"understand-user-behavior\"\u003e\u003ca href=\"#understand-user-behavior\"\u003eUnderstand user behavior\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eIf you’re a UI or UX designer, real user data can be an important source of truth for understanding the efficacy of your designs. Using Session Replay, you can observe how users traverse your website to get insight into how long it takes them to make decisions, what they hover over before clicking on something else, how they respond to broken UI elements and other errors, and more.\u003c/p\u003e\u003cp\u003eLet’s say you’re a designer investigating a drop in click-through rate for a key part of your application, such as a checkout page. You might first want to check if something in a common user flow to this endpoint is causing a bottleneck. By filtering the RUM Sessions view to sessions that include common gateways to the checkout page, such as the shopping cart, and sorting the resulting list by duration, you can surface replays that represent cases where the user spent a particularly long time on the previous page.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Session Replays query\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eExamining Session Replays for these slow cases, you can directly observe users’ behavior to not only understand what is happening, but also form hypotheses about why. For example, you might watch the user unsuccessfully attempt to enter their password several times before churning away. Then, you can use the insight you’ve gathered to create design interventions to try and guide these situations. For example, you could build a new password recovery workflow, or add an option to check out as a guest so users can bypass the sign-in form that is causing them to churn. After deploying your change, you can monitor key RUM metrics like the pageview count for the checkout page to see if it rises, indicating more users are successfully getting through the sign-in page.\u003c/p\u003e\u003ch2 id=\"get-started-with-session-replay\"\u003e\u003ca href=\"#get-started-with-session-replay\"\u003eGet started with Session Replay\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eRUM’s Session Replay feature is a powerful tool for providing qualitative context around your frontend performance metrics, helping designers understand user behavior, and automatically reproducing bugs so your frontend developers can iterate fixes faster. Session Replay is currently available in beta—if you’re a Datadog customer, you can sign up for the beta \u003ca href=\"https://www.datadoghq.com/session-replay-beta-request-form/\"\u003ehere\u003c/a\u003e. Or, you can get started using Datadog with a \u003ca href=\"#\"\u003e14-day free trial\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-hero-1.png\" width=\"100%\"/\u003eWhen developing large, customer-facing applications, it’s paramount to have visibility into real user behavior in order to optimize your UX. Without a direct view into what users are actually doing when navigating your app, it can be difficult to reproduce bugs and understand how aspects of your frontend design are causing user frustration and churn. With Datadog RUM’s Session Replay feature, currently available in beta, you can watch individual user sessions using a video-like interface.",
      "date_published": "2021-07-28T00:00:00Z",
      "author": {
        "name": "Thomas Sobolik"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/datadog-ci-visibility/",
      "title": "Monitor your CI pipelines and tests with Datadog CI Visibility",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eDatadog CI Visibility, now available in beta, provides critical visibility into your organization’s CI/CD workflows. CI Visibility complements Datadog’s \u003ca href=\"https://www.datadoghq.com/blog/monitor-ci-pipelines/\"\u003eturn-key CI provider integrations\u003c/a\u003e and the integration of \u003ca href=\"https://www.datadoghq.com/blog/datadog-synthetic-ci-cd-testing/\"\u003esynthetic tests in CI pipelines\u003c/a\u003e to give you deep insight into key pipeline metrics and help you identify issues with your builds and testing.\u003c/p\u003e\u003cp\u003eWith modern agile development methods and advances in CI/CD automation, organizations are able to build and ship releases quickly and regularly to deliver new value to customers. But without granular visibility into the performance of their pre-production testing and deployment pipelines, organizations can experience development outages due to slow builds or increases in failing or flaky tests.\u003c/p\u003e\u003cp\u003eDatadog CI Visibility provides deep insight into the performance of your CI pipelines, making it easy to identify issues—like error-prone jobs or flaky tests that cause your builds to fail randomly—and enabling you to make your CI workflows faster and more reliable. In this post, we’ll discuss how you can use CI Visibility to:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"#monitor-your-CI-pipelines\"\u003eMonitor pipeline builds, stages, and jobs to locate problems\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"#monitor-test-trends-and-identify-problems\"\u003eTrack test performance and identify flaky tests\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"monitor-your-ci-pipelines\"\u003e\u003ca href=\"#monitor-your-ci-pipelines\"\u003eMonitor your CI pipelines\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog CI Pipeline Visibility provides comprehensive visibility into all your pipelines—across CI providers—by generating key performance metrics to help you understand, for example, which pipelines, build stages, or jobs are run the most, how often they fail, and how long they take to complete. Datadog visualizes this information in a customizable out-of-the-box Pipelines dashboard. This gives you a high-level overview of performance across all your pipelines, stages, and jobs so you can track trends at a glance and identify where to focus your troubleshooting efforts.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Pipelines dashboard\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eThe Pipelines Visibility page provides more granular insight into your CI workflows by breaking down health and performance metrics by pipeline. You can sort and filter the list to quickly surface which pipelines are the slowest or experience the most errors. In the example below, we have sorted pipelines by average build duration to show which ones are the slowest.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Pipeline Visibility overview page\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch3 id=\"drill-into-individual-pipelines\"\u003e\u003ca href=\"#drill-into-individual-pipelines\"\u003eDrill into individual pipelines\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eOnce you’ve identified a pipeline with a high error rate or long build duration, you can drill into it to get more detailed information about its performance over time. The pipeline summary shows a breakdown of duration and failure rates across the pipeline’s individual stages and jobs to spot where slowdowns or failures might be occurring.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Pipeline summary\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eA pipeline’s summary includes a table of all of that pipeline’s executions. You can easily filter your executions by key attributes like branch, status, and duration, or scope the table to a specific stage or job.\u003c/p\u003e\u003cp\u003eOnce you’ve integrated Datadog with your CI provider, Datadog automatically instruments your pipelines. This means that, if you spot a slow or failing build and need to understand what’s happening, you can drill into a flame graph visualization of the build to look for high duration or errorful jobs. Then, you can dive into the error details to understand the source of the error, or look in the tags for the job URL to find the context you need to identify and remediate the underlying issue.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Pipeline trace\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch2 id=\"monitor-test-trends-and-identify-problems\"\u003e\u003ca href=\"#monitor-test-trends-and-identify-problems\"\u003eMonitor test trends and identify problems\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eMonitoring your tests is key to identifying faulty tests and understanding overall test suite performance. With Datadog CI Testing Visibility, you can easily monitor your tests across all of your builds to surface common errors and visualize test performance over time to spot regressions. In the Testing Visibility page, you can see each of your services’ test suites along with the corresponding branch, duration, and number of fails, passes, and skips. Datadog also tracks the number of new flaky tests, or tests that variably pass and fail for the same commit, which were previously unseen in the default branch.\u003c/p\u003e\u003ch3 id=\"identify-and-troubleshoot-flaky-tests\"\u003e\u003ca href=\"#identify-and-troubleshoot-flaky-tests\"\u003eIdentify and troubleshoot flaky tests\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eFlaky tests can compromise the effectiveness of your testing and break builds seemingly at random. Locating and debugging flaky tests is important for ensuring the reliability of your test suites. Datadog automatically detects when commits introduce flaky tests and displays that data for the relevant branch.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Test Visibility overview page\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eOnce you’ve spotted a branch with new flaky tests to examine, you can dive into the commit overviews for that service. Looking at the Latest Commit Overview, you can see which tests failed and the most common errors between them.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Test summary\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eThe Flaky Tests summary surfaces all the tests in this service’s test suite that flaked. Selecting a test row, you can view runs of the test from the commit that first flaked, which is likely to contain the code change responsible for making the test flaky.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Flaky tests overview\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003ch3 id=\"analyze-test-performance\"\u003e\u003ca href=\"#analyze-test-performance\"\u003eAnalyze test performance\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eJust like with CI Pipeline Visibility, Datadog Testing Visibility automatically instruments each of your tests so you can trace them from end to end without spending time reproducing test failures. For example, once you’ve found a flaky test you want to debug, you can drill into the test trace for more information. Using the flame graph, you can, for example, easily find the point(s) of failure in a complex integration test. Clicking on an errorful span, you can examine the stacktrace along with related error messages to examine what caused the test to fail in that instance. For more context, Datadog links to the relevant pipeline so you can jump into your CI provider to examine the console output from the test run.\u003c/p\u003e\u003ch2 id=\"ensure-smooth-reliable-builds\"\u003e\u003ca href=\"#ensure-smooth-reliable-builds\"\u003eEnsure smooth, reliable builds\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eDatadog CI Visibility enables you to fill in the pre-production observability gap. It gives you deep visibility into your test performance, so you can ensure your tests will catch performance issues before they reach customers, while also empowering you to manage your pipelines—saving precious developer time and computing resources. Combined with Datadog’s extensive support for synthetic testing within your CI, you can use Datadog to shift full-stack observability to the left, nipping outages and regressions in the bud.\u003c/p\u003e\u003cp\u003eCI Visibility is currently in a public beta—see our \u003ca href=\"https://docs.datadoghq.com/continuous_integration/\"\u003edocumentation\u003c/a\u003e for detailed installation steps. Or, if you’re brand new to Datadog, sign up for a \u003ca href=\"#\"\u003e14-day free trial\u003c/a\u003e to get started.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/ci-visibility-hero.png\" width=\"100%\"/\u003eDatadog CI Visibility, now available in beta, provides critical visibility into your organization’s CI/CD workflows. CI Visibility complements Datadog’s turn-key CI provider integrations and the integration of synthetic tests in CI pipelines to give you deep insight into key pipeline metrics and help you identify issues with your builds and testing.With modern agile development methods and advances in CI/CD automation, organizations are able to build and ship releases quickly and regularly to deliver new value to customers.",
      "date_published": "2021-07-27T00:00:00Z",
      "author": {
        "name": "Thomas Sobolik"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/blog/internal-application-testing-with-datadog/",
      "title": "Test internal applications with Datadog's testing tunnel and private locations",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cp\u003eAs part of your monitoring and testing strategy, you may run tests on different types of applications that are not publicly available—from local versions of production-level websites to internal applications that directly support your employees. Testing each one requires leveraging tools that allow you to verify functionality across a wide range of devices, browsers, and workflows while maintaining a secure environment. \u003ca href=\"https://docs.datadoghq.com/synthetics/\"\u003eDatadog Synthetic Monitoring\u003c/a\u003e already lets you create your own custom probes (on-premise test runners) with \u003ca href=\"https://docs.datadoghq.com/synthetics/private_locations?tab=docker\"\u003eprivate locations\u003c/a\u003e to routinely test and monitor all of your internal-facing applications. Now, for on-demand testing, you can also use Datadog’s \u003ca href=\"https://docs.datadoghq.com/synthetics/testing_tunnel\"\u003etesting tunnel\u003c/a\u003e, a secure tunnel connection that requires little setup.\u003c/p\u003e\u003cp\u003ePrivate locations and the testing tunnel give you more flexibility over how you test applications in your internal environments, but each tool offers some unique benefits to support different testing goals.\u003c/p\u003e\u003cp\u003eIn this post, we’ll look at:\u003c/p\u003e\u003cul\u003e\u003cli\u003eusing the \u003ca href=\"#ci-and-local-testing-with-the-testing-tunnel\"\u003etesting tunnel\u003c/a\u003e for on-demand testing in local and continuous integration (CI) environments\u003c/li\u003e\u003cli\u003ecreating \u003ca href=\"#durable-testing-and-monitoring-using-private-locations\"\u003eprivate locations\u003c/a\u003e for durable testing and monitoring\u003c/li\u003e\u003c/ul\u003e\u003ch2 id=\"ci-and-local-testing-with-the-testing-tunnel\"\u003e\u003ca href=\"#ci-and-local-testing-with-the-testing-tunnel\"\u003eCI and local testing with the testing tunnel\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eThe testing tunnel leverages Datadog’s \u003ca href=\"https://docs.datadoghq.com/synthetics/ci/?tab=apitest\"\u003ecommand line interface (CLI)\u003c/a\u003e to create an end-to-end encrypted HTTP proxy between your infrastructure and Datadog. The CLI is an \u003ca href=\"https://www.npmjs.com/package/@datadog/datadog-ci\"\u003eNPM package\u003c/a\u003e that enables you to launch Datadog Synthetic tests \u003ca href=\"https://www.datadoghq.com/blog/datadog-synthetic-ci-cd-testing/\"\u003eas part of your CI/CD pipelines\u003c/a\u003e, so you can identify and fix regressions in your applications before they impact your users. When used in conjunction with the testing tunnel feature, any test requests you send using the CLI are automatically routed through the \u003ccode\u003edatadog-ci\u003c/code\u003e client, allowing Datadog to access and test your internal applications.\u003c/p\u003e\u003cp\u003eDatadog’s testing tunnel is designed to support CI pipelines and local development, so you can use it for:\u003c/p\u003e\u003cul\u003e\u003cli\u003everifying hotfixes or new features locally before committing code\u003c/li\u003e\u003cli\u003erunning tests in environments reserved for CI pipelines (e.g., staging, user acceptance testing, etc.) or in ephemeral cloud environments\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe’ll look at how the tunnel’s unique features and benefits can support these particular testing goals next.\u003c/p\u003e\u003ch3 id=\"an-easy-to-use-tool-for-testing-on-demand\"\u003e\u003ca href=\"#an-easy-to-use-tool-for-testing-on-demand\"\u003eAn easy-to-use tool for testing on demand\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eA key benefit of the testing tunnel is its ease of use within existing infrastructure; it enables you to incorporate API and end-to-end tests into all of your workflows. For example, your teams (e.g., developers, testers) can use this tool out of the box to quickly verify that a hotfix for a time-sensitive issue, such as a service outage, works as expected locally before deploying it to end users. You can also use the tunnel service to run test suites as part of your CI pipelines without launching multiple browsers directly on CI servers, where processing power may be limited.\u003c/p\u003e\u003cp\u003eYou can instantly create a tunnel connection to run tests using a simple command:\u003c/p\u003e\u003cdiv\u003e\u003cpre\u003e\u003ccode data-lang=\"text\"\u003e \ndatadog-ci synthetics run-tests --config synthetics.global.json --tunnel\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eThe example command above will open a WebSocket Secure \u003ca href=\"https://docs.datadoghq.com/synthetics/testing_tunnel/#what-is-the-testing-tunnel\"\u003etunnel connection\u003c/a\u003e and launch the suite of tests defined in your local machine’s or CI server’s \u003ca href=\"https://docs.datadoghq.com/synthetics/ci/?tab=apitest#configure-tests\"\u003etest configuration files\u003c/a\u003e. These files include the public IDs of the tests that you want to run, along with other configuration attributes, such as endpoint URLs, device IDs, and locations.\u003c/p\u003e\u003cp\u003eSince the tunnel is built into Datadog’s CLI, it enables you to quickly start testing your internal applications at any time.\u003c/p\u003e\u003ch3 id=\"launch-tests-with-minimal-overhead\"\u003e\u003ca href=\"#launch-tests-with-minimal-overhead\"\u003eLaunch tests with minimal overhead\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eThe tunnel is independent of existing infrastructure, so you can use it without deploying, maintaining, or monitoring additional services. Tests launched via the tunnel are executed from Datadog-managed locations. This means that as long as the host running Datadog’s CI client can create the connections needed to run multiple tests, Datadog will automatically scale to support the increased load as needed. Tunnel connections then end when the Datadog CI client receives all necessary results, so you do not need to track long-running connections to your network.\u003c/p\u003e\u003cp\u003eThe tunnel also makes it easy to dynamically override where your tests run with Datadog’s \u003ca href=\"https://docs.datadoghq.com/synthetics/ci/?tab=apitest#start-url\"\u003ebuilt-in environment variables\u003c/a\u003e, so you can continue testing your applications without interruption, even as the environment you are testing changes. This includes environments that rely on ephemeral cloud instances and containers. For example, you can automatically pass the URL of a newly deployed application instance as the starting URL for any tests launched with the tunnel, instead of hard coding that data into your tests.\u003c/p\u003e\u003cp\u003eDatadog shows which tests were launched through the tunnel service so you can monitor them alongside the rest of your synthetic tests. For any test failures, Datadog provides \u003ca href=\"https://www.datadoghq.com/blog/introducing-synthetic-monitoring/#end-to-end-visibility\"\u003eend-to-end visibility\u003c/a\u003e for troubleshooting and resolving issues, including details such as screenshots of the UI, JavaScript and network errors, load times for page resources, and APM traces if your test is hitting an instrumented service endpoint.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"View test results after using the testing tunnel for local testing\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eNow that we’ve covered the benefits of using the testing tunnel for straightforward, on-demand testing, we’ll look at how Datadog’s private locations support your long-term testing and monitoring goals.\u003c/p\u003e\u003ch2 id=\"durable-testing-and-monitoring-using-private-locations\"\u003e\u003ca href=\"#durable-testing-and-monitoring-using-private-locations\"\u003eDurable testing and monitoring using private locations\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eAs we’ve seen, the testing tunnel offers a turn-key solution for secure, rapid testing in short-lived environments. For organizations who need to regularly test and monitor applications hosted on permanent environments, Datadog provides \u003ca href=\"https://www.datadoghq.com/blog/private-synthetic-monitoring/\"\u003eprivate locations\u003c/a\u003e: Docker containers that you can deploy as custom \u003ca href=\"https://en.wikipedia.org/wiki/Point_of_presence\"\u003epoints of presence\u003c/a\u003e (e.g., data centers, geographic locations) inside of your infrastructure \u003ca href=\"https://docs.datadoghq.com/synthetics/private_locations/?tab=docker#install-your-private-location\"\u003eusing orchestration tools\u003c/a\u003e like Docker Compose, Kubernetes, AWS Fargate, and Amazon ECS.\u003c/p\u003e\u003cp\u003eBecause private locations are deployed as a durable probing service for launching your tests, they can be useful for:\u003c/p\u003e\u003cul\u003e\u003cli\u003ecustomizing and managing a centralized testing tool that is readily available for teams across your organization\u003c/li\u003e\u003cli\u003etriggering tests on long-running environments (e.g., staging, pre-production) as part of your CI/CD pipelines\u003c/li\u003e\u003cli\u003eregularly running tests on internal applications that are hosted on private networks to ensure you can maintain your availability SLOs\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe’ll look at how you can use private locations to create a customizable, scalable, and easily accessible service in more detail next.\u003c/p\u003e\u003ch3 id=\"a-fully-fledged-and-customizable-testing-service-for-internal-applications\"\u003e\u003ca href=\"#a-fully-fledged-and-customizable-testing-service-for-internal-applications\"\u003eA fully-fledged and customizable testing service for internal applications\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eSince testing is a crucial part of building resilient applications, you need a system that can support testing a growing network of services as your organization scales. Using private locations, your SRE teams have greater flexibility in not only customizing a probing service for every use case—via their \u003ca href=\"https://docs.datadoghq.com/synthetics/private_locations/?tab=docker#install-your-private-location\"\u003epreferred orchestration tool\u003c/a\u003e—but also ensuring it can scale to continually verify functionality and monitor application performance.\u003c/p\u003e\u003cp\u003ePrivate locations come with a number of parameters you can use to match your infrastructure and private network configurations, such as built-in controls to \u003ca href=\"https://docs.datadoghq.com/synthetics/private_locations/?tab=docker#blocking-reserved-ips\"\u003eblock IPs\u003c/a\u003e in order to prevent users from creating synthetic tests on potentially sensitive endpoints in reserved IP ranges. And, as your applications grow, you can horizontally or vertically \u003ca href=\"https://docs.datadoghq.com/synthetics/private_locations?tab=docker#scale-your-private-locations\"\u003escale your locations\u003c/a\u003e in order to run more synthetic tests concurrently, enabling you to seamlessly test newly added features alongside existing functionality. Leveraging these measures ensure your applications—and your test infrastructure—remain secure and continue supporting your users.\u003c/p\u003e\u003ch4 id=\"monitoring-private-locations\"\u003e\u003ca href=\"#monitoring-private-locations\"\u003eMonitoring private locations\u003c/a\u003e\u003c/h4\u003e\u003cp\u003ePrivate locations are designed to regularly test and monitor your applications long term. Because of their longevity—and since tests run on the servers where you’ve deployed private locations—you need to ensure that every location is working as expected. Datadog provides visibility into your entire infrastructure, so you can monitor the performance of your custom locations in one place. For example, you can create custom dashboards to get a high-level overview of all of your private locations and easily monitor usage, as seen below.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Create custom dashboards to monitor private locations\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eYou can also use the Datadog Agent to \u003ca href=\"https://docs.datadoghq.com/infrastructure/livecontainers/?tab=helm\"\u003eget deeper visibility\u003c/a\u003e into the state of your private locations\u0026#39; underlying containers and confirm that they are performing optimally. If you notice unusual changes in the tests executed by your private location, such as a significant increase in response time, you can then drill down to the affected container in order to troubleshoot further.\u003c/p\u003e\u003ch3 id=\"self-service-testing-for-every-team\"\u003e\u003ca href=\"#self-service-testing-for-every-team\"\u003eSelf-service testing for every team\u003c/a\u003e\u003c/h3\u003e\u003cp\u003eOnce deployed, private locations provide a centralized and readily available service for testing, so your teams can create their own tests and assign them to specific locations in one click.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"Teams can easily set up tests using any deployed private location for internal application monitoring.\"/\u003e\u003c/picture\u003e\u003cfigcaption\u003eAll of your teams can easily add available private locations when creating new tests\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eThis enables your teams to routinely test applications under a wide variety of conditions. For example, your corporate IT team can launch tests on private locations deployed to multiple data centers to ensure that your company intranet or a key SaaS provider is performing optimally for a growing team of distributed employees, regardless of their location.\u003c/p\u003e\u003cdiv\u003e\u003cfigure\u003e\u003cpicture\u003e\n\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format\u0026amp;fit=max\u0026amp;w=847 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format\u0026amp;fit=max\u0026amp;w=847\u0026amp;dpr=2 2x\" media=\"(min-width: 1200px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format\u0026amp;fit=max\u0026amp;w=698 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format\u0026amp;fit=max\u0026amp;w=698\u0026amp;dpr=2 2x\" media=\"(min-width: 992px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format\u0026amp;fit=max\u0026amp;w=720 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format\u0026amp;fit=max\u0026amp;w=720\u0026amp;dpr=2 2x\" media=\"(min-width: 759px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format\u0026amp;fit=max\u0026amp;w=600 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format\u0026amp;fit=max\u0026amp;w=600\u0026amp;dpr=2 2x\" media=\"(min-width: 630px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format\u0026amp;fit=max\u0026amp;w=500 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format\u0026amp;fit=max\u0026amp;w=500\u0026amp;dpr=2 2x\" media=\"(min-width: 530px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format\u0026amp;fit=max\u0026amp;w=420px 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format\u0026amp;fit=max\u0026amp;w=420\u0026amp;dpr=2 2x\" media=\"(min-width: 361px)\"/\u003e\u003csource srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format\u0026amp;fit=max\u0026amp;w=360px 1x,\n                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format\u0026amp;fit=max\u0026amp;w=360\u0026amp;dpr=2 2x\" media=\"(min-width: 0px)\"/\u003e\u003cimg loading=\"lazy\" srcset=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format\u0026amp;fit=max\u0026amp;w=847\" alt=\"View test results for monitoring behind the firewall using private locations\"/\u003e\u003c/picture\u003e\u003c/figure\u003e\u003c/div\u003e\u003cp\u003eOr, your QA team can leverage the same tests and private locations as part of their CI/CD pipelines to verify that key workflows are still accessible to users after a canary deployment of new intranet features.\u003c/p\u003e\u003ch2 id=\"your-map-for-comprehensive-internal-application-testing\"\u003e\u003ca href=\"#your-map-for-comprehensive-internal-application-testing\"\u003eYour map for comprehensive internal application testing\u003c/a\u003e\u003c/h2\u003e\u003cp\u003eWith private locations and the testing tunnel, you have more options for testing and monitoring your internal-facing applications. Each service offers unique features to help you accomplish your testing goals, whether they require long-running probing services or the ability to quickly launch tests on demand and with little setup. Check out the documentation for \u003ca href=\"https://docs.datadoghq.com/synthetics/private_locations?tab=docker\"\u003eprivate locations\u003c/a\u003e and the \u003ca href=\"https://docs.datadoghq.com/synthetics/testing_tunnel\"\u003etunnel service\u003c/a\u003e (currently in public beta) to learn how to get started with both. If you don’t already have a Datadog account, you can sign up for a \u003ca href=\"#\"\u003efree 14-day trial\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003cimg class=\"webfeedsFeaturedVisual rss\" src=\"https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-hero.png\" width=\"100%\"/\u003eAs part of your monitoring and testing strategy, you may run tests on different types of applications that are not publicly available—from local versions of production-level websites to internal applications that directly support your employees. Testing each one requires leveraging tools that allow you to verify functionality across a wide range of devices, browsers, and workflows while maintaining a secure environment. Datadog Synthetic Monitoring already lets you create your own custom probes (on-premise test runners) with private locations to routinely test and monitor all of your internal-facing applications.",
      "date_published": "2021-07-27T00:00:00Z",
      "author": {
        "name": "Mallory Mooney"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/event/micro-gitlabcommit-2021/",
      "title": "Datadog at GitLab Commit 2021",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003csection\u003e\u003ca name=\"main\"\u003e\u003c/a\u003e\u003c/section\u003e\u003csection\u003e\u003ca name=\"raffle\"\u003e\u003c/a\u003e\u003cdiv\u003e\u003cp\u003eNo purchase necessary to enter or win. Limit 1 entry per person. Void where prohibited. The contest ends August 4, 2021, at 5:00pm EDT. Open to legal residents of Australia, Austria, Belgium, Brazil, Canada, Denmark, France, Germany, Ireland, Japan, Norway, Poland, Singapore, Spain, Sweden, Switzerland, The Netherlands, UK, and USA (excluding Puerto Rico) who are 18 years of age or older (or the age of majority in their state or country of residence, whichever is older) as of the date of entry who attended the event. The Sweepstakes is not open to any employee of a current Datadog customer, any current students or any employee of a competitor of Datadog. In addition, the Sweepstakes is not open to any agent or employee of Datadog or its affiliates or marketing firms, or to any immediate family or household member of those individuals. The winner will be notified via email. By submitting an entry to the contest, the entrant agrees to be bound by the Official Rules. See \u003ca href=\"http://dtdg.co/gitlabrafflelegal\" target=\"_blank\"\u003ehere\u003c/a\u003e for Official Rules. Sponsor: Datadog, Inc., 620 8th Avenue, 45th Floor, New York, NY 10018.\u003c/p\u003e\u003c/div\u003e\u003c/section\u003e\u003csection\u003e\u003ca name=\"trial\"\u003e\u003c/a\u003e\u003cdiv\u003e\u003cp\u003eNo purchase necessary to enter or win. Limit 1 entry per person. Void where prohibited. The contest ends August 24, 2021, at 11:59pm EDT. Open to legal residents of Australia, Austria, Belgium, Brazil, Canada, Denmark, France, Germany, Ireland, Japan, Norway, Poland, Singapore, Spain, Sweden, Switzerland, The Netherlands, UK, and USA (excluding Puerto Rico) who are 18 years of age or older (or the age of majority in their state or country of residence, whichever is older) as of the date of entry who attended the event. The Sweepstakes is not open to any employee of a current Datadog customer, any current students or any employee of a competitor of Datadog. In addition, the Sweepstakes is not open to any agent or employee of Datadog or its affiliates or marketing firms, or to any immediate family or household member of those individuals. The winner will be notified via email. By submitting an entry to the contest, the entrant agrees to be bound by the Official Rules. See \u003ca href=\"http://dtdg.co/gitlabcommitlegal\" target=\"_blank\"\u003ehere\u003c/a\u003e for Official Rules. Sponsor: Datadog, Inc., 620 8th Avenue, 45th Floor, New York, NY 10018.\u003c/p\u003e\u003c/div\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "Datadog at GitLab Commit 2021",
      "date_published": "2021-07-27T00:00:00Z",
      "author": {
        "name": "Datadog"
      }
    },
    {
      "id": "",
      "url": "https://www.datadoghq.com/case-studies/econocom/",
      "title": "Partnership Brings Joint Success in LATAM",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cspan\u003e\u003ch2 id=\"span-classheader-purplegrowing-demand-for-consulting-servicesspan\"\u003e\u003c/h2\u003e\u003cp\u003eEconocom Brazil offers a suite of services, including technology resale and consultation work, to help their customers modernize their IT infrastructure, development and operation practices. As their customer base has grown, Econocom has seen an increase in demand not only for implementation of new technologies, but for consultation on cultural changes like shifting to DevOps, as well. “About one-third of our revenue comes from project and consultation activities, and two-thirds are related to other services. We’re really interested in increasing the volume of projects and consulting work that we offer, because it’s such a big value-add for our customers,” said Rodrigo Bocchi, the CEO of Econocom Brazil. “We expect this will be the main portion of the company’s revenue in the near future.”\u003c/p\u003e\u003cp\u003eTo ensure their readiness to help their clients adopt modern technology and practices successfully, Econocom needed to offer a modern monitoring platform designed to facilitate DevOps-style communication within ephemeral, cloud-based and Kubernetes-based systems. Additionally, Econocom was looking for a product that could cover any customer’s stack—and that could be implemented quickly to accelerate their deal cycles. In the end, Econocom Brazil chose to partner with Datadog to provide these services for their customers because of Datadog’s expansive coverage, ease of use, and rapid implementation speed.\u003c/p\u003e\u003cp\u003eWith Datadog, users have access to a unified platform encompassing infrastructure metrics, application management, logs, security, monitoring, and more. Bringing these capabilities together into one platform allows end users to quickly find a reported issue and the root cause in just a few clicks, with all the context they need at hand. This accelerates resolution time, which leads to more productive engineering teams, reduces risk during migrations and transitions, and improves end-user experiences.\u003c/p\u003e\u003cp\u003eDatadog also provides coverage across modern environments as well as legacy or on-premise installations. With extensive support for containers, including container Autodiscovery, a dedicated Kubernetes Cluster Agent, and out-of-the-box dashboards, Datadog makes it easier for Econocom’s customers to enact digital transformations. “In some cases, we are replacing old technologies (which support systems, applications and logs separately and are from different vendors) inside our client. We are helping them to transform their monitoring and adapt to cloud environments and Kubernetes environments with a unified and fully correlated view, quickly identifying the root cause,” said Rosano Moraes, Head of Sales, Brazil.\u003c/p\u003e\u003cblockquote\u003e\u003cp\u003e\u003cem\u003e\u0026#34; We’re replacing old technologies […] and helping them transform their monitoring and adapt to cloud environments and Kubernetes environments.\u0026#34;\u003c/em\u003e\u003c/p\u003e\u003cp\u003eRosano Moraes\nHead of Sales, Econocom Brazil\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003eAnother big appeal for Econocom is Datadog’s ease of use. The Datadog platform itself can be used by both Dev and Ops teams with minimal training, and it doesn’t require certification or knowledge of a query language. All dashboards can be created using a point-and-click interface, which allows companies to democratize their data so that centralized monitoring teams aren’t backlogged with routine work. Ease of use also reduces troubleshooting time when problems do arise, because the teams that are closest to the problem feel empowered to use Datadog to understand and address the root cause.\u003c/p\u003e\u003cp\u003eThe simplicity of a unified platform is core to Econocom’s DevOps consulting practices. Using Datadog as the single source of truth eliminates the messy communication silos that come from having tooling divisions across teams. “The Datadog platform was attractive because it unifies so many other products. It all drives towards simplicity—so it’s easier to solve problems. That’s something our customers really respond to,” said Moraes. “We use Datadog with our DevOps Excellence consulting program, and it helps our customers adopt DevOps culture more easily,” he added.\u003c/p\u003e\u003cblockquote\u003e\u003cp\u003e\u003cem\u003e\u0026#34; It all drives towards simplicity—so it’s easier to solve problems. That’s something our customers really respond to.\u0026#34;\u003c/em\u003e\u003c/p\u003e\u003cp\u003eRosano Moraes\nHead of Sales, Econocom Brazil\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003eDatadog also helps Econocom deploy quickly and consistently in every customer’s environment. “Implementation is so simple and fast with Datadog,” said Moraes. Implementation speed is driven by Datadog’s 450+ integrations, which provide key metrics, out-of-the-box dashboards, and recommended monitors for popular technologies. And because Datadog is a SaaS product, it can be deployed as a single agent for all data collection, doesn’t require the setup of any dedicated hosts or collectors, and can be rolled out automatically with a variety of tools like Chef, Puppet, or Helm. This not only saves the customer time, but also gives Econocom more opportunity to focus on the unique needs of each customer while providing higher value-add services like consulting. It also accelerates overall deal cycles, which improves Econocom’s operational efficiency.\u003c/p\u003e\u003cblockquote\u003e\u003cp\u003e\u003cem\u003e\u0026#34; Implementation is so simple and fast with Datadog\u0026#34;\u003c/em\u003e\u003c/p\u003e\u003cp\u003eRosano Moraes\nHead of Sales, Econocom Brazil\u003c/p\u003e\u003c/blockquote\u003e\u003cp\u003eEconocom took advantage of training courses provided by the Datadog Partner Network to enable their staff to understand and position Datadog effectively. Econocom Brazil was one of the first Gold-tier Datadog Partner Network members in Latin America, due to their technical qualifications and certifications, which led to a close relationship with Datadog’s sales team and unlocked better prices for their customers. Within the first year, Datadog and Econocom worked together to land over 15 major new logos, spanning industries like financial services, cloud technology, hospitality, and marketing.\u003c/p\u003e\u003cp\u003e“Our first year with Datadog has been very successful. The solution is strong, which makes it easy to position, and easy to prove the value. On top of that, Datadog’s commercial and enterprise teams in Brazil have worked really closely with us-” said Bocchi. “It feels like we’re an extension of the Datadog sales team,” added Moraes.\u003c/p\u003e\u003cp\u003eBocchi also praised the high demand he’s seen for Datadog, as well as the flexibility it gives Econocom. “With one of our major customers, it took us about nine months to close the deal initially. But in the three months after deploying Datadog, they loved it so much they came back to us twice looking to expand,” said Bocchi, adding: “Datadog’s fresh, it’s easier, it’s more flexible in terms of sizing. There’s no delay in implementation. Our customers are more confident in what they’re getting from us.”\u003c/p\u003e\u003cblockquote\u003e\u003cp\u003e\u003cem\u003e\u0026#34; Datadog’s fresh, it’s easier, it’s more flexible in terms of sizing. There’s no delay in implementation. Our customers are more confident in what they’re getting from us.\u0026#34;\u003c/em\u003e\u003c/p\u003e\u003cp\u003eRodrigo Bocchi\nCEO, Econocom Brazil\u003c/p\u003e\u003c/blockquote\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "About Econocom Econocom is a B2B reseller and technology consulting company with an annual revenue of more than $3 billion. As part of their global operations, Econocom Brazil has joined the Datadog Partner Network to better equip their customers with cloud-native monitoring. Key Results 15+ logos New major logos closed via the Datadog + Econocom partnership in the first year3 expansions The number of times Econocom landed and expanded in a single account in 3 months with Datadog",
      "date_published": "2021-07-26T00:00:00Z",
      "author": {
        "name": "Datadog"
      }
    }
  ]
}
