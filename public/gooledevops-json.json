{
  "version": "https://jsonfeed.org/version/1",
  "title": "GooleDevops",
  "home_page_url": "https://cloudblog.withgoogle.com/products/devops-sre/rss/",
  "items": [
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/use-slack-and-webhooks-for-notifications/",
      "title": "Deliver exception messages through Slack and Webhooks for fast resolution",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle-page\u003e\u003cmain id=\"jump-content\"\u003e\u003cpromo-banner-block _nghost-c56=\"\"\u003e\u003c/promo-banner-block\u003e\u003carticle\u003e\u003carticle-header-block\u003e\u003c/article-header-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-author-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003e Alek Szilagyi \u003c/p\u003e\u003cp\u003e Software Engineer, Google Cloud \u003c/p\u003e\u003c/div\u003e\u003cp\u003e\u003cspan\u003e April 5, 2022 \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-author-block\u003e\u003c/div\u003e\u003carticle-cta _nghost-c58=\"\"\u003e\u003c/article-cta\u003e\u003c/div\u003e\u003carticle-share-block\u003e\u003c/article-share-block\u003e\u003carticle-sticky-share-block\u003e\u003c/article-sticky-share-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-content-stream-block\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c60=\"\"\u003e\u003cdiv _ngcontent-c60=\"\" innerhtml=\"\u0026lt;p\u0026gt;Building new applications is a lot of fun, but troubleshooting and fixing the crashes that can come with app development is not. While many organizations are fast adopting the DevOps model, there are still some legacy frameworks where developers and operations teams are separate. Developers build and submit apps to their ops team, who in turn deploy and maintain the production stack.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;A common issue that arises due to this workflow is the time it takes to find and resolve crashes. To help reduce the time it takes to find crashes, we recently introduced new \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/operations/pub-sub-webook-and-slack-notifications-are-now-available\u0026#34;\u0026gt;notification\u0026lt;/a\u0026gt; channels for our Alerting product. Building on that release, we\u0026amp;#8217;re happy to announce today that you can send Error Reporting notifications through both \u0026lt;a href=\u0026#34;https://cloud.google.com/error-reporting/docs/notifications#slack\u0026#34;\u0026gt;Slack\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/error-reporting/docs/notifications#webhooks\u0026#34;\u0026gt;Webhooks\u0026lt;/a\u0026gt;.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;What is Error Reporting?\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Error Reporting can analyze, aggregate, and notify you about crashes in your running cloud services. It can synthesize this information from ingested logs in \u0026lt;a href=\u0026#34;https://cloud.google.com/logging\u0026#34;\u0026gt;Cloud Logging\u0026lt;/a\u0026gt; and has a \u0026lt;a href=\u0026#34;http://console.cloud.google.com/errors\u0026#34;\u0026gt;\u0026lt;i\u0026gt;\u0026lt;b\u0026gt;dedicated page\u0026lt;/b\u0026gt;\u0026lt;/i\u0026gt;\u0026lt;/a\u0026gt; that displays the details of the errors, including a histogram of occurrences, list of affected versions, request URL, and links to the request log.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eBuilding new applications is a lot of fun, but troubleshooting and fixing the crashes that can come with app development is not. While many organizations are fast adopting the DevOps model, there are still some legacy frameworks where developers and operations teams are separate. Developers build and submit apps to their ops team, who in turn deploy and maintain the production stack. \u003c/p\u003e\u003cp\u003eA common issue that arises due to this workflow is the time it takes to find and resolve crashes. To help reduce the time it takes to find crashes, we recently introduced new \u003ca href=\"https://cloud.google.com/blog/products/operations/pub-sub-webook-and-slack-notifications-are-now-available\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/operations/pub-sub-webook-and-slack-notifications-are-now-available\" track-metadata-module=\"post\"\u003enotification\u003c/a\u003e channels for our Alerting product. Building on that release, we’re happy to announce today that you can send Error Reporting notifications through both \u003ca href=\"https://cloud.google.com/error-reporting/docs/notifications#slack\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/error-reporting/docs/notifications#slack\" track-metadata-module=\"post\"\u003eSlack\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/error-reporting/docs/notifications#webhooks\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/error-reporting/docs/notifications#webhooks\" track-metadata-module=\"post\"\u003eWebhooks\u003c/a\u003e. \u003c/p\u003e\u003ch3\u003eWhat is Error Reporting?\u003c/h3\u003e\u003cp\u003eError Reporting can analyze, aggregate, and notify you about crashes in your running cloud services. It can synthesize this information from ingested logs in \u003ca href=\"https://cloud.google.com/logging\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/logging\" track-metadata-module=\"post\"\u003eCloud Logging\u003c/a\u003e and has a \u003ca href=\"http://console.cloud.google.com/errors\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"http://console.cloud.google.com/errors\" track-metadata-module=\"post\"\u003e\u003ci\u003e\u003cb\u003ededicated page\u003c/b\u003e\u003c/i\u003e\u003c/a\u003e that displays the details of the errors, including a histogram of occurrences, list of affected versions, request URL, and links to the request log.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c60=\"\"\u003e\u003cdiv _ngcontent-c60=\"\" innerhtml=\"\u0026lt;h3\u0026gt;What are we launching?\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Building on our recent launch of \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/operations/pub-sub-webook-and-slack-notifications-are-now-available\u0026#34;\u0026gt;alerting notification\u0026lt;/a\u0026gt; channels, today we are announcing an extension of \u0026lt;b\u0026gt;Error Reporting\u0026amp;#8217;s notification capabilities to include Slack and Webhooks\u0026lt;/b\u0026gt;.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;With this launch, your teams can receive notifications about crashes directly into their configured Slack channel or preferred collaboration platform using webhooks.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Crash information can then be quickly swarmed, discussed, and resolved.\u0026lt;/p\u0026gt;\"\u003e\u003ch3\u003eWhat are we launching?\u003c/h3\u003e\u003cp\u003eBuilding on our recent launch of \u003ca href=\"https://cloud.google.com/blog/products/operations/pub-sub-webook-and-slack-notifications-are-now-available\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/operations/pub-sub-webook-and-slack-notifications-are-now-available\" track-metadata-module=\"post\"\u003ealerting notification\u003c/a\u003e channels, today we are announcing an extension of \u003cb\u003eError Reporting’s notification capabilities to include Slack and Webhooks\u003c/b\u003e. \u003c/p\u003e\u003cp\u003eWith this launch, your teams can receive notifications about crashes directly into their configured Slack channel or preferred collaboration platform using webhooks. \u003c/p\u003e\u003cp\u003eCrash information can then be quickly swarmed, discussed, and resolved.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c60=\"\"\u003e\u003cdiv _ngcontent-c60=\"\" innerhtml=\"\u0026lt;p\u0026gt;These new channels\u0026amp;#160; join our existing Error Reporting notification capabilities of email and the Google Cloud Console mobile app.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;What do I have to do to enable Error Reporting and these notifications?\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Error Reporting is automatically enabled as soon as logs that contain error events like stack traces are ingested into Cloud Logging. Alternatively,\u0026amp;#160; you can \u0026lt;a href=\u0026#34;https://cloud.google.com/error-reporting/docs/how-to\u0026#34;\u0026gt;self configure\u0026lt;/a\u0026gt; Error Reporting for a new project if you won\u0026amp;#8217;t be using Cloud Logging.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;To configure the new notification channels, see documentation \u0026lt;a href=\u0026#34;https://cloud.google.com/error-reporting/docs/notifications#create-channel\u0026#34;\u0026gt;here\u0026lt;/a\u0026gt; for \u0026lt;b\u0026gt;\u0026lt;i\u0026gt;Slack\u0026lt;/i\u0026gt;\u0026lt;/b\u0026gt; and \u0026lt;b\u0026gt;\u0026lt;i\u0026gt;Webhooks\u0026lt;/i\u0026gt;\u0026lt;/b\u0026gt;, or keep reading below:\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Enabling Slack\u0026lt;/h3\u0026gt;\u0026lt;ol\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;In Slack\u0026lt;/b\u0026gt;: Create a Slack workspace and channel at the \u0026lt;a href=\u0026#34;https://www.slack.com/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Slack site\u0026lt;/a\u0026gt;. Record the channel URL.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;In the Cloud Console, select \u0026lt;a href=\u0026#34;https://console.cloud.google.com/monitoring\u0026#34;\u0026gt;\u0026lt;b\u0026gt;Monitoring\u0026lt;/b\u0026gt;\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Click \u0026lt;b\u0026gt;Alerting\u0026lt;/b\u0026gt; and then click \u0026lt;b\u0026gt;Edit notification channels\u0026lt;/b\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;In the \u0026lt;b\u0026gt;Slack\u0026lt;/b\u0026gt; section, click \u0026lt;b\u0026gt;Add new\u0026lt;/b\u0026gt; to open the Slack sign-in page:\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;ol\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Select your Slack workspace.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Click \u0026lt;b\u0026gt;Allow\u0026lt;/b\u0026gt; to enable Cloud Monitoring access to your Slack workspace. This action takes you back to the Monitoring configuration page for your notification channel.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Enter the name of the Slack channel you want to use for notifications.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Enter a display name for the Slack notification channel.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;(Optional) To test the connection between Cloud Monitoring and your Slack workspace, click \u0026lt;b\u0026gt;Send test notification\u0026lt;/b\u0026gt;. If the connection is successful, then you see a message This is a test alert notification... in the Slack notification channel that you specified. Check the notification channel to confirm receipt.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ol\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;If the Slack channel you want to use for notifications is a private channel, then you must manually invite the Monitoring app to the channel:\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;ol\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Open Slack.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Go to the channel you specified as your Monitoring notification channel.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Invite the Monitoring app to the channel by entering and sending the following message in the channel:\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;/invite @Google Cloud Monitoring\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Be sure you invite the Monitoring app to the private channel you specified when creating the notification channel in Monitoring. Inviting the Monitoring app to public channels is optional.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ol\u0026gt;\u0026lt;/ol\u0026gt;\u0026lt;h3\u0026gt;Enabling Webhooks\u0026lt;/h3\u0026gt;\u0026lt;ol\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;The webhook handler\u0026lt;/b\u0026gt;: Identify the public endpoint URL to receive webhook data from Monitoring.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;In the Cloud Console, select \u0026lt;a href=\u0026#34;https://console.cloud.google.com/monitoring\u0026#34;\u0026gt;\u0026lt;b\u0026gt;Monitoring\u0026lt;/b\u0026gt;\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Click \u0026lt;b\u0026gt;Alerting\u0026lt;/b\u0026gt; and then click \u0026lt;b\u0026gt;Edit notification channels\u0026lt;/b\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;In the Webhook section, click Add new.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Complete the dialog.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Click \u0026lt;b\u0026gt;Test Connection\u0026lt;/b\u0026gt; to send a test payload to the Webhook endpoint. You can go to the receiving endpoint to verify delivery.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Click \u0026lt;b\u0026gt;Save\u0026lt;/b\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ol\u0026gt;\u0026lt;h3\u0026gt;Webhook schema\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;The Webhook schema structure for Error Reporting, is as follows:\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Schema structure, version 1.0\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eThese new channels  join our existing Error Reporting notification capabilities of email and the Google Cloud Console mobile app.\u003c/p\u003e\u003ch3\u003eWhat do I have to do to enable Error Reporting and these notifications?\u003c/h3\u003e\u003cp\u003eError Reporting is automatically enabled as soon as logs that contain error events like stack traces are ingested into Cloud Logging. Alternatively,  you can \u003ca href=\"https://cloud.google.com/error-reporting/docs/how-to\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/error-reporting/docs/how-to\" track-metadata-module=\"post\"\u003eself configure\u003c/a\u003e Error Reporting for a new project if you won’t be using Cloud Logging.\u003c/p\u003e\u003cp\u003eTo configure the new notification channels, see documentation \u003ca href=\"https://cloud.google.com/error-reporting/docs/notifications#create-channel\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/error-reporting/docs/notifications#create-channel\" track-metadata-module=\"post\"\u003ehere\u003c/a\u003e for \u003cb\u003e\u003ci\u003eSlack\u003c/i\u003e\u003c/b\u003e and \u003cb\u003e\u003ci\u003eWebhooks\u003c/i\u003e\u003c/b\u003e, or keep reading below:\u003c/p\u003e\u003ch3\u003eEnabling Slack\u003c/h3\u003e\u003col\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eIn Slack\u003c/b\u003e: Create a Slack workspace and channel at the \u003ca href=\"https://www.slack.com/\" target=\"_blank\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://www.slack.com\" track-metadata-module=\"post\"\u003eSlack site\u003c/a\u003e. Record the channel URL.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eIn the Cloud Console, select \u003ca href=\"https://console.cloud.google.com/monitoring\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://console.cloud.google.com/monitoring\" track-metadata-module=\"post\"\u003e\u003cb\u003eMonitoring\u003c/b\u003e\u003c/a\u003e.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eClick \u003cb\u003eAlerting\u003c/b\u003e and then click \u003cb\u003eEdit notification channels\u003c/b\u003e.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eIn the \u003cb\u003eSlack\u003c/b\u003e section, click \u003cb\u003eAdd new\u003c/b\u003e to open the Slack sign-in page:\u003c/p\u003e\u003c/li\u003e\u003col\u003e\u003cli\u003e\u003cp\u003eSelect your Slack workspace.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eClick \u003cb\u003eAllow\u003c/b\u003e to enable Cloud Monitoring access to your Slack workspace. This action takes you back to the Monitoring configuration page for your notification channel.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eEnter the name of the Slack channel you want to use for notifications.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eEnter a display name for the Slack notification channel.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e(Optional) To test the connection between Cloud Monitoring and your Slack workspace, click \u003cb\u003eSend test notification\u003c/b\u003e. If the connection is successful, then you see a message This is a test alert notification... in the Slack notification channel that you specified. Check the notification channel to confirm receipt.\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003cli\u003e\u003cp\u003eIf the Slack channel you want to use for notifications is a private channel, then you must manually invite the Monitoring app to the channel:\u003c/p\u003e\u003c/li\u003e\u003col\u003e\u003cli\u003e\u003cp\u003eOpen Slack.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eGo to the channel you specified as your Monitoring notification channel.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eInvite the Monitoring app to the channel by entering and sending the following message in the channel:\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e/invite @Google Cloud Monitoring\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eBe sure you invite the Monitoring app to the private channel you specified when creating the notification channel in Monitoring. Inviting the Monitoring app to public channels is optional.\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003c/ol\u003e\u003ch3\u003eEnabling Webhooks\u003c/h3\u003e\u003col\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eThe webhook handler\u003c/b\u003e: Identify the public endpoint URL to receive webhook data from Monitoring.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eIn the Cloud Console, select \u003ca href=\"https://console.cloud.google.com/monitoring\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://console.cloud.google.com/monitoring\" track-metadata-module=\"post\"\u003e\u003cb\u003eMonitoring\u003c/b\u003e\u003c/a\u003e.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eClick \u003cb\u003eAlerting\u003c/b\u003e and then click \u003cb\u003eEdit notification channels\u003c/b\u003e.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eIn the Webhook section, click Add new.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eComplete the dialog.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eClick \u003cb\u003eTest Connection\u003c/b\u003e to send a test payload to the Webhook endpoint. You can go to the receiving endpoint to verify delivery.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eClick \u003cb\u003eSave\u003c/b\u003e.\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003ch3\u003eWebhook schema\u003c/h3\u003e\u003cp\u003eThe Webhook schema structure for Error Reporting, is as follows:\u003c/p\u003e\u003cp\u003e\u003cb\u003eSchema structure, version 1.0\u003c/b\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c61=\"\"\u003e\u003cpre _ngcontent-c61=\"\"\u003e  \u003ccode _ngcontent-c61=\"\"\u003e{\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e  \u0026#34;version\u0026#34;: \u0026#34;1.0\u0026#34;,\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e  \u0026#34;subject\u0026#34;: string, description of the new or reopened error group.\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e  \u0026#34;group_info\u0026#34;: {\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e    \u0026#34;project_id\u0026#34;: string, project that owns the error group.\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e    \u0026#34;detail_link\u0026#34;: string, link to the Error Reporting Details page for the error group.\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e  },\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e  \u0026#34;exception_info\u0026#34;: {\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e    \u0026#34;type\u0026#34;: string, type of the exception logged in the event.\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e    \u0026#34;message\u0026#34;: string, exception message for the event.\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e  },\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e  \u0026#34;event_info\u0026#34;: {\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e    \u0026#34;log_message\u0026#34;: string\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e    \u0026#34;request_method\u0026#34;: string\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e    \u0026#34;request_url\u0026#34;: string\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e    \u0026#34;referrer\u0026#34;: string\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e    \u0026#34;user_agent\u0026#34;: string\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e    \u0026#34;service\u0026#34;: string\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e    \u0026#34;version\u0026#34;: string\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e    \u0026#34;response_status\u0026#34;: string\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e  },\n\u003c/code\u003e\u003ccode _ngcontent-c61=\"\"\u003e}\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c60=\"\"\u003e\u003cdiv _ngcontent-c60=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Basic authentication\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In addition to the webhook request sent by Cloud Monitoring, basic authentication utilizes the HTTP specification for the username and password. Cloud Monitoring requires your server to return a 401 response with the proper WWW-Authenticate header. For more information about basic authentication, see the following:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://www.ietf.org/rfc/rfc2617.txt\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;RFC Specification\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://en.wikipedia.org/wiki/Basic_access_authentication\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Basic authentication\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Token authentication\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Token Authentication requires a query string parameter in the endpoint URL and a key that the server expects to be secret between itself and Monitoring. The following is a sample URL that includes a token:\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;https://www.myserver.com/stackdriver-hook?auth_token=1234-abcd\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;If Monitoring posts an incident to the endpoint URL, your server can validate the attached token. This method of authentication can be more effective when used with SSL/TLS to encrypt the HTTP request, which can prevent snoopers from learning the token.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;For an example server in Python, see this \u0026lt;a href=\u0026#34;https://gist.github.com/tschieggm/7604940\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;sample server\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Get Started Today\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;If you haven\u0026amp;#8217;t visited your Error Reporting console yet, \u0026lt;a href=\u0026#34;http://console.cloud.google.com/errors\u0026#34;\u0026gt;give it a try today\u0026lt;/a\u0026gt; and learn more about it in \u0026lt;a href=\u0026#34;https://cloud.google.com/error-reporting/docs/viewing-errors\u0026#34;\u0026gt;documentation\u0026lt;/a\u0026gt;. When you\u0026amp;#8217;re ready to configure your notifications, consider \u0026lt;a href=\u0026#34;https://cloud.google.com/error-reporting/docs/notifications#slack\u0026#34;\u0026gt;Slack\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/error-reporting/docs/notifications#webhooks\u0026#34;\u0026gt;Webhooks\u0026lt;/a\u0026gt; if they fit into your current alerting and notification strategy.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;If you have any questions or want to start a discussion with other Error Reporting users, visit the Cloud Operations section of the \u0026lt;a href=\u0026#34;https://www.googlecloudcommunity.com/gc/Google-Cloud-s-operations-suite/bd-p/cloud-operations\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Google Cloud Community\u0026lt;/a\u0026gt; and post a discussion topic.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e\u003cb\u003eBasic authentication\u003c/b\u003e\u003c/p\u003e\u003cp\u003eIn addition to the webhook request sent by Cloud Monitoring, basic authentication utilizes the HTTP specification for the username and password. Cloud Monitoring requires your server to return a 401 response with the proper WWW-Authenticate header. For more information about basic authentication, see the following:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://www.ietf.org/rfc/rfc2617.txt\" target=\"_blank\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://www.ietf.org\" track-metadata-module=\"post\"\u003eRFC Specification\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Basic_access_authentication\" target=\"_blank\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://en.wikipedia.org\" track-metadata-module=\"post\"\u003eBasic authentication\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cb\u003eToken authentication\u003c/b\u003e\u003c/p\u003e\u003cp\u003eToken Authentication requires a query string parameter in the endpoint URL and a key that the server expects to be secret between itself and Monitoring. The following is a sample URL that includes a token:\u003c/p\u003e\u003cp\u003ehttps://www.myserver.com/stackdriver-hook?auth_token=1234-abcd\u003c/p\u003e\u003cp\u003eIf Monitoring posts an incident to the endpoint URL, your server can validate the attached token. This method of authentication can be more effective when used with SSL/TLS to encrypt the HTTP request, which can prevent snoopers from learning the token.\u003c/p\u003e\u003cp\u003eFor an example server in Python, see this \u003ca href=\"https://gist.github.com/tschieggm/7604940\" target=\"_blank\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://gist.github.com\" track-metadata-module=\"post\"\u003esample server\u003c/a\u003e.\u003c/p\u003e\u003ch3\u003eGet Started Today\u003c/h3\u003e\u003cp\u003eIf you haven’t visited your Error Reporting console yet, \u003ca href=\"http://console.cloud.google.com/errors\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"http://console.cloud.google.com/errors\" track-metadata-module=\"post\"\u003egive it a try today\u003c/a\u003e and learn more about it in \u003ca href=\"https://cloud.google.com/error-reporting/docs/viewing-errors\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://cloud.google.com/error-reporting/docs/viewing-errors\" track-metadata-module=\"post\"\u003edocumentation\u003c/a\u003e. When you’re ready to configure your notifications, consider \u003ca href=\"https://cloud.google.com/error-reporting/docs/notifications#slack\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://cloud.google.com/error-reporting/docs/notifications#slack\" track-metadata-module=\"post\"\u003eSlack\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/error-reporting/docs/notifications#webhooks\" track-type=\"inline link\" track-name=\"18\" track-metadata-eventdetail=\"https://cloud.google.com/error-reporting/docs/notifications#webhooks\" track-metadata-module=\"post\"\u003eWebhooks\u003c/a\u003e if they fit into your current alerting and notification strategy.\u003c/p\u003e\u003cp\u003eIf you have any questions or want to start a discussion with other Error Reporting users, visit the Cloud Operations section of the \u003ca href=\"https://www.googlecloudcommunity.com/gc/Google-Cloud-s-operations-suite/bd-p/cloud-operations\" target=\"_blank\" track-type=\"inline link\" track-name=\"19\" track-metadata-eventdetail=\"https://www.googlecloudcommunity.com\" track-metadata-module=\"post\"\u003eGoogle Cloud Community\u003c/a\u003e and post a discussion topic.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/article-content-stream-block\u003e\u003carticle-tag-list-block\u003e\u003c/article-tag-list-block\u003e\u003c/div\u003e\u003csection\u003e\u003carticle-up-1to3-block _nghost-c59=\"\"\u003e\u003c/article-up-1to3-block\u003e\u003c/section\u003e\u003c/div\u003e\u003c/article\u003e\u003c/main\u003e\u003c/article-page\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eBuilding new applications is a lot of fun, but troubleshooting and fixing the crashes that can come with app development is not. While many organizations are fast adopting the DevOps model, there are still some legacy frameworks where developers and operations teams are separate. Developers build and submit apps to their ops team, who in turn deploy and maintain the production stack. \u003c/p\u003e\u003cp\u003eA common issue that arises due to this workflow is the time it takes to find and resolve crashes. To help reduce the time it takes to find crashes, we recently introduced new \u003ca href=\"https://cloud.google.com/blog/products/operations/pub-sub-webook-and-slack-notifications-are-now-available\"\u003enotification\u003c/a\u003e channels for our Alerting product. Building on that release, we’re happy to announce today that you can send Error Reporting notifications through both \u003ca href=\"https://cloud.google.com/error-reporting/docs/notifications#slack\"\u003eSlack\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/error-reporting/docs/notifications#webhooks\"\u003eWebhooks\u003c/a\u003e. \u003c/p\u003e\u003ch3\u003eWhat is Error Reporting?\u003c/h3\u003e\u003cp\u003eError Reporting can analyze, aggregate, and notify you about crashes in your running cloud services. It can synthesize this information from ingested logs in \u003ca href=\"https://cloud.google.com/logging\"\u003eCloud Logging\u003c/a\u003e and has a \u003ca href=\"http://console.cloud.google.com/errors\"\u003e\u003ci\u003e\u003cb\u003ededicated page\u003c/b\u003e\u003c/i\u003e\u003c/a\u003e that displays the details of the errors, including a histogram of occurrences, list of affected versions, request URL, and links to the request log.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Error_Reporting_interface.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"1 Error Reporting interface.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Error_Reporting_interface.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eWhat are we launching?\u003c/h3\u003e\u003cp\u003eBuilding on our recent launch of \u003ca href=\"https://cloud.google.com/blog/products/operations/pub-sub-webook-and-slack-notifications-are-now-available\"\u003ealerting notification\u003c/a\u003e channels, today we are announcing an extension of \u003cb\u003eError Reporting’s notification capabilities to include Slack and Webhooks\u003c/b\u003e. \u003c/p\u003e\u003cp\u003eWith this launch, your teams can receive notifications about crashes directly into their configured Slack channel or preferred collaboration platform using webhooks. \u003c/p\u003e\u003cp\u003eCrash information can then be quickly swarmed, discussed, and resolved.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_Slack_and_Webhooks.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"2 Slack and Webhooks.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_Slack_and_Webhooks.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eThese new channels  join our existing Error Reporting notification capabilities of email and the Google Cloud Console mobile app.\u003c/p\u003e\u003ch3\u003eWhat do I have to do to enable Error Reporting and these notifications?\u003c/h3\u003e\u003cp\u003eError Reporting is automatically enabled as soon as logs that contain error events like stack traces are ingested into Cloud Logging. Alternatively,  you can \u003ca href=\"https://cloud.google.com/error-reporting/docs/how-to\"\u003eself configure\u003c/a\u003e Error Reporting for a new project if you won’t be using Cloud Logging.\u003c/p\u003e\u003cp\u003eTo configure the new notification channels, see documentation \u003ca href=\"https://cloud.google.com/error-reporting/docs/notifications#create-channel\"\u003ehere\u003c/a\u003e for \u003cb\u003e\u003ci\u003eSlack\u003c/i\u003e\u003c/b\u003e and \u003cb\u003e\u003ci\u003eWebhooks\u003c/i\u003e\u003c/b\u003e, or keep reading below:\u003c/p\u003e\u003ch3\u003eEnabling Slack\u003c/h3\u003e\u003col\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eIn Slack\u003c/b\u003e: Create a Slack workspace and channel at the \u003ca href=\"https://www.slack.com/\" target=\"_blank\"\u003eSlack site\u003c/a\u003e. Record the channel URL.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eIn the Cloud Console, select \u003ca href=\"https://console.cloud.google.com/monitoring\"\u003e\u003cb\u003eMonitoring\u003c/b\u003e\u003c/a\u003e.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eClick \u003cb\u003eAlerting\u003c/b\u003e and then click \u003cb\u003eEdit notification channels\u003c/b\u003e.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eIn the \u003cb\u003eSlack\u003c/b\u003e section, click \u003cb\u003eAdd new\u003c/b\u003e to open the Slack sign-in page:\u003c/p\u003e\u003c/li\u003e\u003col\u003e\u003cli\u003e\u003cp\u003eSelect your Slack workspace.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eClick \u003cb\u003eAllow\u003c/b\u003e to enable Cloud Monitoring access to your Slack workspace. This action takes you back to the Monitoring configuration page for your notification channel.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eEnter the name of the Slack channel you want to use for notifications.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eEnter a display name for the Slack notification channel.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e(Optional) To test the connection between Cloud Monitoring and your Slack workspace, click \u003cb\u003eSend test notification\u003c/b\u003e. If the connection is successful, then you see a message This is a test alert notification... in the Slack notification channel that you specified. Check the notification channel to confirm receipt.\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003cli\u003e\u003cp\u003eIf the Slack channel you want to use for notifications is a private channel, then you must manually invite the Monitoring app to the channel:\u003c/p\u003e\u003c/li\u003e\u003col\u003e\u003cli\u003e\u003cp\u003eOpen Slack.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eGo to the channel you specified as your Monitoring notification channel.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eInvite the Monitoring app to the channel by entering and sending the following message in the channel:\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e/invite @Google Cloud Monitoring\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eBe sure you invite the Monitoring app to the private channel you specified when creating the notification channel in Monitoring. Inviting the Monitoring app to public channels is optional.\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003c/ol\u003e\u003ch3\u003eEnabling Webhooks\u003c/h3\u003e\u003col\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eThe webhook handler\u003c/b\u003e: Identify the public endpoint URL to receive webhook data from Monitoring.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eIn the Cloud Console, select \u003ca href=\"https://console.cloud.google.com/monitoring\"\u003e\u003cb\u003eMonitoring\u003c/b\u003e\u003c/a\u003e.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eClick \u003cb\u003eAlerting\u003c/b\u003e and then click \u003cb\u003eEdit notification channels\u003c/b\u003e.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eIn the Webhook section, click Add new.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eComplete the dialog.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eClick \u003cb\u003eTest Connection\u003c/b\u003e to send a test payload to the Webhook endpoint. You can go to the receiving endpoint to verify delivery.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eClick \u003cb\u003eSave\u003c/b\u003e.\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003ch3\u003eWebhook schema\u003c/h3\u003e\u003cp\u003eThe Webhook schema structure for Error Reporting, is as follows:\u003c/p\u003e\u003cp\u003e\u003cb\u003eSchema structure, version 1.0\u003c/b\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'{\\r\\n \"version\": \"1.0\",\\r\\n \"subject\": string, description of the new or reopened error group.\\r\\n \"group_info\": {\\r\\n \"project_id\": string, project that owns the error group.\\r\\n \"detail_link\": string, link to the Error Reporting Details page for the error group.\\r\\n },\\r\\n \"exception_info\": {\\r\\n \"type\": string, type of the exception logged in the event.\\r\\n \"message\": string, exception message for the event.\\r\\n },\\r\\n \"event_info\": {\\r\\n \"log_message\": string\\r\\n \"request_method\": string\\r\\n \"request_url\": string\\r\\n \"referrer\": string\\r\\n \"user_agent\": string\\r\\n \"service\": string\\r\\n \"version\": string\\r\\n \"response_status\": string\\r\\n },\\r\\n}'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003cb\u003eBasic authentication\u003c/b\u003e\u003c/p\u003e\u003cp\u003eIn addition to the webhook request sent by Cloud Monitoring, basic authentication utilizes the HTTP specification for the username and password. Cloud Monitoring requires your server to return a 401 response with the proper WWW-Authenticate header. For more information about basic authentication, see the following:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://www.ietf.org/rfc/rfc2617.txt\" target=\"_blank\"\u003eRFC Specification\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Basic_access_authentication\" target=\"_blank\"\u003eBasic authentication\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003cb\u003eToken authentication\u003c/b\u003e\u003c/p\u003e\u003cp\u003eToken Authentication requires a query string parameter in the endpoint URL and a key that the server expects to be secret between itself and Monitoring. The following is a sample URL that includes a token:\u003c/p\u003e\u003cp\u003ehttps://www.myserver.com/stackdriver-hook?auth_token=1234-abcd\u003c/p\u003e\u003cp\u003eIf Monitoring posts an incident to the endpoint URL, your server can validate the attached token. This method of authentication can be more effective when used with SSL/TLS to encrypt the HTTP request, which can prevent snoopers from learning the token.\u003c/p\u003e\u003cp\u003eFor an example server in Python, see this \u003ca href=\"https://gist.github.com/tschieggm/7604940\" target=\"_blank\"\u003esample server\u003c/a\u003e.\u003c/p\u003e\u003ch3\u003eGet Started Today\u003c/h3\u003e\u003cp\u003eIf you haven’t visited your Error Reporting console yet, \u003ca href=\"http://console.cloud.google.com/errors\"\u003egive it a try today\u003c/a\u003e and learn more about it in \u003ca href=\"https://cloud.google.com/error-reporting/docs/viewing-errors\"\u003edocumentation\u003c/a\u003e. When you’re ready to configure your notifications, consider \u003ca href=\"https://cloud.google.com/error-reporting/docs/notifications#slack\"\u003eSlack\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/error-reporting/docs/notifications#webhooks\"\u003eWebhooks\u003c/a\u003e if they fit into your current alerting and notification strategy.\u003c/p\u003e\u003cp\u003eIf you have any questions or want to start a discussion with other Error Reporting users, visit the Cloud Operations section of the \u003ca href=\"https://www.googlecloudcommunity.com/gc/Google-Cloud-s-operations-suite/bd-p/cloud-operations\" target=\"_blank\"\u003eGoogle Cloud Community\u003c/a\u003e and post a discussion topic.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/operations/pub-sub-webook-and-slack-notifications-are-now-available/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Genric_GCP_upA1oyz.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eWebhook, Pub/Sub, and Slack Alerting notification channels launched\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eAnnouncing the general availability of the new Pub/Sub, Webhook, and Slack Notification channels.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://cloud.google.com/blog/static/assets/GCP_Twitter_Card-2000×1000.png",
      "date_published": "2022-04-05T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eAlek Szilagyi\u003c/name\u003e\u003ctitle\u003eSoftware Engineer, Google Cloud\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/vm-best-practices-app-observability-with-the-ops-agent/",
      "title": "Application observability made easier for Compute Engine",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWhen IT operators and architects begin their journey with Google Cloud, Day 0 observability needs tend to focus on infrastructure and aim to address questions about resource needs, a plan for scaling, and similar considerations. During this phase, developers and DevOps engineers also make a plan for how to get deep observability into the performance of third-party and open-source applications running on their \u003ca href=\"https://cloud.google.com/compute\"\u003eCompute Engine VMs\u003c/a\u003e. That’s why we recently launched a \u003ca href=\"https://cloud.google.com/monitoring/agent/integrations\"\u003ededicated UI\u003c/a\u003e under \u003cb\u003eMonitoring → Integrations\u003c/b\u003e that guides you to the available integrations that may be a good fit for your fleet, automatically installs relevant dashboards to help you get value faster, and shows you the integrations that are live on your VMs.   \u003c/p\u003e\u003ch3\u003eGetting up and running faster with application observability \u003c/h3\u003e\u003cp\u003eSince the Ops Agent \u003ca href=\"https://cloud.google.com/blog/products/operations/ops-agent-now-ga-and-it-includes-opentelemetry\"\u003eentered General Availability\u003c/a\u003e, we have added out of the box integrations with dozens of \u003ca href=\"https://cloud.google.com/monitoring/agent/ops-agent/third-party\"\u003epopular open source and licensed applications\u003c/a\u003e like databases, web servers, in-memory caches, event streaming, and application runtimes.  \u003c/p\u003e\u003cp\u003eThese integrations can be easily turned on within the Ops Agent on any VM, usually with a simple YAML configuration file update. Application-specific metrics and logs are sent to \u003ca href=\"https://cloud.google.com/products/operations\"\u003ecloud operations\u003c/a\u003e, providing deep visibility not just into infrastructure health indicators, but also into the application-specific telemetry that drives underlying infrastructure utilization. This data populates the analysis and query tools of \u003ca href=\"https://cloud.google.com/logging\"\u003eCloud Logging\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/monitoring\"\u003eCloud Monitoring\u003c/a\u003e like dashboards, Logs Explorer, alerts, SLOs, and more.    \u003c/p\u003e\u003ch3\u003e A single location for all integrations\u003c/h3\u003e\u003cp\u003eEven with easy configuration instructions, setting up an observability toolset with a view of dozens of third-party applications can be tricky. That’s why we created one UI that lists out all application integrations that we offer, along with instructions on how to get up and running quickly. With this UI, you can:  \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eFilter by integrations already installed on one or more VMs in your fleet, or those that are available but not yet installed on any VMs.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCheck at a glance which of your VMs have the Ops Agent installed already, and go through quick installation for VMs that will need the Ops Agent for application monitoring.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eQuickly identify lists of the specific metrics and log types collected for each integration so you know the telemetry collected.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eLink directly to the setup instructions for each integration to save time searching through documentation.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eView samples and screenshots of “out of the box” dashboards and visualizations available with zero configuration, and have the dashboards automatically added to your ‘Integration Dashboards’ list based on what is live on your fleet. Links to the dashboards will be available in the Integrations UI, or by going to \u003cb\u003eMonitoring → Dashboards → Integrations\u003c/b\u003e.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eWith a single click, choose “Copy Dashboard” to clone a given dashboard into your Custom list, and make modifications and edits specific to your applications and use cases.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Application_observability.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"1 Application observability.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Application_observability.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ci\u003eThe integrations UI makes it easy to browse available application integrations and learn more\u003c/i\u003e\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_Application_observability.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"2 Application observability.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_Application_observability.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ci\u003eEach integration lists telemetry collected and helps you get up and running with intuitive dashboards that you can later customize\u003c/i\u003e\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWe also heard from our customers that you want a feedback loop that clearly shows which VMs have which integrations live. So, we added the following to our VM Instances Dashboard (located under \u003cb\u003eMonitoring → Dashboards → GCP → VM Instances\u003c/b\u003e):\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eClick into any VM to see whether the Ops Agent is installed, and the exact version running.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eView the “Integrations” chips to check which Integrations are currently collecting metrics and logs for each VM.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eView other infrastructure metrics and logs per VM, and quickly spot if there are any alerts or uptime checks set up for the VM or live events and incidents that require attention.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_Application_observability.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"3 Application observability.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_Application_observability.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eGet started today\u003c/h3\u003e\u003cp\u003eIn the coming months, we will add more integrations to the Ops Agent for more open source and licensed applications that you have told us are priorities. \u003c/p\u003e\u003cp\u003eTo get started with application observability today, make sure you are running the latest version of the \u003ca href=\"https://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent\"\u003eOps Agent\u003c/a\u003e on your GCE VMs, check out the instructions to add \u003ca href=\"https://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent/third-party\"\u003ethird-party application integrations\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/monitoring/agent/integrations\"\u003echeck out the Integrations UI\u003c/a\u003e in the Monitoring section of the Google Cloud Console. \u003c/p\u003e\u003cp\u003eLastly, if you have feedback, want to ask us questions, or request another application integration, drop us a line on the \u003ca href=\"https://www.googlecloudcommunity.com/gc/Google-Cloud-s-operations-suite/bd-p/cloud-operations\" target=\"_blank\"\u003eGoogle Cloud Community Cloud Ops\u003c/a\u003e area!\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/operations/ops-agent-now-ga-and-it-includes-opentelemetry/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Blog_CloudMigration_D.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eThe Ops Agent is now GA and it leverages OpenTelemetry\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eToday, we’re happy to announce the General Availability of the new Ops Agent, which replaces both the Logging and Monitoring agents and s...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://cloud.google.com/blog/static/assets/GCP_Twitter_Card-2000×1000.png",
      "date_published": "2022-04-04T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eJJ Roepke\u003c/name\u003e\u003ctitle\u003eSoftware Engineer\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/topics/cloud-first/whats-new-cloud-native-apps/",
      "title": "What’s new in cloud-native apps?",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c53=\"\"\u003e\u003cdiv _ngcontent-c53=\"\" innerhtml=\"\u0026lt;h3\u0026gt;Week of Mar 07 - Mar 11 2022\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Rhode Island moves to Google Cloud-based job board\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;When the pandemic hit, the State of Rhode Island moved its workforce development operations entirely online on a foundation of Google Workspace and Google Cloud resources, including Firestore, Cloud Functions, and Kubernetes, among others. Check out \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/topics/developers-practitioners/how-rhode-island-created-virtual-career-center\u0026#34;\u0026gt;how they did it\u0026lt;/a\u0026gt;.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Containerized microservices at Lowe\u0026amp;#8217;s\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;Lowe\u0026amp;#8217;s already told us \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/how-lowes-leverages-google-sre-practices\u0026#34;\u0026gt;how they use SRE\u0026lt;/a\u0026gt;. They\u0026amp;#8217;re at it again, describing how they built an e-commerce website using a \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/topics/retail/how-google-cloud-services-helped-lowes-transform-ecommerce\u0026#34;\u0026gt;containerized microservices architecture and Kubernetes\u0026lt;/a\u0026gt;, with Istio for service mesh and Cloud Operations for good measure.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Cruise AVs hit the road with Google Cloud services\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;Autonomous Vehicle (AV) startup Cruise detailed how it\u0026amp;#8217;s using data analytics and machine learning on a foundation of Google Kubernetes Engine (GKE) and other services to develop and test its self-driving cars. \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/containers-kubernetes/how-cruise-tests-its-avs-on-a-google-cloud-platform\u0026#34;\u0026gt;Read the guest post\u0026lt;/a\u0026gt;.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;L\u0026amp;#8217;Or\u0026amp;#233;al\u0026amp;#8217;s data analytics gets a makeover with serverless\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;We\u0026amp;#8217;re hurtling toward a \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/serverless/introducing-the-programmable-cloud\u0026#34;\u0026gt;programmable cloud\u0026lt;/a\u0026gt; \u0026amp;#8212; a world where developers use cloud-native serverless tools like Cloud Functions to quickly prototype and build powerful, data-driven business insights. \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/serverless/loreal-combines-google-cloud-serverless-and-data-offerings\u0026#34;\u0026gt;L\u0026amp;#8217;Or\u0026amp;#233;al is a great example\u0026lt;/a\u0026gt;.\u0026amp;#160;\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Better telemetry for your Anthos clusters\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/service-mesh/docs/observability/explore-dashboard\u0026#34;\u0026gt;Anthos Service Mesh Dashboard\u0026lt;/a\u0026gt; is now available (public preview) on the \u0026lt;a href=\u0026#34;https://cloud.google.com/anthos/clusters/docs/bare-metal/latest\u0026#34;\u0026gt;Anthos clusters on Bare Metal\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/anthos/clusters/docs/on-prem/1.10\u0026#34;\u0026gt;Anthos clusters on VMware\u0026lt;/a\u0026gt;. Now, you can get out-of-the-box telemetry dashboards to see a services-first view of your application on the Cloud Console.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Instrument your Java apps\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;With the new version of the \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/google-cloud-logging-java-client-library-new-features\u0026#34;\u0026gt;Google Cloud Logging Java library\u0026lt;/a\u0026gt;, you can wire your application logs with more information \u0026amp;#8212; without adding a single line of code.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Visualize metrics from Cloud Spanner\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;Building an app on top of Cloud Spanner but can\u0026amp;#8217;t assess how well it\u0026amp;#8217;s operating? The new \u0026lt;a href=\u0026#34;https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/googlecloudspannerreceiver\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;OpenTelemetery receiver for Cloud Spanner\u0026lt;/a\u0026gt; provides an easy way for you to process and visualize metrics from Cloud Spanner \u0026lt;a href=\u0026#34;https://cloud.google.com/spanner/docs/introspection\u0026#34;\u0026gt;System tables\u0026lt;/a\u0026gt;, and export these to the APM tool of your choice. \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/databases/consume-spanner-metrics-using-opentelemetery\u0026#34;\u0026gt;Read more here\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003ch3\u003eWeek of Mar 07 - Mar 11 2022\u003c/h3\u003e\u003cp\u003e\u003cb\u003eRhode Island moves to Google Cloud-based job board\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eWhen the pandemic hit, the State of Rhode Island moved its workforce development operations entirely online on a foundation of Google Workspace and Google Cloud resources, including Firestore, Cloud Functions, and Kubernetes, among others. Check out \u003ca href=\"https://cloud.google.com/blog/topics/developers-practitioners/how-rhode-island-created-virtual-career-center\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/blog/topics/developers-practitioners/how-rhode-island-created-virtual-career-center\" track-metadata-module=\"post\"\u003ehow they did it\u003c/a\u003e. \u003c/p\u003e\u003cp\u003e\u003cb\u003eContainerized microservices at Lowe’s\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eLowe’s already told us \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/how-lowes-leverages-google-sre-practices\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/how-lowes-leverages-google-sre-practices\" track-metadata-module=\"post\"\u003ehow they use SRE\u003c/a\u003e. They’re at it again, describing how they built an e-commerce website using a \u003ca href=\"https://cloud.google.com/blog/topics/retail/how-google-cloud-services-helped-lowes-transform-ecommerce\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/blog/topics/retail/how-google-cloud-services-helped-lowes-transform-ecommerce\" track-metadata-module=\"post\"\u003econtainerized microservices architecture and Kubernetes\u003c/a\u003e, with Istio for service mesh and Cloud Operations for good measure.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCruise AVs hit the road with Google Cloud services\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eAutonomous Vehicle (AV) startup Cruise detailed how it’s using data analytics and machine learning on a foundation of Google Kubernetes Engine (GKE) and other services to develop and test its self-driving cars. \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/how-cruise-tests-its-avs-on-a-google-cloud-platform\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/containers-kubernetes/how-cruise-tests-its-avs-on-a-google-cloud-platform\" track-metadata-module=\"post\"\u003eRead the guest post\u003c/a\u003e. \u003c/p\u003e\u003cp\u003e\u003cb\u003eL’Oréal’s data analytics gets a makeover with serverless\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eWe’re hurtling toward a \u003ca href=\"https://cloud.google.com/blog/products/serverless/introducing-the-programmable-cloud\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/serverless/introducing-the-programmable-cloud\" track-metadata-module=\"post\"\u003eprogrammable cloud\u003c/a\u003e — a world where developers use cloud-native serverless tools like Cloud Functions to quickly prototype and build powerful, data-driven business insights. \u003ca href=\"https://cloud.google.com/blog/products/serverless/loreal-combines-google-cloud-serverless-and-data-offerings\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/serverless/loreal-combines-google-cloud-serverless-and-data-offerings\" track-metadata-module=\"post\"\u003eL’Oréal is a great example\u003c/a\u003e.  \u003c/p\u003e\u003cp\u003e\u003cb\u003eBetter telemetry for your Anthos clusters\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003ca href=\"https://cloud.google.com/service-mesh/docs/observability/explore-dashboard\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://cloud.google.com/service-mesh/docs/observability/explore-dashboard\" track-metadata-module=\"post\"\u003eAnthos Service Mesh Dashboard\u003c/a\u003e is now available (public preview) on the \u003ca href=\"https://cloud.google.com/anthos/clusters/docs/bare-metal/latest\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://cloud.google.com/anthos/clusters/docs/bare-metal/latest\" track-metadata-module=\"post\"\u003eAnthos clusters on Bare Metal\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/anthos/clusters/docs/on-prem/1.10\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://cloud.google.com/anthos/clusters/docs/on-prem/1.10\" track-metadata-module=\"post\"\u003eAnthos clusters on VMware\u003c/a\u003e. Now, you can get out-of-the-box telemetry dashboards to see a services-first view of your application on the Cloud Console.\u003c/p\u003e\u003cp\u003e\u003cb\u003eInstrument your Java apps\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eWith the new version of the \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/google-cloud-logging-java-client-library-new-features\" track-type=\"inline link\" track-name=\"18\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/google-cloud-logging-java-client-library-new-features\" track-metadata-module=\"post\"\u003eGoogle Cloud Logging Java library\u003c/a\u003e, you can wire your application logs with more information — without adding a single line of code.\u003c/p\u003e\u003cp\u003e\u003cb\u003eVisualize metrics from Cloud Spanner\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eBuilding an app on top of Cloud Spanner but can’t assess how well it’s operating? The new \u003ca href=\"https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/googlecloudspannerreceiver\" target=\"_blank\" track-type=\"inline link\" track-name=\"19\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eOpenTelemetery receiver for Cloud Spanner\u003c/a\u003e provides an easy way for you to process and visualize metrics from Cloud Spanner \u003ca href=\"https://cloud.google.com/spanner/docs/introspection\" track-type=\"inline link\" track-name=\"20\" track-metadata-eventdetail=\"https://cloud.google.com/spanner/docs/introspection\" track-metadata-module=\"post\"\u003eSystem tables\u003c/a\u003e, and export these to the APM tool of your choice. \u003ca href=\"https://cloud.google.com/blog/products/databases/consume-spanner-metrics-using-opentelemetery\" track-type=\"inline link\" track-name=\"21\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/databases/consume-spanner-metrics-using-opentelemetery\" track-metadata-module=\"post\"\u003eRead more here\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eDevelopers and IT operations pros of all stripes come to Google Cloud to build modern, cloud-first and cloud-native applications. Here’s the latest from Google Cloud on everything app dev, containers, Kubernetes, DevOps, serverless and open source, all in one place.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eWeek of Mar 28 - Apr 1 2022\u003c/h3\u003e\u003cp\u003e\u003cb\u003eAnother cool thing you can do with Cloud Functions\u003cbr/\u003e\u003c/b\u003eGot data you want to ingest from Cloud Storage to BigQuery? Cloud Functions can help with that. This tutorial \u003ca href=\"https://cloud.google.com/blog/products/data-analytics/ingesting-data-into-bigquery-using-serverless-spark\"\u003eshows you how\u003c/a\u003e.  \u003c/p\u003e\u003cp\u003e\u003cb\u003eAdd custom severity levels to Cloud Monitoring alert policies\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eNot all alerts are created equal. \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/devops-best-practices-add-severity-levels-to-alerts\"\u003eIn this blog post\u003c/a\u003e, learn how to add static and dynamic severity levels to a Cloud Monitoring alert policy, with enhanced notification channels including email, webhooks, Cloud Pub/Sub and PagerDuty. \u003c/p\u003e\u003cp\u003e\u003cb\u003eLearn how to use CPU allocation controls in Cloud Run\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eLast fall, \u003ca href=\"https://cloud.google.com/blog/products/serverless/cloud-run-gets-always-on-cpu-allocation\"\u003ewe added\u003c/a\u003e “always-on CPU” capabilities to Cloud Run, making it a better fit for running background- and other asynchronous-processing tasks. \u003ca href=\"https://cloud.google.com/blog/topics/developers-practitioners/use-cloud-run-always-cpu-allocation-background-work\"\u003eIn this post\u003c/a\u003e, Developer Advocate Wesley Chun uses a weather alerting app to demonstrate how to use the feature, and along the way, reduces the app’s average user response latency by over 80%.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/gcp/go-1-18-and-google-cloud-go-now-with-google-cloud/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_App_Dev_4.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eGo 1.18 and Google Cloud: Go now with Google Cloud\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eGo 1.18 release and Google Cloud working better together.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eWeek of Mar 21 - Mar 25 2022\u003c/h3\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cb\u003eGet Going with latest Go 1.18 release\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eWith the release of version 1.18, the Go programming language now includes support for generic code using parameterized types, integrated fuzz testing, and a new Go workspace mode that makes it simple to work with multiple modules. \u003ca href=\"https://cloud.google.com/blog/products/gcp/go-1-18-and-google-cloud-go-now-with-google-cloud\"\u003eLearn more here\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/serverless/paris-based-news-organization-expands-markets-with-serverless-containers-and-php-cms/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/serverless_2.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eScaling quickly to new markets with Cloud Run—a web modernization story\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eMoving from on-prem to cloud using serverless containers and PHP, a French news outlet more easily expands to reach new markets.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eWeek of Mar 14 - Mar 18 2022\u003c/h3\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cb\u003eCreate EventArc triggers with Terraform\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eIn addition to the Google Cloud Console or gcloud, you can also use a Terraform resource to create an Eventarc trigger. Mete Atamel \u003ca href=\"https://cloud.google.com/blog/topics/developers-practitioners/creating-eventarc-triggers-terraform\"\u003eshows you how\u003c/a\u003e. \u003c/p\u003e\u003cp\u003e\u003cb\u003eScaling to new markets with Cloud Run\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eFrench publisher Les Echos Le Parisien Annonces switched from dedicated on-prem infrastructure to Cloud Run to supplement its main news site with regional variations. Les Echos shares its \u003ca href=\"https://cloud.google.com/blog/products/serverless/paris-based-news-organization-expands-markets-with-serverless-containers-and-php-cms\"\u003ewebsite architecture\u003c/a\u003e here. \u003c/p\u003e\u003cp\u003e\u003cb\u003eThe serverless way to celebrate Pi Day\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eIn honor of Pi Day, Google Cloud Developer Advocate Emma Haruka Iwao shows you how to use the new Cloud Functions (2nd gen) to \u003ca href=\"https://cloud.google.com/blog/topics/developers-practitioners/celebrating-pi-day-cloud-functions\"\u003ecalculate π\u003c/a\u003e — serverlessly.\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/containers-kubernetes/how-cruise-tests-its-avs-on-a-google-cloud-platform/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/automotive.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eBuilding continuous integration \u0026amp; continuous delivery for autonomous vehicles on Google Cloud\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eCruise relies on a whole host of Google Cloud technologies to develop and test the tech that goes into its autonomous vehicles, or AVs.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eWeek of Mar 07 - Mar 11 2022\u003c/h3\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cb\u003eRhode Island moves to Google Cloud-based job board\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eWhen the pandemic hit, the State of Rhode Island moved its workforce development operations entirely online on a foundation of Google Workspace and Google Cloud resources, including Firestore, Cloud Functions, and Kubernetes, among others. Check out \u003ca href=\"https://cloud.google.com/blog/topics/developers-practitioners/how-rhode-island-created-virtual-career-center\"\u003ehow they did it\u003c/a\u003e. \u003c/p\u003e\u003cp\u003e\u003cb\u003eContainerized microservices at Lowe’s\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eLowe’s already told us \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/how-lowes-leverages-google-sre-practices\"\u003ehow they use SRE\u003c/a\u003e. They’re at it again, describing how they built an e-commerce website using a \u003ca href=\"https://cloud.google.com/blog/topics/retail/how-google-cloud-services-helped-lowes-transform-ecommerce\"\u003econtainerized microservices architecture and Kubernetes\u003c/a\u003e, with Istio for service mesh and Cloud Operations for good measure.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCruise AVs hit the road with Google Cloud services\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eAutonomous Vehicle (AV) startup Cruise detailed how it’s using data analytics and machine learning on a foundation of Google Kubernetes Engine (GKE) and other services to develop and test its self-driving cars. \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/how-cruise-tests-its-avs-on-a-google-cloud-platform\"\u003eRead the guest post\u003c/a\u003e. \u003c/p\u003e\u003cp\u003e\u003cb\u003eL’Oréal’s data analytics gets a makeover with serverless\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eWe’re hurtling toward a \u003ca href=\"https://cloud.google.com/blog/products/serverless/introducing-the-programmable-cloud\"\u003eprogrammable cloud\u003c/a\u003e — a world where developers use cloud-native serverless tools like Cloud Functions to quickly prototype and build powerful, data-driven business insights. \u003ca href=\"https://cloud.google.com/blog/products/serverless/loreal-combines-google-cloud-serverless-and-data-offerings\"\u003eL’Oréal is a great example\u003c/a\u003e.  \u003c/p\u003e\u003cp\u003e\u003cb\u003eBetter telemetry for your Anthos clusters\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003ca href=\"https://cloud.google.com/service-mesh/docs/observability/explore-dashboard\"\u003eAnthos Service Mesh Dashboard\u003c/a\u003e is now available (public preview) on the \u003ca href=\"https://cloud.google.com/anthos/clusters/docs/bare-metal/latest\"\u003eAnthos clusters on Bare Metal\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/anthos/clusters/docs/on-prem/1.10\"\u003eAnthos clusters on VMware\u003c/a\u003e. Now, you can get out-of-the-box telemetry dashboards to see a services-first view of your application on the Cloud Console.\u003c/p\u003e\u003cp\u003e\u003cb\u003eInstrument your Java apps\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eWith the new version of the \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/google-cloud-logging-java-client-library-new-features\"\u003eGoogle Cloud Logging Java library\u003c/a\u003e, you can wire your application logs with more information — without adding a single line of code.\u003c/p\u003e\u003cp\u003e\u003cb\u003eVisualize metrics from Cloud Spanner\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eBuilding an app on top of Cloud Spanner but can’t assess how well it’s operating? The new \u003ca href=\"https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/googlecloudspannerreceiver\" target=\"_blank\"\u003eOpenTelemetery receiver for Cloud Spanner\u003c/a\u003e provides an easy way for you to process and visualize metrics from Cloud Spanner \u003ca href=\"https://cloud.google.com/spanner/docs/introspection\"\u003eSystem tables\u003c/a\u003e, and export these to the APM tool of your choice. \u003ca href=\"https://cloud.google.com/blog/products/databases/consume-spanner-metrics-using-opentelemetery\"\u003eRead more here\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eWeek of Feb 28 - Mar 4 2022\u003c/h3\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntroducing Cloud SDK\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eThe rebranded \u003ca href=\"https://cloud.google.com/sdk\"\u003eCloud SDK\u003c/a\u003e is a collection of all the libraries and tools (including Google Cloud CLI) you need to interact with Google Cloud products and services. Learn more \u003ca href=\"https://cloud.google.com/blog/products/application-development/redesigning-the-cloud-sdk-cli-for-easier-development\"\u003ehere\u003c/a\u003e. \u003c/p\u003e\u003cp\u003e\u003cb\u003eCloud CLI, meet Terraform\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eGoogle Cloud CLI’s new Declarative Export for Terraform allows you to export the current state of your Google Cloud infrastructure into a descriptive file compatible with Terraform (HCL) or Google’s KRM declarative tooling, and is now \u003ca href=\"https://cloud.google.com/blog/products/application-development/google-cloud-cli-declarative-export-preview\"\u003eavailable in preview\u003c/a\u003e. \u003c/p\u003e\u003cp\u003e\u003cb\u003eKnative graduates to incubating project \u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eCongratulations to Knative, which has been \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/knative-enters-the-cncf-as-an-incubating-project\"\u003eaccepted by the Cloud Native Computing Foundation\u003c/a\u003e, or CNCF, as an incubating project, enabling the next phase of serverless architecture. \u003c/p\u003e\u003cp\u003e\u003cb\u003eWe manage Prometheus so you don’t have to\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003ca href=\"https://cloud.google.com/stackdriver/docs/managed-prometheus\"\u003eGoogle Cloud Managed Service for Prometheus\u003c/a\u003e is now generally available! Get all the benefits of open source-compatible monitoring with the ease of use of Google-scale managed services. \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/easy-managed-prometheus-metrics-service-for-kubernetes\"\u003eLearn more here\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/inframod_living_3.max-2200x2200.jpg",
      "date_published": "2022-03-31T20:00:00Z",
      "author": {
        "name": "\u003cname\u003eGoogle Cloud Content \u0026 Editorial \u003c/name\u003e\u003ctitle\u003e\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/devops-best-practices-add-severity-levels-to-alerts/",
      "title": "Add severity levels to your alert policies in Cloud Monitoring",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c60=\"\"\u003e\u003cdiv _ngcontent-c60=\"\" innerhtml=\"\u0026lt;p\u0026gt;When you are dealing with a situation that fires a bevy of alerts, do you instinctively know which alerts are the most pressing? Severity levels are an important concept in alerting to aid you and your team in properly assessing which notifications should be prioritized. You can use these levels to focus on the issues deemed most critical for your operations and triage through the noise. Today, we\u0026amp;#8217;re happy to announce that you can create custom severity levels on your alert policies and have this data included in your notifications for more effective alerting and integration with downstream third-party services (e.g. Webhook, Cloud Pub/Sub, PagerDuty).\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The \u0026lt;a href=\u0026#34;https://cloud.google.com/monitoring/support/notification-options\u0026#34;\u0026gt;notification channels\u0026lt;/a\u0026gt; have been enhanced to accept this data - including Email, Webhooks, Cloud Pub/Sub, and PagerDuty - with planned support for Slack at a later time. This enables further automation/customization based on importance wherever the notifications are consumed.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Below, we\u0026#39;ll walk through examples of \u0026lt;a href=\u0026#34;https://cloud.google.com/monitoring/alerts/labels\u0026#34;\u0026gt;how to add\u0026lt;/a\u0026gt; static and dynamic severity levels to an Alert Policy.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Create user labels to support static severity levels\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;When you add user labels on an alert policy, they will appear on every notification and incident generated by that alert policy. Refer to the \u0026lt;a href=\u0026#34;https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.alertPolicies\u0026#34;\u0026gt;documentation\u0026lt;/a\u0026gt; to see how to add user labels to alert policies via the Alert Policy API.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Let\u0026amp;#8217;s walk through an example: suppose you want to configure Alert Policies that notify you when the CPU utilization crosses a particular threshold. Further, you want the notifications to indicate the following severity levels:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;INFO\u0026lt;/code\u0026gt; when CPU utilization is between 70% and 80%\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;WARNING\u0026lt;/code\u0026gt; when CPU utilization is between 80% and 90%\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;CRITICAL\u0026lt;/code\u0026gt; when CPU utilization is above 90%\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;To accomplish this, you can create three separate alert policies with user labels defined as below:\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Create alert policy (\u0026lt;code\u0026gt;A\u0026lt;/code\u0026gt;) which triggers when the CPU utilization is above 90%, and includes the following user labels: any incident generated by this policy will include a label \u0026lt;code\u0026gt;Severity\u0026lt;/code\u0026gt; with value \u0026lt;code\u0026gt;CRITICAL\u0026lt;/code\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;\u0026amp;#34;userLabels\u0026amp;#34;: {\u0026lt;/code\u0026gt;\u0026lt;br\u0026gt;\u0026amp;#160;\u0026amp;#160;\u0026amp;#160;\u0026amp;#160;\u0026lt;code\u0026gt;\u0026amp;#8220;Severity\u0026amp;#8221;: \u0026amp;#8220;CRITICAL\u0026amp;#8221;,\u0026lt;/code\u0026gt;\u0026lt;br\u0026gt;\u0026lt;code\u0026gt;}\u0026lt;/code\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Create a second policy (\u0026lt;code\u0026gt;B\u0026lt;/code\u0026gt;) which triggers when resource CPU utilization is above 80%, and includes the following user labels: any incident generated on this policy will include a label \u0026lt;code\u0026gt;Severity\u0026lt;/code\u0026gt; with value \u0026lt;code\u0026gt;WARNING\u0026lt;/code\u0026gt;.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;\u0026amp;#34;userLabels\u0026amp;#34;: {\u0026lt;/code\u0026gt;\u0026lt;br\u0026gt;\u0026amp;#160; \u0026amp;#160;\u0026amp;#160;\u0026lt;code\u0026gt;\u0026amp;#8220;Severity\u0026amp;#8221;: \u0026amp;#8220;WARNING\u0026amp;#8221;,\u0026lt;/code\u0026gt;\u0026lt;br\u0026gt;\u0026lt;code\u0026gt;}\u0026lt;/code\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Create a third policy (\u0026lt;code\u0026gt;C\u0026lt;/code\u0026gt;) which triggers when resource CPU utilization is above 70%, and includes the following user labels: any incident generated on this policy will include a label \u0026lt;code\u0026gt;Severity\u0026lt;/code\u0026gt; with value \u0026lt;code\u0026gt;INFO\u0026lt;/code\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;\u0026amp;#34;userLabels\u0026amp;#34;: {\u0026lt;/code\u0026gt;\u0026lt;br\u0026gt;\u0026amp;#160; \u0026amp;#160;\u0026amp;#160;\u0026lt;code\u0026gt;\u0026amp;#8220;Severity\u0026amp;#8221;: \u0026amp;#8220;INFO\u0026amp;#8221;,\u0026lt;/code\u0026gt;\u0026lt;br\u0026gt;\u0026lt;code\u0026gt;}\u0026lt;/code\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In this scenario, when the CPU utilization crosses a threshold of 90% policies \u0026lt;code\u0026gt;A\u0026lt;/code\u0026gt;, \u0026lt;code\u0026gt;B\u0026lt;/code\u0026gt;, and \u0026lt;code\u0026gt;C\u0026lt;/code\u0026gt; will trigger alerts. If the CPU utilization falls back down to 85%, the incident from policy \u0026lt;code\u0026gt;A\u0026lt;/code\u0026gt; will close, but the incidents from policies \u0026lt;code\u0026gt;B\u0026lt;/code\u0026gt; and \u0026lt;code\u0026gt;C\u0026lt;/code\u0026gt; will remain open. If the CPU utilization falls even further down to 75%, the incident from policy \u0026lt;code\u0026gt;B\u0026lt;/code\u0026gt; will close, and the incident from policy C will remain open. If the CPU utilization drops down to 40%, incidents generated by all three policies will automatically close.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Use MQL to create dynamic severity levels\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Alert policy user labels are static in nature, meaning you cannot dynamically apply user labels based on a changing threshold. As shown earlier, you need to create three separate alert policies to generate notifications that contain user label \u0026lt;code\u0026gt;Severity\u0026lt;/code\u0026gt; with value:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;INFO\u0026lt;/code\u0026gt; below a threshold of 80%,\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;WARNING\u0026lt;/code\u0026gt; below a threshold of 90%, and\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;CRITICAL\u0026lt;/code\u0026gt; above a threshold of 90%.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;If you\u0026#39;d like to dynamically apply the severity level based on threshold within a single alert policy, you can use MQL. You can \u0026lt;a href=\u0026#34;https://cloud.google.com/monitoring/mql/alerts\u0026#34;\u0026gt;utilize MQL to create alert policies\u0026lt;/a\u0026gt; with dynamic custom metric labels that will be embedded in the incident. Via MQL \u0026lt;a href=\u0026#34;https://cloud.google.com/monitoring/mql/reference#map\u0026#34;\u0026gt;map\u0026lt;/a\u0026gt;, you can specify what threshold level should result in which severity label. This means you can accomplish the above scenario of three severity levels based on threshold by creating only one alert policy.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Take the sample MQL query below:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eWhen you are dealing with a situation that fires a bevy of alerts, do you instinctively know which alerts are the most pressing? Severity levels are an important concept in alerting to aid you and your team in properly assessing which notifications should be prioritized. You can use these levels to focus on the issues deemed most critical for your operations and triage through the noise. Today, we’re happy to announce that you can create custom severity levels on your alert policies and have this data included in your notifications for more effective alerting and integration with downstream third-party services (e.g. Webhook, Cloud Pub/Sub, PagerDuty). \u003c/p\u003e\u003cp\u003eThe \u003ca href=\"https://cloud.google.com/monitoring/support/notification-options\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/monitoring/support/notification-options\" track-metadata-module=\"post\"\u003enotification channels\u003c/a\u003e have been enhanced to accept this data - including Email, Webhooks, Cloud Pub/Sub, and PagerDuty - with planned support for Slack at a later time. This enables further automation/customization based on importance wherever the notifications are consumed.\u003c/p\u003e\u003cp\u003eBelow, we\u0026#39;ll walk through examples of \u003ca href=\"https://cloud.google.com/monitoring/alerts/labels\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/monitoring/alerts/labels\" track-metadata-module=\"post\"\u003ehow to add\u003c/a\u003e static and dynamic severity levels to an Alert Policy. \u003c/p\u003e\u003ch3\u003eCreate user labels to support static severity levels\u003c/h3\u003e\u003cp\u003eWhen you add user labels on an alert policy, they will appear on every notification and incident generated by that alert policy. Refer to the \u003ca href=\"https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.alertPolicies\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.alertPolicies\" track-metadata-module=\"post\"\u003edocumentation\u003c/a\u003e to see how to add user labels to alert policies via the Alert Policy API. \u003c/p\u003e\u003cp\u003eLet’s walk through an example: suppose you want to configure Alert Policies that notify you when the CPU utilization crosses a particular threshold. Further, you want the notifications to indicate the following severity levels:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eINFO\u003c/code\u003e when CPU utilization is between 70% and 80%\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eWARNING\u003c/code\u003e when CPU utilization is between 80% and 90%\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eCRITICAL\u003c/code\u003e when CPU utilization is above 90%\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eTo accomplish this, you can create three separate alert policies with user labels defined as below:\u003c/p\u003e\u003cp\u003eCreate alert policy (\u003ccode\u003eA\u003c/code\u003e) which triggers when the CPU utilization is above 90%, and includes the following user labels: any incident generated by this policy will include a label \u003ccode\u003eSeverity\u003c/code\u003e with value \u003ccode\u003eCRITICAL\u003c/code\u003e.\u003c/p\u003e\u003cp\u003e\u003ccode\u003e\u0026#34;userLabels\u0026#34;: {\u003c/code\u003e\u003cbr/\u003e    \u003ccode\u003e“Severity”: “CRITICAL”,\u003c/code\u003e\u003cbr/\u003e\u003ccode\u003e}\u003c/code\u003e\u003c/p\u003e\u003cp\u003eCreate a second policy (\u003ccode\u003eB\u003c/code\u003e) which triggers when resource CPU utilization is above 80%, and includes the following user labels: any incident generated on this policy will include a label \u003ccode\u003eSeverity\u003c/code\u003e with value \u003ccode\u003eWARNING\u003c/code\u003e. \u003c/p\u003e\u003cp\u003e\u003ccode\u003e\u0026#34;userLabels\u0026#34;: {\u003c/code\u003e\u003cbr/\u003e    \u003ccode\u003e“Severity”: “WARNING”,\u003c/code\u003e\u003cbr/\u003e\u003ccode\u003e}\u003c/code\u003e\u003c/p\u003e\u003cp\u003eCreate a third policy (\u003ccode\u003eC\u003c/code\u003e) which triggers when resource CPU utilization is above 70%, and includes the following user labels: any incident generated on this policy will include a label \u003ccode\u003eSeverity\u003c/code\u003e with value \u003ccode\u003eINFO\u003c/code\u003e.\u003c/p\u003e\u003cp\u003e\u003ccode\u003e\u0026#34;userLabels\u0026#34;: {\u003c/code\u003e\u003cbr/\u003e    \u003ccode\u003e“Severity”: “INFO”,\u003c/code\u003e\u003cbr/\u003e\u003ccode\u003e}\u003c/code\u003e\u003c/p\u003e\u003cp\u003eIn this scenario, when the CPU utilization crosses a threshold of 90% policies \u003ccode\u003eA\u003c/code\u003e, \u003ccode\u003eB\u003c/code\u003e, and \u003ccode\u003eC\u003c/code\u003e will trigger alerts. If the CPU utilization falls back down to 85%, the incident from policy \u003ccode\u003eA\u003c/code\u003e will close, but the incidents from policies \u003ccode\u003eB\u003c/code\u003e and \u003ccode\u003eC\u003c/code\u003e will remain open. If the CPU utilization falls even further down to 75%, the incident from policy \u003ccode\u003eB\u003c/code\u003e will close, and the incident from policy C will remain open. If the CPU utilization drops down to 40%, incidents generated by all three policies will automatically close.\u003c/p\u003e\u003ch3\u003eUse MQL to create dynamic severity levels\u003c/h3\u003e\u003cp\u003eAlert policy user labels are static in nature, meaning you cannot dynamically apply user labels based on a changing threshold. As shown earlier, you need to create three separate alert policies to generate notifications that contain user label \u003ccode\u003eSeverity\u003c/code\u003e with value:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eINFO\u003c/code\u003e below a threshold of 80%,\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eWARNING\u003c/code\u003e below a threshold of 90%, and\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eCRITICAL\u003c/code\u003e above a threshold of 90%.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eIf you\u0026#39;d like to dynamically apply the severity level based on threshold within a single alert policy, you can use MQL. You can \u003ca href=\"https://cloud.google.com/monitoring/mql/alerts\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/monitoring/mql/alerts\" track-metadata-module=\"post\"\u003eutilize MQL to create alert policies\u003c/a\u003e with dynamic custom metric labels that will be embedded in the incident. Via MQL \u003ca href=\"https://cloud.google.com/monitoring/mql/reference#map\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/monitoring/mql/reference#map\" track-metadata-module=\"post\"\u003emap\u003c/a\u003e, you can specify what threshold level should result in which severity label. This means you can accomplish the above scenario of three severity levels based on threshold by creating only one alert policy.\u003c/p\u003e\u003cp\u003eTake the sample MQL query below:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWhen you are dealing with a situation that fires a bevy of alerts, do you instinctively know which alerts are the most pressing? Severity levels are an important concept in alerting to aid you and your team in properly assessing which notifications should be prioritized. You can use these levels to focus on the issues deemed most critical for your operations and triage through the noise. Today, we’re happy to announce that you can create custom severity levels on your alert policies and have this data included in your notifications for more effective alerting and integration with downstream third-party services (e.g. Webhook, Cloud Pub/Sub, PagerDuty). \u003c/p\u003e\u003cp\u003eThe \u003ca href=\"https://cloud.google.com/monitoring/support/notification-options\"\u003enotification channels\u003c/a\u003e have been enhanced to accept this data - including Email, Webhooks, Cloud Pub/Sub, and PagerDuty - with planned support for Slack at a later time. This enables further automation/customization based on importance wherever the notifications are consumed.\u003c/p\u003e\u003cp\u003eBelow, we'll walk through examples of \u003ca href=\"https://cloud.google.com/monitoring/alerts/labels\"\u003ehow to add\u003c/a\u003e static and dynamic severity levels to an Alert Policy. \u003c/p\u003e\u003ch3\u003eCreate user labels to support static severity levels\u003c/h3\u003e\u003cp\u003eWhen you add user labels on an alert policy, they will appear on every notification and incident generated by that alert policy. Refer to the \u003ca href=\"https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.alertPolicies\"\u003edocumentation\u003c/a\u003e to see how to add user labels to alert policies via the Alert Policy API. \u003c/p\u003e\u003cp\u003eLet’s walk through an example: suppose you want to configure Alert Policies that notify you when the CPU utilization crosses a particular threshold. Further, you want the notifications to indicate the following severity levels:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eINFO\u003c/code\u003e when CPU utilization is between 70% and 80%\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eWARNING\u003c/code\u003e when CPU utilization is between 80% and 90%\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eCRITICAL\u003c/code\u003e when CPU utilization is above 90%\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eTo accomplish this, you can create three separate alert policies with user labels defined as below:\u003c/p\u003e\u003cp\u003eCreate alert policy (\u003ccode\u003eA\u003c/code\u003e) which triggers when the CPU utilization is above 90%, and includes the following user labels: any incident generated by this policy will include a label \u003ccode\u003eSeverity\u003c/code\u003e with value \u003ccode\u003eCRITICAL\u003c/code\u003e.\u003c/p\u003e\u003cp\u003e\u003ccode\u003e\"userLabels\": {\u003c/code\u003e\u003cbr/\u003e    \u003ccode\u003e“Severity”: “CRITICAL”,\u003c/code\u003e\u003cbr/\u003e\u003ccode\u003e}\u003c/code\u003e\u003c/p\u003e\u003cp\u003eCreate a second policy (\u003ccode\u003eB\u003c/code\u003e) which triggers when resource CPU utilization is above 80%, and includes the following user labels: any incident generated on this policy will include a label \u003ccode\u003eSeverity\u003c/code\u003e with value \u003ccode\u003eWARNING\u003c/code\u003e. \u003c/p\u003e\u003cp\u003e\u003ccode\u003e\"userLabels\": {\u003c/code\u003e\u003cbr/\u003e    \u003ccode\u003e“Severity”: “WARNING”,\u003c/code\u003e\u003cbr/\u003e\u003ccode\u003e}\u003c/code\u003e\u003c/p\u003e\u003cp\u003eCreate a third policy (\u003ccode\u003eC\u003c/code\u003e) which triggers when resource CPU utilization is above 70%, and includes the following user labels: any incident generated on this policy will include a label \u003ccode\u003eSeverity\u003c/code\u003e with value \u003ccode\u003eINFO\u003c/code\u003e.\u003c/p\u003e\u003cp\u003e\u003ccode\u003e\"userLabels\": {\u003c/code\u003e\u003cbr/\u003e    \u003ccode\u003e“Severity”: “INFO”,\u003c/code\u003e\u003cbr/\u003e\u003ccode\u003e}\u003c/code\u003e\u003c/p\u003e\u003cp\u003eIn this scenario, when the CPU utilization crosses a threshold of 90% policies \u003ccode\u003eA\u003c/code\u003e, \u003ccode\u003eB\u003c/code\u003e, and \u003ccode\u003eC\u003c/code\u003e will trigger alerts. If the CPU utilization falls back down to 85%, the incident from policy \u003ccode\u003eA\u003c/code\u003e will close, but the incidents from policies \u003ccode\u003eB\u003c/code\u003e and \u003ccode\u003eC\u003c/code\u003e will remain open. If the CPU utilization falls even further down to 75%, the incident from policy \u003ccode\u003eB\u003c/code\u003e will close, and the incident from policy C will remain open. If the CPU utilization drops down to 40%, incidents generated by all three policies will automatically close.\u003c/p\u003e\u003ch3\u003eUse MQL to create dynamic severity levels\u003c/h3\u003e\u003cp\u003eAlert policy user labels are static in nature, meaning you cannot dynamically apply user labels based on a changing threshold. As shown earlier, you need to create three separate alert policies to generate notifications that contain user label \u003ccode\u003eSeverity\u003c/code\u003e with value:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eINFO\u003c/code\u003e below a threshold of 80%,\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eWARNING\u003c/code\u003e below a threshold of 90%, and\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eCRITICAL\u003c/code\u003e above a threshold of 90%.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eIf you'd like to dynamically apply the severity level based on threshold within a single alert policy, you can use MQL. You can \u003ca href=\"https://cloud.google.com/monitoring/mql/alerts\"\u003eutilize MQL to create alert policies\u003c/a\u003e with dynamic custom metric labels that will be embedded in the incident. Via MQL \u003ca href=\"https://cloud.google.com/monitoring/mql/reference#map\"\u003emap\u003c/a\u003e, you can specify what threshold level should result in which severity label. This means you can accomplish the above scenario of three severity levels based on threshold by creating only one alert policy.\u003c/p\u003e\u003cp\u003eTake the sample MQL query below:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u\"fetch gce_instance\\r\\n| metric 'compute.googleapis.com/instance/cpu/utilization'\\r\\n| filter (metadata.user_labels.env == 'prod') \u0026amp;\u0026amp; (resource.zone =~ 'asia.*')\\r\\n| group_by sliding(5m), [value_utilization_mean: mean(value.utilization)]\\r\\n| map\\r\\n add[\\r\\n Severity:\\r\\n if(val() \u0026gt; 90 '%', 'CRITICAL',\\r\\n if(val() \u0026gt;= 80 '%' \u0026amp;\u0026amp; val() \u0026lt;= 90 '%', 'WARNING', 'INFO'))]\\r\\n| condition val() \u0026gt; 70 '%'\"), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIn this example, an incident will be created any time CPU utilization is above a threshold of 70%. If the value is between 70-80%, the incident will contain a metric label called \u003ccode\u003eSeverity\u003c/code\u003e with value \u003ccode\u003eINFO\u003c/code\u003e. If the value is between 80-90%, the metric label \u003ccode\u003eSeverity\u003c/code\u003e will have value WARNING, and if the value is above 90%, the label \u003ccode\u003eSeverity\u003c/code\u003e will have value \u003ccode\u003eCRITICAL\u003c/code\u003e.\u003c/p\u003e\u003cp\u003eIn the above scenario, if the CPU utilization value starts at 92%, incident A will be created with severity level \u003ccode\u003eCRITICAL\u003c/code\u003e. If the utilization value then drops down to 73%, a new incident \u003ccode\u003eB\u003c/code\u003e will be opened with severity level \u003ccode\u003eINFO\u003c/code\u003e. Incident \u003ccode\u003eA\u003c/code\u003e, however, will remain open. If the value jumps to 82%, a new incident \u003ccode\u003eC\u003c/code\u003e will open with severity level \u003ccode\u003eWARNING\u003c/code\u003e and incidents \u003ccode\u003eA\u003c/code\u003e and \u003ccode\u003eB\u003c/code\u003e will remain open. If \u003ca href=\"https://cloud.google.com/monitoring/alerts/incidents-events#closing\"\u003eauto-close\u003c/a\u003e is configured in your policy with a duration of 30 minutes, incident `A` will auto-close 30 minutes after incident `B` starts, and incident `B` will auto-close 30 minutes after incident `C` starts.  If the value drops below 70%, all incidents will close. \u003c/p\u003e\u003cp\u003eIn order to ensure the alert policy only has one incident open at a time with the correct corresponding label, and to avoid waiting for incidents to auto-close as in the example above, set \u003ca href=\"https://cloud.google.com/monitoring/alerts/concepts-indepth#partial-metric-data\"\u003eevaluationMissingData\u003c/a\u003e to \u003ccode\u003eEVALUATION_MISSING_DATA_INACTIVE\u003c/code\u003e in your API request. This field tells the Alert Policy how to handle situations when the metric stream has sparse or missing data, so the incident can be closed appropriately as needed. If you are making your MQL alert policy in the UI, select the \u003ccode\u003eMissing data points treated as values that do not violate the policy condition\u003c/code\u003e button in the \u003ccode\u003eAdvanced Options\u003c/code\u003e dropdown in the \u003ccode\u003eConfigure Trigger\u003c/code\u003e section:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Monitoring_trigger.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Monitoring trigger.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Monitoring_trigger.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWhen \u003ccode\u003eEVALUATION_MISSING_DATA_INACTIVE\u003c/code\u003e is specified in the above scenario, incident \u003ccode\u003eA\u003c/code\u003e will close once incident\u003ccode\u003eB\u003c/code\u003e is created, and incident \u003ccode\u003eB\u003c/code\u003e will close once incident \u003ccode\u003eC\u003c/code\u003e is created.\u003c/p\u003e\u003ch3\u003eSeverity Labels in Notification Channels\u003c/h3\u003e\u003cp\u003eIf you send \u003ca href=\"https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.notificationChannels#resource:-notificationchannel\"\u003enotifications\u003c/a\u003e to a third-party service like \u003ca href=\"https://cloud.google.com/monitoring/support/notification-options#creating_channels\"\u003ePagerDuty, Webhooks, or Pub/Sub\u003c/a\u003e then you can parse the JSON payload and route the notification according to its severity so that critical information is not missed by your team. \u003c/p\u003e\u003cp\u003eIf you utilize alert policy user labels, these will appear as an object on the notification with the key \u003ccode\u003epolicy_user_labels\u003c/code\u003e i.e.:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'\"policy_user_labels\": {\\r\\n \"Severity\": \"CRITICAL\",\\r\\n}'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIf you utilize metric labels via MQL, these will appear as an object with key \u003ccode\u003elabels\u003c/code\u003e nested in an object with key \u003ccode\u003emetric\u003c/code\u003e i.e.:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'\"metric\": {\\r\\n \"displayName\": \"Some Display Name\",\\r\\n \"labels\": {\\r\\n \"instance_name\": \"some_instance_name\",\\r\\n \"Severity\": \"CRITICAL\"\\r\\n },\\r\\n }'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eGet Started Today\u003c/h3\u003e\u003cp\u003eAlerts can be configured on nearly any metric, log, or trace (or the absence of that data) that is captured in \u003ca href=\"https://cloud.google.com/products/operations\"\u003eGoogle Cloud’s operations suite\u003c/a\u003e. Severity levels give you and your teams an additional way to cut through noise to find the issues that you know will have the most positive impact when resolved. Check out this video on \u003ca href=\"https://youtu.be/4RgJjx4IxMs\" target=\"_blank\"\u003elog alerts\u003c/a\u003e as part of our Observability in-depth video series and if you have questions, feature requests, or just want to read topics from other customers who are using Cloud Alerting, visit our \u003ca href=\"https://www.googlecloudcommunity.com/gc/Google-Cloud-s-operations-suite/bd-p/cloud-operations\" target=\"_blank\"\u003eGoogle Cloud Community site\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/operations/pub-sub-webook-and-slack-notifications-are-now-available/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Genric_GCP_upA1oyz.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eWebhook, Pub/Sub, and Slack Alerting notification channels launched\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eAnnouncing the general availability of the new Pub/Sub, Webhook, and Slack Notification channels.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://cloud.google.com/blog/static/assets/GCP_Twitter_Card-2000×1000.png",
      "date_published": "2022-03-29T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eAlizah Lalani\u003c/name\u003e\u003ctitle\u003eSoftware Engineer\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/identity-security/automate-public-certificate-lifecycle-management-via--acme-client-api/",
      "title": "Automate Public Certificates Lifecycle Management via RFC 8555 (ACME)",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c60=\"\"\u003e\u003cdiv _ngcontent-c60=\"\" innerhtml=\"\u0026lt;p\u0026gt;It is that simple. Just schedule this task to run periodically and you will now be automatically acquiring and maintaining the TLS certificates for the associated workload.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;For Kubernetes based workloads\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;If you are using Kubernetes, thanks to \u0026lt;a href=\u0026#34;https://cert-manager.io/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;cert-manager\u0026lt;/a\u0026gt; (another ACME client), it is just as easy. Simply specify the ACME url and \u0026lt;a href=\u0026#34;https://cert-manager.io/docs/configuration/acme/#external-account-bindings\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;External Account Binding\u0026lt;/a\u0026gt; details in your configuration. Your ACME client will ensure you always have an up to date certificate for your Kubernetes deployment.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Announcing the Private Preview\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;We have heard loud and clear that our customers want to use a unified solution for managing their HTTPS certificates which is why we have launched this offering today.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Using this service and Google Trust Services means you will get the same industry leading \u0026lt;a href=\u0026#34;https://security.googleblog.com/2021/03/google-https-and-device-compatibility.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;device compatibility\u0026lt;/a\u0026gt; we use for services like YouTube and Google search for your own products and services.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;FAQ\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;We know you might have some questions about this release so here are our answers to the most frequent questions we hear:\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;How can I get access?\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;You can request access to this Private Preview using \u0026lt;a href=\u0026#34;https://docs.google.com/forms/d/1Euhflb5CXpuLik8czElhyAloTZJZobar4086dmlPqXA/viewform?ts=620a6854\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;this sign up form\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;How long are the certificates you issue good for?\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;By default all certificates issued by Google Trust Services are good for up to 90 days; however, ACME allows for clients to request certificates with different validity periods. Using this capability we allow the requestor to get certificates that are good for as little as 1 day, though we would not recommend using anything less than 3 days due to concerns over \u0026lt;a href=\u0026#34;https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46359.pdf\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;clock skew\u0026lt;/a\u0026gt; and certificate validity overlap.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;What forms of domain control verification do you support?\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;The ACME protocol defines several mechanisms for domain control verification and we support three of them, they include : TLS-ALPN-01, HTTP-01, and DNS-01. \u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Each of these have different scenarios where their use makes the most sense, for example TLS-ALPN-01 might make sense in cases where HTTPS is not used and the requestor does not have access to dynamically update DNS records. Choose the mechanism that fits your use case best.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Do you support email based domain control verification?\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;No we do not.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Do you issue wildcard certificates?\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;Yes we do. Please note, as with other Certificate Authorities you must currently use\u0026amp;#160; DNS based domain control verification to get a wildcard certificate.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Do you issue certificates for punycode encoded Unicode domain names?\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;Not at this time.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Do you issue certificates containing IP addresses?\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;Yes we do; however, this is currently limited to customers who control an IANA assigned IP address block. Contact your sales representative for more information.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Can I use ACME to get private certificates from Cloud CA Service?\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;Yes, but not directly. Our partner \u0026lt;a href=\u0026#34;https://smallstep.com/blog/private-acme-server/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;SmallStep\u0026lt;/a\u0026gt; created an ACME Registration Authority (RA) that can be used to get certificates from the \u0026lt;a href=\u0026#34;https://cloud.google.com/certificate-authority-service\u0026#34;\u0026gt;Cloud CA Service\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;What algorithms and key lengths do you support?\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;We support issuing both ECC and RSA certificates. For more information see our \u0026lt;a href=\u0026#34;https://pki.goog/repository/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Certificate Practice Statement\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://pki.goog/repository/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;CA Certificate Repository\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Do you offer certificates from a pure ECC based certificate chain?\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;Not at this time.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;What root certificates do you use?\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;We list all of our root certificates and intermediate certificates \u0026lt;a href=\u0026#34;https://pki.goog/repository/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;here\u0026lt;/a\u0026gt; and we do change which ones we use from time to time.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;It is important to also note that we send the appropriate intermediate certificates with every certificate request via the \u0026lt;a href=\u0026#34;https://tools.ietf.org/html/rfc8555#section-7.4.2\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;ACME protocol. \u0026lt;/a\u0026gt;\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Why should I use Google Trust Services instead of another certificate authority?\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;There are multiple good ACME CAs you may use.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;We envision a world where those that deploy SSL use a number of ACME based certificate authorities to enable sites to continue to operate without downtime when one provider has availability issues. If you need a large number of certificates or guarantees on geographic diversity, the GTS CA may be an especially good fit.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;It is our hope that by making this service available to cloud customers they will be able to get the benefit of that robustness, and reduce latency for workloads terminating TLS within Google Cloud.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;You recently announced Certificate Manager, is this an alternative to that offering?\u0026lt;/b\u0026gt;\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;No it is not. This extends Certificate Manager so that workloads that choose to terminate TLS on their own are able to get certificates from the same CA we use when we manage your certificates for you.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;It is our hope that with this ACME API, you will be able to simplify your HTTPS certificate lifecycle management for your workloads.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eIt is that simple. Just schedule this task to run periodically and you will now be automatically acquiring and maintaining the TLS certificates for the associated workload.\u003c/p\u003e\u003ch3\u003eFor Kubernetes based workloads\u003c/h3\u003e\u003cp\u003eIf you are using Kubernetes, thanks to \u003ca href=\"https://cert-manager.io/\" target=\"_blank\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cert-manager.io\" track-metadata-module=\"post\"\u003ecert-manager\u003c/a\u003e (another ACME client), it is just as easy. Simply specify the ACME url and \u003ca href=\"https://cert-manager.io/docs/configuration/acme/#external-account-bindings\" target=\"_blank\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cert-manager.io\" track-metadata-module=\"post\"\u003eExternal Account Binding\u003c/a\u003e details in your configuration. Your ACME client will ensure you always have an up to date certificate for your Kubernetes deployment.\u003c/p\u003e\u003ch3\u003eAnnouncing the Private Preview\u003c/h3\u003e\u003cp\u003eWe have heard loud and clear that our customers want to use a unified solution for managing their HTTPS certificates which is why we have launched this offering today.\u003c/p\u003e\u003cp\u003eUsing this service and Google Trust Services means you will get the same industry leading \u003ca href=\"https://security.googleblog.com/2021/03/google-https-and-device-compatibility.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://security.googleblog.com\" track-metadata-module=\"post\"\u003edevice compatibility\u003c/a\u003e we use for services like YouTube and Google search for your own products and services.\u003c/p\u003e\u003ch3\u003eFAQ\u003c/h3\u003e\u003cp\u003eWe know you might have some questions about this release so here are our answers to the most frequent questions we hear:\u003c/p\u003e\u003cp\u003e\u003cb\u003eHow can I get access?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eYou can request access to this Private Preview using \u003ca href=\"https://docs.google.com/forms/d/1Euhflb5CXpuLik8czElhyAloTZJZobar4086dmlPqXA/viewform?ts=620a6854\" target=\"_blank\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://docs.google.com\" track-metadata-module=\"post\"\u003ethis sign up form\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cb\u003eHow long are the certificates you issue good for?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eBy default all certificates issued by Google Trust Services are good for up to 90 days; however, ACME allows for clients to request certificates with different validity periods. Using this capability we allow the requestor to get certificates that are good for as little as 1 day, though we would not recommend using anything less than 3 days due to concerns over \u003ca href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46359.pdf\" target=\"_blank\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://static.googleusercontent.com\" track-metadata-module=\"post\"\u003eclock skew\u003c/a\u003e and certificate validity overlap.\u003c/p\u003e\u003cp\u003e\u003cb\u003eWhat forms of domain control verification do you support?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eThe ACME protocol defines several mechanisms for domain control verification and we support three of them, they include : TLS-ALPN-01, HTTP-01, and DNS-01. \u003cbr/\u003e\u003c/p\u003e\u003cp\u003eEach of these have different scenarios where their use makes the most sense, for example TLS-ALPN-01 might make sense in cases where HTTPS is not used and the requestor does not have access to dynamically update DNS records. Choose the mechanism that fits your use case best.\u003c/p\u003e\u003cp\u003e\u003cb\u003eDo you support email based domain control verification?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eNo we do not.\u003c/p\u003e\u003cp\u003e\u003cb\u003eDo you issue wildcard certificates?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eYes we do. Please note, as with other Certificate Authorities you must currently use  DNS based domain control verification to get a wildcard certificate.\u003c/p\u003e\u003cp\u003e\u003cb\u003eDo you issue certificates for punycode encoded Unicode domain names?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eNot at this time.\u003c/p\u003e\u003cp\u003e\u003cb\u003eDo you issue certificates containing IP addresses?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eYes we do; however, this is currently limited to customers who control an IANA assigned IP address block. Contact your sales representative for more information.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCan I use ACME to get private certificates from Cloud CA Service?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eYes, but not directly. Our partner \u003ca href=\"https://smallstep.com/blog/private-acme-server/\" target=\"_blank\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://smallstep.com\" track-metadata-module=\"post\"\u003eSmallStep\u003c/a\u003e created an ACME Registration Authority (RA) that can be used to get certificates from the \u003ca href=\"https://cloud.google.com/certificate-authority-service\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloud.google.com/certificate-authority-service\" track-metadata-module=\"post\"\u003eCloud CA Service\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cb\u003eWhat algorithms and key lengths do you support?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eWe support issuing both ECC and RSA certificates. For more information see our \u003ca href=\"https://pki.goog/repository/\" target=\"_blank\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://pki.goog\" track-metadata-module=\"post\"\u003eCertificate Practice Statement\u003c/a\u003e and \u003ca href=\"https://pki.goog/repository/\" target=\"_blank\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://pki.goog\" track-metadata-module=\"post\"\u003eCA Certificate Repository\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003cb\u003eDo you offer certificates from a pure ECC based certificate chain?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eNot at this time.\u003c/p\u003e\u003cp\u003e\u003cb\u003eWhat root certificates do you use?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eWe list all of our root certificates and intermediate certificates \u003ca href=\"https://pki.goog/repository/\" target=\"_blank\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://pki.goog\" track-metadata-module=\"post\"\u003ehere\u003c/a\u003e and we do change which ones we use from time to time. \u003c/p\u003e\u003cp\u003eIt is important to also note that we send the appropriate intermediate certificates with every certificate request via the \u003ca href=\"https://tools.ietf.org/html/rfc8555#section-7.4.2\" target=\"_blank\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://tools.ietf.org\" track-metadata-module=\"post\"\u003eACME protocol. \u003c/a\u003e \u003c/p\u003e\u003cp\u003e\u003cb\u003eWhy should I use Google Trust Services instead of another certificate authority?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eThere are multiple good ACME CAs you may use. \u003c/p\u003e\u003cp\u003eWe envision a world where those that deploy SSL use a number of ACME based certificate authorities to enable sites to continue to operate without downtime when one provider has availability issues. If you need a large number of certificates or guarantees on geographic diversity, the GTS CA may be an especially good fit.\u003c/p\u003e\u003cp\u003eIt is our hope that by making this service available to cloud customers they will be able to get the benefit of that robustness, and reduce latency for workloads terminating TLS within Google Cloud. \u003c/p\u003e\u003cp\u003e\u003cb\u003eYou recently announced Certificate Manager, is this an alternative to that offering?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eNo it is not. This extends Certificate Manager so that workloads that choose to terminate TLS on their own are able to get certificates from the same CA we use when we manage your certificates for you.\u003c/p\u003e\u003cp\u003eIt is our hope that with this ACME API, you will be able to simplify your HTTPS certificate lifecycle management for your workloads.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWe’re excited to announce an enhancement of our preview of Certificate Manager which allows Google Cloud customers to acquire public certificates for their workloads that terminate TLS directly or for their cross-cloud and on-premise workloads. This is accomplished via the Automatic Certificate Management Environment (\u003ca href=\"https://datatracker.ietf.org/doc/html/rfc8555\" target=\"_blank\"\u003eACME\u003c/a\u003e) protocol which is the same protocol used by Certificate Authorities  to enable seamless automatic lifecycle management of TLS certificates.\u003c/p\u003e\u003cp\u003eThese certificates come from Google Trust Services, the same Certificate Authority (CA) we use by default when we manage certificates on your behalf with the Global External HTTPS Load Balancer. By using the same CA for managed certificates and unmanaged certificates you are assured that both scenarios work equally well across the entire spectrum of devices that use your services.\u003c/p\u003e\u003cp\u003eThis also enables Cloud Customers to get a more reliable TLS deployment. It does so by enabling one common certificate lifecycle management story based on ACME to be used without a single point of failure (relying just on one certificate authority). In other words, it is now possible to freely load balance or fail over to multiple ACME CAs with confidence. \u003c/p\u003e\u003ch3\u003eHow do I use it ? \u003c/h3\u003e\u003cp\u003eTo use this feature you will need an API key so you can use a feature in ACME called \u003ca href=\"https://tools.ietf.org/html/rfc8555#section-7.3.4\" target=\"_blank\"\u003eExternal Account Binding\u003c/a\u003e. This enables us to associate your certificate requests to your Google Cloud account and allows us to impose rate limits on a per customer basis. You may easily get an API key using the following commands:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'$ gcloud config set project \u0026lt;project ID\u0026gt;\\r\\n$ gcloud projects add-iam-policy-binding project-foo \\\\\\r\\n --member=user:ca-manager@example.net \\\\\\r\\n --role=roles/publicca.externalAccountKeyCreator\\r\\n# Request a key:\\r\\n$ gcloud alpha publicca external-account-keys create'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eEach ACME implementation differs slightly on how you specify this API key but as an example with the popular\u003ca href=\"https://certbot.eff.org/\" target=\"_blank\"\u003eCertbot ACME\u003c/a\u003e client the configuration looks something like this:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'certbot -d \u0026lt;domain.com\u0026gt; --server https://dv.acme-v02.api.pki.goog/directory --eab-kid \u0026lt;EAB_KEY_ID\u0026gt; --eab-hmac-key \u0026lt;EAB_HMAC_KEY\u0026gt; --standalone --preferred-challenges dns certonly'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIt is that simple. Just schedule this task to run periodically and you will now be automatically acquiring and maintaining the TLS certificates for the associated workload.\u003c/p\u003e\u003ch3\u003eFor Kubernetes based workloads\u003c/h3\u003e\u003cp\u003eIf you are using Kubernetes, thanks to \u003ca href=\"https://cert-manager.io/\" target=\"_blank\"\u003ecert-manager\u003c/a\u003e (another ACME client), it is just as easy. Simply specify the ACME url and \u003ca href=\"https://cert-manager.io/docs/configuration/acme/#external-account-bindings\" target=\"_blank\"\u003eExternal Account Binding\u003c/a\u003e details in your configuration. Your ACME client will ensure you always have an up to date certificate for your Kubernetes deployment.\u003c/p\u003e\u003ch3\u003eAnnouncing the Private Preview\u003c/h3\u003e\u003cp\u003eWe have heard loud and clear that our customers want to use a unified solution for managing their HTTPS certificates which is why we have launched this offering today.\u003c/p\u003e\u003cp\u003eUsing this service and Google Trust Services means you will get the same industry leading \u003ca href=\"https://security.googleblog.com/2021/03/google-https-and-device-compatibility.html\" target=\"_blank\"\u003edevice compatibility\u003c/a\u003e we use for services like YouTube and Google search for your own products and services.\u003c/p\u003e\u003ch3\u003eFAQ\u003c/h3\u003e\u003cp\u003eWe know you might have some questions about this release so here are our answers to the most frequent questions we hear:\u003c/p\u003e\u003cp\u003e\u003cb\u003eHow can I get access?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eYou can request access to this Private Preview using \u003ca href=\"https://docs.google.com/forms/d/1Euhflb5CXpuLik8czElhyAloTZJZobar4086dmlPqXA/viewform?ts=620a6854\" target=\"_blank\"\u003ethis sign up form\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cb\u003eHow long are the certificates you issue good for?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eBy default all certificates issued by Google Trust Services are good for up to 90 days; however, ACME allows for clients to request certificates with different validity periods. Using this capability we allow the requestor to get certificates that are good for as little as 1 day, though we would not recommend using anything less than 3 days due to concerns over \u003ca href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/46359.pdf\" target=\"_blank\"\u003eclock skew\u003c/a\u003e and certificate validity overlap.\u003c/p\u003e\u003cp\u003e\u003cb\u003eWhat forms of domain control verification do you support?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eThe ACME protocol defines several mechanisms for domain control verification and we support three of them, they include : TLS-ALPN-01, HTTP-01, and DNS-01. \u003cbr/\u003e\u003c/p\u003e\u003cp\u003eEach of these have different scenarios where their use makes the most sense, for example TLS-ALPN-01 might make sense in cases where HTTPS is not used and the requestor does not have access to dynamically update DNS records. Choose the mechanism that fits your use case best.\u003c/p\u003e\u003cp\u003e\u003cb\u003eDo you support email based domain control verification?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eNo we do not.\u003c/p\u003e\u003cp\u003e\u003cb\u003eDo you issue wildcard certificates?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eYes we do. Please note, as with other Certificate Authorities you must currently use  DNS based domain control verification to get a wildcard certificate.\u003c/p\u003e\u003cp\u003e\u003cb\u003eDo you issue certificates for punycode encoded Unicode domain names?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eNot at this time.\u003c/p\u003e\u003cp\u003e\u003cb\u003eDo you issue certificates containing IP addresses?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eYes we do; however, this is currently limited to customers who control an IANA assigned IP address block. Contact your sales representative for more information.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCan I use ACME to get private certificates from Cloud CA Service?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eYes, but not directly. Our partner \u003ca href=\"https://smallstep.com/blog/private-acme-server/\" target=\"_blank\"\u003eSmallStep\u003c/a\u003e created an ACME Registration Authority (RA) that can be used to get certificates from the \u003ca href=\"https://cloud.google.com/certificate-authority-service\"\u003eCloud CA Service\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003cb\u003eWhat algorithms and key lengths do you support?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eWe support issuing both ECC and RSA certificates. For more information see our \u003ca href=\"https://pki.goog/repository/\" target=\"_blank\"\u003eCertificate Practice Statement\u003c/a\u003e and \u003ca href=\"https://pki.goog/repository/\" target=\"_blank\"\u003eCA Certificate Repository\u003c/a\u003e\u003c/p\u003e\u003cp\u003e\u003cb\u003eDo you offer certificates from a pure ECC based certificate chain?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eNot at this time.\u003c/p\u003e\u003cp\u003e\u003cb\u003eWhat root certificates do you use?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eWe list all of our root certificates and intermediate certificates \u003ca href=\"https://pki.goog/repository/\" target=\"_blank\"\u003ehere\u003c/a\u003e and we do change which ones we use from time to time. \u003c/p\u003e\u003cp\u003eIt is important to also note that we send the appropriate intermediate certificates with every certificate request via the \u003ca href=\"https://tools.ietf.org/html/rfc8555#section-7.4.2\" target=\"_blank\"\u003eACME protocol.\u003c/a\u003e \u003c/p\u003e\u003cp\u003e\u003cb\u003eWhy should I use Google Trust Services instead of another certificate authority?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eThere are multiple good ACME CAs you may use. \u003c/p\u003e\u003cp\u003eWe envision a world where those that deploy SSL use a number of ACME based certificate authorities to enable sites to continue to operate without downtime when one provider has availability issues. If you need a large number of certificates or guarantees on geographic diversity, the GTS CA may be an especially good fit.\u003c/p\u003e\u003cp\u003eIt is our hope that by making this service available to cloud customers they will be able to get the benefit of that robustness, and reduce latency for workloads terminating TLS within Google Cloud. \u003c/p\u003e\u003cp\u003e\u003cb\u003eYou recently announced Certificate Manager, is this an alternative to that offering?\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eNo it is not. This extends Certificate Manager so that workloads that choose to terminate TLS on their own are able to get certificates from the same CA we use when we manage your certificates for you.\u003c/p\u003e\u003cp\u003eIt is our hope that with this ACME API, you will be able to simplify your HTTPS certificate lifecycle management for your workloads.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/identity-security/simplify-saas-scale-tls-certificate-management/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/google_cloud_security.0999040819990817.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eIntroducing Certificate Manager to simplify SaaS scale TLS and certificate management\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eCloud Certificate Manager lets our users acquire and manage TLS certificates for use with Cloud Load Balancing.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://cloud.google.com/blog/static/assets/GCP_Twitter_Card-2000×1000.png",
      "date_published": "2022-03-29T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eBabi Seal\u003c/name\u003e\u003ctitle\u003eProduct Manager, Load Balancing\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/devops-best-practices-add-severity-levels-to-alerts/",
      "title": "Add severity levels to your alert policies in Cloud Monitoring",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c77=\"\"\u003e\u003cdiv _ngcontent-c77=\"\" innerhtml=\"\u0026lt;p\u0026gt;When you are dealing with a situation that fires a bevy of alerts, do you instinctively know which alerts are the most pressing? Severity levels are an important concept in alerting to aid you and your team in properly assessing which notifications should be prioritized. You can use these levels to focus on the issues deemed most critical for your operations and triage through the noise. Today, we\u0026amp;#8217;re happy to announce that you can create custom severity levels on your alert policies and have this data included in your notifications for more effective alerting and integration with downstream third-party services (e.g. Webhook, Cloud Pub/Sub, PagerDuty).\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The \u0026lt;a href=\u0026#34;https://cloud.google.com/monitoring/support/notification-options\u0026#34;\u0026gt;notification channels\u0026lt;/a\u0026gt; have been enhanced to accept this data - including Email, Webhooks, Cloud Pub/Sub, and PagerDuty - with planned support for Slack at a later time. This enables further automation/customization based on importance wherever the notifications are consumed.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Below, we\u0026#39;ll walk through examples of \u0026lt;a href=\u0026#34;https://cloud.google.com/monitoring/alerts/labels\u0026#34;\u0026gt;how to add\u0026lt;/a\u0026gt; static and dynamic severity levels to an Alert Policy.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Create user labels to support static severity levels\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;When you add user labels on an alert policy, they will appear on every notification and incident generated by that alert policy. Refer to the \u0026lt;a href=\u0026#34;https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.alertPolicies\u0026#34;\u0026gt;documentation\u0026lt;/a\u0026gt; to see how to add user labels to alert policies via the Alert Policy API.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Let\u0026amp;#8217;s walk through an example: suppose you want to configure Alert Policies that notify you when the CPU utilization crosses a particular threshold. Further, you want the notifications to indicate the following severity levels:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;INFO\u0026lt;/code\u0026gt; when CPU utilization is between 70% and 80%\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;WARNING\u0026lt;/code\u0026gt; when CPU utilization is between 80% and 90%\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;CRITICAL\u0026lt;/code\u0026gt; when CPU utilization is above 90%\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;To accomplish this, you can create three separate alert policies with user labels defined as below:\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Create alert policy (\u0026lt;code\u0026gt;A\u0026lt;/code\u0026gt;) which triggers when the CPU utilization is above 90%, and includes the following user labels: any incident generated by this policy will include a label \u0026lt;code\u0026gt;Severity\u0026lt;/code\u0026gt; with value \u0026lt;code\u0026gt;CRITICAL\u0026lt;/code\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;\u0026amp;#34;userLabels\u0026amp;#34;: {\u0026lt;/code\u0026gt;\u0026lt;br\u0026gt;\u0026amp;#160;\u0026amp;#160;\u0026amp;#160;\u0026amp;#160;\u0026lt;code\u0026gt;\u0026amp;#8220;Severity\u0026amp;#8221;: \u0026amp;#8220;CRITICAL\u0026amp;#8221;,\u0026lt;/code\u0026gt;\u0026lt;br\u0026gt;\u0026lt;code\u0026gt;}\u0026lt;/code\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Create a second policy (\u0026lt;code\u0026gt;B\u0026lt;/code\u0026gt;) which triggers when resource CPU utilization is above 80%, and includes the following user labels: any incident generated on this policy will include a label \u0026lt;code\u0026gt;Severity\u0026lt;/code\u0026gt; with value \u0026lt;code\u0026gt;WARNING\u0026lt;/code\u0026gt;.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;\u0026amp;#34;userLabels\u0026amp;#34;: {\u0026lt;/code\u0026gt;\u0026lt;br\u0026gt;\u0026amp;#160; \u0026amp;#160;\u0026amp;#160;\u0026lt;code\u0026gt;\u0026amp;#8220;Severity\u0026amp;#8221;: \u0026amp;#8220;WARNING\u0026amp;#8221;,\u0026lt;/code\u0026gt;\u0026lt;br\u0026gt;\u0026lt;code\u0026gt;}\u0026lt;/code\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Create a third policy (\u0026lt;code\u0026gt;C\u0026lt;/code\u0026gt;) which triggers when resource CPU utilization is above 70%, and includes the following user labels: any incident generated on this policy will include a label \u0026lt;code\u0026gt;Severity\u0026lt;/code\u0026gt; with value \u0026lt;code\u0026gt;INFO\u0026lt;/code\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;\u0026amp;#34;userLabels\u0026amp;#34;: {\u0026lt;/code\u0026gt;\u0026lt;br\u0026gt;\u0026amp;#160; \u0026amp;#160;\u0026amp;#160;\u0026lt;code\u0026gt;\u0026amp;#8220;Severity\u0026amp;#8221;: \u0026amp;#8220;INFO\u0026amp;#8221;,\u0026lt;/code\u0026gt;\u0026lt;br\u0026gt;\u0026lt;code\u0026gt;}\u0026lt;/code\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In this scenario, when the CPU utilization crosses a threshold of 90% policies \u0026lt;code\u0026gt;A\u0026lt;/code\u0026gt;, \u0026lt;code\u0026gt;B\u0026lt;/code\u0026gt;, and \u0026lt;code\u0026gt;C\u0026lt;/code\u0026gt; will trigger alerts. If the CPU utilization falls back down to 85%, the incident from policy \u0026lt;code\u0026gt;A\u0026lt;/code\u0026gt; will close, but the incidents from policies \u0026lt;code\u0026gt;B\u0026lt;/code\u0026gt; and \u0026lt;code\u0026gt;C\u0026lt;/code\u0026gt; will remain open. If the CPU utilization falls even further down to 75%, the incident from policy \u0026lt;code\u0026gt;B\u0026lt;/code\u0026gt; will close, and the incident from policy C will remain open. If the CPU utilization drops down to 40%, incidents generated by all three policies will automatically close.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Use MQL to create dynamic severity levels\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Alert policy user labels are static in nature, meaning you cannot dynamically apply user labels based on a changing threshold. As shown earlier, you need to create three separate alert policies to generate notifications that contain user label \u0026lt;code\u0026gt;Severity\u0026lt;/code\u0026gt; with value:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;INFO\u0026lt;/code\u0026gt; below a threshold of 80%,\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;WARNING\u0026lt;/code\u0026gt; below a threshold of 90%, and\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;CRITICAL\u0026lt;/code\u0026gt; above a threshold of 90%.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;If you\u0026#39;d like to dynamically apply the severity level based on threshold within a single alert policy, you can use MQL. You can \u0026lt;a href=\u0026#34;https://cloud.google.com/monitoring/mql/alerts\u0026#34;\u0026gt;utilize MQL to create alert policies\u0026lt;/a\u0026gt; with dynamic custom metric labels that will be embedded in the incident. Via MQL \u0026lt;a href=\u0026#34;https://cloud.google.com/monitoring/mql/reference#map\u0026#34;\u0026gt;map\u0026lt;/a\u0026gt;, you can specify what threshold level should result in which severity label. This means you can accomplish the above scenario of three severity levels based on threshold by creating only one alert policy.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Take the sample MQL query below:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eWhen you are dealing with a situation that fires a bevy of alerts, do you instinctively know which alerts are the most pressing? Severity levels are an important concept in alerting to aid you and your team in properly assessing which notifications should be prioritized. You can use these levels to focus on the issues deemed most critical for your operations and triage through the noise. Today, we’re happy to announce that you can create custom severity levels on your alert policies and have this data included in your notifications for more effective alerting and integration with downstream third-party services (e.g. Webhook, Cloud Pub/Sub, PagerDuty). \u003c/p\u003e\u003cp\u003eThe \u003ca href=\"https://cloud.google.com/monitoring/support/notification-options\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/monitoring/support/notification-options\" track-metadata-module=\"post\"\u003enotification channels\u003c/a\u003e have been enhanced to accept this data - including Email, Webhooks, Cloud Pub/Sub, and PagerDuty - with planned support for Slack at a later time. This enables further automation/customization based on importance wherever the notifications are consumed.\u003c/p\u003e\u003cp\u003eBelow, we\u0026#39;ll walk through examples of \u003ca href=\"https://cloud.google.com/monitoring/alerts/labels\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/monitoring/alerts/labels\" track-metadata-module=\"post\"\u003ehow to add\u003c/a\u003e static and dynamic severity levels to an Alert Policy. \u003c/p\u003e\u003ch3\u003eCreate user labels to support static severity levels\u003c/h3\u003e\u003cp\u003eWhen you add user labels on an alert policy, they will appear on every notification and incident generated by that alert policy. Refer to the \u003ca href=\"https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.alertPolicies\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.alertPolicies\" track-metadata-module=\"post\"\u003edocumentation\u003c/a\u003e to see how to add user labels to alert policies via the Alert Policy API. \u003c/p\u003e\u003cp\u003eLet’s walk through an example: suppose you want to configure Alert Policies that notify you when the CPU utilization crosses a particular threshold. Further, you want the notifications to indicate the following severity levels:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eINFO\u003c/code\u003e when CPU utilization is between 70% and 80%\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eWARNING\u003c/code\u003e when CPU utilization is between 80% and 90%\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eCRITICAL\u003c/code\u003e when CPU utilization is above 90%\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eTo accomplish this, you can create three separate alert policies with user labels defined as below:\u003c/p\u003e\u003cp\u003eCreate alert policy (\u003ccode\u003eA\u003c/code\u003e) which triggers when the CPU utilization is above 90%, and includes the following user labels: any incident generated by this policy will include a label \u003ccode\u003eSeverity\u003c/code\u003e with value \u003ccode\u003eCRITICAL\u003c/code\u003e.\u003c/p\u003e\u003cp\u003e\u003ccode\u003e\u0026#34;userLabels\u0026#34;: {\u003c/code\u003e\u003cbr/\u003e    \u003ccode\u003e“Severity”: “CRITICAL”,\u003c/code\u003e\u003cbr/\u003e\u003ccode\u003e}\u003c/code\u003e\u003c/p\u003e\u003cp\u003eCreate a second policy (\u003ccode\u003eB\u003c/code\u003e) which triggers when resource CPU utilization is above 80%, and includes the following user labels: any incident generated on this policy will include a label \u003ccode\u003eSeverity\u003c/code\u003e with value \u003ccode\u003eWARNING\u003c/code\u003e. \u003c/p\u003e\u003cp\u003e\u003ccode\u003e\u0026#34;userLabels\u0026#34;: {\u003c/code\u003e\u003cbr/\u003e    \u003ccode\u003e“Severity”: “WARNING”,\u003c/code\u003e\u003cbr/\u003e\u003ccode\u003e}\u003c/code\u003e\u003c/p\u003e\u003cp\u003eCreate a third policy (\u003ccode\u003eC\u003c/code\u003e) which triggers when resource CPU utilization is above 70%, and includes the following user labels: any incident generated on this policy will include a label \u003ccode\u003eSeverity\u003c/code\u003e with value \u003ccode\u003eINFO\u003c/code\u003e.\u003c/p\u003e\u003cp\u003e\u003ccode\u003e\u0026#34;userLabels\u0026#34;: {\u003c/code\u003e\u003cbr/\u003e    \u003ccode\u003e“Severity”: “INFO”,\u003c/code\u003e\u003cbr/\u003e\u003ccode\u003e}\u003c/code\u003e\u003c/p\u003e\u003cp\u003eIn this scenario, when the CPU utilization crosses a threshold of 90% policies \u003ccode\u003eA\u003c/code\u003e, \u003ccode\u003eB\u003c/code\u003e, and \u003ccode\u003eC\u003c/code\u003e will trigger alerts. If the CPU utilization falls back down to 85%, the incident from policy \u003ccode\u003eA\u003c/code\u003e will close, but the incidents from policies \u003ccode\u003eB\u003c/code\u003e and \u003ccode\u003eC\u003c/code\u003e will remain open. If the CPU utilization falls even further down to 75%, the incident from policy \u003ccode\u003eB\u003c/code\u003e will close, and the incident from policy C will remain open. If the CPU utilization drops down to 40%, incidents generated by all three policies will automatically close.\u003c/p\u003e\u003ch3\u003eUse MQL to create dynamic severity levels\u003c/h3\u003e\u003cp\u003eAlert policy user labels are static in nature, meaning you cannot dynamically apply user labels based on a changing threshold. As shown earlier, you need to create three separate alert policies to generate notifications that contain user label \u003ccode\u003eSeverity\u003c/code\u003e with value:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eINFO\u003c/code\u003e below a threshold of 80%,\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eWARNING\u003c/code\u003e below a threshold of 90%, and\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eCRITICAL\u003c/code\u003e above a threshold of 90%.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eIf you\u0026#39;d like to dynamically apply the severity level based on threshold within a single alert policy, you can use MQL. You can \u003ca href=\"https://cloud.google.com/monitoring/mql/alerts\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/monitoring/mql/alerts\" track-metadata-module=\"post\"\u003eutilize MQL to create alert policies\u003c/a\u003e with dynamic custom metric labels that will be embedded in the incident. Via MQL \u003ca href=\"https://cloud.google.com/monitoring/mql/reference#map\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/monitoring/mql/reference#map\" track-metadata-module=\"post\"\u003emap\u003c/a\u003e, you can specify what threshold level should result in which severity label. This means you can accomplish the above scenario of three severity levels based on threshold by creating only one alert policy.\u003c/p\u003e\u003cp\u003eTake the sample MQL query below:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWhen you are dealing with a situation that fires a bevy of alerts, do you instinctively know which alerts are the most pressing? Severity levels are an important concept in alerting to aid you and your team in properly assessing which notifications should be prioritized. You can use these levels to focus on the issues deemed most critical for your operations and triage through the noise. Today, we’re happy to announce that you can create custom severity levels on your alert policies and have this data included in your notifications for more effective alerting and integration with downstream third-party services (e.g. Webhook, Cloud Pub/Sub, PagerDuty). \u003c/p\u003e\u003cp\u003eThe \u003ca href=\"https://cloud.google.com/monitoring/support/notification-options\"\u003enotification channels\u003c/a\u003e have been enhanced to accept this data - including Email, Webhooks, Cloud Pub/Sub, and PagerDuty - with planned support for Slack at a later time. This enables further automation/customization based on importance wherever the notifications are consumed.\u003c/p\u003e\u003cp\u003eBelow, we'll walk through examples of \u003ca href=\"https://cloud.google.com/monitoring/alerts/labels\"\u003ehow to add\u003c/a\u003e static and dynamic severity levels to an Alert Policy. \u003c/p\u003e\u003ch3\u003eCreate user labels to support static severity levels\u003c/h3\u003e\u003cp\u003eWhen you add user labels on an alert policy, they will appear on every notification and incident generated by that alert policy. Refer to the \u003ca href=\"https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.alertPolicies\"\u003edocumentation\u003c/a\u003e to see how to add user labels to alert policies via the Alert Policy API. \u003c/p\u003e\u003cp\u003eLet’s walk through an example: suppose you want to configure Alert Policies that notify you when the CPU utilization crosses a particular threshold. Further, you want the notifications to indicate the following severity levels:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eINFO\u003c/code\u003e when CPU utilization is between 70% and 80%\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eWARNING\u003c/code\u003e when CPU utilization is between 80% and 90%\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eCRITICAL\u003c/code\u003e when CPU utilization is above 90%\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eTo accomplish this, you can create three separate alert policies with user labels defined as below:\u003c/p\u003e\u003cp\u003eCreate alert policy (\u003ccode\u003eA\u003c/code\u003e) which triggers when the CPU utilization is above 90%, and includes the following user labels: any incident generated by this policy will include a label \u003ccode\u003eSeverity\u003c/code\u003e with value \u003ccode\u003eCRITICAL\u003c/code\u003e.\u003c/p\u003e\u003cp\u003e\u003ccode\u003e\"userLabels\": {\u003c/code\u003e\u003cbr/\u003e    \u003ccode\u003e“Severity”: “CRITICAL”,\u003c/code\u003e\u003cbr/\u003e\u003ccode\u003e}\u003c/code\u003e\u003c/p\u003e\u003cp\u003eCreate a second policy (\u003ccode\u003eB\u003c/code\u003e) which triggers when resource CPU utilization is above 80%, and includes the following user labels: any incident generated on this policy will include a label \u003ccode\u003eSeverity\u003c/code\u003e with value \u003ccode\u003eWARNING\u003c/code\u003e. \u003c/p\u003e\u003cp\u003e\u003ccode\u003e\"userLabels\": {\u003c/code\u003e\u003cbr/\u003e    \u003ccode\u003e“Severity”: “WARNING”,\u003c/code\u003e\u003cbr/\u003e\u003ccode\u003e}\u003c/code\u003e\u003c/p\u003e\u003cp\u003eCreate a third policy (\u003ccode\u003eC\u003c/code\u003e) which triggers when resource CPU utilization is above 70%, and includes the following user labels: any incident generated on this policy will include a label \u003ccode\u003eSeverity\u003c/code\u003e with value \u003ccode\u003eINFO\u003c/code\u003e.\u003c/p\u003e\u003cp\u003e\u003ccode\u003e\"userLabels\": {\u003c/code\u003e\u003cbr/\u003e    \u003ccode\u003e“Severity”: “INFO”,\u003c/code\u003e\u003cbr/\u003e\u003ccode\u003e}\u003c/code\u003e\u003c/p\u003e\u003cp\u003eIn this scenario, when the CPU utilization crosses a threshold of 90% policies \u003ccode\u003eA\u003c/code\u003e, \u003ccode\u003eB\u003c/code\u003e, and \u003ccode\u003eC\u003c/code\u003e will trigger alerts. If the CPU utilization falls back down to 85%, the incident from policy \u003ccode\u003eA\u003c/code\u003e will close, but the incidents from policies \u003ccode\u003eB\u003c/code\u003e and \u003ccode\u003eC\u003c/code\u003e will remain open. If the CPU utilization falls even further down to 75%, the incident from policy \u003ccode\u003eB\u003c/code\u003e will close, and the incident from policy C will remain open. If the CPU utilization drops down to 40%, incidents generated by all three policies will automatically close.\u003c/p\u003e\u003ch3\u003eUse MQL to create dynamic severity levels\u003c/h3\u003e\u003cp\u003eAlert policy user labels are static in nature, meaning you cannot dynamically apply user labels based on a changing threshold. As shown earlier, you need to create three separate alert policies to generate notifications that contain user label \u003ccode\u003eSeverity\u003c/code\u003e with value:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eINFO\u003c/code\u003e below a threshold of 80%,\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eWARNING\u003c/code\u003e below a threshold of 90%, and\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ccode\u003eCRITICAL\u003c/code\u003e above a threshold of 90%.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eIf you'd like to dynamically apply the severity level based on threshold within a single alert policy, you can use MQL. You can \u003ca href=\"https://cloud.google.com/monitoring/mql/alerts\"\u003eutilize MQL to create alert policies\u003c/a\u003e with dynamic custom metric labels that will be embedded in the incident. Via MQL \u003ca href=\"https://cloud.google.com/monitoring/mql/reference#map\"\u003emap\u003c/a\u003e, you can specify what threshold level should result in which severity label. This means you can accomplish the above scenario of three severity levels based on threshold by creating only one alert policy.\u003c/p\u003e\u003cp\u003eTake the sample MQL query below:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u\"fetch gce_instance\\r\\n| metric 'compute.googleapis.com/instance/cpu/utilization'\\r\\n| filter (metadata.user_labels.env == 'prod') \u0026amp;\u0026amp; (resource.zone =~ 'asia.*')\\r\\n| group_by sliding(5m), [value_utilization_mean: mean(value.utilization)]\\r\\n| map\\r\\n add[\\r\\n Severity:\\r\\n if(val() \u0026gt; 90 '%', 'CRITICAL',\\r\\n if(val() \u0026gt;= 80 '%' \u0026amp;\u0026amp; val() \u0026lt;= 90 '%', 'WARNING', 'INFO'))]\\r\\n| condition val() \u0026gt; 70 '%'\"), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIn this example, an incident will be created any time CPU utilization is above a threshold of 70%. If the value is between 70-80%, the incident will contain a metric label called \u003ccode\u003eSeverity\u003c/code\u003e with value \u003ccode\u003eINFO\u003c/code\u003e. If the value is between 80-90%, the metric label \u003ccode\u003eSeverity\u003c/code\u003e will have value WARNING, and if the value is above 90%, the label \u003ccode\u003eSeverity\u003c/code\u003e will have value \u003ccode\u003eCRITICAL\u003c/code\u003e.\u003c/p\u003e\u003cp\u003eIn the above scenario, if the CPU utilization value starts at 92%, incident A will be created with severity level \u003ccode\u003eCRITICAL\u003c/code\u003e. If the utilization value then drops down to 73%, a new incident \u003ccode\u003eB\u003c/code\u003e will be opened with severity level \u003ccode\u003eINFO\u003c/code\u003e. Incident \u003ccode\u003eA\u003c/code\u003e, however, will remain open. If the value jumps to 82%, a new incident \u003ccode\u003eC\u003c/code\u003e will open with severity level \u003ccode\u003eWARNING\u003c/code\u003e and incidents \u003ccode\u003eA\u003c/code\u003e and \u003ccode\u003eB\u003c/code\u003e will remain open. If \u003ca href=\"https://cloud.google.com/monitoring/alerts/incidents-events#closing\"\u003eauto-close\u003c/a\u003e is configured in your policy with a duration of 30 minutes, incident `A` will auto-close 30 minutes after incident `B` starts, and incident `B` will auto-close 30 minutes after incident `C` starts.  If the value drops below 70%, all incidents will close. \u003c/p\u003e\u003cp\u003eIn order to ensure the alert policy only has one incident open at a time with the correct corresponding label, and to avoid waiting for incidents to auto-close as in the example above, set \u003ca href=\"https://cloud.google.com/monitoring/alerts/concepts-indepth#partial-metric-data\"\u003eevaluationMissingData\u003c/a\u003e to \u003ccode\u003eEVALUATION_MISSING_DATA_INACTIVE\u003c/code\u003e in your API request. This field tells the Alert Policy how to handle situations when the metric stream has sparse or missing data, so the incident can be closed appropriately as needed. If you are making your MQL alert policy in the UI, select the \u003ccode\u003eMissing data points treated as values that do not violate the policy condition\u003c/code\u003e button in the \u003ccode\u003eAdvanced Options\u003c/code\u003e dropdown in the \u003ccode\u003eConfigure Trigger\u003c/code\u003e section:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Monitoring_trigger.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Monitoring trigger.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Monitoring_trigger.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWhen \u003ccode\u003eEVALUATION_MISSING_DATA_INACTIVE\u003c/code\u003e is specified in the above scenario, incident \u003ccode\u003eA\u003c/code\u003e will close once incident\u003ccode\u003eB\u003c/code\u003e is created, and incident \u003ccode\u003eB\u003c/code\u003e will close once incident \u003ccode\u003eC\u003c/code\u003e is created.\u003c/p\u003e\u003ch3\u003eSeverity Labels in Notification Channels\u003c/h3\u003e\u003cp\u003eIf you send \u003ca href=\"https://cloud.google.com/monitoring/api/ref_v3/rest/v3/projects.notificationChannels#resource:-notificationchannel\"\u003enotifications\u003c/a\u003e to a third-party service like \u003ca href=\"https://cloud.google.com/monitoring/support/notification-options#creating_channels\"\u003ePagerDuty, Webhooks, or Pub/Sub\u003c/a\u003e then you can parse the JSON payload and route the notification according to its severity so that critical information is not missed by your team. \u003c/p\u003e\u003cp\u003eIf you utilize alert policy user labels, these will appear as an object on the notification with the key \u003ccode\u003epolicy_user_labels\u003c/code\u003e i.e.:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'\"policy_user_labels\": {\\r\\n \"Severity\": \"CRITICAL\",\\r\\n}'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIf you utilize metric labels via MQL, these will appear as an object with key \u003ccode\u003elabels\u003c/code\u003e nested in an object with key \u003ccode\u003emetric\u003c/code\u003e i.e.:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'\"metric\": {\\r\\n \"displayName\": \"Some Display Name\",\\r\\n \"labels\": {\\r\\n \"instance_name\": \"some_instance_name\",\\r\\n \"Severity\": \"CRITICAL\"\\r\\n },\\r\\n }'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eGet Started Today\u003c/h3\u003e\u003cp\u003eAlerts can be configured on nearly any metric, log, or trace (or the absence of that data) that is captured in \u003ca href=\"https://cloud.google.com/products/operations\"\u003eGoogle Cloud’s operations suite\u003c/a\u003e. Severity levels give you and your teams an additional way to cut through noise to find the issues that you know will have the most positive impact when resolved. Check out this video on \u003ca href=\"https://youtu.be/4RgJjx4IxMs\" target=\"_blank\"\u003elog alerts\u003c/a\u003e as part of our Observability in-depth video series and if you have questions, feature requests, or just want to read topics from other customers who are using Cloud Alerting, visit our \u003ca href=\"https://www.googlecloudcommunity.com/gc/Google-Cloud-s-operations-suite/bd-p/cloud-operations\" target=\"_blank\"\u003eGoogle Cloud Community site\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/operations/pub-sub-webook-and-slack-notifications-are-now-available/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Genric_GCP_upA1oyz.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eWebhook, Pub/Sub, and Slack Alerting notification channels launched\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eAnnouncing the general availability of the new Pub/Sub, Webhook, and Slack Notification channels.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://cloud.google.com/blog/static/assets/GCP_Twitter_Card-2000×1000.png",
      "date_published": "2022-03-29T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eAlizah Lalani\u003c/name\u003e\u003ctitle\u003eSoftware Engineer\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/topics/cloud-first/whats-new-cloud-native-apps/",
      "title": "What’s new in cloud-native apps?",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eDevelopers and IT operations pros of all stripes come to Google Cloud to build modern, cloud-first and cloud-native applications. Here’s the latest from Google Cloud on everything app dev, containers, Kubernetes, DevOps, serverless and open source, all in one place.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eWeek of Mar 14 - Mar 18 2022\u003c/h3\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cb\u003eCreate EventArc triggers with Terraform\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eIn addition to the Google Cloud Console or gcloud, you can also use a Terraform resource to create an Eventarc trigger. Mete Atamel \u003ca href=\"https://cloud.google.com/blog/topics/developers-practitioners/creating-eventarc-triggers-terraform\"\u003eshows you how\u003c/a\u003e. \u003c/p\u003e\u003cp\u003e\u003cb\u003eScaling to new markets with Cloud Run\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eFrench publisher Les Echos Le Parisien Annonces switched from dedicated on-prem infrastructure to Cloud Run to supplement its main news site with regional variations. Les Echos shares its \u003ca href=\"https://cloud.google.com/blog/products/serverless/paris-based-news-organization-expands-markets-with-serverless-containers-and-php-cms\"\u003ewebsite architecture\u003c/a\u003e here. \u003c/p\u003e\u003cp\u003e\u003cb\u003eThe serverless way to celebrate Pi Day\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eIn honor of Pi Day, Google Cloud Developer Advocate Emma Haruka Iwao shows you how to use the new Cloud Functions (2nd gen) to \u003ca href=\"https://cloud.google.com/blog/topics/developers-practitioners/celebrating-pi-day-cloud-functions\"\u003ecalculate π\u003c/a\u003e — serverlessly.\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/containers-kubernetes/how-cruise-tests-its-avs-on-a-google-cloud-platform/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/automotive.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eBuilding continuous integration \u0026amp; continuous delivery for autonomous vehicles on Google Cloud\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eCruise relies on a whole host of Google Cloud technologies to develop and test the tech that goes into its autonomous vehicles, or AVs.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eWeek of Mar 07 - Mar 11 2022\u003c/h3\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cb\u003eRhode Island moves to Google Cloud-based job board\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eWhen the pandemic hit, the State of Rhode Island moved its workforce development operations entirely online on a foundation of Google Workspace and Google Cloud resources, including Firestore, Cloud Functions, and Kubernetes, among others. Check out \u003ca href=\"https://cloud.google.com/blog/topics/developers-practitioners/how-rhode-island-created-virtual-career-center\"\u003ehow they did it\u003c/a\u003e. \u003c/p\u003e\u003cp\u003e\u003cb\u003eContainerized microservices at Lowe’s\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eLowe’s already told us \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/how-lowes-leverages-google-sre-practices\"\u003ehow they use SRE\u003c/a\u003e. They’re at it again, describing how they built an e-commerce website using a \u003ca href=\"https://cloud.google.com/blog/topics/retail/how-google-cloud-services-helped-lowes-transform-ecommerce\"\u003econtainerized microservices architecture and Kubernetes\u003c/a\u003e, with Istio for service mesh and Cloud Operations for good measure.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCruise AVs hit the road with Google Cloud services\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eAutonomous Vehicle (AV) startup Cruise detailed how it’s using data analytics and machine learning on a foundation of Google Kubernetes Engine (GKE) and other services to develop and test its self-driving cars. \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/how-cruise-tests-its-avs-on-a-google-cloud-platform\"\u003eRead the guest post\u003c/a\u003e. \u003c/p\u003e\u003cp\u003e\u003cb\u003eL’Oréal’s data analytics gets a makeover with serverless\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eWe’re hurtling toward a \u003ca href=\"https://cloud.google.com/blog/products/serverless/introducing-the-programmable-cloud\"\u003eprogrammable cloud\u003c/a\u003e — a world where developers use cloud-native serverless tools like Cloud Functions to quickly prototype and build powerful, data-driven business insights. \u003ca href=\"https://cloud.google.com/blog/products/serverless/loreal-combines-google-cloud-serverless-and-data-offerings\"\u003eL’Oréal is a great example\u003c/a\u003e.  \u003c/p\u003e\u003cp\u003e\u003cb\u003eBetter telemetry for your Anthos clusters\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003ca href=\"https://cloud.google.com/service-mesh/docs/observability/explore-dashboard\"\u003eAnthos Service Mesh Dashboard\u003c/a\u003e is now available (public preview) on the \u003ca href=\"https://cloud.google.com/anthos/clusters/docs/bare-metal/latest\"\u003eAnthos clusters on Bare Metal\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/anthos/clusters/docs/on-prem/1.10\"\u003eAnthos clusters on VMware\u003c/a\u003e. Now, you can get out-of-the-box telemetry dashboards to see a services-first view of your application on the Cloud Console.\u003c/p\u003e\u003cp\u003e\u003cb\u003eInstrument your Java apps\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eWith the new version of the \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/google-cloud-logging-java-client-library-new-features\"\u003eGoogle Cloud Logging Java library\u003c/a\u003e, you can wire your application logs with more information — without adding a single line of code.\u003c/p\u003e\u003cp\u003e\u003cb\u003eVisualize metrics from Cloud Spanner\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eBuilding an app on top of Cloud Spanner but can’t assess how well it’s operating? The new \u003ca href=\"https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/googlecloudspannerreceiver\" target=\"_blank\"\u003eOpenTelemetery receiver for Cloud Spanner\u003c/a\u003e provides an easy way for you to process and visualize metrics from Cloud Spanner \u003ca href=\"https://cloud.google.com/spanner/docs/introspection\"\u003eSystem tables\u003c/a\u003e, and export these to the APM tool of your choice. \u003ca href=\"https://cloud.google.com/blog/products/databases/consume-spanner-metrics-using-opentelemetery\"\u003eRead more here\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/containers-kubernetes/knative-enters-the-cncf-as-an-incubating-project/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/knative.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eCongratulations Knative on becoming part of the CNCF\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eKnative enters the CNCF as an incubating project\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eWeek of Feb 28 - Mar 4 2022\u003c/h3\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntroducing Cloud SDK\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eThe rebranded \u003ca href=\"https://cloud.google.com/sdk\"\u003eCloud SDK\u003c/a\u003e is a collection of all the libraries and tools (including Google Cloud CLI) you need to interact with Google Cloud products and services. Learn more \u003ca href=\"https://cloud.google.com/blog/products/application-development/redesigning-the-cloud-sdk-cli-for-easier-development\"\u003ehere\u003c/a\u003e. \u003c/p\u003e\u003cp\u003e\u003cb\u003eCloud CLI, meet Terraform\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eGoogle Cloud CLI’s new Declarative Export for Terraform allows you to export the current state of your Google Cloud infrastructure into a descriptive file compatible with Terraform (HCL) or Google’s KRM declarative tooling, and is now \u003ca href=\"https://cloud.google.com/blog/products/application-development/google-cloud-cli-declarative-export-preview\"\u003eavailable in preview\u003c/a\u003e. \u003c/p\u003e\u003cp\u003e\u003cb\u003eKnative graduates to incubating project \u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003eCongratulations to Knative, which has been \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/knative-enters-the-cncf-as-an-incubating-project\"\u003eaccepted by the Cloud Native Computing Foundation\u003c/a\u003e, or CNCF, as an incubating project, enabling the next phase of serverless architecture. \u003c/p\u003e\u003cp\u003e\u003cb\u003eWe manage Prometheus so you don’t have to\u003c/b\u003e\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003ca href=\"https://cloud.google.com/stackdriver/docs/managed-prometheus\"\u003eGoogle Cloud Managed Service for Prometheus\u003c/a\u003e is now generally available! Get all the benefits of open source-compatible monitoring with the ease of use of Google-scale managed services. \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/easy-managed-prometheus-metrics-service-for-kubernetes\"\u003eLearn more here\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/original_images/inframod_living_3.jpg",
      "date_published": "2022-03-18T20:00:00Z",
      "author": {
        "name": "\u003cname\u003eGoogle Cloud Content \u0026 Editorial \u003c/name\u003e\u003ctitle\u003e\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/google-cloud-logging-java-client-library-new-features/",
      "title": "Get more insights from your Java applications logs",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle-content-stream-block\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c74=\"\"\u003e\u003cdiv _ngcontent-c74=\"\" innerhtml=\"\u0026lt;p\u0026gt;Today it is even easier to capture logs in your Java applications. Developers can get more data with their application logs using a new version of the Cloud Logging client library for Java. The library populates the current executing context implicitly with every ingested log entry. Read this if you want to learn how to get HTTP requests and tracing information and additional metadata in your logs without writing a single line of code.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;There are three ways to ingest log data into Google Cloud Logging:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Develop a proprietary solution that directly calls the \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/api-overview\u0026#34;\u0026gt;Logging API\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Leverage logging capabilities of the Google Cloud managed environments like \u0026lt;a href=\u0026#34;https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#overview\u0026#34;\u0026gt;GKE\u0026lt;/a\u0026gt; or install Google Cloud \u0026lt;a href=\u0026#34;https://cloud.google.com/monitoring/agent\u0026#34;\u0026gt;Ops agent\u0026lt;/a\u0026gt; and print your application logs to stdout and stderr.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Use Google Cloud \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/libraries\u0026#34;\u0026gt;Logging client library\u0026lt;/a\u0026gt; in one of many supported programming languages.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;The library provides you with ready to use boilerplate constructs built following the best practices of using Logging API. Java applications can use the Google Cloud Logging library to ingest logs using the integrations with \u0026lt;a href=\u0026#34;https://docs.oracle.com/javase/10/core/java-logging-overview.htm\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Java Logging\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://logback.qos.ch/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Logback framework\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;If you are new to using Google Logging client libraries for Java, follow the steps to \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/setup/java\u0026#34;\u0026gt;set up Cloud Logging for Java\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/libraries\u0026#34;\u0026gt;get started\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In the version 3.6 release of the the Logging client library for Java you get many long demanding features including automatic population of the metadata about the environment\u0026#39;s resource supporting Cloud Run and Cloud Functions, HTTP request contextual information, tracing correlation that enables displaying grouped log entries in Logs Explorer and more. This release of the library is composed of the three packages:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://github.com/googleapis/java-logging\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;google-cloud-logging\u0026lt;/a\u0026gt; -- provides the hand-written layer above Cloud Logging API and the integration with legacy \u0026lt;a href=\u0026#34;https://docs.oracle.com/javase/10/core/java-logging-overview.htm\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Java Logging\u0026lt;/a\u0026gt; solution.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://github.com/googleapis/java-logging-logback\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;google-cloud-logging-logback\u0026lt;/a\u0026gt; is the integration with the Logback framework and ingests logs using the google-cloud-logging package.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://github.com/googleapis/java-logging-servlet-initializer\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;google-cloud-logging-servlet-initializer\u0026lt;/a\u0026gt; is a new addition to the library; it provides integration with servlet-based Web applications.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;The features are available in the versions \u0026amp;#8805;3.6.3 and \u0026amp;#8805;0.123.3-alpha of the google-cloud-logging and google-cloud-logging-logback packages respectively.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;If you are using \u0026lt;a href=\u0026#34;https://maven.apache.org/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Maven\u0026lt;/a\u0026gt;, update the packages\u0026#39; versions in the pom.xml:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eToday it is even easier to capture logs in your Java applications. Developers can get more data with their application logs using a new version of the Cloud Logging client library for Java. The library populates the current executing context implicitly with every ingested log entry. Read this if you want to learn how to get HTTP requests and tracing information and additional metadata in your logs without writing a single line of code.\u003c/p\u003e\u003cp\u003eThere are three ways to ingest log data into Google Cloud Logging:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eDevelop a proprietary solution that directly calls the \u003ca href=\"https://cloud.google.com/logging/docs/reference/api-overview\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/api-overview\" track-metadata-module=\"post\"\u003eLogging API\u003c/a\u003e.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eLeverage logging capabilities of the Google Cloud managed environments like \u003ca href=\"https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#overview\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#overview\" track-metadata-module=\"post\"\u003eGKE\u003c/a\u003e or install Google Cloud \u003ca href=\"https://cloud.google.com/monitoring/agent\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/monitoring/agent\" track-metadata-module=\"post\"\u003eOps agent\u003c/a\u003e and print your application logs to stdout and stderr.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eUse Google Cloud \u003ca href=\"https://cloud.google.com/logging/docs/reference/libraries\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/libraries\" track-metadata-module=\"post\"\u003eLogging client library\u003c/a\u003e in one of many supported programming languages.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThe library provides you with ready to use boilerplate constructs built following the best practices of using Logging API. Java applications can use the Google Cloud Logging library to ingest logs using the integrations with \u003ca href=\"https://docs.oracle.com/javase/10/core/java-logging-overview.htm\" target=\"_blank\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://docs.oracle.com\" track-metadata-module=\"post\"\u003eJava Logging\u003c/a\u003e and \u003ca href=\"https://logback.qos.ch/\" target=\"_blank\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://logback.qos.ch\" track-metadata-module=\"post\"\u003eLogback framework\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIf you are new to using Google Logging client libraries for Java, follow the steps to \u003ca href=\"https://cloud.google.com/logging/docs/setup/java\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/setup/java\" track-metadata-module=\"post\"\u003eset up Cloud Logging for Java\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/logging/docs/reference/libraries\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/libraries\" track-metadata-module=\"post\"\u003eget started\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIn the version 3.6 release of the the Logging client library for Java you get many long demanding features including automatic population of the metadata about the environment\u0026#39;s resource supporting Cloud Run and Cloud Functions, HTTP request contextual information, tracing correlation that enables displaying grouped log entries in Logs Explorer and more. This release of the library is composed of the three packages:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://github.com/googleapis/java-logging\" target=\"_blank\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003egoogle-cloud-logging\u003c/a\u003e -- provides the hand-written layer above Cloud Logging API and the integration with legacy \u003ca href=\"https://docs.oracle.com/javase/10/core/java-logging-overview.htm\" target=\"_blank\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://docs.oracle.com\" track-metadata-module=\"post\"\u003eJava Logging\u003c/a\u003e solution.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://github.com/googleapis/java-logging-logback\" target=\"_blank\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003egoogle-cloud-logging-logback\u003c/a\u003e is the integration with the Logback framework and ingests logs using the google-cloud-logging package.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://github.com/googleapis/java-logging-servlet-initializer\" target=\"_blank\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003egoogle-cloud-logging-servlet-initializer\u003c/a\u003e is a new addition to the library; it provides integration with servlet-based Web applications.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThe features are available in the versions ≥3.6.3 and ≥0.123.3-alpha of the google-cloud-logging and google-cloud-logging-logback packages respectively.\u003c/p\u003e\u003cp\u003eIf you are using \u003ca href=\"https://maven.apache.org/\" target=\"_blank\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://maven.apache.org\" track-metadata-module=\"post\"\u003eMaven\u003c/a\u003e, update the packages\u0026#39; versions in the pom.xml:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c75=\"\"\u003e\u003cpre _ngcontent-c75=\"\"\u003e  \u003ccode _ngcontent-c75=\"\"\u003e\u0026lt;dependency\u0026gt;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e  \u0026lt;groupId\u0026gt;com.google.cloud\u0026lt;/groupId\u0026gt;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e  \u0026lt;artifactId\u0026gt;google-cloud-logging\u0026lt;/artifactId\u0026gt;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e  \u0026lt;version\u0026gt;3.6.3\u0026lt;/version\u0026gt;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e\u0026lt;/dependency\u0026gt;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e\u0026lt;dependency\u0026gt;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e  \u0026lt;groupId\u0026gt;com.google.cloud\u0026lt;/groupId\u0026gt;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e  \u0026lt;artifactId\u0026gt;google-cloud-logging-logback\u0026lt;/artifactId\u0026gt;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e  \u0026lt;version\u0026gt;0.123.3-alpha\u0026lt;/version\u0026gt;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e\u0026lt;/dependency\u0026gt;\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c74=\"\"\u003e\u003cp\u003eIf you are using \u003ca href=\"https://gradle.org/\" target=\"_blank\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://gradle.org\" track-metadata-module=\"post\"\u003eGradle\u003c/a\u003e, , update your dependencies:\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c75=\"\"\u003e\u003cpre _ngcontent-c75=\"\"\u003e  \u003ccode _ngcontent-c75=\"\"\u003eimplementation \u0026#39;com.google.cloud:google-cloud-logging:3.6.3\u0026#39;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003eimplementation \u0026#39;com.google.cloud:google-cloud-logging-logback:0.123.3-alpha\u0026#39;\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c74=\"\"\u003e\u003cdiv _ngcontent-c74=\"\" innerhtml=\"\u0026lt;p\u0026gt;You can use the official Google Cloud BOM version 0.167.0 that includes the new releases of the packages.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;What is new\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;The Java library inserts structured information about the executing environment including resource types, HTTP request metadata, tracing and more. Using the library you can write your payloads in one of the three formats:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;A text provided as a Java string\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;A JSON object provided as an instance of \u0026lt;a href=\u0026#34;https://docs.oracle.com/javase/8/docs/api/java/util/Map.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Map\u0026amp;lt;String, ?\u0026amp;gt;\u0026lt;/a\u0026gt; or \u0026lt;a href=\u0026#34;https://developers.google.com/protocol-buffers/docs/reference/java/com/google/protobuf/Struct\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Struct\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;A protobuf object provided as an instance of \u0026lt;a href=\u0026#34;https://developers.google.com/protocol-buffers/docs/reference/java/com/google/protobuf/Any\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Any\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;You can use the structured logs with enhanced filtering in Logs Explorer to observe and troubleshoot their applications. The Logs Explorer uses structured logs to establish \u0026lt;a href=\u0026#34;https://cloud.google.com/trace/docs/trace-log-integration\u0026#34;\u0026gt;correlations\u0026lt;/a\u0026gt; between traces and logs and to group together logs that belong to the same transaction. The correlated \u0026amp;#34;child\u0026amp;#34; logs are displayed \u0026amp;#34;under\u0026amp;#34; the entry of the \u0026amp;#34;parent\u0026amp;#34; log:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eYou can use the official Google Cloud BOM version 0.167.0 that includes the new releases of the packages.\u003c/p\u003e\u003ch3\u003eWhat is new\u003c/h3\u003e\u003cp\u003eThe Java library inserts structured information about the executing environment including resource types, HTTP request metadata, tracing and more. Using the library you can write your payloads in one of the three formats:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eA text provided as a Java string\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eA JSON object provided as an instance of \u003ca href=\"https://docs.oracle.com/javase/8/docs/api/java/util/Map.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://docs.oracle.com\" track-metadata-module=\"post\"\u003eMap\u0026lt;String, ?\u0026gt;\u003c/a\u003e or \u003ca href=\"https://developers.google.com/protocol-buffers/docs/reference/java/com/google/protobuf/Struct\" target=\"_blank\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://developers.google.com\" track-metadata-module=\"post\"\u003eStruct\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eA protobuf object provided as an instance of \u003ca href=\"https://developers.google.com/protocol-buffers/docs/reference/java/com/google/protobuf/Any\" target=\"_blank\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://developers.google.com\" track-metadata-module=\"post\"\u003eAny\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eYou can use the structured logs with enhanced filtering in Logs Explorer to observe and troubleshoot their applications. The Logs Explorer uses structured logs to establish \u003ca href=\"https://cloud.google.com/trace/docs/trace-log-integration\" track-type=\"inline link\" track-name=\"18\" track-metadata-eventdetail=\"https://cloud.google.com/trace/docs/trace-log-integration\" track-metadata-module=\"post\"\u003ecorrelations\u003c/a\u003e between traces and logs and to group together logs that belong to the same transaction. The correlated \u0026#34;child\u0026#34; logs are displayed \u0026#34;under\u0026#34; the entry of the \u0026#34;parent\u0026#34; log:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c74=\"\"\u003e\u003cp\u003eWith the previous versions of the Logging library you had to write code to explicitly populate these fields. For example, developers that use Logback framework had to write a code like below to populate the \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.trace\" track-type=\"inline link\" track-name=\"19\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.trace\" track-metadata-module=\"post\"\u003etrace\u003c/a\u003e field of the ingested logs:\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c75=\"\"\u003e\u003cpre _ngcontent-c75=\"\"\u003e  \u003ccode _ngcontent-c75=\"\"\u003e// . . .\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003eString traceInfo = request.getHeader(\u0026#34;x-cloud-trace-context\u0026#34;);\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003eTraceLoggingEventEnhancer.setCurrentTraceId(traceInfo);\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e// . . .\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c74=\"\"\u003e\u003cdiv _ngcontent-c74=\"\" innerhtml=\"\u0026lt;p\u0026gt;And to invoke this code at the beginning of each transaction.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The new features of the Logging library makes implementing the population logic unnecessary. The new version of the library supports automatic population of following log entry fields:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.resource\u0026#34;\u0026gt;resource\u0026lt;/a\u0026gt; \u0026amp;#8210; describes the resource type and its attributes where the application is running. Along with GCE instances, it supports Google Cloud managed services such as GKE, AppEngine (both Standard and Flexible), Cloud Run and Cloud Functions.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.http_request\u0026#34;\u0026gt;httpRequest\u0026lt;/a\u0026gt; \u0026amp;#8210; captures info about HTTP requests from the current application\u0026#39;s context. The context is defined per-thread and can be populated both explicitly in the application code or implicitly from the \u0026lt;a href=\u0026#34;https://docs.oracle.com/cd/E26180_01/Platform.94/ATGProgGuide/html/s0801requesthandlingwithservletpipeli01.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Jakarta servlet requests pipeline\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.trace\u0026#34;\u0026gt;trace\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.span_id\u0026#34;\u0026gt;spanId\u0026lt;/a\u0026gt; \u0026amp;#8210; reads the tracing data from the HTTP request header. The tracing data assists in correlating multiple logs that belong to the same transaction.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.source_location\u0026#34;\u0026gt;sourceLocation\u0026lt;/a\u0026gt; \u0026amp;#8210; stores info about the class and method names as well as the line of code where the application called the log ingestion method. The library retrieves the data by traversing the trace stack up until the first entry that is not part of the Logging library code or the system package.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;What is left to you is to set the payload and relevant payload\u0026#39;s metadata labels. The only field in the \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\u0026#34;\u0026gt;log entry\u0026lt;/a\u0026gt; that the library does not automatically populate now is the \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.operation\u0026#34;\u0026gt;operation\u0026lt;/a\u0026gt; field.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Disable information auto-population in log entries\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;You have full control over the auto-population functionality. The auto-population is enabled by default for your convenience. But in certain scenarios it can be desirable to disable it. For example, if your application is log intensive and has a narrow bandwidth, you may want to disable the auto-population in order to save the connection\u0026#39;s bandwidth for the application communication.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;If you are ingesting logs using the \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/libraries#write_standard_logs\u0026#34;\u0026gt;write()\u0026lt;/a\u0026gt; method of the Logging interface\u0026lt;a href=\u0026#34;https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/Logging.java#L1209\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;,\u0026lt;/a\u0026gt; you can configure the LoggingOptions argument to disable the auto-population:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eAnd to invoke this code at the beginning of each transaction.\u003c/p\u003e\u003cp\u003eThe new features of the Logging library makes implementing the population logic unnecessary. The new version of the library supports automatic population of following log entry fields:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.resource\" track-type=\"inline link\" track-name=\"20\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.resource\" track-metadata-module=\"post\"\u003eresource\u003c/a\u003e ‒ describes the resource type and its attributes where the application is running. Along with GCE instances, it supports Google Cloud managed services such as GKE, AppEngine (both Standard and Flexible), Cloud Run and Cloud Functions.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.http_request\" track-type=\"inline link\" track-name=\"21\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.http_request\" track-metadata-module=\"post\"\u003ehttpRequest\u003c/a\u003e ‒ captures info about HTTP requests from the current application\u0026#39;s context. The context is defined per-thread and can be populated both explicitly in the application code or implicitly from the \u003ca href=\"https://docs.oracle.com/cd/E26180_01/Platform.94/ATGProgGuide/html/s0801requesthandlingwithservletpipeli01.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"22\" track-metadata-eventdetail=\"https://docs.oracle.com\" track-metadata-module=\"post\"\u003eJakarta servlet requests pipeline\u003c/a\u003e.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.trace\" track-type=\"inline link\" track-name=\"23\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.trace\" track-metadata-module=\"post\"\u003etrace\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.span_id\" track-type=\"inline link\" track-name=\"24\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.span_id\" track-metadata-module=\"post\"\u003espanId\u003c/a\u003e ‒ reads the tracing data from the HTTP request header. The tracing data assists in correlating multiple logs that belong to the same transaction.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.source_location\" track-type=\"inline link\" track-name=\"25\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.source_location\" track-metadata-module=\"post\"\u003esourceLocation\u003c/a\u003e ‒ stores info about the class and method names as well as the line of code where the application called the log ingestion method. The library retrieves the data by traversing the trace stack up until the first entry that is not part of the Logging library code or the system package.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWhat is left to you is to set the payload and relevant payload\u0026#39;s metadata labels. The only field in the \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\" track-type=\"inline link\" track-name=\"26\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\" track-metadata-module=\"post\"\u003elog entry\u003c/a\u003e that the library does not automatically populate now is the \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.operation\" track-type=\"inline link\" track-name=\"27\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.operation\" track-metadata-module=\"post\"\u003eoperation\u003c/a\u003e field.\u003c/p\u003e\u003ch3\u003eDisable information auto-population in log entries\u003c/h3\u003e\u003cp\u003eYou have full control over the auto-population functionality. The auto-population is enabled by default for your convenience. But in certain scenarios it can be desirable to disable it. For example, if your application is log intensive and has a narrow bandwidth, you may want to disable the auto-population in order to save the connection\u0026#39;s bandwidth for the application communication.\u003c/p\u003e\u003cp\u003eIf you are ingesting logs using the \u003ca href=\"https://cloud.google.com/logging/docs/reference/libraries#write_standard_logs\" track-type=\"inline link\" track-name=\"28\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/libraries#write_standard_logs\" track-metadata-module=\"post\"\u003ewrite()\u003c/a\u003e method of the Logging interface\u003ca href=\"https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/Logging.java#L1209\" target=\"_blank\" track-type=\"inline link\" track-name=\"29\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003e,\u003c/a\u003e you can configure the LoggingOptions argument to disable the auto-population:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c75=\"\"\u003e\u003cpre _ngcontent-c75=\"\"\u003e  \u003ccode _ngcontent-c75=\"\"\u003eLoggingOptions options = LoggingOptions.newBuilder()\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e    .setAutoPopulateMetadata(false).build();\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003eLogging logging = options.getService();\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c74=\"\"\u003e\u003cp\u003eIf you are using Java Logging, you can disable auto population by adding the following to your logging.properties file:\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c75=\"\"\u003e\u003cpre _ngcontent-c75=\"\"\u003e  \u003ccode _ngcontent-c75=\"\"\u003ecom.google.cloud.logging.LoggingHandler.autoPopulateMetadata=false\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c74=\"\"\u003e\u003cp\u003eIf you are using Logback framework, you can disable auto population by adding the following to your Logback configuration:\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c75=\"\"\u003e\u003cpre _ngcontent-c75=\"\"\u003e  \u003ccode _ngcontent-c75=\"\"\u003e\u0026lt;autoPopulateMetadata\u0026gt;false\u0026lt;/autoPopulateMetadata\u0026gt;\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c74=\"\"\u003e\u003cdiv _ngcontent-c74=\"\" innerhtml=\"\u0026lt;h3\u0026gt;How the current context is populated\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Rich query and display capabilities of Log Explorer such as displaying correlated logs use the log entries\u0026#39; fields such as httpRequest and trace. The new version of the library uses the \u0026lt;a href=\u0026#34;https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/Context.java\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Context\u0026lt;/a\u0026gt; class to store the information about the HTTP request and tracing data in the current application context. The context\u0026#39;s scope is per thread. Before the library ingests logs into Cloud Logging, it reads the HTTP request and tracing information from the current context and sets the respective fields in the log entries. The fields are populated only if the caller did not explicitly provide values in these fields. Using the \u0026lt;a href=\u0026#34;https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/ContextHandler.java\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;ContextHandler\u0026lt;/a\u0026gt; class you can setup the HTTP request and tracing data of the current context:\u0026lt;/p\u0026gt;\"\u003e\u003ch3\u003eHow the current context is populated\u003c/h3\u003e\u003cp\u003eRich query and display capabilities of Log Explorer such as displaying correlated logs use the log entries\u0026#39; fields such as httpRequest and trace. The new version of the library uses the \u003ca href=\"https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/Context.java\" target=\"_blank\" track-type=\"inline link\" track-name=\"30\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eContext\u003c/a\u003e class to store the information about the HTTP request and tracing data in the current application context. The context\u0026#39;s scope is per thread. Before the library ingests logs into Cloud Logging, it reads the HTTP request and tracing information from the current context and sets the respective fields in the log entries. The fields are populated only if the caller did not explicitly provide values in these fields. Using the \u003ca href=\"https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/ContextHandler.java\" target=\"_blank\" track-type=\"inline link\" track-name=\"31\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eContextHandler\u003c/a\u003e class you can setup the HTTP request and tracing data of the current context:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c75=\"\"\u003e\u003cpre _ngcontent-c75=\"\"\u003e  \u003ccode _ngcontent-c75=\"\"\u003eimport com.google.cloud.logging.HttpRequest;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e// . . .\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003eHttpRequest request;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e// . . .\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003eContextHandler ctxHandler = new ContextHandler();\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003eContext ctx = Context.newBuilder()\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e        .setRequest(request)\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e        .setTraceId(traceId)\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e        .setSpanId(spanId)\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e        .build();\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003ectxHandler.setCurrentContext(ctx);\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c74=\"\"\u003e\u003cp\u003eAfter the context is set all logs that will be ingested in the same scope as the context will be populated with the HTTP request and tracing information that was set in the current context. The \u003ca href=\"https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/Context.java\" target=\"_blank\" track-type=\"inline link\" track-name=\"32\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eContext\u003c/a\u003e class can setup the HTTP request using partial data such as URL or request method:\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c75=\"\"\u003e\u003cpre _ngcontent-c75=\"\"\u003e  \u003ccode _ngcontent-c75=\"\"\u003eimport com.google.cloud.logging.HttpRequest.RequestMethod;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e// . . .\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003eContextHandler ctxHandler = new ContextHandler();\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003eContext ctx = Context.newBuilder()\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e        .setRequestUrl(\u0026#34;https://example.com/info\u0026#34;)\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e        .setRequestMethod(RequestMethod.GET);\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e        .build();\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003ectxHandler.setCurrentContext(ctx);\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c74=\"\"\u003e\u003cdiv _ngcontent-c74=\"\" innerhtml=\"\u0026lt;p\u0026gt;The builder of the Context class also supports setting the tracing information from the parsed values of the \u0026lt;a href=\u0026#34;https://cloud.google.com/trace/docs/setup#force-trace\u0026#34;\u0026gt;Google tracing context\u0026lt;/a\u0026gt; and\u0026amp;#160; \u0026lt;a href=\u0026#34;https://www.w3.org/TR/trace-context/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;W3C tracing context\u0026lt;/a\u0026gt; strings using the methods \u0026lt;a href=\u0026#34;https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/Context.java#L116\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;loadCloudTraceContext()\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/Context.java#L149\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;loadW3CTraceParentContext()\u0026lt;/a\u0026gt; respectively.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Implementation of the context population can be a complex task. Java Web servers support asynchronous execution of the request handlers. To manage the context in the right scope may require in-depth knowledge of specific implementation details about each Web server. The new version of the Logging library provides a simple way to automate the process of the current context management, saving you the effort of implementing the code by themselves. The automation supports all Web servers that are based on the Jakarta servlets such as \u0026lt;a href=\u0026#34;https://tomcat.apache.org/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Tomcat\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://www.eclipse.org/jetty/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Jetty\u0026lt;/a\u0026gt; or \u0026lt;a href=\u0026#34;https://undertow.io/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Undertow\u0026lt;/a\u0026gt;. The current implementation supports Jakarta servlets version \u0026amp;#8805; 4.0.4. The implementation is added to the new \u0026lt;a href=\u0026#34;https://github.com/googleapis/java-logging-servlet-initializer\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;google-cloud-logging-servlet-initializer\u0026lt;/a\u0026gt; package. All that you have to do to enable automatic capturing of the current context is to add the package to your application.\u0026lt;/p\u0026gt;If you are using \u0026lt;a href=\u0026#34;https://maven.apache.org/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Maven\u0026lt;/a\u0026gt; add the following to your pom.xml:\"\u003e\u003cp\u003eThe builder of the Context class also supports setting the tracing information from the parsed values of the \u003ca href=\"https://cloud.google.com/trace/docs/setup#force-trace\" track-type=\"inline link\" track-name=\"33\" track-metadata-eventdetail=\"https://cloud.google.com/trace/docs/setup#force-trace\" track-metadata-module=\"post\"\u003eGoogle tracing context\u003c/a\u003e and  \u003ca href=\"https://www.w3.org/TR/trace-context/\" target=\"_blank\" track-type=\"inline link\" track-name=\"34\" track-metadata-eventdetail=\"https://www.w3.org\" track-metadata-module=\"post\"\u003eW3C tracing context\u003c/a\u003e strings using the methods \u003ca href=\"https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/Context.java#L116\" target=\"_blank\" track-type=\"inline link\" track-name=\"35\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eloadCloudTraceContext()\u003c/a\u003e and \u003ca href=\"https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/Context.java#L149\" target=\"_blank\" track-type=\"inline link\" track-name=\"36\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eloadW3CTraceParentContext()\u003c/a\u003e respectively.\u003c/p\u003e\u003cp\u003eImplementation of the context population can be a complex task. Java Web servers support asynchronous execution of the request handlers. To manage the context in the right scope may require in-depth knowledge of specific implementation details about each Web server. The new version of the Logging library provides a simple way to automate the process of the current context management, saving you the effort of implementing the code by themselves. The automation supports all Web servers that are based on the Jakarta servlets such as \u003ca href=\"https://tomcat.apache.org/\" target=\"_blank\" track-type=\"inline link\" track-name=\"37\" track-metadata-eventdetail=\"https://tomcat.apache.org\" track-metadata-module=\"post\"\u003eTomcat\u003c/a\u003e, \u003ca href=\"https://www.eclipse.org/jetty/\" target=\"_blank\" track-type=\"inline link\" track-name=\"38\" track-metadata-eventdetail=\"https://www.eclipse.org\" track-metadata-module=\"post\"\u003eJetty\u003c/a\u003e or \u003ca href=\"https://undertow.io/\" target=\"_blank\" track-type=\"inline link\" track-name=\"39\" track-metadata-eventdetail=\"https://undertow.io\" track-metadata-module=\"post\"\u003eUndertow\u003c/a\u003e. The current implementation supports Jakarta servlets version ≥ 4.0.4. The implementation is added to the new \u003ca href=\"https://github.com/googleapis/java-logging-servlet-initializer\" target=\"_blank\" track-type=\"inline link\" track-name=\"40\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003egoogle-cloud-logging-servlet-initializer\u003c/a\u003e package. All that you have to do to enable automatic capturing of the current context is to add the package to your application.\u003c/p\u003e\u003cp\u003eIf you are using \u003ca href=\"https://maven.apache.org/\" target=\"_blank\" track-type=\"inline link\" track-name=\"41\" track-metadata-eventdetail=\"https://maven.apache.org\" track-metadata-module=\"post\"\u003eMaven\u003c/a\u003e add the following to your pom.xml:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c75=\"\"\u003e\u003cpre _ngcontent-c75=\"\"\u003e  \u003ccode _ngcontent-c75=\"\"\u003e\u0026lt;dependency\u0026gt;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e  \u0026lt;groupId\u0026gt;com.google.cloud\u0026lt;/groupId\u0026gt;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e  \u0026lt;artifactId\u0026gt;google-cloud-logging-servlet-initializer\u0026lt;/artifactId\u0026gt;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e  \u0026lt;version\u0026gt;0.1.7-alpha\u0026lt;/version\u0026gt;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e  \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt;\n\u003c/code\u003e\u003ccode _ngcontent-c75=\"\"\u003e\u0026lt;/dependency\u0026gt;\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c74=\"\"\u003e\u003cp\u003eIf you are using \u003ca href=\"https://gradle.org/\" target=\"_blank\" track-type=\"inline link\" track-name=\"42\" track-metadata-eventdetail=\"https://gradle.org\" track-metadata-module=\"post\"\u003eGradle\u003c/a\u003e, add the following to your dependencies:\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c75=\"\"\u003e\u003cpre _ngcontent-c75=\"\"\u003e  \u003ccode _ngcontent-c75=\"\"\u003eimplementation \u0026#39;com.google.cloud:google-cloud-logging-servlet-initializer:0.1.7-alpha\u0026#39;\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c74=\"\"\u003e\u003cdiv _ngcontent-c74=\"\" innerhtml=\"\u0026lt;p\u0026gt;The added package uses the Java\u0026#39;s \u0026lt;a href=\u0026#34;https://docs.oracle.com/javase/tutorial/sound/SPI-intro.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Service Provider Interface\u0026lt;/a\u0026gt; to register the \u0026lt;a href=\u0026#34;https://github.com/googleapis/java-logging-servlet-initializer/blob/5076b0cc81fd1c0c3b39c6add17a0c25c38c7ece/src/main/java/com/google/cloud/logging/servlet/ContextCaptureInitializer.java\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;ContextCaptureInitializer\u0026lt;/a\u0026gt; class which integrates into the servlet pipeline to capture information about current HTTP requests. The information is parsed to populate the \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#HttpRequest\u0026#34;\u0026gt;HttpRequest\u0026lt;/a\u0026gt; structure. It also parses the request\u0026#39;s headers to retrieve tracing information. It supports \u0026amp;#34;\u0026lt;code\u0026gt;x-cloud-trace-context\u0026lt;/code\u0026gt;\u0026amp;#34; (\u0026lt;a href=\u0026#34;https://cloud.google.com/trace/docs/setup#force-trace\u0026#34;\u0026gt;Google tracing context\u0026lt;/a\u0026gt;) and \u0026amp;#34;traceparent\u0026amp;#34; (\u0026lt;a href=\u0026#34;https://www.w3.org/TR/trace-context/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;W3C tracing context\u0026lt;/a\u0026gt;) headers.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Use Logging library with logging agents\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Many applications utilize logging capabilities of the Google Cloud managed services. The applications output their logs to \u0026lt;code\u0026gt;stdout\u0026lt;/code\u0026gt; and \u0026lt;code\u0026gt;stderr\u0026lt;/code\u0026gt;, and the logs are ingested into Cloud Logging by \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/agent\u0026#34;\u0026gt;Logging agents\u0026lt;/a\u0026gt; or the Cloud managed services with the logging agent capabilities. This approach benefits from asynchronous log processing that does not consume application resources. The drawback of the approach is that if you want to populate fields in the structured logs or provide the structured payload, they have to format their output following the special \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/structured-logging#special-payload-fields\u0026#34;\u0026gt;Json format\u0026lt;/a\u0026gt; that the logging agents can parse. Also, while the logging agents can detect and populate the resource information about the managed environment, they cannot help with auto population of other fields of the log entry such as traceId or sourceLocation.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The new release of the Logging library for Java introduces the support for logging agents in both of its Java Logging and Logback integrations. Now the library\u0026#39;s users can instruct the appropriate handler to redirect the log writing to stdout instead of Logging API.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;If you are using Java Logging, add the following to your logging.properties file:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eThe added package uses the Java\u0026#39;s \u003ca href=\"https://docs.oracle.com/javase/tutorial/sound/SPI-intro.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"43\" track-metadata-eventdetail=\"https://docs.oracle.com\" track-metadata-module=\"post\"\u003eService Provider Interface\u003c/a\u003e to register the \u003ca href=\"https://github.com/googleapis/java-logging-servlet-initializer/blob/5076b0cc81fd1c0c3b39c6add17a0c25c38c7ece/src/main/java/com/google/cloud/logging/servlet/ContextCaptureInitializer.java\" target=\"_blank\" track-type=\"inline link\" track-name=\"44\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eContextCaptureInitializer\u003c/a\u003e class which integrates into the servlet pipeline to capture information about current HTTP requests. The information is parsed to populate the \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#HttpRequest\" track-type=\"inline link\" track-name=\"45\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#HttpRequest\" track-metadata-module=\"post\"\u003eHttpRequest\u003c/a\u003e structure. It also parses the request\u0026#39;s headers to retrieve tracing information. It supports \u0026#34;\u003ccode\u003ex-cloud-trace-context\u003c/code\u003e\u0026#34; (\u003ca href=\"https://cloud.google.com/trace/docs/setup#force-trace\" track-type=\"inline link\" track-name=\"46\" track-metadata-eventdetail=\"https://cloud.google.com/trace/docs/setup#force-trace\" track-metadata-module=\"post\"\u003eGoogle tracing context\u003c/a\u003e) and \u0026#34;traceparent\u0026#34; (\u003ca href=\"https://www.w3.org/TR/trace-context/\" target=\"_blank\" track-type=\"inline link\" track-name=\"47\" track-metadata-eventdetail=\"https://www.w3.org\" track-metadata-module=\"post\"\u003eW3C tracing context\u003c/a\u003e) headers.\u003c/p\u003e\u003ch3\u003eUse Logging library with logging agents\u003c/h3\u003e\u003cp\u003eMany applications utilize logging capabilities of the Google Cloud managed services. The applications output their logs to \u003ccode\u003estdout\u003c/code\u003e and \u003ccode\u003estderr\u003c/code\u003e, and the logs are ingested into Cloud Logging by \u003ca href=\"https://cloud.google.com/logging/docs/agent\" track-type=\"inline link\" track-name=\"48\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/agent\" track-metadata-module=\"post\"\u003eLogging agents\u003c/a\u003e or the Cloud managed services with the logging agent capabilities. This approach benefits from asynchronous log processing that does not consume application resources. The drawback of the approach is that if you want to populate fields in the structured logs or provide the structured payload, they have to format their output following the special \u003ca href=\"https://cloud.google.com/logging/docs/structured-logging#special-payload-fields\" track-type=\"inline link\" track-name=\"49\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/structured-logging#special-payload-fields\" track-metadata-module=\"post\"\u003eJson format\u003c/a\u003e that the logging agents can parse. Also, while the logging agents can detect and populate the resource information about the managed environment, they cannot help with auto population of other fields of the log entry such as traceId or sourceLocation.\u003c/p\u003e\u003cp\u003eThe new release of the Logging library for Java introduces the support for logging agents in both of its Java Logging and Logback integrations. Now the library\u0026#39;s users can instruct the appropriate handler to redirect the log writing to stdout instead of Logging API.\u003c/p\u003e\u003cp\u003eIf you are using Java Logging, add the following to your logging.properties file:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c75=\"\"\u003e\u003cpre _ngcontent-c75=\"\"\u003e  \u003ccode _ngcontent-c75=\"\"\u003ecom.google.cloud.logging.LoggingHandler.redirectToStdout=true\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c74=\"\"\u003e\u003cp\u003eIf you are using Logback, add the following to the Logback configuration:\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c75=\"\"\u003e\u003cpre _ngcontent-c75=\"\"\u003e  \u003ccode _ngcontent-c75=\"\"\u003e\u0026lt;redirectToStdout\u0026gt;true\u0026lt;/redirectToStdout\u0026gt;\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c74=\"\"\u003e\u003cdiv _ngcontent-c74=\"\" innerhtml=\"\u0026lt;p\u0026gt;By default, both \u0026lt;a href=\u0026#34;https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/LoggingHandler.java\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;LoggingHandler\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://github.com/googleapis/java-logging-logback/blob/6ce7950d4fe380c6f4f785660af80373c136352a/src/main/java/com/google/cloud/logging/logback/LoggingAppender.java\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;LoggingAppender\u0026lt;/a\u0026gt; write logs by calling the Logging API. You have to add the above configurations to make them utilize the logging agents for the log ingestion.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Some limitations of using Logging Agents\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;When configuring the library\u0026#39;s Java Logging handler or Logback adapter to redirect log writing to stdout, you should be aware of the constraints that the use of logging agents implies.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud managed services (e.g. GKE) automatically install logging agents in the resources that they provision. For example, a GKE cluster has a logging agent installed in each worker node (GCE instance) of the cluster. As a result, logging agents are constrained with the resource they run and do not support customization of the \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.resource\u0026#34;\u0026gt;resource\u0026lt;/a\u0026gt; field of the ingested log entries.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Additionally, the \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.log_name\u0026#34;\u0026gt;logName\u0026lt;/a\u0026gt; of all ingested logs is defined by the agent and cannot be changed*. It means that the application cannot define the log name or where the log entry will be stored (a.k.a. \u0026lt;a href=\u0026#34;https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/LogDestinationName.java\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;log\u0026#39;s destination name\u0026lt;/a\u0026gt;).\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;If it is essential for you to define a custom resource type or to control to which project the logs will be routed and/or the log name, you should not redirect the log writing to standard output.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;* It is possible to customize the log name (but not the destination) by \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/agent/logging/configuration#configure\u0026#34;\u0026gt;customizing the Logging agent\u0026#39;s configuration\u0026lt;/a\u0026gt; in GCE instances by defining the name as the \u0026amp;#34;tag\u0026amp;#34;.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;What is next\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Let\u0026#39;s recap the benefits of upgrading your logging client to the latest version.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Use the new Logging library if you need log correlation capabilities of Log Explorer or forward Cloud Logging structured logs to external solutions and use the data in the auto-populated fields.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Use the \u0026lt;a href=\u0026#34;https://github.com/googleapis/java-logging-servlet-initializer\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;google-cloud-logging-servlet-initializer\u0026lt;/a\u0026gt; package to automate the context management if you run a request based application that uses Jakarta servlets. Note that it will not work with legacy Java EE servlets or Web servers that are not based on Java servlets such as \u0026lt;a href=\u0026#34;https://netty.io/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Netty\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;If you run your application in the Google Cloud serverless environments like Cloud Run or Cloud Functions, consider using Java Logging or Logback with the configuration that redirects formatted logs to standard output like it is described in the previous section. Leveraging logging agents for ingesting logs resolves some reliability problems about asynchronous log ingestion such as \u0026lt;a href=\u0026#34;https://cloud.google.com/run/docs/configuring/cpu-allocation\u0026#34;\u0026gt;CPU throttling\u0026lt;/a\u0026gt; on Cloud Run or no grace period in Cloud Functions.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eBy default, both \u003ca href=\"https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/LoggingHandler.java\" target=\"_blank\" track-type=\"inline link\" track-name=\"50\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eLoggingHandler\u003c/a\u003e and \u003ca href=\"https://github.com/googleapis/java-logging-logback/blob/6ce7950d4fe380c6f4f785660af80373c136352a/src/main/java/com/google/cloud/logging/logback/LoggingAppender.java\" target=\"_blank\" track-type=\"inline link\" track-name=\"51\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eLoggingAppender\u003c/a\u003e write logs by calling the Logging API. You have to add the above configurations to make them utilize the logging agents for the log ingestion.\u003c/p\u003e\u003ch3\u003eSome limitations of using Logging Agents\u003c/h3\u003e\u003cp\u003eWhen configuring the library\u0026#39;s Java Logging handler or Logback adapter to redirect log writing to stdout, you should be aware of the constraints that the use of logging agents implies.\u003c/p\u003e\u003cp\u003eGoogle Cloud managed services (e.g. GKE) automatically install logging agents in the resources that they provision. For example, a GKE cluster has a logging agent installed in each worker node (GCE instance) of the cluster. As a result, logging agents are constrained with the resource they run and do not support customization of the \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.resource\" track-type=\"inline link\" track-name=\"52\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.resource\" track-metadata-module=\"post\"\u003eresource\u003c/a\u003e field of the ingested log entries.\u003c/p\u003e\u003cp\u003eAdditionally, the \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.log_name\" track-type=\"inline link\" track-name=\"53\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.log_name\" track-metadata-module=\"post\"\u003elogName\u003c/a\u003e of all ingested logs is defined by the agent and cannot be changed*. It means that the application cannot define the log name or where the log entry will be stored (a.k.a. \u003ca href=\"https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/LogDestinationName.java\" target=\"_blank\" track-type=\"inline link\" track-name=\"54\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003elog\u0026#39;s destination name\u003c/a\u003e).\u003c/p\u003e\u003cp\u003eIf it is essential for you to define a custom resource type or to control to which project the logs will be routed and/or the log name, you should not redirect the log writing to standard output.\u003c/p\u003e\u003cp\u003e* It is possible to customize the log name (but not the destination) by \u003ca href=\"https://cloud.google.com/logging/docs/agent/logging/configuration#configure\" track-type=\"inline link\" track-name=\"55\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/agent/logging/configuration#configure\" track-metadata-module=\"post\"\u003ecustomizing the Logging agent\u0026#39;s configuration\u003c/a\u003e in GCE instances by defining the name as the \u0026#34;tag\u0026#34;.\u003c/p\u003e\u003ch3\u003eWhat is next\u003c/h3\u003e\u003cp\u003eLet\u0026#39;s recap the benefits of upgrading your logging client to the latest version.\u003c/p\u003e\u003cp\u003eUse the new Logging library if you need log correlation capabilities of Log Explorer or forward Cloud Logging structured logs to external solutions and use the data in the auto-populated fields.\u003c/p\u003e\u003cp\u003eUse the \u003ca href=\"https://github.com/googleapis/java-logging-servlet-initializer\" target=\"_blank\" track-type=\"inline link\" track-name=\"56\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003egoogle-cloud-logging-servlet-initializer\u003c/a\u003e package to automate the context management if you run a request based application that uses Jakarta servlets. Note that it will not work with legacy Java EE servlets or Web servers that are not based on Java servlets such as \u003ca href=\"https://netty.io/\" target=\"_blank\" track-type=\"inline link\" track-name=\"57\" track-metadata-eventdetail=\"https://netty.io\" track-metadata-module=\"post\"\u003eNetty\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIf you run your application in the Google Cloud serverless environments like Cloud Run or Cloud Functions, consider using Java Logging or Logback with the configuration that redirects formatted logs to standard output like it is described in the previous section. Leveraging logging agents for ingesting logs resolves some reliability problems about asynchronous log ingestion such as \u003ca href=\"https://cloud.google.com/run/docs/configuring/cpu-allocation\" track-type=\"inline link\" track-name=\"58\" track-metadata-eventdetail=\"https://cloud.google.com/run/docs/configuring/cpu-allocation\" track-metadata-module=\"post\"\u003eCPU throttling\u003c/a\u003e on Cloud Run or no grace period in Cloud Functions.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/article-content-stream-block\u003e\u003carticle-tag-list-block\u003e\u003c/article-tag-list-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eToday it is even easier to capture logs in your Java applications. Developers can get more data with their application logs using a new version of the Cloud Logging client library for Java. The library populates the current executing context implicitly with every ingested log entry. Read this if you want to learn how to get HTTP requests and tracing information and additional metadata in your logs without writing a single line of code.\u003c/p\u003e\u003cp\u003eThere are three ways to ingest log data into Google Cloud Logging:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eDevelop a proprietary solution that directly calls the \u003ca href=\"https://cloud.google.com/logging/docs/reference/api-overview\"\u003eLogging API\u003c/a\u003e.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eLeverage logging capabilities of the Google Cloud managed environments like \u003ca href=\"https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#overview\"\u003eGKE\u003c/a\u003e or install Google Cloud \u003ca href=\"https://cloud.google.com/monitoring/agent\"\u003eOps agent\u003c/a\u003e and print your application logs to stdout and stderr.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eUse Google Cloud \u003ca href=\"https://cloud.google.com/logging/docs/reference/libraries\"\u003eLogging client library\u003c/a\u003e in one of many supported programming languages.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThe library provides you with ready to use boilerplate constructs built following the best practices of using Logging API. Java applications can use the Google Cloud Logging library to ingest logs using the integrations with \u003ca href=\"https://docs.oracle.com/javase/10/core/java-logging-overview.htm\" target=\"_blank\"\u003eJava Logging\u003c/a\u003e and \u003ca href=\"https://logback.qos.ch/\" target=\"_blank\"\u003eLogback framework\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIf you are new to using Google Logging client libraries for Java, follow the steps to \u003ca href=\"https://cloud.google.com/logging/docs/setup/java\"\u003eset up Cloud Logging for Java\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/logging/docs/reference/libraries\"\u003eget started\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIn the version 3.6 release of the the Logging client library for Java you get many long demanding features including automatic population of the metadata about the environment's resource supporting Cloud Run and Cloud Functions, HTTP request contextual information, tracing correlation that enables displaying grouped log entries in Logs Explorer and more. This release of the library is composed of the three packages:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://github.com/googleapis/java-logging\" target=\"_blank\"\u003egoogle-cloud-logging\u003c/a\u003e -- provides the hand-written layer above Cloud Logging API and the integration with legacy \u003ca href=\"https://docs.oracle.com/javase/10/core/java-logging-overview.htm\" target=\"_blank\"\u003eJava Logging\u003c/a\u003e solution.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://github.com/googleapis/java-logging-logback\" target=\"_blank\"\u003egoogle-cloud-logging-logback\u003c/a\u003e is the integration with the Logback framework and ingests logs using the google-cloud-logging package.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://github.com/googleapis/java-logging-servlet-initializer\" target=\"_blank\"\u003egoogle-cloud-logging-servlet-initializer\u003c/a\u003e is a new addition to the library; it provides integration with servlet-based Web applications.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThe features are available in the versions ≥3.6.3 and ≥0.123.3-alpha of the google-cloud-logging and google-cloud-logging-logback packages respectively.\u003c/p\u003e\u003cp\u003eIf you are using \u003ca href=\"https://maven.apache.org/\" target=\"_blank\"\u003eMaven\u003c/a\u003e, update the packages' versions in the pom.xml:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'\u0026lt;dependency\u0026gt;\\r\\n \u0026lt;groupId\u0026gt;com.google.cloud\u0026lt;/groupId\u0026gt;\\r\\n \u0026lt;artifactId\u0026gt;google-cloud-logging\u0026lt;/artifactId\u0026gt;\\r\\n \u0026lt;version\u0026gt;3.6.3\u0026lt;/version\u0026gt;\\r\\n\u0026lt;/dependency\u0026gt;\\r\\n\u0026lt;dependency\u0026gt;\\r\\n \u0026lt;groupId\u0026gt;com.google.cloud\u0026lt;/groupId\u0026gt;\\r\\n \u0026lt;artifactId\u0026gt;google-cloud-logging-logback\u0026lt;/artifactId\u0026gt;\\r\\n \u0026lt;version\u0026gt;0.123.3-alpha\u0026lt;/version\u0026gt;\\r\\n\u0026lt;/dependency\u0026gt;'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIf you are using \u003ca href=\"https://gradle.org/\" target=\"_blank\"\u003eGradle\u003c/a\u003e, , update your dependencies:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u\"implementation 'com.google.cloud:google-cloud-logging:3.6.3'\\r\\nimplementation 'com.google.cloud:google-cloud-logging-logback:0.123.3-alpha'\"), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eYou can use the official Google Cloud BOM version 0.167.0 that includes the new releases of the packages.\u003c/p\u003e\u003ch3\u003eWhat is new\u003c/h3\u003e\u003cp\u003eThe Java library inserts structured information about the executing environment including resource types, HTTP request metadata, tracing and more. Using the library you can write your payloads in one of the three formats:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eA text provided as a Java string\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eA JSON object provided as an instance of \u003ca href=\"https://docs.oracle.com/javase/8/docs/api/java/util/Map.html\" target=\"_blank\"\u003eMap\u0026lt;String, ?\u0026gt;\u003c/a\u003e or \u003ca href=\"https://developers.google.com/protocol-buffers/docs/reference/java/com/google/protobuf/Struct\" target=\"_blank\"\u003eStruct\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eA protobuf object provided as an instance of \u003ca href=\"https://developers.google.com/protocol-buffers/docs/reference/java/com/google/protobuf/Any\" target=\"_blank\"\u003eAny\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eYou can use the structured logs with enhanced filtering in Logs Explorer to observe and troubleshoot their applications. The Logs Explorer uses structured logs to establish \u003ca href=\"https://cloud.google.com/trace/docs/trace-log-integration\"\u003ecorrelations\u003c/a\u003e between traces and logs and to group together logs that belong to the same transaction. The correlated \"child\" logs are displayed \"under\" the entry of the \"parent\" log:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"Grouped logs display in Logs Explorer.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Grouped_logs_display_in_Logs_Explorer.max-1000x1000.jpg\"/\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ci\u003eGrouped logs display in Logs Explorer\u003c/i\u003e\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWith the previous versions of the Logging library you had to write code to explicitly populate these fields. For example, developers that use Logback framework had to write a code like below to populate the \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.trace\"\u003etrace\u003c/a\u003e field of the ingested logs:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'// . . .\\r\\nString traceInfo = request.getHeader(\"x-cloud-trace-context\");\\r\\nTraceLoggingEventEnhancer.setCurrentTraceId(traceInfo);\\r\\n// . . .'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eAnd to invoke this code at the beginning of each transaction.\u003c/p\u003e\u003cp\u003eThe new features of the Logging library makes implementing the population logic unnecessary. The new version of the library supports automatic population of following log entry fields:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.resource\"\u003eresource\u003c/a\u003e ‒ describes the resource type and its attributes where the application is running. Along with GCE instances, it supports Google Cloud managed services such as GKE, AppEngine (both Standard and Flexible), Cloud Run and Cloud Functions.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.http_request\"\u003ehttpRequest\u003c/a\u003e ‒ captures info about HTTP requests from the current application's context. The context is defined per-thread and can be populated both explicitly in the application code or implicitly from the \u003ca href=\"https://docs.oracle.com/cd/E26180_01/Platform.94/ATGProgGuide/html/s0801requesthandlingwithservletpipeli01.html\" target=\"_blank\"\u003eJakarta servlet requests pipeline\u003c/a\u003e.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.trace\"\u003etrace\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.span_id\"\u003espanId\u003c/a\u003e ‒ reads the tracing data from the HTTP request header. The tracing data assists in correlating multiple logs that belong to the same transaction.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.source_location\"\u003esourceLocation\u003c/a\u003e ‒ stores info about the class and method names as well as the line of code where the application called the log ingestion method. The library retrieves the data by traversing the trace stack up until the first entry that is not part of the Logging library code or the system package.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWhat is left to you is to set the payload and relevant payload's metadata labels. The only field in the \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\"\u003elog entry\u003c/a\u003e that the library does not automatically populate now is the \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.operation\"\u003eoperation\u003c/a\u003e field.\u003c/p\u003e\u003ch3\u003eDisable information auto-population in log entries\u003c/h3\u003e\u003cp\u003eYou have full control over the auto-population functionality. The auto-population is enabled by default for your convenience. But in certain scenarios it can be desirable to disable it. For example, if your application is log intensive and has a narrow bandwidth, you may want to disable the auto-population in order to save the connection's bandwidth for the application communication.\u003c/p\u003e\u003cp\u003eIf you are ingesting logs using the \u003ca href=\"https://cloud.google.com/logging/docs/reference/libraries#write_standard_logs\"\u003ewrite()\u003c/a\u003e method of the Logging interface\u003ca href=\"https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/Logging.java#L1209\" target=\"_blank\"\u003e,\u003c/a\u003e you can configure the LoggingOptions argument to disable the auto-population:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'LoggingOptions options = LoggingOptions.newBuilder()\\r\\n .setAutoPopulateMetadata(false).build();\\r\\nLogging logging = options.getService();'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIf you are using Java Logging, you can disable auto population by adding the following to your logging.properties file:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'com.google.cloud.logging.LoggingHandler.autoPopulateMetadata=false'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIf you are using Logback framework, you can disable auto population by adding the following to your Logback configuration:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'\u0026lt;autoPopulateMetadata\u0026gt;false\u0026lt;/autoPopulateMetadata\u0026gt;'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eHow the current context is populated\u003c/h3\u003e\u003cp\u003eRich query and display capabilities of Log Explorer such as displaying correlated logs use the log entries' fields such as httpRequest and trace. The new version of the library uses the \u003ca href=\"https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/Context.java\" target=\"_blank\"\u003eContext\u003c/a\u003e class to store the information about the HTTP request and tracing data in the current application context. The context's scope is per thread. Before the library ingests logs into Cloud Logging, it reads the HTTP request and tracing information from the current context and sets the respective fields in the log entries. The fields are populated only if the caller did not explicitly provide values in these fields. Using the \u003ca href=\"https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/ContextHandler.java\" target=\"_blank\"\u003eContextHandler\u003c/a\u003e class you can setup the HTTP request and tracing data of the current context:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'import com.google.cloud.logging.HttpRequest;\\r\\n// . . .\\r\\nHttpRequest request;\\r\\n// . . .\\r\\nContextHandler ctxHandler = new ContextHandler();\\r\\nContext ctx = Context.newBuilder()\\r\\n .setRequest(request)\\r\\n .setTraceId(traceId)\\r\\n .setSpanId(spanId)\\r\\n .build();\\r\\nctxHandler.setCurrentContext(ctx);'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eAfter the context is set all logs that will be ingested in the same scope as the context will be populated with the HTTP request and tracing information that was set in the current context. The \u003ca href=\"https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/Context.java\" target=\"_blank\"\u003eContext\u003c/a\u003e class can setup the HTTP request using partial data such as URL or request method:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'import com.google.cloud.logging.HttpRequest.RequestMethod;\\r\\n// . . .\\r\\nContextHandler ctxHandler = new ContextHandler();\\r\\nContext ctx = Context.newBuilder()\\r\\n .setRequestUrl(\"https://example.com/info\")\\r\\n .setRequestMethod(RequestMethod.GET);\\r\\n .build();\\r\\nctxHandler.setCurrentContext(ctx);'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eThe builder of the Context class also supports setting the tracing information from the parsed values of the \u003ca href=\"https://cloud.google.com/trace/docs/setup#force-trace\"\u003eGoogle tracing context\u003c/a\u003e and  \u003ca href=\"https://www.w3.org/TR/trace-context/\" target=\"_blank\"\u003eW3C tracing context\u003c/a\u003e strings using the methods \u003ca href=\"https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/Context.java#L116\" target=\"_blank\"\u003eloadCloudTraceContext()\u003c/a\u003e and \u003ca href=\"https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/Context.java#L149\" target=\"_blank\"\u003eloadW3CTraceParentContext()\u003c/a\u003e respectively.\u003c/p\u003e\u003cp\u003eImplementation of the context population can be a complex task. Java Web servers support asynchronous execution of the request handlers. To manage the context in the right scope may require in-depth knowledge of specific implementation details about each Web server. The new version of the Logging library provides a simple way to automate the process of the current context management, saving you the effort of implementing the code by themselves. The automation supports all Web servers that are based on the Jakarta servlets such as \u003ca href=\"https://tomcat.apache.org/\" target=\"_blank\"\u003eTomcat\u003c/a\u003e, \u003ca href=\"https://www.eclipse.org/jetty/\" target=\"_blank\"\u003eJetty\u003c/a\u003e or \u003ca href=\"https://undertow.io/\" target=\"_blank\"\u003eUndertow\u003c/a\u003e. The current implementation supports Jakarta servlets version ≥ 4.0.4. The implementation is added to the new \u003ca href=\"https://github.com/googleapis/java-logging-servlet-initializer\" target=\"_blank\"\u003egoogle-cloud-logging-servlet-initializer\u003c/a\u003e package. All that you have to do to enable automatic capturing of the current context is to add the package to your application.\u003c/p\u003eIf you are using \u003ca href=\"https://maven.apache.org/\" target=\"_blank\"\u003eMaven\u003c/a\u003e add the following to your pom.xml:\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'\u0026lt;dependency\u0026gt;\\r\\n \u0026lt;groupId\u0026gt;com.google.cloud\u0026lt;/groupId\u0026gt;\\r\\n \u0026lt;artifactId\u0026gt;google-cloud-logging-servlet-initializer\u0026lt;/artifactId\u0026gt;\\r\\n \u0026lt;version\u0026gt;0.1.7-alpha\u0026lt;/version\u0026gt;\\r\\n \u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt;\\r\\n\u0026lt;/dependency\u0026gt;'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIf you are using \u003ca href=\"https://gradle.org/\" target=\"_blank\"\u003eGradle\u003c/a\u003e, add the following to your dependencies:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u\"implementation 'com.google.cloud:google-cloud-logging-servlet-initializer:0.1.7-alpha'\"), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eThe added package uses the Java's \u003ca href=\"https://docs.oracle.com/javase/tutorial/sound/SPI-intro.html\" target=\"_blank\"\u003eService Provider Interface\u003c/a\u003e to register the \u003ca href=\"https://github.com/googleapis/java-logging-servlet-initializer/blob/5076b0cc81fd1c0c3b39c6add17a0c25c38c7ece/src/main/java/com/google/cloud/logging/servlet/ContextCaptureInitializer.java\" target=\"_blank\"\u003eContextCaptureInitializer\u003c/a\u003e class which integrates into the servlet pipeline to capture information about current HTTP requests. The information is parsed to populate the \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#HttpRequest\"\u003eHttpRequest\u003c/a\u003e structure. It also parses the request's headers to retrieve tracing information. It supports \"\u003ccode\u003ex-cloud-trace-context\u003c/code\u003e\" (\u003ca href=\"https://cloud.google.com/trace/docs/setup#force-trace\"\u003eGoogle tracing context\u003c/a\u003e) and \"traceparent\" (\u003ca href=\"https://www.w3.org/TR/trace-context/\" target=\"_blank\"\u003eW3C tracing context\u003c/a\u003e) headers.\u003c/p\u003e\u003ch3\u003eUse Logging library with logging agents\u003c/h3\u003e\u003cp\u003eMany applications utilize logging capabilities of the Google Cloud managed services. The applications output their logs to \u003ccode\u003estdout\u003c/code\u003e and \u003ccode\u003estderr\u003c/code\u003e, and the logs are ingested into Cloud Logging by \u003ca href=\"https://cloud.google.com/logging/docs/agent\"\u003eLogging agents\u003c/a\u003e or the Cloud managed services with the logging agent capabilities. This approach benefits from asynchronous log processing that does not consume application resources. The drawback of the approach is that if you want to populate fields in the structured logs or provide the structured payload, they have to format their output following the special \u003ca href=\"https://cloud.google.com/logging/docs/structured-logging#special-payload-fields\"\u003eJson format\u003c/a\u003e that the logging agents can parse. Also, while the logging agents can detect and populate the resource information about the managed environment, they cannot help with auto population of other fields of the log entry such as traceId or sourceLocation.\u003c/p\u003e\u003cp\u003eThe new release of the Logging library for Java introduces the support for logging agents in both of its Java Logging and Logback integrations. Now the library's users can instruct the appropriate handler to redirect the log writing to stdout instead of Logging API.\u003c/p\u003e\u003cp\u003eIf you are using Java Logging, add the following to your logging.properties file:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'com.google.cloud.logging.LoggingHandler.redirectToStdout=true'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIf you are using Logback, add the following to the Logback configuration:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdl\u003e\u003cdt\u003ecode_block\u003c/dt\u003e\u003cdd\u003e[StructValue([(u'code', u'\u0026lt;redirectToStdout\u0026gt;true\u0026lt;/redirectToStdout\u0026gt;'), (u'language', u'')])]\u003c/dd\u003e\u003c/dl\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eBy default, both \u003ca href=\"https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/LoggingHandler.java\" target=\"_blank\"\u003eLoggingHandler\u003c/a\u003e and \u003ca href=\"https://github.com/googleapis/java-logging-logback/blob/6ce7950d4fe380c6f4f785660af80373c136352a/src/main/java/com/google/cloud/logging/logback/LoggingAppender.java\" target=\"_blank\"\u003eLoggingAppender\u003c/a\u003e write logs by calling the Logging API. You have to add the above configurations to make them utilize the logging agents for the log ingestion.\u003c/p\u003e\u003ch3\u003eSome limitations of using Logging Agents\u003c/h3\u003e\u003cp\u003eWhen configuring the library's Java Logging handler or Logback adapter to redirect log writing to stdout, you should be aware of the constraints that the use of logging agents implies.\u003c/p\u003e\u003cp\u003eGoogle Cloud managed services (e.g. GKE) automatically install logging agents in the resources that they provision. For example, a GKE cluster has a logging agent installed in each worker node (GCE instance) of the cluster. As a result, logging agents are constrained with the resource they run and do not support customization of the \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.resource\"\u003eresource\u003c/a\u003e field of the ingested log entries.\u003c/p\u003e\u003cp\u003eAdditionally, the \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#FIELDS.log_name\"\u003elogName\u003c/a\u003e of all ingested logs is defined by the agent and cannot be changed*. It means that the application cannot define the log name or where the log entry will be stored (a.k.a. \u003ca href=\"https://github.com/googleapis/java-logging/blob/e24e099ae3cb5780bf122c64de6fde76b880b5d6/google-cloud-logging/src/main/java/com/google/cloud/logging/LogDestinationName.java\" target=\"_blank\"\u003elog's destination name\u003c/a\u003e).\u003c/p\u003e\u003cp\u003eIf it is essential for you to define a custom resource type or to control to which project the logs will be routed and/or the log name, you should not redirect the log writing to standard output.\u003c/p\u003e\u003cp\u003e* It is possible to customize the log name (but not the destination) by \u003ca href=\"https://cloud.google.com/logging/docs/agent/logging/configuration#configure\"\u003ecustomizing the Logging agent's configuration\u003c/a\u003e in GCE instances by defining the name as the \"tag\".\u003c/p\u003e\u003ch3\u003eWhat is next\u003c/h3\u003e\u003cp\u003eLet's recap the benefits of upgrading your logging client to the latest version.\u003c/p\u003e\u003cp\u003eUse the new Logging library if you need log correlation capabilities of Log Explorer or forward Cloud Logging structured logs to external solutions and use the data in the auto-populated fields.\u003c/p\u003e\u003cp\u003eUse the \u003ca href=\"https://github.com/googleapis/java-logging-servlet-initializer\" target=\"_blank\"\u003egoogle-cloud-logging-servlet-initializer\u003c/a\u003e package to automate the context management if you run a request based application that uses Jakarta servlets. Note that it will not work with legacy Java EE servlets or Web servers that are not based on Java servlets such as \u003ca href=\"https://netty.io/\" target=\"_blank\"\u003eNetty\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eIf you run your application in the Google Cloud serverless environments like Cloud Run or Cloud Functions, consider using Java Logging or Logback with the configuration that redirects formatted logs to standard output like it is described in the previous section. Leveraging logging agents for ingesting logs resolves some reliability problems about asynchronous log ingestion such as \u003ca href=\"https://cloud.google.com/run/docs/configuring/cpu-allocation\"\u003eCPU throttling\u003c/a\u003e on Cloud Run or no grace period in Cloud Functions.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/google-cloud-logging-python-client-library-v3-0-0-release/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/logging.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eGetting Started with Google Cloud Logging Python v3.0.0\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eLearn how to manage your app's Python logs and related metadata using Google Cloud client libraries.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Java_applications_logs.max-2200x2200.jpg",
      "date_published": "2022-03-07T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eLeonid Yankulin\u003c/name\u003e\u003ctitle\u003eDeveloper Relations Engineer\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/easy-managed-prometheus-metrics-service-for-kubernetes/",
      "title": "Google Cloud Managed Service for Prometheus is now generally available",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWe are excited to announce that Google Cloud \u003ca href=\"https://cloud.google.com/stackdriver/docs/managed-prometheus\"\u003eManaged Service for Prometheus\u003c/a\u003e is now generally available! Now you can get all the benefits of open source-compatible monitoring with the ease of use of Google-scale managed services.\u003c/p\u003e\u003cp\u003eThe rapid adoption of managed platforms and services across the cloud computing industry has shown that fewer and fewer organizations want to invest developer time into managing infrastructure. Google Cloud was recently recognized as a Leader in \u003ca href=\"https://cloud.google.com/resources/forrester-wave-container-platforms-report\"\u003eThe Forrester Wave™: Public Cloud Container Platforms, Q1 2022\u003c/a\u003e and in the report the authors note: “Large firms are seeking enterprise container platforms that accelerate and simplify the development and operations of cloud-native apps with resiliency, manageability, and observability via full-stack cloud-native capabilities.” \u003c/p\u003e\u003cp\u003eGetting a better picture of the \u003ca href=\"https://sre.google/sre-book/monitoring-distributed-systems/#xref_monitoring_golden-signals\" target=\"_blank\"\u003efour golden signals\u003c/a\u003e of monitoring, as laid out in Google’s SRE book, means you have to capture metrics. In both self-managed Kubernetes and Google Kubernetes Engine (GKE) environments, the de-facto standard monitoring technology is \u003ca href=\"http://prometheus.io\" target=\"_blank\"\u003ePrometheus\u003c/a\u003e, an open source metrics collection and alerting tool. While Prometheus works great out-of-the-box for smaller deployments, running Prometheus at scale creates some uniquely difficult challenges.\u003c/p\u003e\u003cp\u003eMuch like you might use GKE because you prefer to not manage your own Kubernetes infrastructure, Managed Service for Prometheus is here for those who prefer to not manage their own Prometheus infrastructure. Focus your developers’ efforts on building features for your customers, as opposed to focusing efforts on operations toil that merely keeps the lights on.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-pull_quote\"\u003e\u003cdiv class=\"uni-pull-quote h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003cdiv class=\"uni-pull-quote__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cdiv class=\"uni-pull-quote__inner-wrapper h-c-copy h-c-copy\"\u003e\u003cq class=\"uni-pull-quote__text\"\u003eSince adopting the service, we've been able to really streamline our Prometheus management, and we've highly enjoyed simplifying our operations by bringing together more data sources into a single pane of glass,\" says Jonathan Campos, CTO and VP of Engineering at Alto. \"And since we don't have to worry about managing historical data, we've been able to reduce our cluster storage from 1TB down to 50GB while extending our Prometheus data retention period from 7 days to 2 years.\u003c/q\u003e\u003c/div\u003e\u003c/div\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eBenefits of using Managed Service for Prometheus  \u003c/h3\u003e\u003cp\u003e\u003cb\u003eTwo-year retention of all metrics, included in the price\u003c/b\u003e: Manually sharding long-term storage is a major pain point of running your own Prometheus-compatible aggregator. Thanks to the global scale and scalability of \u003ca href=\"https://research.google/pubs/pub50652/\" target=\"_blank\"\u003eMonarch\u003c/a\u003e, the system that powers not just \u003ca href=\"https://cloud.google.com/monitoring\"\u003eCloud Monitoring\u003c/a\u003e but all monitoring at Google, long-term storage of Managed Service for Prometheus metrics is easy for us. That benefit gets passed along to you as a two-year retention policy, for all metrics, at no additional charge.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost-effective monitoring\u003c/b\u003e: Switching from open source to a managed service always brings the fear of increased costs, but the pricing model for this service is straightforward and predictable. Charging on a per-sample basis means you pay only while your containers are alive and sending metrics data, taking the worry out of using features like Horizontal Pod Autoscaling that frequently scale containers up and down. Managed Service for Prometheus also provides other \u003ca href=\"https://cloud.google.com/stackdriver/docs/managed-prometheus/cost-controls\"\u003ecost control and cost reducing measures\u003c/a\u003e such as a reduced charge for sparse histograms, a fee structure that charges less for longer sampling periods, and the ability to only send locally pre-aggregated data.\u003c/p\u003e\u003cp\u003e\u003cb\u003eEasy cost identification and attribution\u003c/b\u003e: Within Cloud Monitoring, you can easily \u003ca href=\"https://cloud.google.com/stackdriver/docs/managed-prometheus/cost-controls#identify-cost-sources\"\u003eseparate out your Prometheus ingestion volume by metric name and namespace\u003c/a\u003e. This allows you to identify which metrics contribute the most to your bill, determine what team’s namespace is responsible for sending those metrics, and take action to reduce your costs.\u003c/p\u003e\u003cp\u003e\u003cb\u003eNo changes needed to existing querying or alerting workflows\u003c/b\u003e: You can choose to \u003ca href=\"https://cloud.google.com/stackdriver/docs/managed-prometheus/setup-unmanaged\"\u003ereuse your existing Prometheus collection deployment\u003c/a\u003e or \u003ca href=\"https://cloud.google.com/stackdriver/docs/managed-prometheus/setup-managed\"\u003eswitch to our managed collection\u003c/a\u003e. In either case you can keep using the same Grafana dashboards and alert configs you’re using today. PromQL compatibility for dashboarding and alerting means that your existing incident creation and investigation workflows will continue to work as before.  \u003c/p\u003e\u003cp\u003e\u003cb\u003eViewing Prometheus metrics and\u003c/b\u003e\u003ca href=\"https://cloud.google.com/blog/products/operations/in-depth-explanation-of-operational-metrics-at-google-cloud\"\u003e\u003cb\u003eGoogle Cloud system metrics\u003c/b\u003e\u003c/a\u003e \u003cb\u003etogether\u003c/b\u003e: Many organizations try, but struggle to simplify their operations by building a “single pane of glass” for all their metric sources. Because our service is built on the same technology and backend as Cloud Monitoring, your Prometheus metrics can be used with the dashboarding, alerting, and SLO monitoring available within Cloud Monitoring. Chart your Prometheus metrics right alongside your \u003ca href=\"https://cloud.google.com/stackdriver/docs/solutions/gke/managing-metrics\"\u003eGKE metrics\u003c/a\u003e, your load balancer metrics, \u003ca href=\"https://cloud.google.com/monitoring/api/metrics_gcp\"\u003eand more\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Google_Cloud_Managed_Service_for_Prometh.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"1 Google Cloud Managed Service for Prometheus.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Google_Cloud_Managed_Service_for_Prometh.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ci\u003eGoogle Cloud Managed Service for Prometheus maintains compatibility with the rich ecosystem of open source tools and services used to analyze, query, and visualize Prometheus metrics\u003c/i\u003e\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eRead more from customers who have used Managed Service for Prometheus on \u003ca href=\"https://cloud.google.com/managed-prometheus#section-3\"\u003eour website\u003c/a\u003e.\u003c/p\u003e\u003ch3\u003eWhat’s coming up next\u003c/h3\u003e\u003cp\u003eGeneral availability is just the beginning! We have many more great Managed Service for Prometheus features on our roadmap, including:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003ePromQL querying of \u003ca href=\"https://cloud.google.com/monitoring/api/metrics_gcp\"\u003efree GCP system metrics\u003c/a\u003e available in Cloud Monitoring, including \u003ca href=\"https://cloud.google.com/monitoring/api/metrics_kubernetes\"\u003eGKE\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/monitoring/api/metrics_anthos\"\u003eAnthos\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/monitoring/api/metrics_istio\"\u003eIstio\u003c/a\u003e metrics, so you can chart these metrics right alongside your Prometheus metrics in Grafana\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eRecommended default collection configs for commonly-used exporters, such as \u003ca href=\"https://github.com/kubernetes/kube-state-metrics\" target=\"_blank\"\u003ekube-state-metrics\u003c/a\u003e and \u003ca href=\"https://github.com/prometheus/node_exporter\" target=\"_blank\"\u003enode-exporter\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eOptimized network performance for on-prem clusters\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDebugging tools, such as a targets discovery and health page\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eAnd more!\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eHow to get started\u003c/h3\u003e\u003cp\u003eSetting up Managed Service for Prometheus is straightforward. \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eFor those \u003cb\u003estarting from scratch\u003c/b\u003e or for those who want a \u003cb\u003emore fully-managed experience\u003c/b\u003e, you can deploy \u003ca href=\"https://cloud.google.com/stackdriver/docs/managed-prometheus/setup-managed\"\u003emanaged collectors\u003c/a\u003e in any Kubernetes cluster by using the GKE UI in Cloud Console, the \u003ccode\u003egcloud\u003c/code\u003e CLI, or \u003ccode\u003ekubectl\u003c/code\u003e. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eFor those with \u003cb\u003eexisting Prometheus deployments\u003c/b\u003e, you can \u003ca href=\"https://cloud.google.com/stackdriver/docs/managed-prometheus/setup-unmanaged\"\u003ekeep using your existing configuration\u003c/a\u003e by just swapping out your Prometheus binary with the Managed Service for Prometheus binary. \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eSee \u003ca href=\"https://cloud.google.com/stackdriver/docs/managed-prometheus\"\u003eManaged Service for Prometheus documentation\u003c/a\u003e to get started. You can also check out \u003ca href=\"https://www.youtube.com/watch?v=X4qAEa8_JxQ\" target=\"_blank\"\u003ethis video\u003c/a\u003e which walks you through a few different ways to set up the service:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_kubectl_commands.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"2 kubectl commands.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_kubectl_commands.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ci\u003eA screenshot from the video, showing kubectl commands used when setting up Managed Service for Prometheus\u003c/i\u003e\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eLastly, if you have questions, feature requests, or just want to read topics from other customers who are using Google Cloud Managed Service for Prometheus and Google Cloud’s operations suite, visit our \u003ca href=\"https://www.googlecloudcommunity.com/gc/Google-Cloud-s-operations-suite/bd-p/cloud-operations\" target=\"_blank\"\u003eGoogle Cloud Community site\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/operations/introducing-google-cloud-managed-service-for-prometheus/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Prometheus.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eGet planet-scale monitoring with Managed Service for Prometheus\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eGoogle Cloud's managed Prometheus monitoring solution, offering collection, storage, and global querying of Prometheus metrics at scale.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/original_images/Prometheus_HCKF6h9.jpg",
      "date_published": "2022-03-02T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eLee Yanco\u003c/name\u003e\u003ctitle\u003eProduct Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/application-exceptions-surfaced-automatically/",
      "title": "Quickly troubleshoot application errors with Error Reporting",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c27=\"\"\u003e\u003cdiv _ngcontent-c27=\"\" innerhtml=\"\u0026lt;p\u0026gt;Are you familiar with the \u0026lt;a href=\u0026#34;https://sre.google/sre-book/monitoring-distributed-systems/#xref_monitoring_golden-signals\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;four golden signals\u0026lt;/a\u0026gt; of Site Reliability Engineering (SRE): latency, traffic, errors, and saturation? Whether you\u0026amp;#8217;re a developer or an operator, you\u0026amp;#8217;ve likely been responsible for collecting, storing, or analyzing the data associated with these concepts. Much of this data is captured in application and infrastructure logs, which provide a rich history of what is happening behind the scenes in your workloads.\u0026amp;#160;\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Getting insights from your logs to track those four golden signals can become unruly very quickly as the application scales up, hindering the ability for your developers and operations teams to identify when and where errors are occurring. If you fail to set up your monitoring and logging systems correctly, your Mean Time to Recovery (MTTR) from service impacting events can be impacted.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud provides guidance on what to think about when deciding how to set up your logging, monitoring, and alert systems in the operational excellence section of the \u0026lt;a href=\u0026#34;https://cloud.google.com/architecture/framework/operational-excellence/set-up-monitoring-alerting-logging\u0026#34;\u0026gt;Cloud Architecture Framework\u0026lt;/a\u0026gt;. Google Cloud also provides managed services as part of the \u0026lt;a href=\u0026#34;https://cloud.google.com/products/operations\u0026#34;\u0026gt;operations suite\u0026lt;/a\u0026gt; to automate collection, storage and analysis of the four golden signals. Cloud Error Reporting is one such service.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Error Reporting - Speed up your MTTR with zero effort\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/error-reporting/\u0026#34;\u0026gt;Error Reporting\u0026lt;/a\u0026gt; automatically captures exceptions found in logs ingested by Cloud Logging from the following languages: \u0026lt;a href=\u0026#34;https://cloud.google.com/error-reporting/docs/setup/go\u0026#34;\u0026gt;Go\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/error-reporting/docs/setup/java\u0026#34;\u0026gt;Java\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/error-reporting/docs/setup/nodejs\u0026#34;\u0026gt;Node.js\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/error-reporting/docs/setup/php\u0026#34;\u0026gt;PHP\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/error-reporting/docs/setup/python\u0026#34;\u0026gt;Python\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/error-reporting/docs/setup/ruby\u0026#34;\u0026gt;Ruby\u0026lt;/a\u0026gt;, and \u0026lt;a href=\u0026#34;https://cloud.google.com/error-reporting/docs/setup/dotnet\u0026#34;\u0026gt;.NET\u0026lt;/a\u0026gt;, aggregates them, and then \u0026lt;a href=\u0026#34;https://cloud.google.com/error-reporting/docs/notifications\u0026#34;\u0026gt;notifies you\u0026lt;/a\u0026gt; of their existence. The service intelligently groups together the errors that it finds and makes them available in a \u0026lt;a href=\u0026#34;http://console.cloud.google.com/errors\u0026#34;\u0026gt;dedicated dashboard\u0026lt;/a\u0026gt;. The dashboard displays the details of the exception including a histogram of occurrences, list of affected versions, request URL and links to the request log, meaning you can get to the affected resource immediately, with just one click!\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eAre you familiar with the \u003ca href=\"https://sre.google/sre-book/monitoring-distributed-systems/#xref_monitoring_golden-signals\" target=\"_blank\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003efour golden signals\u003c/a\u003e of Site Reliability Engineering (SRE): latency, traffic, errors, and saturation? Whether you’re a developer or an operator, you’ve likely been responsible for collecting, storing, or analyzing the data associated with these concepts. Much of this data is captured in application and infrastructure logs, which provide a rich history of what is happening behind the scenes in your workloads.  \u003c/p\u003e\u003cp\u003eGetting insights from your logs to track those four golden signals can become unruly very quickly as the application scales up, hindering the ability for your developers and operations teams to identify when and where errors are occurring. If you fail to set up your monitoring and logging systems correctly, your Mean Time to Recovery (MTTR) from service impacting events can be impacted.\u003c/p\u003e\u003cp\u003eGoogle Cloud provides guidance on what to think about when deciding how to set up your logging, monitoring, and alert systems in the operational excellence section of the \u003ca href=\"https://cloud.google.com/architecture/framework/operational-excellence/set-up-monitoring-alerting-logging\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/architecture/framework/operational-excellence/set-up-monitoring-alerting-logging\" track-metadata-module=\"post\"\u003eCloud Architecture Framework\u003c/a\u003e. Google Cloud also provides managed services as part of the \u003ca href=\"https://cloud.google.com/products/operations\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/products/operations\" track-metadata-module=\"post\"\u003eoperations suite\u003c/a\u003e to automate collection, storage and analysis of the four golden signals. Cloud Error Reporting is one such service.\u003c/p\u003e\u003ch3\u003eError Reporting - Speed up your MTTR with zero effort\u003c/h3\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/error-reporting/\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/error-reporting/\" track-metadata-module=\"post\"\u003eError Reporting\u003c/a\u003e automatically captures exceptions found in logs ingested by Cloud Logging from the following languages: \u003ca href=\"https://cloud.google.com/error-reporting/docs/setup/go\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/error-reporting/docs/setup/go\" track-metadata-module=\"post\"\u003eGo\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/error-reporting/docs/setup/java\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/error-reporting/docs/setup/java\" track-metadata-module=\"post\"\u003eJava\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/error-reporting/docs/setup/nodejs\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/error-reporting/docs/setup/nodejs\" track-metadata-module=\"post\"\u003eNode.js\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/error-reporting/docs/setup/php\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/error-reporting/docs/setup/php\" track-metadata-module=\"post\"\u003ePHP\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/error-reporting/docs/setup/python\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/error-reporting/docs/setup/python\" track-metadata-module=\"post\"\u003ePython\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/error-reporting/docs/setup/ruby\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloud.google.com/error-reporting/docs/setup/ruby\" track-metadata-module=\"post\"\u003eRuby\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/error-reporting/docs/setup/dotnet\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/error-reporting/docs/setup/dotnet\" track-metadata-module=\"post\"\u003e.NET\u003c/a\u003e, aggregates them, and then \u003ca href=\"https://cloud.google.com/error-reporting/docs/notifications\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/error-reporting/docs/notifications\" track-metadata-module=\"post\"\u003enotifies you\u003c/a\u003e of their existence. The service intelligently groups together the errors that it finds and makes them available in a \u003ca href=\"http://console.cloud.google.com/errors\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"http://console.cloud.google.com/errors\" track-metadata-module=\"post\"\u003ededicated dashboard\u003c/a\u003e. The dashboard displays the details of the exception including a histogram of occurrences, list of affected versions, request URL and links to the request log, meaning you can get to the affected resource immediately, with just one click!\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eAre you familiar with the \u003ca href=\"https://sre.google/sre-book/monitoring-distributed-systems/#xref_monitoring_golden-signals\" target=\"_blank\"\u003efour golden signals\u003c/a\u003e of Site Reliability Engineering (SRE): latency, traffic, errors, and saturation? Whether you’re a developer or an operator, you’ve likely been responsible for collecting, storing, or analyzing the data associated with these concepts. Much of this data is captured in application and infrastructure logs, which provide a rich history of what is happening behind the scenes in your workloads.  \u003c/p\u003e\u003cp\u003eGetting insights from your logs to track those four golden signals can become unruly very quickly as the application scales up, hindering the ability for your developers and operations teams to identify when and where errors are occurring. If you fail to set up your monitoring and logging systems correctly, your Mean Time to Recovery (MTTR) from service impacting events can be impacted.\u003c/p\u003e\u003cp\u003eGoogle Cloud provides guidance on what to think about when deciding how to set up your logging, monitoring, and alert systems in the operational excellence section of the \u003ca href=\"https://cloud.google.com/architecture/framework/operational-excellence/set-up-monitoring-alerting-logging\"\u003eCloud Architecture Framework\u003c/a\u003e. Google Cloud also provides managed services as part of the \u003ca href=\"https://cloud.google.com/products/operations\"\u003eoperations suite\u003c/a\u003e to automate collection, storage and analysis of the four golden signals. Cloud Error Reporting is one such service.\u003c/p\u003e\u003ch3\u003eError Reporting - Speed up your MTTR with zero effort\u003c/h3\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/error-reporting/\"\u003eError Reporting\u003c/a\u003e automatically captures exceptions found in logs ingested by Cloud Logging from the following languages: \u003ca href=\"https://cloud.google.com/error-reporting/docs/setup/go\"\u003eGo\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/error-reporting/docs/setup/java\"\u003eJava\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/error-reporting/docs/setup/nodejs\"\u003eNode.js\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/error-reporting/docs/setup/php\"\u003ePHP\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/error-reporting/docs/setup/python\"\u003ePython\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/error-reporting/docs/setup/ruby\"\u003eRuby\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/error-reporting/docs/setup/dotnet\"\u003e.NET\u003c/a\u003e, aggregates them, and then \u003ca href=\"https://cloud.google.com/error-reporting/docs/notifications\"\u003enotifies you\u003c/a\u003e of their existence. The service intelligently groups together the errors that it finds and makes them available in a \u003ca href=\"http://console.cloud.google.com/errors\"\u003ededicated dashboard\u003c/a\u003e. The dashboard displays the details of the exception including a histogram of occurrences, list of affected versions, request URL and links to the request log, meaning you can get to the affected resource immediately, with just one click!\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Homepage_of_the_Error_Reporting_service.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"1 Homepage of the Error Reporting service.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Homepage_of_the_Error_Reporting_service.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ci\u003eHomepage of the Error Reporting service\u003c/i\u003e\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eHow can Error Reporting help your organization today?\u003c/p\u003e\u003cp\u003eError Reporting helps focus your most valuable resource (i.e Developer attention) on the potential source of exceptions that are impacting your workloads. With the notifications and embedded links, exceptions can quickly be resolved before they impact your customers and bottom line.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_Error_Reporting_value.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"2 Error Reporting value.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_Error_Reporting_value.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ci\u003eError Reporting value\u003c/i\u003e\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWhat do you have to do to enable Error Reporting?\u003c/p\u003e\u003cp\u003eError Reporting is automatically enabled as soon as logs that contain error events like stack traces are ingested into Cloud Logging or when you use the API to \u003ca href=\"https://cloud.google.com/error-reporting/docs/how-to\"\u003eself configure\u003c/a\u003e a service to capture exceptions.\u003c/p\u003e\u003cp\u003eWhen you use Google Kubernetes Engine and our serverless offerings, application logs written to stdout or stderr will appear automatically in Cloud Logging, and therefore Error Reporting will automatically start analyzing them. To capture logs from applications running on VMs in Google Compute Engine, you will need to \u003ca href=\"https://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent\"\u003einstall the Ops Agent\u003c/a\u003e. From there, app logs will be captured in Cloud Logging and exceptions will flow through to Error Reporting. \u003c/p\u003e\u003ch3\u003eGet started today\u003c/h3\u003e\u003cp\u003eTo view available error events, visit the \u003ca href=\"http://console.cloud.google.com/errors\"\u003eError Reporting page\u003c/a\u003e in the Google Cloud Console. You can find it in the left navigation panel or by searching in the search bar at the top of the console.\u003c/p\u003e\u003cp\u003eIf you have any questions or want to start a discussion with other Error Reporting users, visit the Cloud Operations section of the \u003ca href=\"https://www.googlecloudcommunity.com/gc/Google-Cloud-s-operations-suite/bd-p/cloud-operations\" target=\"_blank\"\u003eGoogle Cloud Community\u003c/a\u003e and post a discussion topic.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/operations/faster-debugging-with-traces-and-logs-together/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/cloud_logging_OUrfE4R.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eEnabling SRE best practices: new contextual traces in Cloud Logging\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eDevelopers can now view trace information for applications directly in Google Cloud Logging for faster debugging.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/error_reporting.max-2200x2200.jpg",
      "date_published": "2022-02-28T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eJohn Day\u003c/name\u003e\u003ctitle\u003eProduct Marketing Manager, Google Cloud\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/google-cloud-logging-python-client-library-v3-0-0-release/",
      "title": "Getting Started with Google Cloud Logging Python v3.0.0",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle-page\u003e\u003cmain id=\"jump-content\"\u003e\u003cpromo-banner-block _nghost-c34=\"\"\u003e\u003c/promo-banner-block\u003e\u003carticle\u003e\u003carticle-header-block\u003e\u003c/article-header-block\u003e\u003carticle-aspect-image-block\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003elogging.jpg\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/article-aspect-image-block\u003e\u003cdiv\u003e\u003carticle-cta _nghost-c55=\"\"\u003e\u003cdiv _ngcontent-c55=\"\"\u003e\u003ch4 _ngcontent-c55=\"\"\u003e\u003cspan _ngcontent-c55=\"\"\u003eTry Google Cloud\u003c/span\u003e\u003c/h4\u003e\u003cp _ngcontent-c55=\"\"\u003e\u003cspan _ngcontent-c55=\"\"\u003eStart building on Google Cloud with $300 in free credits and 20+ always free products.\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003ca _ngcontent-c55=\"\" clicktracker=\"\" rel=\"external\" track-metadata-module=\"article cta\" track-type=\"button\" track-name=\"free trial\" track-metadata-eventdetail=\"https://cloud.google.com/free/\" href=\"https://cloud.google.com/free/\"\u003e\u003cspan _ngcontent-c55=\"\"\u003eFree Trial\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-cta\u003e\u003c/div\u003e\u003carticle-share-block\u003e\u003c/article-share-block\u003e\u003carticle-sticky-share-block\u003e\u003c/article-sticky-share-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-content-stream-block\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c57=\"\"\u003e\u003cdiv _ngcontent-c57=\"\" innerhtml=\"\u0026lt;p\u0026gt;We\u0026amp;#8217;re excited to announce the release of a major update to the Google Cloud Python logging library.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;v3.0.0 makes it even easier for Python developers to send and read logs from Google Cloud, providing real-time insights into what is happening in your application.\u0026amp;#160; If you\u0026amp;#8217;re a Python developer working with Google Cloud, now is a great time to try out Cloud Logging!\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;If you\u0026#39;re unfamiliar with the `google-cloud-logging` library, getting started is simple. First, download the library using pip:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eWe’re excited to announce the release of a major update to the Google Cloud Python logging library. \u003c/p\u003e\u003cp\u003ev3.0.0 makes it even easier for Python developers to send and read logs from Google Cloud, providing real-time insights into what is happening in your application.  If you’re a Python developer working with Google Cloud, now is a great time to try out Cloud Logging!\u003c/p\u003e\u003cp\u003eIf you\u0026#39;re unfamiliar with the `google-cloud-logging` library, getting started is simple. First, download the library using pip:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c58=\"\"\u003e\u003cpre _ngcontent-c58=\"\"\u003e  \u003ccode _ngcontent-c58=\"\"\u003e$ pip install \u0026#34;google-cloud-logging\u0026gt;=3.0.0\u0026#34;\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c57=\"\"\u003e\u003cp\u003eNow, you can set up the client library to work with Python\u0026#39;s built-in `logging` library. Doing this will make it so that all your standard Python log statements will start sending data to Google Cloud:\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c58=\"\"\u003e\u003cpre _ngcontent-c58=\"\"\u003e  \u003ccode _ngcontent-c58=\"\"\u003e# set up the Google Cloud Logging python client library\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003eimport google.cloud.logging\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003eclient = google.cloud.logging.Client()\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003eclient.setup_logging()\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003e\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003e# use Python\u0026#39;s standard logging library to send logs to GCP\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003e\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003eimport logging\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003elogging.warning(\u0026#34;Hello World\u0026#34;)\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c58=\"\"\u003e\u003cpre _ngcontent-c58=\"\"\u003e  \u003ccode _ngcontent-c58=\"\"\u003eimport google.cloud.logging\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003e\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003eclient = google.cloud.logging.Client()\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003elogger = client.logger(name=\u0026#34;log_id\u0026#34;)\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003e\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003eclient.list_entries(max_size=5) # read logs from GCP\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003elogger.log(\u0026#34;hello world\u0026#34;, resource={\u0026#34;type\u0026#34;:\u0026#34;global\u0026#34;, \u0026#34;labels\u0026#34;:{}}) # write log to GCP\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c57=\"\"\u003e\u003cdiv _ngcontent-c57=\"\" innerhtml=\"\u0026lt;p\u0026gt;Here are some of the main features of the \u0026lt;a href=\u0026#34;https://github.com/googleapis/python-logging/blob/eac5e2db83f83b24962524fd9e0d7afa09e2785b/UPGRADING.md\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;new release\u0026lt;/a\u0026gt;:\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Support More Cloud Environments\u0026lt;/h3\u0026gt;\"\u003e\u003cp\u003eHere are some of the main features of the \u003ca href=\"https://github.com/googleapis/python-logging/blob/eac5e2db83f83b24962524fd9e0d7afa09e2785b/UPGRADING.md\" target=\"_blank\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003enew release\u003c/a\u003e:\u003c/p\u003e\u003ch3\u003eSupport More Cloud Environments\u003c/h3\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c57=\"\"\u003e\u003cdiv _ngcontent-c57=\"\" innerhtml=\"\u0026lt;p\u0026gt;Previous versions of google-cloud-logging supported only\u0026lt;a href=\u0026#34;https://cloud.google.com/appengine\u0026#34;\u0026gt; App Engine\u0026lt;/a\u0026gt; and\u0026lt;a href=\u0026#34;https://cloud.google.com/kubernetes-engine\u0026#34;\u0026gt; Kubernetes Engine\u0026lt;/a\u0026gt;. Users reported that the library would occasionally drop logs on serverless environments like Cloud Run and Cloud Functions. This was because the library would send logs in batches over the network. When a serverless environment would spin down, unsent batches could be lost.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;v3.0.0 fixes this issue by making use of GCP\u0026amp;#8217;s built in\u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/structured-logging\u0026#34;\u0026gt; structured JSON logging functionality\u0026lt;/a\u0026gt; on supported environments (GKE, Cloud Run, or Cloud Functions). If the library detects it is running on an environment that supports structured logging, it will automatically make use of the new\u0026lt;a href=\u0026#34;https://github.com/googleapis/python-logging/blob/v3.0.0/google/cloud/logging_v2/handlers/structured_log.py\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt; StructuredLogHandler\u0026lt;/a\u0026gt;, which writes logs as JSON strings printed to standard out. Google Cloud\u0026amp;#8217;s built-in agents will then parse the logs and deliver them to Cloud Logging, even if the code that produced the logs has spun down.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Structured Logging is more reliable on serverless environments, and it allows us to support all major GCP compute environments in v3.0.0. Still, if you would prefer to send logs over the network as before, you can manually set up the library with a \u0026lt;a href=\u0026#34;https://github.com/googleapis/python-logging/blob/d86be6cf83c3f3b91c4fc0b2e0666b0ca1d7e248/google/cloud/logging_v2/handlers/handlers.py#L118\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;CloudLoggingHandler\u0026lt;/a\u0026gt; instance:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003ePrevious versions of google-cloud-logging supported only\u003ca href=\"https://cloud.google.com/appengine\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/appengine\" track-metadata-module=\"post\"\u003e App Engine\u003c/a\u003e and\u003ca href=\"https://cloud.google.com/kubernetes-engine\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/kubernetes-engine\" track-metadata-module=\"post\"\u003e Kubernetes Engine\u003c/a\u003e. Users reported that the library would occasionally drop logs on serverless environments like Cloud Run and Cloud Functions. This was because the library would send logs in batches over the network. When a serverless environment would spin down, unsent batches could be lost.\u003c/p\u003e\u003cp\u003ev3.0.0 fixes this issue by making use of GCP’s built in\u003ca href=\"https://cloud.google.com/logging/docs/structured-logging\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/structured-logging\" track-metadata-module=\"post\"\u003e structured JSON logging functionality\u003c/a\u003e on supported environments (GKE, Cloud Run, or Cloud Functions). If the library detects it is running on an environment that supports structured logging, it will automatically make use of the new\u003ca href=\"https://github.com/googleapis/python-logging/blob/v3.0.0/google/cloud/logging_v2/handlers/structured_log.py\" target=\"_blank\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003e StructuredLogHandler\u003c/a\u003e, which writes logs as JSON strings printed to standard out. Google Cloud’s built-in agents will then parse the logs and deliver them to Cloud Logging, even if the code that produced the logs has spun down. \u003c/p\u003e\u003cp\u003eStructured Logging is more reliable on serverless environments, and it allows us to support all major GCP compute environments in v3.0.0. Still, if you would prefer to send logs over the network as before, you can manually set up the library with a \u003ca href=\"https://github.com/googleapis/python-logging/blob/d86be6cf83c3f3b91c4fc0b2e0666b0ca1d7e248/google/cloud/logging_v2/handlers/handlers.py#L118\" target=\"_blank\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eCloudLoggingHandler\u003c/a\u003e instance:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c58=\"\"\u003e\u003cpre _ngcontent-c58=\"\"\u003e  \u003ccode _ngcontent-c58=\"\"\u003efrom google.cloud.logging.handlers import CloudLoggingHandler\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003efrom google.cloud.logging_v2.handlers import setup_logging\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003e\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003e# explicitly set up a CloudLoggingHandler to send logs over the network\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003ehandler = CloudLoggingHandler(client)\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003esetup_logging(handler)\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003e\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003eimport logging\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003elogging.warning(“Hello World”)\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c57=\"\"\u003e\u003cdiv _ngcontent-c57=\"\" innerhtml=\"\u0026lt;p\u0026gt;When you troubleshoot your application, it can be useful to have as much information about the environment as possible captured in your application logs. `google-cloud-logging` attempts to help in this process by detecting and attaching metadata about your environment to each log message. The following fields are currently supported:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;`\u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/MonitoredResource\u0026#34;\u0026gt;resource\u0026lt;/a\u0026gt;`: The Google Cloud resource the log originated from\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;for example, Functions, GKE, or Cloud Run\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;`\u0026lt;a href=\u0026#34;http://httprequest\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;httpRequest\u0026lt;/a\u0026gt;`: Information about an HTTP request in the log\u0026amp;#8217;s context\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Flask and Django are currently supported\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;`\u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#LogEntrySourceLocation\u0026#34;\u0026gt;sourceLocation\u0026lt;/a\u0026gt;` : File, line, and function names\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\u0026#34;\u0026gt;trace\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\u0026#34;\u0026gt;spanId\u0026lt;/a\u0026gt;, and \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\u0026#34;\u0026gt;traceSampled\u0026lt;/a\u0026gt;: \u0026lt;a href=\u0026#34;https://medium.com/r/?url=https%3A%2F%2Fcloud.google.com%2Ftrace\u0026#34;\u0026gt;Cloud Trace\u0026lt;/a\u0026gt; metadata\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Supports \u0026lt;a href=\u0026#34;https://cloud.google.com/trace/docs/setup#force-trace\u0026#34;\u0026gt;X-Cloud-Trace-Context\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://www.w3.org/TR/trace-context/#traceparent-header\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;w3c transparent\u0026lt;/a\u0026gt; trace formats\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;The library will make an attempt to populate this data whenever possible, but any of these fields can also be explicitly set by developers using the library.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eWhen you troubleshoot your application, it can be useful to have as much information about the environment as possible captured in your application logs. `google-cloud-logging` attempts to help in this process by detecting and attaching metadata about your environment to each log message. The following fields are currently supported:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e`\u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/MonitoredResource\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/MonitoredResource\" track-metadata-module=\"post\"\u003eresource\u003c/a\u003e`: The Google Cloud resource the log originated from \u003c/p\u003e\u003c/li\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003efor example, Functions, GKE, or Cloud Run\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cli\u003e\u003cp\u003e`\u003ca href=\"http://httprequest\" target=\"_blank\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"http://httprequest\" track-metadata-module=\"post\"\u003ehttpRequest\u003c/a\u003e`: Information about an HTTP request in the log’s context\u003c/p\u003e\u003c/li\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eFlask and Django are currently supported\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cli\u003e\u003cp\u003e`\u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#LogEntrySourceLocation\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#LogEntrySourceLocation\" track-metadata-module=\"post\"\u003esourceLocation\u003c/a\u003e` : File, line, and function names\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\" track-metadata-module=\"post\"\u003etrace\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\" track-metadata-module=\"post\"\u003espanId\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\" track-metadata-module=\"post\"\u003etraceSampled\u003c/a\u003e: \u003ca href=\"https://medium.com/r/?url=https%3A%2F%2Fcloud.google.com%2Ftrace\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://medium.com\" track-metadata-module=\"post\"\u003eCloud Trace\u003c/a\u003e metadata\u003c/p\u003e\u003c/li\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eSupports \u003ca href=\"https://cloud.google.com/trace/docs/setup#force-trace\" track-type=\"inline link\" track-name=\"18\" track-metadata-eventdetail=\"https://cloud.google.com/trace/docs/setup#force-trace\" track-metadata-module=\"post\"\u003eX-Cloud-Trace-Context\u003c/a\u003e and \u003ca href=\"https://www.w3.org/TR/trace-context/#traceparent-header\" target=\"_blank\" track-type=\"inline link\" track-name=\"19\" track-metadata-eventdetail=\"https://www.w3.org\" track-metadata-module=\"post\"\u003ew3c transparent\u003c/a\u003e trace formats\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003cp\u003eThe library will make an attempt to populate this data whenever possible, but any of these fields can also be explicitly set by developers using the library.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c58=\"\"\u003e\u003cpre _ngcontent-c58=\"\"\u003e  \u003ccode _ngcontent-c58=\"\"\u003elogging.info(\u0026#34;hello\u0026#34;, extra={\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003e    \u0026#34;labels\u0026#34;: {\u0026#34;foo\u0026#34;: \u0026#34;bar\u0026#34;},\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003e    \u0026#34;http_request\u0026#34;: {\u0026#34;requestUrl\u0026#34;: \u0026#34;localhost\u0026#34;},\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003e    \u0026#34;trace\u0026#34;: \u0026#34;01234\u0026#34;\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003e})\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c57=\"\"\u003e\u003cp _ngcontent-c57=\"\" innerhtml=\"\u0026lt;h3\u0026gt;JSON Support in Standard Library Integration\u0026lt;/h3\u0026gt;\"\u003e\u003ch3\u003eJSON Support in Standard Library Integration\u003c/h3\u003e\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c58=\"\"\u003e\u003cpre _ngcontent-c58=\"\"\u003e  \u003ccode _ngcontent-c58=\"\"\u003eimport logging\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003eimport json\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003e\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003edata_dict = {\u0026#34;hello\u0026#34;: \u0026#34;world\u0026#34;}\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003elogging.info(json.dumps(data_dict))\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c57=\"\"\u003e\u003cp\u003e2. Pass a `json_fields` dictionary using Python logging\u0026#39;s `extra` argument:\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c58=\"\"\u003e\u003cpre _ngcontent-c58=\"\"\u003e  \u003ccode _ngcontent-c58=\"\"\u003eimport logging\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003e\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003edata_dict = {\u0026#34;hello\u0026#34;: \u0026#34;world\u0026#34;}\n\u003c/code\u003e\u003ccode _ngcontent-c58=\"\"\u003elogging.info(\u0026#34;message field\u0026#34;, extra={\u0026#34;json_fields\u0026#34;: data_dict})\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c57=\"\"\u003e\u003cdiv _ngcontent-c57=\"\" innerhtml=\"\u0026lt;h3\u0026gt;Next Steps\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;With version v3.0.0, the Google Cloud Logging Python library now supports more compute environments, detects more helpful metadata, and provides more thorough support for JSON logs. Along with these major features, there are also user-experience improvements like a new \u0026lt;a href=\u0026#34;https://googleapis.dev/python/logging/latest/UPGRADING.html#new-logger-log-method-316\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;log method\u0026lt;/a\u0026gt; and more \u0026lt;a href=\u0026#34;https://googleapis.dev/python/logging/latest/UPGRADING.html#more-permissive-arguments-422\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;permissive argument parsing\u0026lt;/a\u0026gt;.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;If you want to learn more about the latest release, these changes and others are described in more detail in the \u0026lt;a href=\u0026#34;https://googleapis.dev/python/logging/latest/UPGRADING.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;v3.0.0 Migration Guide\u0026lt;/a\u0026gt;. If you\u0026amp;#8217;re new to the library, check out the \u0026lt;a href=\u0026#34;https://googleapis.dev/python/logging/latest/index.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;google-cloud-logging user guide\u0026lt;/a\u0026gt;. If you want to learn more about observability on GCP in general, you can spin up test environments using \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/operations/on-the-road-to-sre-with-cloud-operations-sandbox\u0026#34;\u0026gt;Cloud Ops Sandbox\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Finally, if you have any feedback about the latest release, have new feature requests, or would like to make any contributions, feel free to open issues on \u0026lt;a href=\u0026#34;https://github.com/googleapis/python-logging\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;our GitHub repo\u0026lt;/a\u0026gt;. The Google Cloud Logging libraries are open source software, and we welcome new contributors!\u0026lt;/p\u0026gt;\"\u003e\u003ch3\u003eNext Steps\u003c/h3\u003e\u003cp\u003eWith version v3.0.0, the Google Cloud Logging Python library now supports more compute environments, detects more helpful metadata, and provides more thorough support for JSON logs. Along with these major features, there are also user-experience improvements like a new \u003ca href=\"https://googleapis.dev/python/logging/latest/UPGRADING.html#new-logger-log-method-316\" target=\"_blank\" track-type=\"inline link\" track-name=\"22\" track-metadata-eventdetail=\"https://googleapis.dev\" track-metadata-module=\"post\"\u003elog method\u003c/a\u003e and more \u003ca href=\"https://googleapis.dev/python/logging/latest/UPGRADING.html#more-permissive-arguments-422\" target=\"_blank\" track-type=\"inline link\" track-name=\"23\" track-metadata-eventdetail=\"https://googleapis.dev\" track-metadata-module=\"post\"\u003epermissive argument parsing\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eIf you want to learn more about the latest release, these changes and others are described in more detail in the \u003ca href=\"https://googleapis.dev/python/logging/latest/UPGRADING.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"24\" track-metadata-eventdetail=\"https://googleapis.dev\" track-metadata-module=\"post\"\u003ev3.0.0 Migration Guide\u003c/a\u003e. If you’re new to the library, check out the \u003ca href=\"https://googleapis.dev/python/logging/latest/index.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"25\" track-metadata-eventdetail=\"https://googleapis.dev\" track-metadata-module=\"post\"\u003egoogle-cloud-logging user guide\u003c/a\u003e. If you want to learn more about observability on GCP in general, you can spin up test environments using \u003ca href=\"https://cloud.google.com/blog/products/operations/on-the-road-to-sre-with-cloud-operations-sandbox\" track-type=\"inline link\" track-name=\"26\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/operations/on-the-road-to-sre-with-cloud-operations-sandbox\" track-metadata-module=\"post\"\u003eCloud Ops Sandbox\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eFinally, if you have any feedback about the latest release, have new feature requests, or would like to make any contributions, feel free to open issues on \u003ca href=\"https://github.com/googleapis/python-logging\" target=\"_blank\" track-type=\"inline link\" track-name=\"27\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eour GitHub repo\u003c/a\u003e. The Google Cloud Logging libraries are open source software, and we welcome new contributors!\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/article-content-stream-block\u003e\u003carticle-tag-list-block\u003e\u003c/article-tag-list-block\u003e\u003c/div\u003e\u003csection\u003e\u003carticle-up-1to3-block _nghost-c56=\"\"\u003e\u003c/article-up-1to3-block\u003e\u003c/section\u003e\u003c/div\u003e\u003c/article\u003e\u003c/main\u003e\u003c/article-page\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWe’re excited to announce the release of a major update to the Google Cloud Python logging library. \u003c/p\u003e\u003cp\u003ev3.0.0 makes it even easier for Python developers to send and read logs from Google Cloud, providing real-time insights into what is happening in your application.  If you’re a Python developer working with Google Cloud, now is a great time to try out Cloud Logging!\u003c/p\u003e\u003cp\u003eIf you're unfamiliar with the `google-cloud-logging` library, getting started is simple. First, download the library using pip:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eNow, you can set up the client library to work with Python's built-in `logging` library. Doing this will make it so that all your standard Python log statements will start sending data to Google Cloud:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWe recommend \u003ca href=\"https://googleapis.dev/python/logging/latest/std-lib-integration.html\" target=\"_blank\"\u003eusing the standard Python `logging` interface\u003c/a\u003e for log creation, as demonstrated above. However, if you need access to other \u003ca href=\"https://cloud.google.com/logging\"\u003eGoogle Cloud Logging features\u003c/a\u003e (reading logs, managing \u003ca href=\"https://cloud.google.com/logging/docs/export/configure_export_v2\"\u003elog sinks\u003c/a\u003e, etc), you can \u003ca href=\"https://googleapis.dev/python/logging/latest/direct-lib-usage.html\" target=\"_blank\"\u003euse `google.cloud.logging` directly\u003c/a\u003e:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eHere are some of the main features of the \u003ca href=\"https://github.com/googleapis/python-logging/blob/eac5e2db83f83b24962524fd9e0d7afa09e2785b/UPGRADING.md\" target=\"_blank\"\u003enew release\u003c/a\u003e:\u003c/p\u003e\u003ch3\u003eSupport More Cloud Environments\u003c/h3\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"1.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_jAhSLdi.0999065319990470.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003ePrevious versions of google-cloud-logging supported only\u003ca href=\"https://cloud.google.com/appengine\"\u003eApp Engine\u003c/a\u003e and\u003ca href=\"https://cloud.google.com/kubernetes-engine\"\u003eKubernetes Engine\u003c/a\u003e. Users reported that the library would occasionally drop logs on serverless environments like Cloud Run and Cloud Functions. This was because the library would send logs in batches over the network. When a serverless environment would spin down, unsent batches could be lost.\u003c/p\u003e\u003cp\u003ev3.0.0 fixes this issue by making use of GCP’s built in\u003ca href=\"https://cloud.google.com/logging/docs/structured-logging\"\u003estructured JSON logging functionality\u003c/a\u003e on supported environments (GKE, Cloud Run, or Cloud Functions). If the library detects it is running on an environment that supports structured logging, it will automatically make use of the new\u003ca href=\"https://github.com/googleapis/python-logging/blob/v3.0.0/google/cloud/logging_v2/handlers/structured_log.py\" target=\"_blank\"\u003eStructuredLogHandler\u003c/a\u003e, which writes logs as JSON strings printed to standard out. Google Cloud’s built-in agents will then parse the logs and deliver them to Cloud Logging, even if the code that produced the logs has spun down. \u003c/p\u003e\u003cp\u003eStructured Logging is more reliable on serverless environments, and it allows us to support all major GCP compute environments in v3.0.0. Still, if you would prefer to send logs over the network as before, you can manually set up the library with a \u003ca href=\"https://github.com/googleapis/python-logging/blob/d86be6cf83c3f3b91c4fc0b2e0666b0ca1d7e248/google/cloud/logging_v2/handlers/handlers.py#L118\" target=\"_blank\"\u003eCloudLoggingHandler\u003c/a\u003e instance:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eMetadata Autodetection\u003c/h3\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"2.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_om8Pxs0.0999064919990643.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWhen you troubleshoot your application, it can be useful to have as much information about the environment as possible captured in your application logs. `google-cloud-logging` attempts to help in this process by detecting and attaching metadata about your environment to each log message. The following fields are currently supported:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e`\u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/MonitoredResource\"\u003eresource\u003c/a\u003e`: The Google Cloud resource the log originated from \u003c/p\u003e\u003c/li\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003efor example, Functions, GKE, or Cloud Run\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cli\u003e\u003cp\u003e`\u003ca href=\"http://httprequest\" target=\"_blank\"\u003ehttpRequest\u003c/a\u003e`: Information about an HTTP request in the log’s context\u003c/p\u003e\u003c/li\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eFlask and Django are currently supported\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cli\u003e\u003cp\u003e`\u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry#LogEntrySourceLocation\"\u003esourceLocation\u003c/a\u003e` : File, line, and function names\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\"\u003etrace\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\"\u003espanId\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry\"\u003etraceSampled\u003c/a\u003e: \u003ca href=\"https://medium.com/r/?url=https%3A%2F%2Fcloud.google.com%2Ftrace\"\u003eCloud Trace\u003c/a\u003e metadata\u003c/p\u003e\u003c/li\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eSupports \u003ca href=\"https://cloud.google.com/trace/docs/setup#force-trace\"\u003eX-Cloud-Trace-Context\u003c/a\u003e and \u003ca href=\"https://www.w3.org/TR/trace-context/#traceparent-header\" target=\"_blank\"\u003ew3c transparent\u003c/a\u003e trace formats\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/ul\u003e\u003cp\u003eThe library will make an attempt to populate this data whenever possible, but any of these fields can also be explicitly set by developers using the library.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eJSON Support in Standard Library Integration\u003c/h3\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--medium h-c-grid__col h-c-grid__col--4 h-c-grid__col--offset-4 \"\u003e\u003cimg alt=\"3.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_wcTDIdW.0999064519990884.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eGoogle Cloud Logging supports both\u003ca href=\"https://cloud.google.com/logging/docs/structured-logging\"\u003estring and JSON payloads\u003c/a\u003e for LogEntries, but up until now,\u003ca href=\"https://googleapis.dev/python/logging/latest/std-lib-integration.html\" target=\"_blank\"\u003ethe Python standard library integration\u003c/a\u003e could only send logs with string payloads.\u003c/p\u003e\u003cp\u003eIn `google-cloud-logging` v3,  you can log JSON data in two ways:\u003c/p\u003e\u003cp\u003e1. Log a JSON-parsable string:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e2. Pass a `json_fields` dictionary using Python logging's `extra` argument:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eNext Steps\u003c/h3\u003e\u003cp\u003eWith version v3.0.0, the Google Cloud Logging Python library now supports more compute environments, detects more helpful metadata, and provides more thorough support for JSON logs. Along with these major features, there are also user-experience improvements like a new \u003ca href=\"https://googleapis.dev/python/logging/latest/UPGRADING.html#new-logger-log-method-316\" target=\"_blank\"\u003elog method\u003c/a\u003e and more \u003ca href=\"https://googleapis.dev/python/logging/latest/UPGRADING.html#more-permissive-arguments-422\" target=\"_blank\"\u003epermissive argument parsing\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eIf you want to learn more about the latest release, these changes and others are described in more detail in the \u003ca href=\"https://googleapis.dev/python/logging/latest/UPGRADING.html\" target=\"_blank\"\u003ev3.0.0 Migration Guide\u003c/a\u003e. If you’re new to the library, check out the \u003ca href=\"https://googleapis.dev/python/logging/latest/index.html\" target=\"_blank\"\u003egoogle-cloud-logging user guide\u003c/a\u003e. If you want to learn more about observability on GCP in general, you can spin up test environments using \u003ca href=\"https://cloud.google.com/blog/products/operations/on-the-road-to-sre-with-cloud-operations-sandbox\"\u003eCloud Ops Sandbox\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eFinally, if you have any feedback about the latest release, have new feature requests, or would like to make any contributions, feel free to open issues on \u003ca href=\"https://github.com/googleapis/python-logging\" target=\"_blank\"\u003eour GitHub repo\u003c/a\u003e. The Google Cloud Logging libraries are open source software, and we welcome new contributors!\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/operations/on-the-road-to-sre-with-cloud-operations-sandbox/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Public-Sector-Momentum.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eTake the first step toward SRE with Cloud Operations Sandbox\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eSpin up the Cloud Operations Sandbox to see how Google’s logging, monitoring, tracing, profiling and debugging can kickstart your SRE pra...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/logging.max-2200x2200.jpg",
      "date_published": "2022-02-07T18:00:00Z",
      "author": {
        "name": "\u003cname\u003eDaniel Sanche\u003c/name\u003e\u003ctitle\u003eDeveloper Programs Engineer\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/identity-security/simplify-saas-scale-tls-certificate-management/",
      "title": "Introducing Certificate Manager to simplify SaaS scale TLS and certificate management",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c49=\"\"\u003e\u003cdiv _ngcontent-c49=\"\" innerhtml=\"\u0026lt;p\u0026gt;We\u0026amp;#8217;re excited to announce the public preview of Certificate Manager and its integration with External HTTPS Load Balancing. Certificate Manager enables you to use External HTTPS Load Balancing with as many certificates or domains as you need. You can bring your own TLS certificates and keys if you have an existing certificate lifecycle management solution you\u0026#39;d like to use with Google Cloud, or enjoy the convenience of our fully Managed TLS offerings.\u0026amp;#160;\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Extend the security and performance of the Google network to your customers\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Certificate Manager brings support for multiple certificates per customer. When\u0026amp;#160; coupled with our \u0026lt;a href=\u0026#34;https://cloud.google.com/load-balancing/docs/load-balancing-overview\u0026#34;\u0026gt;global anycast load balancing solution\u0026lt;/a\u0026gt; with automated autoscaling and failover, you now have a powerful platform for building robust SaaS and PaaS offerings. This enables custom domain support for your customers with the lowest latency and the highest level of availability.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://il.linkedin.com/in/alonkochba\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Alon Kochba\u0026lt;/a\u0026gt;, the head of web performance at website-building service Wix, explained how the new features lighten their workload.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026amp;#8220;As a SaaS product, we need to terminate SSL for millions of custom domains and certificates. GCP\u0026#39;s Certificate Manager and External HTTPS Load Balancing lets us do this at the edge, close to the clients, without having to rely on our own custom solution for terminating SSL,\u0026amp;#8221; Kochba said.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Customers who switch to External HTTPS Load Balancing can also now protect their SaaS users from \u0026lt;a href=\u0026#34;https://cloud.google.com/armor/docs/adaptive-protection-overview\u0026#34;\u0026gt;denial of service attacks\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/architecture/owasp-top-ten-mitigation\u0026#34;\u0026gt;OWASP Top 10 risks\u0026lt;/a\u0026gt;, and other common Web attacks by adopting \u0026lt;a href=\u0026#34;https://cloud.google.com/armor\u0026#34;\u0026gt;Cloud Armor\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;DNS authorization\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;This release also now enables you to provision your Google-managed certificates with DNS-based authorizations and have them ready to use before your load-balancing production environment is fully set up. This will help streamline the migration process to Google Cloud, for example. To create a DNS authorization, use the following command:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eWe’re excited to announce the public preview of Certificate Manager and its integration with External HTTPS Load Balancing. Certificate Manager enables you to use External HTTPS Load Balancing with as many certificates or domains as you need. You can bring your own TLS certificates and keys if you have an existing certificate lifecycle management solution you\u0026#39;d like to use with Google Cloud, or enjoy the convenience of our fully Managed TLS offerings.  \u003c/p\u003e\u003ch3\u003eExtend the security and performance of the Google network to your customers\u003c/h3\u003e\u003cp\u003eCertificate Manager brings support for multiple certificates per customer. When  coupled with our \u003ca href=\"https://cloud.google.com/load-balancing/docs/load-balancing-overview\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/load-balancing/docs/load-balancing-overview\" track-metadata-module=\"post\"\u003eglobal anycast load balancing solution\u003c/a\u003e with automated autoscaling and failover, you now have a powerful platform for building robust SaaS and PaaS offerings. This enables custom domain support for your customers with the lowest latency and the highest level of availability. \u003c/p\u003e\u003cp\u003e\u003ca href=\"https://il.linkedin.com/in/alonkochba\" target=\"_blank\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://il.linkedin.com\" track-metadata-module=\"post\"\u003eAlon Kochba\u003c/a\u003e, the head of web performance at website-building service Wix, explained how the new features lighten their workload. \u003c/p\u003e\u003cp\u003e“As a SaaS product, we need to terminate SSL for millions of custom domains and certificates. GCP\u0026#39;s Certificate Manager and External HTTPS Load Balancing lets us do this at the edge, close to the clients, without having to rely on our own custom solution for terminating SSL,” Kochba said.\u003c/p\u003e\u003cp\u003eCustomers who switch to External HTTPS Load Balancing can also now protect their SaaS users from \u003ca href=\"https://cloud.google.com/armor/docs/adaptive-protection-overview\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/armor/docs/adaptive-protection-overview\" track-metadata-module=\"post\"\u003edenial of service attacks\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/architecture/owasp-top-ten-mitigation\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/architecture/owasp-top-ten-mitigation\" track-metadata-module=\"post\"\u003eOWASP Top 10 risks\u003c/a\u003e, and other common Web attacks by adopting \u003ca href=\"https://cloud.google.com/armor\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/armor\" track-metadata-module=\"post\"\u003eCloud Armor\u003c/a\u003e.\u003c/p\u003e\u003ch3\u003eDNS authorization\u003c/h3\u003e\u003cp\u003eThis release also now enables you to provision your Google-managed certificates with DNS-based authorizations and have them ready to use before your load-balancing production environment is fully set up. This will help streamline the migration process to Google Cloud, for example. To create a DNS authorization, use the following command:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWe’re excited to announce the public preview of Certificate Manager and its integration with External HTTPS Load Balancing. Certificate Manager enables you to use External HTTPS Load Balancing with as many certificates or domains as you need. You can bring your own TLS certificates and keys if you have an existing certificate lifecycle management solution you'd like to use with Google Cloud, or enjoy the convenience of our fully Managed TLS offerings.  \u003c/p\u003e\u003ch3\u003eExtend the security and performance of the Google network to your customers\u003c/h3\u003e\u003cp\u003eCertificate Manager brings support for multiple certificates per customer. When  coupled with our \u003ca href=\"https://cloud.google.com/load-balancing/docs/load-balancing-overview\"\u003eglobal anycast load balancing solution\u003c/a\u003e with automated autoscaling and failover, you now have a powerful platform for building robust SaaS and PaaS offerings. This enables custom domain support for your customers with the lowest latency and the highest level of availability. \u003c/p\u003e\u003cp\u003e\u003ca href=\"https://il.linkedin.com/in/alonkochba\" target=\"_blank\"\u003eAlon Kochba\u003c/a\u003e, the head of web performance at website-building service Wix, explained how the new features lighten their workload. \u003c/p\u003e\u003cp\u003e“As a SaaS product, we need to terminate SSL for millions of custom domains and certificates. GCP's Certificate Manager and External HTTPS Load Balancing lets us do this at the edge, close to the clients, without having to rely on our own custom solution for terminating SSL,” Kochba said.\u003c/p\u003e\u003cp\u003eCustomers who switch to External HTTPS Load Balancing can also now protect their SaaS users from \u003ca href=\"https://cloud.google.com/armor/docs/adaptive-protection-overview\"\u003edenial of service attacks\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/architecture/owasp-top-ten-mitigation\"\u003eOWASP Top 10 risks\u003c/a\u003e, and other common Web attacks by adopting \u003ca href=\"https://cloud.google.com/armor\"\u003eCloud Armor\u003c/a\u003e.\u003c/p\u003e\u003ch3\u003eDNS authorization\u003c/h3\u003e\u003cp\u003eThis release also now enables you to provision your Google-managed certificates with DNS-based authorizations and have them ready to use before your load-balancing production environment is fully set up. This will help streamline the migration process to Google Cloud, for example. To create a DNS authorization, use the following command:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eThis command returns the CNAME record for \u003ccode\u003e_acme-challenge.\u003c/code\u003e\u003ca href=\"http://www.example.com\" target=\"_blank\"\u003e\u003ccode\u003eexample.com\u003c/code\u003e\u003c/a\u003e that you must \u003ca href=\"https://cloud.devsite.corp.google.com/certificate-manager/docs/certificates#cert-dns-auth\" target=\"_blank\"\u003eadd to your DNS configuration\u003c/a\u003e in the DNS zone of the target domain. This CNAME record points to a special Google Cloud domain, e.g.: \"\u003ccode\u003e534959-1a8a-40cf-90b6-b1f5f8d22517.2.authorize.certificatemanager.goog\u003c/code\u003e” that is used  to verify domain ownership.\u003c/p\u003e\u003cp\u003eWhen you request a certificate based on the above authorization, Cloud Certificate Manager will work with the Certificate Authority automatically to get and later renew your certificate for that domain.\u003c/p\u003e\u003ch3\u003eWildcard support\u003c/h3\u003e\u003cp\u003eThis \u003cb\u003eDNS-based domain control authorization\u003c/b\u003e also allows us to bring you support for \u003cb\u003ewildcard certificates\u003c/b\u003e. To configure the use of wildcard certificates you first must configure the DNS authorization as we’ve indicated above. Once that has been completed, you can configure the use of a wildcard certificate using the following command. Our example below is for a top-level registered domain and its wildcard subdomains.\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eMonitoring for Certificate Expiration\u003c/h3\u003e\u003cp\u003eAnother new feature that will be enabled with this product  is the ability to monitor certificate expiration with \u003ca href=\"https://cloud.google.com/products/operations\"\u003eGoogle Cloud Logging\u003c/a\u003e.  Cloud Logging creates a record of certificate expiration, uses the `\u003ccode\u003ecertificatemanager.googleapis.com/Project\u003c/code\u003e` monitored resource, and is represented by the following message:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eThe log message is delivered every hour and contains a sample of the certificates being close to expiry or already expired.\u003c/p\u003e\u003ch3\u003ePricing\u003c/h3\u003e\u003cp\u003eThe best part is that there’s no additional charge to use the Certificate Manager for the first 100 certificates. To use more than 100 certificates with the management tools, we will charge on a per-certificate, per-month pricing structure. This empowers you to scale up to as many certificates as you need, and as cost-effectively as possible. The pricing will be enabled when the solution goes to General Availability.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"Certificate Manager pricing.png\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Certificate_Manager_prici.0999064919990490.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIt is our hope that these \u003ca href=\"https://cloud.google.com/certificate-manager/docs/how-it-works\"\u003enew features\u003c/a\u003e, combined with the programmability offered by \u003ca href=\"https://cloud.google.com/certificate-manager/docs/overview\"\u003eCertificate Manager\u003c/a\u003e, will enable you to simplify the way you deploy HTTPS and offer a more scalable and secure service to your customers.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/identity-security/10-questions-to-help-boards-safely-maximize-cloud-opportunities/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/cybersecurity_action_team_jl2RU0c.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e10 questions to help boards safely maximize cloud opportunities\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eThese 10 questions from a new Google Cloud whitepaper will help boards of directors safely guide their organizations through cloud migrat...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/google_cloud_security.0999040819990817.max-2000x2000.jpg",
      "date_published": "2022-01-31T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eBabi Seal\u003c/name\u003e\u003ctitle\u003eProduct Manager, Load Balancing\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/google-cloud-deploy-now-ga/",
      "title": "Google Cloud Deploy, now GA, makes it easier to do continuous delivery to GKE",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle-page\u003e\u003cmain id=\"jump-content\"\u003e\u003cpromo-banner-block _nghost-c45=\"\"\u003e\u003c/promo-banner-block\u003e\u003carticle\u003e\u003carticle-header-block\u003e\u003c/article-header-block\u003e\u003carticle-aspect-image-block\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003eGoogle Cloud Deploy\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/article-aspect-image-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-author-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003e Victor Szalvay \u003c/p\u003e\u003cp\u003e Product Manager \u003c/p\u003e\u003c/div\u003e\u003cp\u003e\u003cspan\u003e January 25, 2022 \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-author-block\u003e\u003c/div\u003e\u003carticle-cta _nghost-c47=\"\"\u003e\u003cdiv _ngcontent-c47=\"\"\u003e\u003ch4 _ngcontent-c47=\"\"\u003e\u003cspan _ngcontent-c47=\"\"\u003eTry Google Cloud\u003c/span\u003e\u003c/h4\u003e\u003cp _ngcontent-c47=\"\"\u003e\u003cspan _ngcontent-c47=\"\"\u003eStart building on Google Cloud with $300 in free credits and 20+ always free products.\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003ca _ngcontent-c47=\"\" clicktracker=\"\" rel=\"external\" track-metadata-module=\"article cta\" track-type=\"button\" track-name=\"free trial\" track-metadata-eventdetail=\"https://cloud.google.com/free/\" href=\"https://cloud.google.com/free/\"\u003e\u003cspan _ngcontent-c47=\"\"\u003eFree Trial\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-cta\u003e\u003c/div\u003e\u003carticle-share-block\u003e\u003c/article-share-block\u003e\u003carticle-sticky-share-block\u003e\u003c/article-sticky-share-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-content-stream-block\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c49=\"\"\u003e\u003cdiv _ngcontent-c49=\"\" innerhtml=\"\u0026lt;p\u0026gt;Effective software delivery \u0026amp;#8212; usually achieved via continuous integration (CI) and continuous delivery (CD) \u0026amp;#8212; is a top priority for many product development teams. It\u0026amp;#8217;s easy to understand why: the \u0026lt;a href=\u0026#34;https://cloud.google.com/devops/state-of-devops\u0026#34;\u0026gt;2021 State of DevOps report\u0026lt;/a\u0026gt; found that elite performers of software delivery deployed code much more frequently than low performers, with three times fewer change-related failures. Teams who excel at modern software delivery operational practices were also 1.8 times more likely to report better business outcomes.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;You need great tools to do software delivery effectively. Without capable tooling, teams have to design, maintain, and scale their software delivery solutions on their own, which can be difficult given the breadth of continuous delivery\u0026amp;#8217;s flow control, security and audit, and integration requirements. Deploying container image artifacts adds further complexity, particularly in Kubernetes environments.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eEffective software delivery — usually achieved via continuous integration (CI) and continuous delivery (CD) — is a top priority for many product development teams. It’s easy to understand why: the \u003ca href=\"https://cloud.google.com/devops/state-of-devops\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/devops/state-of-devops\" track-metadata-module=\"post\"\u003e2021 State of DevOps report\u003c/a\u003e found that elite performers of software delivery deployed code much more frequently than low performers, with three times fewer change-related failures. Teams who excel at modern software delivery operational practices were also 1.8 times more likely to report better business outcomes.\u003c/p\u003e\u003cp\u003eYou need great tools to do software delivery effectively. Without capable tooling, teams have to design, maintain, and scale their software delivery solutions on their own, which can be difficult given the breadth of continuous delivery’s flow control, security and audit, and integration requirements. Deploying container image artifacts adds further complexity, particularly in Kubernetes environments.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c49=\"\"\u003e\u003cdiv _ngcontent-c49=\"\" innerhtml=\"\u0026lt;p\u0026gt;Building on your feedback and Google\u0026amp;#8217;s own best practices, we\u0026amp;#8217;ve been working on software delivery tooling that helps you meet your continuous delivery goals \u0026amp;#8212; especially with respect to \u0026lt;a href=\u0026#34;https://cloud.google.com/kubernetes-engine\u0026#34;\u0026gt;Google Kubernetes Engine (GKE)\u0026lt;/a\u0026gt; environments. Today, we are pleased to announce the general availability of \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/\u0026#34;\u0026gt;Google Cloud Deploy\u0026lt;/a\u0026gt;, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Solving for continuous delivery challenges\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;While designing Google Cloud Deploy, we talked to a number of customers to better understand the challenges they face doing continuous delivery to GKE. While a handful of themes emerged, three stood out: cost of ownership, security and audit, and measurement.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Cost of ownership\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;As shared in our \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/google-cloud-deploy-automates-deploys-to-gke\u0026#34;\u0026gt;Preview launch post\u0026lt;/a\u0026gt; this past September, the operational cost of Kubernetes continuous delivery can be very high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, collecting key metrics, and staying current \u0026amp;#8212; to say nothing of maintenance \u0026amp;#8212; is resource-intensive and takes time away from the core business.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;As a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy also provides structure. \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\u0026#34;\u0026gt;Delivery pipelines\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology\u0026#34;\u0026gt;targets\u0026lt;/a\u0026gt; are defined \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/config-files\u0026#34;\u0026gt;declaratively\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/pipeline-instances\u0026#34;\u0026gt;retained with each release\u0026lt;/a\u0026gt;. That means if your delivery pipeline changes, the release\u0026amp;#8217;s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eBuilding on your feedback and Google’s own best practices, we’ve been working on software delivery tooling that helps you meet your continuous delivery goals — especially with respect to \u003ca href=\"https://cloud.google.com/kubernetes-engine\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/kubernetes-engine\" track-metadata-module=\"post\"\u003eGoogle Kubernetes Engine (GKE)\u003c/a\u003e environments. Today, we are pleased to announce the general availability of \u003ca href=\"https://cloud.google.com/deploy/\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/\" track-metadata-module=\"post\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable. \u003c/p\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003c/h3\u003e\u003cp\u003eWhile designing Google Cloud Deploy, we talked to a number of customers to better understand the challenges they face doing continuous delivery to GKE. While a handful of themes emerged, three stood out: cost of ownership, security and audit, and measurement.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eAs shared in our \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/google-cloud-deploy-automates-deploys-to-gke\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/google-cloud-deploy-automates-deploys-to-gke\" track-metadata-module=\"post\"\u003ePreview launch post\u003c/a\u003e this past September, the operational cost of Kubernetes continuous delivery can be very high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, collecting key metrics, and staying current — to say nothing of maintenance — is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\" track-metadata-module=\"post\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology\" track-metadata-module=\"post\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/config-files\" track-metadata-module=\"post\"\u003edeclaratively\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/pipeline-instances\" track-metadata-module=\"post\"\u003eretained with each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c49=\"\"\u003e\u003cdiv _ngcontent-c49=\"\" innerhtml=\"\u0026lt;p\u0026gt;Whether or not you already have a continuous delivery capability, you likely already have continuous integration, approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating\u0026#34;\u0026gt;embraces the GKE delivery tooling ecosystems\u0026lt;/a\u0026gt; in three ways: \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating-ci\u0026#34;\u0026gt;connectivity to CI systems\u0026lt;/a\u0026gt;, support for leading configuration (\u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology#render\u0026#34;\u0026gt;rendering\u0026lt;/a\u0026gt;) tooling, and \u0026lt;a href=\u0026#34;https://cloud.google.com/pubsub\u0026#34;\u0026gt;Pub/Sub\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\u0026#34;\u0026gt;notifications\u0026lt;/a\u0026gt; to enable \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating\u0026#34;\u0026gt;related software delivery tooling\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;\u0026amp;#8220;While looking for a Continuous Delivery solution we considered ArgoCD and Spinnaker, however we chose Google Cloud Deploy because it is a managed service, provided proper CD primitives and integrated seamlessly with our GKE clusters. It has empowered every team member to safely and reliably promote their code from commit all the way through to production.\u0026amp;#8221;\u0026amp;#8212;Jonathan Sokolowski, DevOps Engineer, Search.io\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;A variety of GKE roles and personas interact with continuous delivery processes. DevOps engineers are focused on release promotion and rollback decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy\u0026amp;#8217;s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eWhether or not you already have a continuous delivery capability, you likely already have continuous integration, approval and/or operation workflows, and other systems that intersect with your software delivery practices. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating\" track-metadata-module=\"post\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: \u003ca href=\"https://cloud.google.com/deploy/docs/integrating-ci\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating-ci\" track-metadata-module=\"post\"\u003econnectivity to CI systems\u003c/a\u003e, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology#render\" track-metadata-module=\"post\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/pubsub\" track-metadata-module=\"post\"\u003ePub/Sub\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\" track-metadata-module=\"post\"\u003enotifications\u003c/a\u003e to enable \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating\" track-metadata-module=\"post\"\u003erelated software delivery tooling\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003ci\u003e“While looking for a Continuous Delivery solution we considered ArgoCD and Spinnaker, however we chose Google Cloud Deploy because it is a managed service, provided proper CD primitives and integrated seamlessly with our GKE clusters. It has empowered every team member to safely and reliably promote their code from commit all the way through to production.”—Jonathan Sokolowski, DevOps Engineer, Search.io\u003c/i\u003e\u003c/p\u003e\u003cp\u003eA variety of GKE roles and personas interact with continuous delivery processes. DevOps engineers are focused on release promotion and rollback decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c49=\"\"\u003e\u003cdiv _ngcontent-c49=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Security and control\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy\u0026amp;#8217;s security foundations strengthen secure software supply chain practices through delivery flow control and auditability.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Lots of different users interact with a software delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn\u0026amp;#8217;t always mean you can create release candidates, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Throughout, Google Cloud Deploy enables fine-grained \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/iam-roles-permissions\u0026#34;\u0026gt;restriction through IAM\u0026lt;/a\u0026gt;, with \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/securing/iam\u0026#34;\u0026gt;discrete access control\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/execution-environment\u0026#34;\u0026gt;execution-level security\u0026lt;/a\u0026gt;. Google Cloud Deploy also supports \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/execution-environment#deploying_to_a_private_cluster_on_a_network\u0026#34;\u0026gt;deploying to private GKE clusters\u0026lt;/a\u0026gt; and\u0026amp;#160; \u0026lt;a href=\u0026#34;https://cloud.google.com/vpc-service-controls/docs/supported-products#table_deploy\u0026#34;\u0026gt;Virtual Private Cloud (VPC) Service Controls\u0026lt;/a\u0026gt; (currently in Beta) to respect security perimeters. For safeguards against unwanted approvals, you can take advantage of flow management features such as release \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/deploying-application#promoting_a_release\u0026#34;\u0026gt;promotion\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/managing-delivery-pipeline#rolling_back_a_deployment\u0026#34;\u0026gt;rollback\u0026lt;/a\u0026gt;, and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\u0026#34;\u0026gt;approvals\u0026lt;/a\u0026gt;.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Auditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u0026lt;a href=\u0026#34;https://cloud.google.com/audit-logs\u0026#34;\u0026gt;Cloud Audit Logs\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/audit-logs\u0026#34;\u0026gt;audits\u0026lt;/a\u0026gt; user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline. You can also create Google Cloud Deploy pipelines in \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/regions\u0026#34;\u0026gt;supported locations\u0026lt;/a\u0026gt; to better conform with your business needs.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Measurement\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Great tooling is only part of an effective software delivery strategy \u0026amp;#8212; you also need to know what metrics you need to measure, how, and why. By making it easier to measure software delivery performance, Google Cloud Deploy helps teams focus on software delivery optimization and achieve their desired business outcomes.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy collects and makes available \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/metrics\u0026#34;\u0026gt;built in metrics\u0026lt;/a\u0026gt; about delivery pipelines. These include deployment history and success, and also the DORA metric \u0026amp;#8216;deployment frequency.\u0026amp;#8217;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e\u003cb\u003eSecurity and control\u003c/b\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy’s security foundations strengthen secure software supply chain practices through delivery flow control and auditability.\u003c/p\u003e\u003cp\u003eLots of different users interact with a software delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create release candidates, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\" track-metadata-module=\"post\"\u003erestriction through IAM\u003c/a\u003e, with \u003ca href=\"https://cloud.google.com/deploy/docs/securing/iam\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/securing/iam\" track-metadata-module=\"post\"\u003ediscrete access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/execution-environment\" track-metadata-module=\"post\"\u003eexecution-level security\u003c/a\u003e. Google Cloud Deploy also supports \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment#deploying_to_a_private_cluster_on_a_network\" track-type=\"inline link\" track-name=\"18\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/execution-environment#deploying_to_a_private_cluster_on_a_network\" track-metadata-module=\"post\"\u003edeploying to private GKE clusters\u003c/a\u003e and  \u003ca href=\"https://cloud.google.com/vpc-service-controls/docs/supported-products#table_deploy\" track-type=\"inline link\" track-name=\"19\" track-metadata-eventdetail=\"https://cloud.google.com/vpc-service-controls/docs/supported-products#table_deploy\" track-metadata-module=\"post\"\u003eVirtual Private Cloud (VPC) Service Controls\u003c/a\u003e (currently in Beta) to respect security perimeters. For safeguards against unwanted approvals, you can take advantage of flow management features such as release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application#promoting_a_release\" track-type=\"inline link\" track-name=\"20\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/deploying-application#promoting_a_release\" track-metadata-module=\"post\"\u003epromotion\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#rolling_back_a_deployment\" track-type=\"inline link\" track-name=\"21\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#rolling_back_a_deployment\" track-metadata-module=\"post\"\u003erollback\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\" track-type=\"inline link\" track-name=\"22\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\" track-metadata-module=\"post\"\u003eapprovals\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\" track-type=\"inline link\" track-name=\"23\" track-metadata-eventdetail=\"https://cloud.google.com/audit-logs\" track-metadata-module=\"post\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\" track-type=\"inline link\" track-name=\"24\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/audit-logs\" track-metadata-module=\"post\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline. You can also create Google Cloud Deploy pipelines in \u003ca href=\"https://cloud.google.com/deploy/docs/regions\" track-type=\"inline link\" track-name=\"25\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/regions\" track-metadata-module=\"post\"\u003esupported locations\u003c/a\u003e to better conform with your business needs.\u003c/p\u003e\u003cp\u003e\u003cb\u003eMeasurement\u003c/b\u003e\u003c/p\u003e\u003cp\u003eGreat tooling is only part of an effective software delivery strategy — you also need to know what metrics you need to measure, how, and why. By making it easier to measure software delivery performance, Google Cloud Deploy helps teams focus on software delivery optimization and achieve their desired business outcomes.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy collects and makes available \u003ca href=\"https://cloud.google.com/deploy/docs/metrics\" track-type=\"inline link\" track-name=\"26\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/metrics\" track-metadata-module=\"post\"\u003ebuilt in metrics\u003c/a\u003e about delivery pipelines. These include deployment history and success, and also the DORA metric ‘deployment frequency.’\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c49=\"\"\u003e\u003cdiv _ngcontent-c49=\"\" innerhtml=\"\u0026lt;p\u0026gt;Monitoring your deployed resources is another way to measure the effectiveness of your software delivery processes. To aid monitoring, Google Cloud Deploy \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/labels-annotations#automatic_labels_from\u0026#34;\u0026gt;automatically labels deployed Kubernetes resources\u0026lt;/a\u0026gt;, making it easier to associate\u0026amp;#160; your delivery pipelines with application performance. You can integrate application monitoring further using the \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/api/reference/rest\u0026#34;\u0026gt;Google Cloud Deploy API\u0026lt;/a\u0026gt;, so you can automatically promote code if it is stable and roll it back if an anomaly is detected.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;The future\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Comprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it\u0026amp;#8217;s our hope that Google Cloud Deploy will help you implement complete CI/CD pipelines. And we\u0026amp;#8217;re just getting started! Stay tuned as we introduce exciting new capabilities and features to Google Cloud Deploy in the months to come.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In the meantime, check out the \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy\u0026#34;\u0026gt;product page\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs\u0026#34;\u0026gt;documentation\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/quickstart-basic\u0026#34;\u0026gt;quickstart\u0026lt;/a\u0026gt;, and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/tutorials\u0026#34;\u0026gt;tutorials\u0026lt;/a\u0026gt;. Finally, If you have feedback on Google Cloud Deploy, you can \u0026lt;a href=\u0026#34;https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;join the conversation\u0026lt;/a\u0026gt;. We look forward to hearing from you!\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eMonitoring your deployed resources is another way to measure the effectiveness of your software delivery processes. To aid monitoring, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/labels-annotations#automatic_labels_from\" track-type=\"inline link\" track-name=\"27\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/labels-annotations#automatic_labels_from\" track-metadata-module=\"post\"\u003eautomatically labels deployed Kubernetes resources\u003c/a\u003e, making it easier to associate  your delivery pipelines with application performance. You can integrate application monitoring further using the \u003ca href=\"https://cloud.google.com/deploy/docs/api/reference/rest\" track-type=\"inline link\" track-name=\"28\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/api/reference/rest\" track-metadata-module=\"post\"\u003eGoogle Cloud Deploy API\u003c/a\u003e, so you can automatically promote code if it is stable and roll it back if an anomaly is detected. \u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you implement complete CI/CD pipelines. And we’re just getting started! Stay tuned as we introduce exciting new capabilities and features to Google Cloud Deploy in the months to come. \u003c/p\u003e\u003cp\u003eIn the meantime, check out the \u003ca href=\"https://cloud.google.com/deploy\" track-type=\"inline link\" track-name=\"29\" track-metadata-eventdetail=\"https://cloud.google.com/deploy\" track-metadata-module=\"post\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\" track-type=\"inline link\" track-name=\"30\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs\" track-metadata-module=\"post\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\" track-type=\"inline link\" track-name=\"31\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/quickstart-basic\" track-metadata-module=\"post\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\" track-type=\"inline link\" track-name=\"32\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/tutorials\" track-metadata-module=\"post\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\" track-type=\"inline link\" track-name=\"33\" track-metadata-eventdetail=\"https://www.googlecloudcommunity.com\" track-metadata-module=\"post\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/article-content-stream-block\u003e\u003carticle-tag-list-block\u003e\u003c/article-tag-list-block\u003e\u003c/div\u003e\u003csection\u003e\u003carticle-up-1to3-block _nghost-c48=\"\"\u003e\u003c/article-up-1to3-block\u003e\u003c/section\u003e\u003c/div\u003e\u003c/article\u003e\u003c/main\u003e\u003c/article-page\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eEffective software delivery — usually achieved via continuous integration (CI) and continuous delivery (CD) — is a top priority for many product development teams. It’s easy to understand why: the \u003ca href=\"https://cloud.google.com/devops/state-of-devops\"\u003e2021 State of DevOps report\u003c/a\u003e found that elite performers of software delivery deployed code much more frequently than low performers, with three times fewer change-related failures. Teams who excel at modern software delivery operational practices were also 1.8 times more likely to report better business outcomes.\u003c/p\u003e\u003cp\u003eYou need great tools to do software delivery effectively. Without capable tooling, teams have to design, maintain, and scale their software delivery solutions on their own, which can be difficult given the breadth of continuous delivery’s flow control, security and audit, and integration requirements. Deploying container image artifacts adds further complexity, particularly in Kubernetes environments.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_cloud_deploy.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"1 cloud deploy.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_cloud_deploy.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eBuilding on your feedback and Google’s own best practices, we’ve been working on software delivery tooling that helps you meet your continuous delivery goals — especially with respect to \u003ca href=\"https://cloud.google.com/kubernetes-engine\"\u003eGoogle Kubernetes Engine (GKE)\u003c/a\u003e environments. Today, we are pleased to announce the general availability of \u003ca href=\"https://cloud.google.com/deploy/\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable. \u003c/p\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003c/h3\u003e\u003cp\u003eWhile designing Google Cloud Deploy, we talked to a number of customers to better understand the challenges they face doing continuous delivery to GKE. While a handful of themes emerged, three stood out: cost of ownership, security and audit, and measurement.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eAs shared in our \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/google-cloud-deploy-automates-deploys-to-gke\"\u003ePreview launch post\u003c/a\u003e this past September, the operational cost of Kubernetes continuous delivery can be very high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, collecting key metrics, and staying current — to say nothing of maintenance — is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\"\u003edeclaratively\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\"\u003eretained with each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"4 Delivery pipeline metrics.gif\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/4_Delivery_pipeline_metrics.gif\"/\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ci\u003ePromoting a release\u003c/i\u003e\u003cbr/\u003e\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWhether or not you already have a continuous delivery capability, you likely already have continuous integration, approval and/or operation workflows, and other systems that intersect with your software delivery practices. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: \u003ca href=\"https://cloud.google.com/deploy/docs/integrating-ci\"\u003econnectivity to CI systems\u003c/a\u003e, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\"\u003ePub/Sub\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\"\u003enotifications\u003c/a\u003e to enable \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\"\u003erelated software delivery tooling\u003c/a\u003e.\u003c/p\u003e\u003cp\u003e\u003ci\u003e“While looking for a Continuous Delivery solution we considered ArgoCD and Spinnaker, however we chose Google Cloud Deploy because it is a managed service, provided proper CD primitives and integrated seamlessly with our GKE clusters. It has empowered every team member to safely and reliably promote their code from commit all the way through to production.”—Jonathan Sokolowski, DevOps Engineer, Search.io\u003c/i\u003e\u003c/p\u003e\u003cp\u003eA variety of GKE roles and personas interact with continuous delivery processes. DevOps engineers are focused on release promotion and rollback decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"3 Deployment approvals.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_Deployment_approvals.max-1000x1000.jpg\"/\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ci\u003eDeployment approvals\u003c/i\u003e\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003cb\u003eSecurity and control\u003c/b\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy’s security foundations strengthen secure software supply chain practices through delivery flow control and auditability.\u003c/p\u003e\u003cp\u003eLots of different users interact with a software delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create release candidates, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\"\u003erestriction through IAM\u003c/a\u003e, with \u003ca href=\"https://cloud.google.com/deploy/docs/securing/iam\"\u003ediscrete access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\"\u003eexecution-level security\u003c/a\u003e. Google Cloud Deploy also supports \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment#deploying_to_a_private_cluster_on_a_network\"\u003edeploying to private GKE clusters\u003c/a\u003e and  \u003ca href=\"https://cloud.google.com/vpc-service-controls/docs/supported-products#table_deploy\"\u003eVirtual Private Cloud (VPC) Service Controls\u003c/a\u003e (currently in Beta) to respect security perimeters. For safeguards against unwanted approvals, you can take advantage of flow management features such as release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application#promoting_a_release\"\u003epromotion\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#rolling_back_a_deployment\"\u003erollback\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\"\u003eapprovals\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline. You can also create Google Cloud Deploy pipelines in \u003ca href=\"https://cloud.google.com/deploy/docs/regions\"\u003esupported locations\u003c/a\u003e to better conform with your business needs.\u003c/p\u003e\u003cp\u003e\u003cb\u003eMeasurement\u003c/b\u003e\u003c/p\u003e\u003cp\u003eGreat tooling is only part of an effective software delivery strategy — you also need to know what metrics you need to measure, how, and why. By making it easier to measure software delivery performance, Google Cloud Deploy helps teams focus on software delivery optimization and achieve their desired business outcomes.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy collects and makes available \u003ca href=\"https://cloud.google.com/deploy/docs/metrics\"\u003ebuilt in metrics\u003c/a\u003e about delivery pipelines. These include deployment history and success, and also the DORA metric ‘deployment frequency.’\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"2 Promoting a release.gif\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/2_Promoting_a_release.gif\"/\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ci\u003eDelivery pipeline metrics\u003c/i\u003e\u003cbr/\u003e\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eMonitoring your deployed resources is another way to measure the effectiveness of your software delivery processes. To aid monitoring, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/labels-annotations#automatic_labels_from\"\u003eautomatically labels deployed Kubernetes resources\u003c/a\u003e, making it easier to associate  your delivery pipelines with application performance. You can integrate application monitoring further using the \u003ca href=\"https://cloud.google.com/deploy/docs/api/reference/rest\"\u003eGoogle Cloud Deploy API\u003c/a\u003e, so you can automatically promote code if it is stable and roll it back if an anomaly is detected. \u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you implement complete CI/CD pipelines. And we’re just getting started! Stay tuned as we introduce exciting new capabilities and features to Google Cloud Deploy in the months to come. \u003c/p\u003e\u003cp\u003eIn the meantime, check out the \u003ca href=\"https://cloud.google.com/deploy\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/google-cloud-deploy-automates-deploys-to-gke/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/blog_post_header.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eIntroducing Google Cloud Deploy: Managed continuous delivery to GKE\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eThe new Google Cloud Deploy managed services makes it easier to do continuous delivery to Google Kubernetes Engine, and soon, Anthos.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/blog_post_header.max-2200x2200.jpg",
      "date_published": "2022-01-25T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eVictor Szalvay\u003c/name\u003e\u003ctitle\u003eProduct Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/implementing-google-cloud-devops-for-your-cloud-native-organization/",
      "title": "DevOps for tech companies and startups: Learn from over 32,000 professionals on how to drive success with Google Cloud’s DORA research",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c16=\"\"\u003e\u003cdiv _ngcontent-c16=\"\" innerhtml=\"\u0026lt;p\u0026gt;Many technology-driven organizations and startups use \u0026lt;a href=\u0026#34;https://cloud.google.com/devops\u0026#34;\u0026gt;DevOps\u0026lt;/a\u0026gt; as a business enabler, allowing them to bring ideas to market quickly, increase developer productivity, and increase their customer base. Adopting DevOps workflows can drive success but many companies continue to struggle with how to get started or optimize the DevOps tools they currently have incorporated.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud\u0026amp;#8217;s DevOps Research and Assessment (\u0026lt;a href=\u0026#34;https://cloud.google.com/devops\u0026#34;\u0026gt;DORA\u0026lt;/a\u0026gt;) team helps organizations to deploy faster, scale on demand, and balance costs by providing essential tools and resources for you to succeed. Over the past seven years, our DORA team has surveyed more than 32,000 professionals worldwide via our yearly \u0026lt;a href=\u0026#34;https://cloud.google.com/devops/state-of-devops\u0026#34;\u0026gt;Accelerate State of DevOps reports\u0026lt;/a\u0026gt; (SODR). As the largest and longest-running research of its kind, the SODR provides data-driven industry insights that examine the capabilities and practices that drive software delivery and operational and organizational performance - no matter the industry.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Read below to learn more from our DORA team about how and why your organization should focus on DevOps this year:\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Benchmark your team, identify improvement opportunities\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Our \u0026lt;a href=\u0026#34;https://inthecloud.withgoogle.com/devops-quick-check/dl-cd.html?utm_source=google_owned_website\u0026amp;amp;utm_medium=et\u0026amp;amp;utm_campaign=FY20-Q3-global-demandgen-website-other-gcp_gtm_cost_amp_devops_quick_check_mc\u0026amp;amp;utm_content=app_mod_lp_cta\u0026amp;amp;utm_term=-\u0026amp;amp;_ga=2.131280267.562104682.1627912649-1057981864.1627522111\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;DevOps Quick Check\u0026lt;/a\u0026gt; is based on DORA research and allows companies to gauge their DevOps implementation with just five multiple choice questions. The DevOps Quick Check uses the \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/using-the-four-keys-to-measure-your-devops-performance\u0026#34;\u0026gt;four key DevOps metrics\u0026lt;/a\u0026gt; to help your team assess your current performance, compare your performance to others in your industry, and identify which capabilities are most likely to impact your performance. Teams in every industry recognize the value of quickly taking code from development to production and are looking for ways to improve their organizations\u0026#39; agility. Compromising stability is not an option. The data from the research program shows that speed and stability go hand-in-hand, in fact elite performing teams are nearly twice as likely to have increased software delivery performance and achieve 6570x faster lead-time-to-deploy changes.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Increasing developer productivity\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Along with driving software delivery performance, DevOps helps to increase developer productivity by reducing burnout - something that is a top priority for many organizations. According to the SODR, 89% of respondents worked from home during the pandemic but teams with a\u0026lt;a href=\u0026#34;https://cloud.google.com/architecture/devops/devops-culture-westrum-organizational-culture\u0026#34;\u0026gt; generative team culture,\u0026lt;/a\u0026gt; with people who had feelings of inclusion and belonging within their team, were half as likely to experience burnout. A generative culture along with easy to use \u0026lt;a href=\u0026#34;https://cloud.google.com/architecture/devops/devops-tech-teams-empowered-to-choose-tools\u0026#34;\u0026gt;developer tools \u0026lt;/a\u0026gt;help to streamline developers\u0026amp;#8217; workflows and the process of working with cloud infrastructure.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Developer tools that keep developers focused on what they do best, writing code,\u0026amp;#160; is vital to increase developer productivity. Companies should utilize tools that ensure developers spend as little time as possible containerizing applications while increasing automation are paramount.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;We commonly see developers leverage \u0026lt;a href=\u0026#34;https://docs.docker.com/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Docker\u0026lt;/a\u0026gt; to bring modern applications to life, and there are many benefits of doing so, especially in terms of portability. However, using Docker increases the operational burden on developers. Whereas those that leverage \u0026lt;a href=\u0026#34;https://www.youtube.com/watch?v=suhCr5W_bFc\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Buildpacks\u0026lt;/a\u0026gt; are able to reduce operational burden while supporting enterprise operators who manage apps at scale. They are able to do this because Buildpacks allows code to go straight from source to production, in addition to making it easier to meet security and compliance requirements without developer intervention.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Plus when developers want to speed up the deployment process with flexibility they have the option to leverage \u0026lt;a href=\u0026#34;https://cloud.google.com/run\u0026#34;\u0026gt;Cloud Run\u0026lt;/a\u0026gt;, our fully managed serverless platform offering, which fully supports the use of Buildpacks. Below are some benefits developers and operators can see from Cloud Run:\u0026lt;/p\u0026gt;\u0026lt;ol\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Increased Productivity\u0026lt;/b\u0026gt;: make it easier for developers to onboard more quickly and deploy faster\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;i\u0026gt;Hiring\u0026lt;/i\u0026gt;: choose a platform that makes all developers productive. Serverless platforms, like Cloud Run, help developers who know fewer programming languages become\u0026amp;#160; productive without the need to also be an IT expert\u0026amp;#160;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Decreased Time to Market\u0026lt;/b\u0026gt;: accelerate software releases and value creation to customers that ultimately increase revenue and customer loyalty\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Decreased Cost\u0026lt;/b\u0026gt;: Cloud Run abstracts away all infrastructure management by automatically scaling up and down from zero almost instantaneously - so you only pay for what you use\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ol\u0026gt;\u0026lt;p\u0026gt;Whether you choose Cloud Run or another offering - it\u0026amp;#8217;s not just which cloud infrastructure you choose, but how you implement cloud services that really matters. This is especially important when it comes to being able to scale quickly and efficiently. In the SODR, we found that Elite performers were 3.5 times more likely to have met all essential \u0026lt;a href=\u0026#34;https://cloud.google.com/architecture/devops/devops-tech-cloud-infrastructure\u0026#34;\u0026gt;NIST cloud characteristics\u0026lt;/a\u0026gt;. In terms of scaling, the characteristic of rapid elasticity is key to rapidly scaling outward or inward with demand. In other words, it is very important that your capabilities can be elastically provisioned and released - so no matter how much you grow, your customers always have access to your services.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;The Business Case for DevOps\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Maybe you\u0026#39;re convinced that achieving better speed and stability will help your team but how do you convince your boss?\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The \u0026lt;a href=\u0026#34;https://cloud.google.com/resources/roi-of-devops-transformation-whitepaper\u0026#34;\u0026gt;ROI of DevOps Transformation\u0026lt;/a\u0026gt; provides IT and business decision makers an industry backed, data-driven foundational basis for measuring their investment in DevOps. We found that money saved from DevOps transformation varies from $10M to $259M a year with a return on investment of approximately 30 days. You can use the metrics you provided in the \u0026lt;a href=\u0026#34;https://www.devops-research.com/quickcheck.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;DevOps Quick Check\u0026lt;/a\u0026gt; along with some additional information to get an estimate on your team\u0026#39;s potential return.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Google Cloud DevOps Awards\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Using a collection of these resources along with an objective assessment of how your team is doing, your organization will be able to get quick insights into improvement areas. Change your work by improving these capabilities to deliver more innovation to your customers and improve the speed and stability of your software delivery.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Now that we have shared some of our DevOps best practices with you, we would love to hear about how you are transforming your organization with DevOps. During our awards celebration in March we will be celebrating how our most advanced teams are using DevOps, so tell us about the positive impact that DevOps has had on your teams, customers, and organization. \u0026lt;a href=\u0026#34;https://cloud.google.com/awards/devops\u0026#34;\u0026gt;Enter your submission for the Google Cloud DevOps Awards\u0026lt;/a\u0026gt; today. But don\u0026#39;t delay! The deadline for submissions is January 31, 2022.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;What questions do you have about incorporating DevOps practices into your daily work? \u0026lt;a href=\u0026#34;https://inthecloud.withgoogle.com/born-digital/dl-cd.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Reach out to our experts at Google Cloud.\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eMany technology-driven organizations and startups use \u003ca href=\"https://cloud.google.com/devops\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/devops\" track-metadata-module=\"post\"\u003eDevOps\u003c/a\u003e as a business enabler, allowing them to bring ideas to market quickly, increase developer productivity, and increase their customer base. Adopting DevOps workflows can drive success but many companies continue to struggle with how to get started or optimize the DevOps tools they currently have incorporated.\u003c/p\u003e\u003cp\u003eGoogle Cloud’s DevOps Research and Assessment (\u003ca href=\"https://cloud.google.com/devops\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/devops\" track-metadata-module=\"post\"\u003eDORA\u003c/a\u003e) team helps organizations to deploy faster, scale on demand, and balance costs by providing essential tools and resources for you to succeed. Over the past seven years, our DORA team has surveyed more than 32,000 professionals worldwide via our yearly \u003ca href=\"https://cloud.google.com/devops/state-of-devops\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/devops/state-of-devops\" track-metadata-module=\"post\"\u003eAccelerate State of DevOps reports\u003c/a\u003e (SODR). As the largest and longest-running research of its kind, the SODR provides data-driven industry insights that examine the capabilities and practices that drive software delivery and operational and organizational performance - no matter the industry. \u003c/p\u003e\u003cp\u003eRead below to learn more from our DORA team about how and why your organization should focus on DevOps this year: \u003c/p\u003e\u003ch3\u003eBenchmark your team, identify improvement opportunities\u003c/h3\u003e\u003cp\u003eOur \u003ca href=\"https://inthecloud.withgoogle.com/devops-quick-check/dl-cd.html?utm_source=google_owned_website\u0026amp;utm_medium=et\u0026amp;utm_campaign=FY20-Q3-global-demandgen-website-other-gcp_gtm_cost_amp_devops_quick_check_mc\u0026amp;utm_content=app_mod_lp_cta\u0026amp;utm_term=-\u0026amp;_ga=2.131280267.562104682.1627912649-1057981864.1627522111\" target=\"_blank\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://inthecloud.withgoogle.com\" track-metadata-module=\"post\"\u003eDevOps Quick Check\u003c/a\u003e is based on DORA research and allows companies to gauge their DevOps implementation with just five multiple choice questions. The DevOps Quick Check uses the \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/using-the-four-keys-to-measure-your-devops-performance\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/using-the-four-keys-to-measure-your-devops-performance\" track-metadata-module=\"post\"\u003efour key DevOps metrics\u003c/a\u003e to help your team assess your current performance, compare your performance to others in your industry, and identify which capabilities are most likely to impact your performance. Teams in every industry recognize the value of quickly taking code from development to production and are looking for ways to improve their organizations\u0026#39; agility. Compromising stability is not an option. The data from the research program shows that speed and stability go hand-in-hand, in fact elite performing teams are nearly twice as likely to have increased software delivery performance and achieve 6570x faster lead-time-to-deploy changes.\u003c/p\u003e\u003ch3\u003eIncreasing developer productivity\u003c/h3\u003e\u003cp\u003eAlong with driving software delivery performance, DevOps helps to increase developer productivity by reducing burnout - something that is a top priority for many organizations. According to the SODR, 89% of respondents worked from home during the pandemic but teams with a\u003ca href=\"https://cloud.google.com/architecture/devops/devops-culture-westrum-organizational-culture\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/architecture/devops/devops-culture-westrum-organizational-culture\" track-metadata-module=\"post\"\u003e generative team culture,\u003c/a\u003e with people who had feelings of inclusion and belonging within their team, were half as likely to experience burnout. A generative culture along with easy to use \u003ca href=\"https://cloud.google.com/architecture/devops/devops-tech-teams-empowered-to-choose-tools\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/architecture/devops/devops-tech-teams-empowered-to-choose-tools\" track-metadata-module=\"post\"\u003edeveloper tools \u003c/a\u003ehelp to streamline developers’ workflows and the process of working with cloud infrastructure.\u003c/p\u003e\u003cp\u003eDeveloper tools that keep developers focused on what they do best, writing code,  is vital to increase developer productivity. Companies should utilize tools that ensure developers spend as little time as possible containerizing applications while increasing automation are paramount. \u003c/p\u003e\u003cp\u003eWe commonly see developers leverage \u003ca href=\"https://docs.docker.com/\" target=\"_blank\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://docs.docker.com\" track-metadata-module=\"post\"\u003eDocker\u003c/a\u003e to bring modern applications to life, and there are many benefits of doing so, especially in terms of portability. However, using Docker increases the operational burden on developers. Whereas those that leverage \u003ca href=\"https://www.youtube.com/watch?v=suhCr5W_bFc\" target=\"_blank\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://www.youtube.com\" track-metadata-module=\"post\"\u003eBuildpacks\u003c/a\u003e are able to reduce operational burden while supporting enterprise operators who manage apps at scale. They are able to do this because Buildpacks allows code to go straight from source to production, in addition to making it easier to meet security and compliance requirements without developer intervention. \u003c/p\u003e\u003cp\u003ePlus when developers want to speed up the deployment process with flexibility they have the option to leverage \u003ca href=\"https://cloud.google.com/run\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloud.google.com/run\" track-metadata-module=\"post\"\u003eCloud Run\u003c/a\u003e, our fully managed serverless platform offering, which fully supports the use of Buildpacks. Below are some benefits developers and operators can see from Cloud Run:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eIncreased Productivity\u003c/b\u003e: make it easier for developers to onboard more quickly and deploy faster \u003c/p\u003e\u003c/li\u003e\u003cul\u003e\u003cli\u003e\u003ci\u003eHiring\u003c/i\u003e: choose a platform that makes all developers productive. Serverless platforms, like Cloud Run, help developers who know fewer programming languages become  productive without the need to also be an IT expert \u003c/li\u003e\u003c/ul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eDecreased Time to Market\u003c/b\u003e: accelerate software releases and value creation to customers that ultimately increase revenue and customer loyalty\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eDecreased Cost\u003c/b\u003e: Cloud Run abstracts away all infrastructure management by automatically scaling up and down from zero almost instantaneously - so you only pay for what you use\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eWhether you choose Cloud Run or another offering - it’s not just which cloud infrastructure you choose, but how you implement cloud services that really matters. This is especially important when it comes to being able to scale quickly and efficiently. In the SODR, we found that Elite performers were 3.5 times more likely to have met all essential \u003ca href=\"https://cloud.google.com/architecture/devops/devops-tech-cloud-infrastructure\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/architecture/devops/devops-tech-cloud-infrastructure\" track-metadata-module=\"post\"\u003eNIST cloud characteristics\u003c/a\u003e. In terms of scaling, the characteristic of rapid elasticity is key to rapidly scaling outward or inward with demand. In other words, it is very important that your capabilities can be elastically provisioned and released - so no matter how much you grow, your customers always have access to your services. \u003c/p\u003e\u003ch3\u003eThe Business Case for DevOps\u003c/h3\u003e\u003cp\u003eMaybe you\u0026#39;re convinced that achieving better speed and stability will help your team but how do you convince your boss?\u003c/p\u003e\u003cp\u003eThe \u003ca href=\"https://cloud.google.com/resources/roi-of-devops-transformation-whitepaper\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/resources/roi-of-devops-transformation-whitepaper\" track-metadata-module=\"post\"\u003eROI of DevOps Transformation\u003c/a\u003e provides IT and business decision makers an industry backed, data-driven foundational basis for measuring their investment in DevOps. We found that money saved from DevOps transformation varies from $10M to $259M a year with a return on investment of approximately 30 days. You can use the metrics you provided in the \u003ca href=\"https://www.devops-research.com/quickcheck.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://www.devops-research.com\" track-metadata-module=\"post\"\u003eDevOps Quick Check\u003c/a\u003e along with some additional information to get an estimate on your team\u0026#39;s potential return.\u003c/p\u003e\u003ch3\u003eGoogle Cloud DevOps Awards\u003c/h3\u003e\u003cp\u003eUsing a collection of these resources along with an objective assessment of how your team is doing, your organization will be able to get quick insights into improvement areas. Change your work by improving these capabilities to deliver more innovation to your customers and improve the speed and stability of your software delivery.\u003c/p\u003e\u003cp\u003eNow that we have shared some of our DevOps best practices with you, we would love to hear about how you are transforming your organization with DevOps. During our awards celebration in March we will be celebrating how our most advanced teams are using DevOps, so tell us about the positive impact that DevOps has had on your teams, customers, and organization. \u003ca href=\"https://cloud.google.com/awards/devops\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://cloud.google.com/awards/devops\" track-metadata-module=\"post\"\u003eEnter your submission for the Google Cloud DevOps Awards\u003c/a\u003e today. But don\u0026#39;t delay! The deadline for submissions is January 31, 2022.\u003c/p\u003e\u003cp\u003eWhat questions do you have about incorporating DevOps practices into your daily work? \u003ca href=\"https://inthecloud.withgoogle.com/born-digital/dl-cd.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://inthecloud.withgoogle.com\" track-metadata-module=\"post\"\u003eReach out to our experts at Google Cloud.\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eMany technology-driven organizations and startups use \u003ca href=\"https://cloud.google.com/devops\"\u003eDevOps\u003c/a\u003e as a business enabler, allowing them to bring ideas to market quickly, increase developer productivity, and increase their customer base. Adopting DevOps workflows can drive success but many companies continue to struggle with how to get started or optimize the DevOps tools they currently have incorporated.\u003c/p\u003e\u003cp\u003eGoogle Cloud’s DevOps Research and Assessment (\u003ca href=\"https://cloud.google.com/devops\"\u003eDORA\u003c/a\u003e) team helps organizations to deploy faster, scale on demand, and balance costs by providing essential tools and resources for you to succeed. Over the past seven years, our DORA team has surveyed more than 32,000 professionals worldwide via our yearly \u003ca href=\"https://cloud.google.com/devops/state-of-devops\"\u003eAccelerate State of DevOps reports\u003c/a\u003e (SODR). As the largest and longest-running research of its kind, the SODR provides data-driven industry insights that examine the capabilities and practices that drive software delivery and operational and organizational performance - no matter the industry. \u003c/p\u003e\u003cp\u003eRead below to learn more from our DORA team about how and why your organization should focus on DevOps this year: \u003c/p\u003e\u003ch3\u003eBenchmark your team, identify improvement opportunities\u003c/h3\u003e\u003cp\u003eOur \u003ca href=\"https://inthecloud.withgoogle.com/devops-quick-check/dl-cd.html?utm_source=google_owned_website\u0026amp;utm_medium=et\u0026amp;utm_campaign=FY20-Q3-global-demandgen-website-other-gcp_gtm_cost_amp_devops_quick_check_mc\u0026amp;utm_content=app_mod_lp_cta\u0026amp;utm_term=-\u0026amp;_ga=2.131280267.562104682.1627912649-1057981864.1627522111\" target=\"_blank\"\u003eDevOps Quick Check\u003c/a\u003e is based on DORA research and allows companies to gauge their DevOps implementation with just five multiple choice questions. The DevOps Quick Check uses the \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/using-the-four-keys-to-measure-your-devops-performance\"\u003efour key DevOps metrics\u003c/a\u003e to help your team assess your current performance, compare your performance to others in your industry, and identify which capabilities are most likely to impact your performance. Teams in every industry recognize the value of quickly taking code from development to production and are looking for ways to improve their organizations' agility. Compromising stability is not an option. The data from the research program shows that speed and stability go hand-in-hand, in fact elite performing teams are nearly twice as likely to have increased software delivery performance and achieve 6570x faster lead-time-to-deploy changes.\u003c/p\u003e\u003ch3\u003eIncreasing developer productivity\u003c/h3\u003e\u003cp\u003eAlong with driving software delivery performance, DevOps helps to increase developer productivity by reducing burnout - something that is a top priority for many organizations. According to the SODR, 89% of respondents worked from home during the pandemic but teams with a\u003ca href=\"https://cloud.google.com/architecture/devops/devops-culture-westrum-organizational-culture\"\u003egenerative team culture,\u003c/a\u003e with people who had feelings of inclusion and belonging within their team, were half as likely to experience burnout. A generative culture along with easy to use \u003ca href=\"https://cloud.google.com/architecture/devops/devops-tech-teams-empowered-to-choose-tools\"\u003edeveloper tools\u003c/a\u003ehelp to streamline developers’ workflows and the process of working with cloud infrastructure.\u003c/p\u003e\u003cp\u003eDeveloper tools that keep developers focused on what they do best, writing code,  is vital to increase developer productivity. Companies should utilize tools that ensure developers spend as little time as possible containerizing applications while increasing automation are paramount. \u003c/p\u003e\u003cp\u003eWe commonly see developers leverage \u003ca href=\"https://docs.docker.com/\" target=\"_blank\"\u003eDocker\u003c/a\u003e to bring modern applications to life, and there are many benefits of doing so, especially in terms of portability. However, using Docker increases the operational burden on developers. Whereas those that leverage \u003ca href=\"https://www.youtube.com/watch?v=suhCr5W_bFc\" target=\"_blank\"\u003eBuildpacks\u003c/a\u003e are able to reduce operational burden while supporting enterprise operators who manage apps at scale. They are able to do this because Buildpacks allows code to go straight from source to production, in addition to making it easier to meet security and compliance requirements without developer intervention. \u003c/p\u003e\u003cp\u003ePlus when developers want to speed up the deployment process with flexibility they have the option to leverage \u003ca href=\"https://cloud.google.com/run\"\u003eCloud Run\u003c/a\u003e, our fully managed serverless platform offering, which fully supports the use of Buildpacks. Below are some benefits developers and operators can see from Cloud Run:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eIncreased Productivity\u003c/b\u003e: make it easier for developers to onboard more quickly and deploy faster \u003c/p\u003e\u003c/li\u003e\u003cul\u003e\u003cli\u003e\u003ci\u003eHiring\u003c/i\u003e: choose a platform that makes all developers productive. Serverless platforms, like Cloud Run, help developers who know fewer programming languages become  productive without the need to also be an IT expert \u003c/li\u003e\u003c/ul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eDecreased Time to Market\u003c/b\u003e: accelerate software releases and value creation to customers that ultimately increase revenue and customer loyalty\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eDecreased Cost\u003c/b\u003e: Cloud Run abstracts away all infrastructure management by automatically scaling up and down from zero almost instantaneously - so you only pay for what you use\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eWhether you choose Cloud Run or another offering - it’s not just which cloud infrastructure you choose, but how you implement cloud services that really matters. This is especially important when it comes to being able to scale quickly and efficiently. In the SODR, we found that Elite performers were 3.5 times more likely to have met all essential \u003ca href=\"https://cloud.google.com/architecture/devops/devops-tech-cloud-infrastructure\"\u003eNIST cloud characteristics\u003c/a\u003e. In terms of scaling, the characteristic of rapid elasticity is key to rapidly scaling outward or inward with demand. In other words, it is very important that your capabilities can be elastically provisioned and released - so no matter how much you grow, your customers always have access to your services. \u003c/p\u003e\u003ch3\u003eThe Business Case for DevOps\u003c/h3\u003e\u003cp\u003eMaybe you're convinced that achieving better speed and stability will help your team but how do you convince your boss?\u003c/p\u003e\u003cp\u003eThe \u003ca href=\"https://cloud.google.com/resources/roi-of-devops-transformation-whitepaper\"\u003eROI of DevOps Transformation\u003c/a\u003e provides IT and business decision makers an industry backed, data-driven foundational basis for measuring their investment in DevOps. We found that money saved from DevOps transformation varies from $10M to $259M a year with a return on investment of approximately 30 days. You can use the metrics you provided in the \u003ca href=\"https://www.devops-research.com/quickcheck.html\" target=\"_blank\"\u003eDevOps Quick Check\u003c/a\u003e along with some additional information to get an estimate on your team's potential return.\u003c/p\u003e\u003ch3\u003eGoogle Cloud DevOps Awards\u003c/h3\u003e\u003cp\u003eUsing a collection of these resources along with an objective assessment of how your team is doing, your organization will be able to get quick insights into improvement areas. Change your work by improving these capabilities to deliver more innovation to your customers and improve the speed and stability of your software delivery.\u003c/p\u003e\u003cp\u003eNow that we have shared some of our DevOps best practices with you, we would love to hear about how you are transforming your organization with DevOps. During our awards celebration in March we will be celebrating how our most advanced teams are using DevOps, so tell us about the positive impact that DevOps has had on your teams, customers, and organization. \u003ca href=\"https://cloud.google.com/awards/devops\"\u003eEnter your submission for the Google Cloud DevOps Awards\u003c/a\u003e today. But don't delay! The deadline for submissions is January 31, 2022.\u003c/p\u003e\u003cp\u003eWhat questions do you have about incorporating DevOps practices into your daily work? \u003ca href=\"https://inthecloud.withgoogle.com/born-digital/dl-cd.html\" target=\"_blank\"\u003eReach out to our experts at Google Cloud.\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/announcing-dora-2021-accelerate-state-of-devops-report/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/SODR2021_1920x1080.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e2021 Accelerate State of DevOps report addresses burnout, team performance\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eThe SODR is continually one of the most downloaded assets on the GCP website. We are releasing the updated version of the report with new...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_C_Rnd3_n7MW7mI.max-2200x2200.jpg",
      "date_published": "2022-01-18T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eFer De Oliveira\u003c/name\u003e\u003ctitle\u003eHead, Serverless Scale Specialist, NorthAM\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/databases/understanding-firestore-performance-with-key-visualizer/",
      "title": "Understanding Firestore performance with Key Visualizer",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c16=\"\"\u003e\u003cdiv _ngcontent-c16=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;http://cloud/blog/topics/developers-practitioners/all-you-need-know-about-firestore-cheatsheet\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Firestore\u0026lt;/a\u0026gt; is a serverless, scalable, NoSQL document database. It is ideal for rapid and flexible web and mobile application development, and uniquely supports real-time client device syncing to the database.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;To get the best performance out of \u0026lt;a href=\u0026#34;https://cloud.google.com/firestore\u0026#34;\u0026gt;Firestore\u0026lt;/a\u0026gt;, while also making the most out of Firestore\u0026#39;s automatic scaling and load balancing features, you need to make sure the data layout of your application allows requests to be processed optimally, particularly as your user traffic increases. There are some subtleties to be aware of when it comes to what could happen when traffic ramps up, and to help make this easier to identify, we\u0026amp;#8217;re announcing the General Availability of \u0026lt;a href=\u0026#34;https://cloud.google.com/firestore/docs/key-visualizer\u0026#34;\u0026gt;\u0026lt;b\u0026gt;Key Visualizer\u0026lt;/b\u0026gt;\u0026lt;/a\u0026gt;, an interactive, performance monitoring tool for Firestore.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Key Visualizer generates visual reports based on Firestore documents accessed over time, that will help you understand and optimize the access patterns of your database, as well as troubleshoot performance issues. With Key Visualizer, you can iteratively design a data model or improve your existing application\u0026amp;#8217;s data usage pattern.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Tip: While Key Visualizer can be used with production databases, it\u0026amp;#8217;s best to identify performance issues prior to rolling out changes in production. Consider running application load tests with Firestore in a pre-production environment, and using Key Visualizer to identify potential issues.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Viewing a visualization\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;The Key Visualizer tool is available to all Firestore customers. Visualizations are generated at every hour boundary, covering data for the preceding two hours. Visualizations are generated as long as overall database traffic during a selected period meets the \u0026lt;a href=\u0026#34;https://cloud.google.com/firestore/docs/key-visualizer#scan_eligibility\u0026#34;\u0026gt;scan eligibility\u0026lt;/a\u0026gt; criteria.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;To get an overview of activity using Key Visualizer, first select a two-hour time period and review the heatmap for the \u0026amp;#34;Total ops/s\u0026amp;#34; metric. This view estimates the number of operations per second and how they are distributed across your database. Total ops/s is an estimated sum of write, lookup, and query operations averaged by seconds.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Firestore automatically scales using a technique called range sharding. When using Firestore, you model data in the form of documents stored in hierarchies of collections. The collection hierarchy and document ID is translated to a single key for each document. Documents are logically stored and ordered lexicographically by this key. We use the term \u0026amp;#34;key range\u0026amp;#34; to refer to a range of keys. The full key range is then automatically split up as-needed, driven by storage and traffic load, and served by many replicated servers inside of Firestore.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The following example of Key Visualizer visualization shows a heatmap where there are some major differences in the usage pattern across the database. The X-axis is time, and the Y-axis is the key range for your database, broken down into buckets by traffic.\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Ranges shown in dark colors have little or no activity.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Ranges in bright colors have significantly more activity. In the example below, you can see the \u0026amp;#34;Bar\u0026amp;#34; and \u0026amp;#34;Qux\u0026amp;#34; collections going beyond 50 operations per second for some period of time.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\"\u003e\u003cp\u003e\u003ca href=\"http://cloud/blog/topics/developers-practitioners/all-you-need-know-about-firestore-cheatsheet\" target=\"_blank\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"http://cloud\" track-metadata-module=\"post\"\u003eFirestore\u003c/a\u003e is a serverless, scalable, NoSQL document database. It is ideal for rapid and flexible web and mobile application development, and uniquely supports real-time client device syncing to the database.\u003c/p\u003e\u003cp\u003eTo get the best performance out of \u003ca href=\"https://cloud.google.com/firestore\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/firestore\" track-metadata-module=\"post\"\u003eFirestore\u003c/a\u003e, while also making the most out of Firestore\u0026#39;s automatic scaling and load balancing features, you need to make sure the data layout of your application allows requests to be processed optimally, particularly as your user traffic increases. There are some subtleties to be aware of when it comes to what could happen when traffic ramps up, and to help make this easier to identify, we’re announcing the General Availability of \u003ca href=\"https://cloud.google.com/firestore/docs/key-visualizer\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/firestore/docs/key-visualizer\" track-metadata-module=\"post\"\u003e\u003cb\u003eKey Visualizer\u003c/b\u003e\u003c/a\u003e, an interactive, performance monitoring tool for Firestore.\u003c/p\u003e\u003cp\u003eKey Visualizer generates visual reports based on Firestore documents accessed over time, that will help you understand and optimize the access patterns of your database, as well as troubleshoot performance issues. With Key Visualizer, you can iteratively design a data model or improve your existing application’s data usage pattern.\u003c/p\u003e\u003cp\u003eTip: While Key Visualizer can be used with production databases, it’s best to identify performance issues prior to rolling out changes in production. Consider running application load tests with Firestore in a pre-production environment, and using Key Visualizer to identify potential issues.\u003c/p\u003e\u003ch3\u003eViewing a visualization\u003c/h3\u003e\u003cp\u003eThe Key Visualizer tool is available to all Firestore customers. Visualizations are generated at every hour boundary, covering data for the preceding two hours. Visualizations are generated as long as overall database traffic during a selected period meets the \u003ca href=\"https://cloud.google.com/firestore/docs/key-visualizer#scan_eligibility\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/firestore/docs/key-visualizer#scan_eligibility\" track-metadata-module=\"post\"\u003escan eligibility\u003c/a\u003e criteria.\u003c/p\u003e\u003cp\u003eTo get an overview of activity using Key Visualizer, first select a two-hour time period and review the heatmap for the \u0026#34;Total ops/s\u0026#34; metric. This view estimates the number of operations per second and how they are distributed across your database. Total ops/s is an estimated sum of write, lookup, and query operations averaged by seconds.\u003c/p\u003e\u003cp\u003eFirestore automatically scales using a technique called range sharding. When using Firestore, you model data in the form of documents stored in hierarchies of collections. The collection hierarchy and document ID is translated to a single key for each document. Documents are logically stored and ordered lexicographically by this key. We use the term \u0026#34;key range\u0026#34; to refer to a range of keys. The full key range is then automatically split up as-needed, driven by storage and traffic load, and served by many replicated servers inside of Firestore.\u003c/p\u003e\u003cp\u003eThe following example of Key Visualizer visualization shows a heatmap where there are some major differences in the usage pattern across the database. The X-axis is time, and the Y-axis is the key range for your database, broken down into buckets by traffic.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eRanges shown in dark colors have little or no activity.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eRanges in bright colors have significantly more activity. In the example below, you can see the \u0026#34;Bar\u0026#34; and \u0026#34;Qux\u0026#34; collections going beyond 50 operations per second for some period of time.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003ca href=\"http://cloud/blog/topics/developers-practitioners/all-you-need-know-about-firestore-cheatsheet\" target=\"_blank\"\u003eFirestore\u003c/a\u003e is a serverless, scalable, NoSQL document database. It is ideal for rapid and flexible web and mobile application development, and uniquely supports real-time client device syncing to the database.\u003c/p\u003e\u003cp\u003eTo get the best performance out of \u003ca href=\"https://cloud.google.com/firestore\"\u003eFirestore\u003c/a\u003e, while also making the most out of Firestore's automatic scaling and load balancing features, you need to make sure the data layout of your application allows requests to be processed optimally, particularly as your user traffic increases. There are some subtleties to be aware of when it comes to what could happen when traffic ramps up, and to help make this easier to identify, we’re announcing the General Availability of \u003ca href=\"https://cloud.google.com/firestore/docs/key-visualizer\"\u003e\u003cb\u003eKey Visualizer\u003c/b\u003e\u003c/a\u003e, an interactive, performance monitoring tool for Firestore.\u003c/p\u003e\u003cp\u003eKey Visualizer generates visual reports based on Firestore documents accessed over time, that will help you understand and optimize the access patterns of your database, as well as troubleshoot performance issues. With Key Visualizer, you can iteratively design a data model or improve your existing application’s data usage pattern.\u003c/p\u003e\u003cp\u003eTip: While Key Visualizer can be used with production databases, it’s best to identify performance issues prior to rolling out changes in production. Consider running application load tests with Firestore in a pre-production environment, and using Key Visualizer to identify potential issues.\u003c/p\u003e\u003ch3\u003eViewing a visualization\u003c/h3\u003e\u003cp\u003eThe Key Visualizer tool is available to all Firestore customers. Visualizations are generated at every hour boundary, covering data for the preceding two hours. Visualizations are generated as long as overall database traffic during a selected period meets the \u003ca href=\"https://cloud.google.com/firestore/docs/key-visualizer#scan_eligibility\"\u003escan eligibility\u003c/a\u003e criteria.\u003c/p\u003e\u003cp\u003eTo get an overview of activity using Key Visualizer, first select a two-hour time period and review the heatmap for the \"Total ops/s\" metric. This view estimates the number of operations per second and how they are distributed across your database. Total ops/s is an estimated sum of write, lookup, and query operations averaged by seconds.\u003c/p\u003e\u003cp\u003eFirestore automatically scales using a technique called range sharding. When using Firestore, you model data in the form of documents stored in hierarchies of collections. The collection hierarchy and document ID is translated to a single key for each document. Documents are logically stored and ordered lexicographically by this key. We use the term \"key range\" to refer to a range of keys. The full key range is then automatically split up as-needed, driven by storage and traffic load, and served by many replicated servers inside of Firestore.\u003c/p\u003e\u003cp\u003eThe following example of Key Visualizer visualization shows a heatmap where there are some major differences in the usage pattern across the database. The X-axis is time, and the Y-axis is the key range for your database, broken down into buckets by traffic.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eRanges shown in dark colors have little or no activity.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eRanges in bright colors have significantly more activity. In the example below, you can see the \"Bar\" and \"Qux\" collections going beyond 50 operations per second for some period of time.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"1 Firestore.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Firestore.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eAdditional methods of interpreting Key Visualizer visualizations are detailed in our \u003ca href=\"https://cloud.google.com/firestore/docs/keyvis-patterns\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eBesides the total number of operations, Key Visualizer also provides views with metrics for ops per second, average latency, and tail latency, where traffic is broken down for writes and deletes, lookups, and queries. This capability allows you to identify issues with your data layout or poorly balanced traffic that may be contributing to increased latencies.\u003c/p\u003e\u003ch3\u003eHotspots and heatmap patterns\u003c/h3\u003e\u003cp\u003eKey Visualizer gives you insight into how your traffic is distributed, and lets you understand if latency increases correlate with a hotspot, thus providing you with information to determine what parts of your application need to change. We refer to a \"hotspot\" as a case where traffic is poorly balanced across the database's keyspace. For the best performance, requests should be distributed evenly across a keyspace. The effect of a hotspot can vary, but typically hotspotting causes higher latency and in some cases, even failed operations.\u003c/p\u003e\u003cp\u003eFirestore automatically splits a key range into smaller pieces and distributes the work of serving traffic to more servers when needed. However, this has some limitations. Splitting storage and load takes time, and ramping up traffic too fast may cause hotspots while the service adjusts. The best practice is to distribute operations across the key range, while \u003ca href=\"https://cloud.google.com/firestore/docs/best-practices#ramping_up_traffic\"\u003eramping up traffic\u003c/a\u003e on a cold database with 500 operations per second, and then increasing traffic by up to 50% every 5 minutes. This is called the \"500/50/5\" rule, and allows you to rapidly warm up a cold database safely. For example, ramping to 1,000,000 ops/s can be achieved in under two hours.\u003c/p\u003e\u003cp\u003eFirestore can automatically split a key range until it is serving a single document using a dedicated set of replicated servers. Once this threshold is hit, Firestore is unable to create further splits beyond a single document. As a result, high and sustained volumes of concurrent operations on a single document may result in elevated latencies. You can observe these high latencies using Key Visualizer’s average and tail latency metrics. If you encounter sustained high latencies on a single document, you should consider modifying your data model to split or replicate the data across multiple documents.\u003c/p\u003e\u003cp\u003eKey Visualizer will also help you identify additional traffic patterns:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph_with_image\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cfigure class=\"article-image--wrap-small \"\u003e\u003cimg alt=\"2 Firestore.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_Firestore.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003cb\u003eEvenly distributed usage\u003c/b\u003e: If a heatmap shows a fine-grained mix of dark and bright colors, then reads and writes are evenly distributed throughout the database. This heatmap represents an effective usage pattern for Firestore, and no additional action is required.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph_with_image\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cfigure class=\"article-image--wrap-small \"\u003e\u003cimg alt=\"3 Firestore.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_Firestore.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003cb\u003eSequential Keys\u003c/b\u003e: A heatmap with a single bright diagonal line can indicate a special hotspotting case where the database is using strictly increasing or decreasing keys (document IDs). Sequential keys are an anti-pattern in Firestore, which will result in elevated latency especially at higher operations per second. In this case, the document IDs that are generated and utilized should be randomized. To learn more, see the \u003ca href=\"https://cloud.devsite.corp.google.com/firestore/docs/best-practices#high_read_write_and_delete_rates_to_a_narrow_document_range\"\u003ebest practices page\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph_with_image\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cfigure class=\"article-image--wrap-small \"\u003e\u003cimg alt=\"4 Firestore.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_Firestore.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003cb\u003eSudden traffic increase\u003c/b\u003e: A heatmap with a key range that suddenly changes from dark to bright indicates a sudden spike in load. If the load increase isn’t well distributed across the key range, and exceeds the 500/50/5 rule best practice, the database can experience elevated latency in the operations. In this case, the data layout should be modified to reflect a better distribution of usage and traffic across the keyspace.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eNext steps\u003c/h3\u003e\u003cp\u003eFirestore Key Visualizer is a performance monitoring tool available to administrators and developers to better understand how their applications interact with Firestore. With this launch, Firestore joins our family of Cloud-native databases, including \u003ca href=\"https://cloud.google.com/spanner\"\u003eCloud Spanner\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/bigtable\"\u003eCloud Bigtable\u003c/a\u003e, in offering Key Visualizer to its customers. You can get started with Firestore Key Visualizer for free, from the \u003ca href=\"https://console.cloud.google.com/firestore/key-visualizer\"\u003eCloud Console\u003c/a\u003e.\u003c/p\u003e\u003chr/\u003e\u003cp\u003e\u003ci\u003eAcknowledgement\u003c/i\u003e\u003c/p\u003e\u003cp\u003e\u003ci\u003eSpecial thanks to Minh Nguyen, Lead Product Manager for Firestore, for contributing to this post.\u003c/i\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/cloud_firestore.max-2200x2200.jpg",
      "date_published": "2022-01-18T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eAmarnath Mullick\u003c/name\u003e\u003ctitle\u003eTech Lead and Engineering Manager for Firestore Performance\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/apply-now-for-the-google-cloud-devops-awards/",
      "title": "The Google Cloud DevOps Awards: Final call for submissions!",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv _ngcontent-c60=\"\" innerhtml=\"\u0026lt;p\u0026gt;DevOps continues to be a major business accelerator for our customers and we continually see success from customers applying DevOps Research and Assessment (\u0026lt;a href=\u0026#34;https://www.devops-research.com/research.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;DORA\u0026lt;/a\u0026gt;) principles and findings to their organization. This is why the first annual \u0026lt;a href=\u0026#34;https://cloud.google.com/awards/devops/?eligible_for_cloud_free_trial=true\u0026#34;\u0026gt;DevOps Awards \u0026lt;/a\u0026gt;is targeted to recognize customers shaping the future of DevOps with DORA. Share your inspirational story, supported by examples of business transformation and operational excellence, today.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;With inputs from over 32,000 professionals worldwide and seven years of research, the \u0026lt;a href=\u0026#34;https://cloud.google.com/devops\u0026#34;\u0026gt;Accelerate State of DevOps Report\u0026lt;/a\u0026gt; is the largest and longest running DevOps research of its kind. The different categories of \u0026lt;a href=\u0026#34;https://cloud.google.com/awards/devops/?eligible_for_cloud_free_trial=true\u0026#34;\u0026gt;DevOps Awards\u0026lt;/a\u0026gt; map closely to the practices and capabilities that drive high performance, as identified by the \u0026lt;a href=\u0026#34;https://cloud.google.com/devops/state-of-devops/\u0026#34;\u0026gt;report\u0026lt;/a\u0026gt;.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Organizations, irrespective of their\u0026amp;#160; size, industry, and region are able to apply to one or all ten categories. Please find the categories and their descriptions below:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Optimizing for Speed without sacrificing stability\u0026lt;/b\u0026gt;: This award recognizes one\u0026amp;#160; Google Cloud customer that has driven improvements in speed without sacrificing quality.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Embracing easy-to-use tools to improve remote productivity\u0026lt;/b\u0026gt;: The research showcases how high performing engineers are 1.5 times more likely to have easy to-use tools. To be eligible for this award, share your stories on how easy to use DevOps tools have helped you improve engineer productivity.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Mastering effective disaster recovery\u0026lt;/b\u0026gt;: This award winner will be awarded to demonstrate how a robust, well-tested\u0026lt;a href=\u0026#34;https://cloud.google.com/architecture/dr-scenarios-planning-guide\u0026#34;\u0026gt; disaster recovery (DR)\u0026lt;/a\u0026gt; plan can\u0026amp;#160; protect business operations.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Leveraging loosely coupled architecture\u0026lt;/b\u0026gt;: This award recognizes one customer that successfully transitioned from a tightly coupled \u0026lt;a href=\u0026#34;https://cloud.google.com/architecture/devops/devops-tech-architecture\u0026#34;\u0026gt;architecture\u0026lt;/a\u0026gt; to service-oriented and microservice architectures.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Unleashing the full power of the Cloud\u0026lt;/b\u0026gt;: This award recognizes a Google Cloud customer leveraging all five capabilities of cloud computing to improve software delivery and organizational performance. Specifically, these five capabilities include:\u0026amp;#160;\u0026lt;br\u0026gt;- On demand self-service\u0026lt;br\u0026gt;- Broad network access\u0026lt;br\u0026gt;- Measured service\u0026lt;br\u0026gt;- Rapid elasticity\u0026lt;br\u0026gt;- Resource pooling.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;Read more about the \u0026lt;a href=\u0026#34;https://cloud.google.com/architecture/devops/devops-tech-cloud-infrastructure\u0026#34;\u0026gt;five essential characteristics of cloud computing\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Most improved documentation quality\u0026lt;/b\u0026gt;: This award recognizes one customer that has successfully integrated documentation into their DevOps workflow using Google Cloud Platform tools.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Reducing burnout during COVID-19\u0026lt;/b\u0026gt;: We will recognize one customer that implemented effective processes to improve work/life balance, foster a healthy DevOps culture, and ultimately prevent burnout.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Utilizing IT operations to drive informed business decisions\u0026lt;/b\u0026gt;: This award will go to one customer that employed DevOps best practices to break down silos between development and operations teams.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Driving inclusion and diversity in DevOps\u0026lt;/b\u0026gt;: To highlight the importance of a diverse organization, this award honors one Google Cloud customer that:\u0026amp;#160;\u0026lt;br\u0026gt;\u0026lt;br\u0026gt;Prioritizes diversity and inclusion initiatives for their organization to transform and strengthen their business.\u0026amp;#160;\u0026lt;br\u0026gt;\u0026lt;br\u0026gt;-or\u0026lt;br\u0026gt;\u0026lt;br\u0026gt;Creates unique solutions to help build a more diverse, inclusive, and accessible workplace for your customer, leading to higher levels of engagement, productivity, and innovation.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Accelerating DevOps with DORA\u0026lt;/b\u0026gt;: This award recognizes one customer that has successfully integrated the most DORA practices and capabilities into their workflow using Google Cloud Platform tools.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;This is your chance to show your innovation globally and become a role model for the industry to improve. Winners will receive invitations to roundtables and discussions, press materials, website and social badges, special announcements and even a trophy award.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;We are excited to see all your great submissions. Applications are open until January 31st, so apply for what best suits your company and stay tuned for our awards show in February 2022!\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;For more information on the awards visit our \u0026lt;a href=\u0026#34;https://cloud.google.com/awards/devops/?eligible_for_cloud_free_trial=true\u0026#34;\u0026gt;webpage \u0026lt;/a\u0026gt;and check out \u0026lt;a href=\u0026#34;https://services.google.com/fh/files/misc/2021_devops_awards_guidebook.pdf\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;The Google Cloud DevOps Awards Guidebook\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\" _nghost-c60=\"\"\u003e\u003cp\u003eDevOps continues to be a major business accelerator for our customers and we continually see success from customers applying DevOps Research and Assessment (\u003ca href=\"https://www.devops-research.com/research.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://www.devops-research.com\" track-metadata-module=\"post\"\u003eDORA\u003c/a\u003e) principles and findings to their organization. This is why the first annual \u003ca href=\"https://cloud.google.com/awards/devops/?eligible_for_cloud_free_trial=true\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/awards/devops/?eligible_for_cloud_free_trial=true\" track-metadata-module=\"post\"\u003eDevOps Awards \u003c/a\u003eis targeted to recognize customers shaping the future of DevOps with DORA. Share your inspirational story, supported by examples of business transformation and operational excellence, today. \u003c/p\u003e\u003cp\u003eWith inputs from over 32,000 professionals worldwide and seven years of research, the \u003ca href=\"https://cloud.google.com/devops\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/devops\" track-metadata-module=\"post\"\u003eAccelerate State of DevOps Report\u003c/a\u003e is the largest and longest running DevOps research of its kind. The different categories of \u003ca href=\"https://cloud.google.com/awards/devops/?eligible_for_cloud_free_trial=true\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/awards/devops/?eligible_for_cloud_free_trial=true\" track-metadata-module=\"post\"\u003eDevOps Awards\u003c/a\u003e map closely to the practices and capabilities that drive high performance, as identified by the \u003ca href=\"https://cloud.google.com/devops/state-of-devops/\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/devops/state-of-devops/\" track-metadata-module=\"post\"\u003ereport\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eOrganizations, irrespective of their  size, industry, and region are able to apply to one or all ten categories. Please find the categories and their descriptions below:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eOptimizing for Speed without sacrificing stability\u003c/b\u003e: This award recognizes one  Google Cloud customer that has driven improvements in speed without sacrificing quality. \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eEmbracing easy-to-use tools to improve remote productivity\u003c/b\u003e: The research showcases how high performing engineers are 1.5 times more likely to have easy to-use tools. To be eligible for this award, share your stories on how easy to use DevOps tools have helped you improve engineer productivity.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eMastering effective disaster recovery\u003c/b\u003e: This award winner will be awarded to demonstrate how a robust, well-tested\u003ca href=\"https://cloud.google.com/architecture/dr-scenarios-planning-guide\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/architecture/dr-scenarios-planning-guide\" track-metadata-module=\"post\"\u003e disaster recovery (DR)\u003c/a\u003e plan can  protect business operations.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eLeveraging loosely coupled architecture\u003c/b\u003e: This award recognizes one customer that successfully transitioned from a tightly coupled \u003ca href=\"https://cloud.google.com/architecture/devops/devops-tech-architecture\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/architecture/devops/devops-tech-architecture\" track-metadata-module=\"post\"\u003earchitecture\u003c/a\u003e to service-oriented and microservice architectures.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eUnleashing the full power of the Cloud\u003c/b\u003e: This award recognizes a Google Cloud customer leveraging all five capabilities of cloud computing to improve software delivery and organizational performance. Specifically, these five capabilities include: \u003cbr/\u003e- On demand self-service\u003cbr/\u003e- Broad network access\u003cbr/\u003e- Measured service\u003cbr/\u003e- Rapid elasticity\u003cbr/\u003e- Resource pooling.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eRead more about the \u003ca href=\"https://cloud.google.com/architecture/devops/devops-tech-cloud-infrastructure\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/architecture/devops/devops-tech-cloud-infrastructure\" track-metadata-module=\"post\"\u003efive essential characteristics of cloud computing\u003c/a\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eMost improved documentation quality\u003c/b\u003e: This award recognizes one customer that has successfully integrated documentation into their DevOps workflow using Google Cloud Platform tools.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eReducing burnout during COVID-19\u003c/b\u003e: We will recognize one customer that implemented effective processes to improve work/life balance, foster a healthy DevOps culture, and ultimately prevent burnout.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eUtilizing IT operations to drive informed business decisions\u003c/b\u003e: This award will go to one customer that employed DevOps best practices to break down silos between development and operations teams.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli\u003e\u003cdiv\u003e\u003cp\u003e\u003cb\u003eDriving inclusion and diversity in DevOps\u003c/b\u003e: To highlight the importance of a diverse organization, this award honors one Google Cloud customer that: \u003c/p\u003e\u003cp\u003ePrioritizes diversity and inclusion initiatives for their organization to transform and strengthen their business. \u003c/p\u003e\u003cp\u003e-or\u003c/p\u003e\u003cp\u003eCreates unique solutions to help build a more diverse, inclusive, and accessible workplace for your customer, leading to higher levels of engagement, productivity, and innovation.\u003c/p\u003e\u003c/div\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eAccelerating DevOps with DORA\u003c/b\u003e: This award recognizes one customer that has successfully integrated the most DORA practices and capabilities into their workflow using Google Cloud Platform tools.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThis is your chance to show your innovation globally and become a role model for the industry to improve. Winners will receive invitations to roundtables and discussions, press materials, website and social badges, special announcements and even a trophy award.\u003c/p\u003e\u003cp\u003eWe are excited to see all your great submissions. Applications are open until January 31st, so apply for what best suits your company and stay tuned for our awards show in February 2022!\u003c/p\u003e\u003cp\u003eFor more information on the awards visit our \u003ca href=\"https://cloud.google.com/awards/devops/?eligible_for_cloud_free_trial=true\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/awards/devops/?eligible_for_cloud_free_trial=true\" track-metadata-module=\"post\"\u003ewebpage \u003c/a\u003eand check out \u003ca href=\"https://services.google.com/fh/files/misc/2021_devops_awards_guidebook.pdf\" target=\"_blank\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://services.google.com\" track-metadata-module=\"post\"\u003eThe Google Cloud DevOps Awards Guidebook\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eDevOps continues to be a major business accelerator for our customers and we continually see success from customers applying DevOps Research and Assessment (\u003ca href=\"https://www.devops-research.com/research.html\" target=\"_blank\"\u003eDORA\u003c/a\u003e) principles and findings to their organization. This is why the first annual \u003ca href=\"https://cloud.google.com/awards/devops/?eligible_for_cloud_free_trial=true\"\u003eDevOps Awards\u003c/a\u003eis targeted to recognize customers shaping the future of DevOps with DORA. Share your inspirational story, supported by examples of business transformation and operational excellence, today. \u003c/p\u003e\u003cp\u003eWith inputs from over 32,000 professionals worldwide and seven years of research, the \u003ca href=\"https://cloud.google.com/devops\"\u003eAccelerate State of DevOps Report\u003c/a\u003e is the largest and longest running DevOps research of its kind. The different categories of \u003ca href=\"https://cloud.google.com/awards/devops/?eligible_for_cloud_free_trial=true\"\u003eDevOps Awards\u003c/a\u003e map closely to the practices and capabilities that drive high performance, as identified by the \u003ca href=\"https://cloud.google.com/devops/state-of-devops/\"\u003ereport\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eOrganizations, irrespective of their  size, industry, and region are able to apply to one or all ten categories. Please find the categories and their descriptions below:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eOptimizing for Speed without sacrificing stability\u003c/b\u003e: This award recognizes one  Google Cloud customer that has driven improvements in speed without sacrificing quality. \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eEmbracing easy-to-use tools to improve remote productivity\u003c/b\u003e: The research showcases how high performing engineers are 1.5 times more likely to have easy to-use tools. To be eligible for this award, share your stories on how easy to use DevOps tools have helped you improve engineer productivity.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eMastering effective disaster recovery\u003c/b\u003e: This award winner will be awarded to demonstrate how a robust, well-tested\u003ca href=\"https://cloud.google.com/architecture/dr-scenarios-planning-guide\"\u003edisaster recovery (DR)\u003c/a\u003e plan can  protect business operations.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eLeveraging loosely coupled architecture\u003c/b\u003e: This award recognizes one customer that successfully transitioned from a tightly coupled \u003ca href=\"https://cloud.google.com/architecture/devops/devops-tech-architecture\"\u003earchitecture\u003c/a\u003e to service-oriented and microservice architectures.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eUnleashing the full power of the Cloud\u003c/b\u003e: This award recognizes a Google Cloud customer leveraging all five capabilities of cloud computing to improve software delivery and organizational performance. Specifically, these five capabilities include: \u003cbr/\u003e- On demand self-service\u003cbr/\u003e- Broad network access\u003cbr/\u003e- Measured service\u003cbr/\u003e- Rapid elasticity\u003cbr/\u003e- Resource pooling.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eRead more about the \u003ca href=\"https://cloud.google.com/architecture/devops/devops-tech-cloud-infrastructure\"\u003efive essential characteristics of cloud computing\u003c/a\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eMost improved documentation quality\u003c/b\u003e: This award recognizes one customer that has successfully integrated documentation into their DevOps workflow using Google Cloud Platform tools.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eReducing burnout during COVID-19\u003c/b\u003e: We will recognize one customer that implemented effective processes to improve work/life balance, foster a healthy DevOps culture, and ultimately prevent burnout.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eUtilizing IT operations to drive informed business decisions\u003c/b\u003e: This award will go to one customer that employed DevOps best practices to break down silos between development and operations teams.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eDriving inclusion and diversity in DevOps\u003c/b\u003e: To highlight the importance of a diverse organization, this award honors one Google Cloud customer that: \u003cbr/\u003e\u003cbr/\u003ePrioritizes diversity and inclusion initiatives for their organization to transform and strengthen their business. \u003cbr/\u003e\u003cbr/\u003e-or\u003cbr/\u003e\u003cbr/\u003eCreates unique solutions to help build a more diverse, inclusive, and accessible workplace for your customer, leading to higher levels of engagement, productivity, and innovation.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eAccelerating DevOps with DORA\u003c/b\u003e: This award recognizes one customer that has successfully integrated the most DORA practices and capabilities into their workflow using Google Cloud Platform tools.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThis is your chance to show your innovation globally and become a role model for the industry to improve. Winners will receive invitations to roundtables and discussions, press materials, website and social badges, special announcements and even a trophy award.\u003c/p\u003e\u003cp\u003eWe are excited to see all your great submissions. Applications are open until January 31st, so apply for what best suits your company and stay tuned for our awards show in February 2022!\u003c/p\u003e\u003cp\u003eFor more information on the awards visit our \u003ca href=\"https://cloud.google.com/awards/devops/?eligible_for_cloud_free_trial=true\"\u003ewebpage\u003c/a\u003eand check out \u003ca href=\"https://services.google.com/fh/files/misc/2021_devops_awards_guidebook.pdf\" target=\"_blank\"\u003eThe Google Cloud DevOps Awards Guidebook\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/original_images/devops_awards.gif",
      "date_published": "2022-01-11T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eBrenna Washington\u003c/name\u003e\u003ctitle\u003eProduct Marketing Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/application-development/a-cloud-built-for-developers-2021-year-in-review/",
      "title": "A cloud built for developers — 2021 year in review",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv _ngcontent-c77=\"\" innerhtml=\"\u0026lt;p\u0026gt;2021 was a seminal year for software developers. Every company accelerated their digital and online efforts, while simultaneously moving to remote development. Innovation by driving developer productivity was top of mind for nearly every IT executive we spoke to. Many asked us about Alphabet\u0026#39;s long track record of innovation. From Google search to Waymo\u0026amp;#8217;s driverless cars,\u0026amp;#160; is there a secret to developing the next big thing?\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The answer is simple: 10X thinking. Look for solutions that help customers drive 10X improvements, through a series of smaller increments that compound to a large impact over time. At Google Cloud, we follow a similar philosophy to help our customers become innovative technology companies. In recent times, we\u0026amp;#8217;ve worked closely with partners, customers, and developers on services that help unlock 10X improvements in developer productivity.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Six years ago, we introduced a managed Kubernetes service, Google Kubernetes Engine (GKE). This year, we added \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/containers-kubernetes/introducing-gke-autopilot\u0026#34;\u0026gt;GKE Autopilot\u0026lt;/a\u0026gt;, which revolutionized Kubernetes management by eliminating all node management operations. Likewise, our \u0026lt;a href=\u0026#34;https://cloud.google.com/run\u0026#34;\u0026gt;Cloud Run\u0026lt;/a\u0026gt; serverless platform was the first service of its kind, allowing developers to go beyond running small bits of code and run full applications in a serverless environment. From September 2020 to September 2021, Cloud Run deployments more than quadrupled. More recently, we co-founded the \u0026lt;a href=\u0026#34;https://openssf.org/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Open Source Security Foundation\u0026lt;/a\u0026gt; and began working on secure continuous Integration and delivery (CI/CD) services a year or so ahead of the cybersecurity threats that made it to headlines.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Here are the top developer challenges that customers asked us to solve in 2021:\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Driving distributed developer productivity\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Securing the software supply chain\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Simplifying running of cloud-native applications\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;Read on for more insights.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Driving distributed developer productivity\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;A critical prerequisite for innovation is time. Investments in developer productivity free developers to work on the important things. Traditionally, developers have spent hours downloading and installing tools to their local environments, updating them with the latest versions, or dependencies. \u0026lt;a href=\u0026#34;https://cloud.google.com/shell/docs/editor-overview\u0026#34;\u0026gt;Cloud Shell Editor\u0026lt;/a\u0026gt; is a full remote development environment with a growing set of built in security capabilities. It comes with developer tools pre-installed, including MySql, Kubernetes, Docker, minikube, Skaffold, etc. Developers just needed a web browser and internet connection to be productive. Developers now have access to \u0026lt;a href=\u0026#34;https://cloud.google.com/shell/docs/cloud-shell-tutorials/tutorials\u0026#34;\u0026gt;tutorials\u0026lt;/a\u0026gt; right from Cloud Shell Editor, and can try code samples directly in \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/topics/developers-practitioners/run-code-samples-directly-google-cloud-documentation\u0026#34;\u0026gt;our documentation\u0026lt;/a\u0026gt;. Additionally, with support for \u0026lt;a href=\u0026#34;https://cloud.google.com/run/docs/building/containers\u0026#34;\u0026gt;buildpacks\u0026lt;/a\u0026gt;, developers can create container images \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/serverless/build-and-deploy-an-app-to-cloud-run-with-a-single-command\u0026#34;\u0026gt;directly from source code\u0026lt;/a\u0026gt;, without knowing anything about docker or containers.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Securing the software supply chain\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Software supply chain vulnerabilities had far reaching consequences in 2021, with events such as \u0026lt;a href=\u0026#34;https://blogs.microsoft.com/on-the-issues/2020/12/17/cyberattacks-cybersecurity-solarwinds-fireeye/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;SolarWinds\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://www.mimecast.com/blog/important-update-from-mimecast/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Mimecast/Microsoft Exchange\u0026lt;/a\u0026gt;, and \u0026lt;a href=\u0026#34;https://logging.apache.org/log4j/2.x/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Log4j \u0026lt;/a\u0026gt;affecting businesses, daily life, and entire \u0026lt;a href=\u0026#34;https://www.cyberscoop.com/dhs-cyber-alert-subpoena-us/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;governments\u0026lt;/a\u0026gt;. President Biden even issued an \u0026lt;a href=\u0026#34;https://www.whitehouse.gov/briefing-room/presidential-actions/2021/05/12/executive-order-on-improving-the-nations-cybersecurity/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;executive order\u0026lt;/a\u0026gt; to strengthen software supply-chain security standards.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Solving the software supply chain problem requires players across industries to work together. This is why we co-founded the\u0026lt;a href=\u0026#34;https://openssf.org/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt; Open Source Security Foundation\u0026lt;/a\u0026gt; (Open SSF). We also proposed \u0026lt;a href=\u0026#34;https://security.googleblog.com/2021/06/introducing-slsa-end-to-end-framework.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;SLSA\u0026lt;/a\u0026gt;, an industry-wide framework for maintaining the integrity of software artifacts throughout the software supply chain.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Open source, with its complex dependency trees, continues to remain a prime target for exploitation. In fact, an estimated \u0026lt;a href=\u0026#34;https://venturebeat.com/2021/04/13/synopsys-84-of-codebases-contain-an-open-source-vulnerability/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;84% of commercial code bases\u0026lt;/a\u0026gt; have at least one open source vulnerability. Today, developers can use our tools such as \u0026lt;a href=\u0026#34;https://github.com/ossf/allstar\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Allstar GitHub App\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://opensource.googleblog.com/2020/11/security-scorecards-for-open-source.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;open source security score cards\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://deps.dev/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Open Source Insights\u0026lt;/a\u0026gt; to implement security best practices, determine a risk score for open source projects, and visualize a project\u0026#39;s deep dependencies. And several of these same\u0026amp;#160; kinds of open-source innovations are available out of the box to Google Cloud customers. Here are a few examples:\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Detailed \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/identity-security/recommendations-for-apache-log4j2-vulnerability\u0026#34;\u0026gt;recommendations\u0026lt;/a\u0026gt; to help mitigate the Apache Log4j vulnerability.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;The \u0026lt;a href=\u0026#34;https://cloud.google.com/container-analysis/docs/java-overview\u0026#34;\u0026gt;Java scanning feature\u0026lt;/a\u0026gt; of Google Cloud \u0026lt;a href=\u0026#34;https://cloud.google.com/container-analysis/docs/container-scanning-overview\u0026#34;\u0026gt;On-Demand Scanning\u0026lt;/a\u0026gt;, which can be quite handy for developers to identify Linux-based container images that use an impacted version of Log4j. On-Demand Scanning can be used with no charge until December 31, 2021.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Cloud Build, our serverless CI/CD service, offers \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/application-development/google-introduces-slsa-framework\u0026#34;\u0026gt;SLSA Level 1 compliance\u0026lt;/a\u0026gt; by default. This verifiable build provenance lets you trace a binary to the source code to prevent tampering and prove that the code you\u0026amp;#8217;re running is the code you think you\u0026amp;#8217;re running.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Cloud Build\u0026amp;#8217;s new \u0026lt;a href=\u0026#34;https://cloud.google.com/build/docs/securing-builds/use-provenance-and-binary-authorization\u0026#34;\u0026gt;build integrity feature\u0026lt;/a\u0026gt; improves on this by automatically generating digital signatures, which can be validated before deployment by \u0026lt;a href=\u0026#34;https://cloud.google.com/binary-authorization\u0026#34;\u0026gt;Binary Authorization\u0026lt;/a\u0026gt;.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;h3\u0026gt;Simplifying running cloud-native applications\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Innovation is rarely a straight road, there are many wrong turns along the way. Developers need a cost effective runtime, a way to run experiments and fail forward fast. That\u0026#39;s why \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/containers-kubernetes/introducing-gke-autopilot\u0026#34;\u0026gt;GKE Autopilot\u0026lt;/a\u0026gt; takes GKE, the \u0026lt;a href=\u0026#34;https://cloud.google.com/resources/gartner-solution-scorecard-for-kubernetes-analyst-report\u0026#34;\u0026gt;most\u0026lt;/a\u0026gt; mature Kubernetes service on the market and further simplifies Kubernetes operations by providing a managed control and data plane, an optimized configuration out-of-the-box, automated scalability, health checks and repairs, and pay-for-use pricing.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;\u0026amp;#8220;With GKE Autopilot, we can do more with our business. We can continue developing and upgrading our products, rather than focusing on fine-tuning infrastructure.\u0026amp;#8221;\u0026amp;#8212;\u0026lt;b\u0026gt;Jun Sakata, Software Engineer, Site Reliability, \u0026lt;a href=\u0026#34;https://cloud.google.com/customers/ubie\u0026#34;\u0026gt;Ubie\u0026lt;/a\u0026gt;\u0026amp;#160;\u0026lt;/b\u0026gt;\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Simpler still is no cluster all. Cloud Run provides developers the freedom to run services from code or container images with no cluster or VM to manage. At the same time, it provides a hypervisor grade secure sandbox environment and several built in DevOps capabilities such as, \u0026lt;a href=\u0026#34;https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration\u0026#34;\u0026gt;multi-versioned deployments, gradual rollouts and rollbacks\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/run/docs/continuous-deployment-with-cloud-build\u0026#34;\u0026gt;GitHub\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/run/docs/building/containers\u0026#34;\u0026gt;Cloud Build\u0026lt;/a\u0026gt; integrations. This is ideal for web and mobile application development. In 2021, with \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/serverless/the-next-big-evolution-in-cloud-computing\u0026#34;\u0026gt;additions\u0026lt;/a\u0026gt; like \u0026lt;a href=\u0026#34;https://cloud.google.com/run/docs/about-concurrency\u0026#34;\u0026gt;higher per-instance concurrency\u0026lt;/a\u0026gt;, new \u0026lt;a href=\u0026#34;https://cloud.google.com/run/docs/configuring/cpu-allocation\u0026#34;\u0026gt;CPU allocation controls\u0026lt;/a\u0026gt;, and support for \u0026lt;a href=\u0026#34;https://cloud.google.com/run/docs/deploying\u0026#34;\u0026gt;standard Docker images\u0026lt;/a\u0026gt;, the benefits of serverless can now be expanded to a wider range of workloads, including legacy ones. Additionally, with newer cost controls along with billing flexibility like \u0026lt;a href=\u0026#34;https://cloud.google.com/run/cud\u0026#34;\u0026gt;committed use contracts\u0026lt;/a\u0026gt; and features like \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/serverless/cloud-run-gets-always-on-cpu-allocation\u0026#34;\u0026gt;always-on CPU\u0026lt;/a\u0026gt;, it\u0026amp;#8217;s possible to run more steady-state pattern workloads cost effectively in a serverless environment.\u0026amp;#160; Best of all, thanks to improvements like these, organizations using Cloud Run have reported reduction in \u0026lt;a href=\u0026#34;https://cloud.google.com/resources/forrester-cloudrun-benefits-report\u0026#34;\u0026gt;developer recruiting costs by 40%\u0026lt;/a\u0026gt;.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Cloud Run is also the first platform to provide developers the option to optimize their carbon footprint.\u0026amp;#160; With the news self-service \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/topics/sustainability/google-cloud-region-picker-helps-you-make-the-green-choice\u0026#34;\u0026gt;Region Picker\u0026lt;/a\u0026gt; you can choose the data center region with the lowest gross carbon cost on which to run your Cloud Run workloads. Further, with just one click, \u0026lt;a href=\u0026#34;https://cloud.google.com/carbon-footprint\u0026#34;\u0026gt;Google Cloud Carbon Footprint \u0026lt;/a\u0026gt;gives you access to the energy-related emissions data for external carbon disclosures.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;\u0026amp;#8220;With Cloud Run, we only need half the people to manage our systems as compared to before\u0026amp;#8221; \u0026lt;b\u0026gt;Google Cloud Platform Architect, \u0026lt;a href=\u0026#34;https://cloud.google.com/resources/forrester-cloudrun-benefits-report\u0026#34;\u0026gt;Cosmetics\u0026lt;/a\u0026gt;\u0026amp;#160;\u0026lt;/b\u0026gt;\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;\u0026amp;#8220;Cloud Run is one of the easiest services on Google Cloud Platform you can deploy to. It\u0026amp;#8217;s just super simple.\u0026amp;#8221; \u0026lt;b\u0026gt;CTO, \u0026lt;/b\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/resources/forrester-cloudrun-benefits-report\u0026#34;\u0026gt;\u0026lt;b\u0026gt;Healthcare SaaS\u0026lt;/b\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;If you want to give Cloud Run and associated Cloud Functions a try, check out the \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/serverless/serverless-hackathon\u0026#34;\u0026gt;Easy as Pie Serverless Hackathon\u0026lt;/a\u0026gt;, which offers \u0026amp;#160;over $20,000 USD in cash prizes.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;2022: More to come\u0026amp;#160;\u0026amp;#160;\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;2021 brought simplification and greater attention to developer productivity. It is essential that developers continue to operate at even higher levels of the stack, without worrying about infrastructure, security, compliance and integrations. This is the Northstar for 2022. In 2022, look for Google Cloud to co-innovate with our ISV partners, developers, and SecOps team to bring you the 10X innovation you need from the cloud that is built for developers.\u0026lt;/p\u0026gt;\" _nghost-c77=\"\"\u003e\u003cp\u003e2021 was a seminal year for software developers. Every company accelerated their digital and online efforts, while simultaneously moving to remote development. Innovation by driving developer productivity was top of mind for nearly every IT executive we spoke to. Many asked us about Alphabet\u0026#39;s long track record of innovation. From Google search to Waymo’s driverless cars,  is there a secret to developing the next big thing? \u003c/p\u003e\u003cp\u003eThe answer is simple: 10X thinking. Look for solutions that help customers drive 10X improvements, through a series of smaller increments that compound to a large impact over time. At Google Cloud, we follow a similar philosophy to help our customers become innovative technology companies. In recent times, we’ve worked closely with partners, customers, and developers on services that help unlock 10X improvements in developer productivity. \u003c/p\u003e\u003cp\u003eSix years ago, we introduced a managed Kubernetes service, Google Kubernetes Engine (GKE). This year, we added \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/introducing-gke-autopilot\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/containers-kubernetes/introducing-gke-autopilot\" track-metadata-module=\"post\"\u003eGKE Autopilot\u003c/a\u003e, which revolutionized Kubernetes management by eliminating all node management operations. Likewise, our \u003ca href=\"https://cloud.google.com/run\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/run\" track-metadata-module=\"post\"\u003eCloud Run\u003c/a\u003e serverless platform was the first service of its kind, allowing developers to go beyond running small bits of code and run full applications in a serverless environment. From September 2020 to September 2021, Cloud Run deployments more than quadrupled. More recently, we co-founded the \u003ca href=\"https://openssf.org/\" target=\"_blank\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://openssf.org\" track-metadata-module=\"post\"\u003eOpen Source Security Foundation\u003c/a\u003e and began working on secure continuous Integration and delivery (CI/CD) services a year or so ahead of the cybersecurity threats that made it to headlines. \u003c/p\u003e\u003cp\u003eHere are the top developer challenges that customers asked us to solve in 2021: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eDriving distributed developer productivity\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eSecuring the software supply chain\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eSimplifying running of cloud-native applications \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eRead on for more insights. \u003c/p\u003e\u003ch3\u003eDriving distributed developer productivity\u003c/h3\u003e\u003cp\u003eA critical prerequisite for innovation is time. Investments in developer productivity free developers to work on the important things. Traditionally, developers have spent hours downloading and installing tools to their local environments, updating them with the latest versions, or dependencies. \u003ca href=\"https://cloud.google.com/shell/docs/editor-overview\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/shell/docs/editor-overview\" track-metadata-module=\"post\"\u003eCloud Shell Editor\u003c/a\u003e is a full remote development environment with a growing set of built in security capabilities. It comes with developer tools pre-installed, including MySql, Kubernetes, Docker, minikube, Skaffold, etc. Developers just needed a web browser and internet connection to be productive. Developers now have access to \u003ca href=\"https://cloud.google.com/shell/docs/cloud-shell-tutorials/tutorials\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/shell/docs/cloud-shell-tutorials/tutorials\" track-metadata-module=\"post\"\u003etutorials\u003c/a\u003e right from Cloud Shell Editor, and can try code samples directly in \u003ca href=\"https://cloud.google.com/blog/topics/developers-practitioners/run-code-samples-directly-google-cloud-documentation\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/blog/topics/developers-practitioners/run-code-samples-directly-google-cloud-documentation\" track-metadata-module=\"post\"\u003eour documentation\u003c/a\u003e. Additionally, with support for \u003ca href=\"https://cloud.google.com/run/docs/building/containers\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/run/docs/building/containers\" track-metadata-module=\"post\"\u003ebuildpacks\u003c/a\u003e, developers can create container images \u003ca href=\"https://cloud.google.com/blog/products/serverless/build-and-deploy-an-app-to-cloud-run-with-a-single-command\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/serverless/build-and-deploy-an-app-to-cloud-run-with-a-single-command\" track-metadata-module=\"post\"\u003edirectly from source code\u003c/a\u003e, without knowing anything about docker or containers. \u003c/p\u003e\u003ch3\u003eSecuring the software supply chain\u003c/h3\u003e\u003cp\u003eSoftware supply chain vulnerabilities had far reaching consequences in 2021, with events such as \u003ca href=\"https://blogs.microsoft.com/on-the-issues/2020/12/17/cyberattacks-cybersecurity-solarwinds-fireeye/\" target=\"_blank\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://blogs.microsoft.com\" track-metadata-module=\"post\"\u003eSolarWinds\u003c/a\u003e, \u003ca href=\"https://www.mimecast.com/blog/important-update-from-mimecast/\" target=\"_blank\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://www.mimecast.com\" track-metadata-module=\"post\"\u003eMimecast/Microsoft Exchange\u003c/a\u003e, and \u003ca href=\"https://logging.apache.org/log4j/2.x/\" target=\"_blank\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://logging.apache.org\" track-metadata-module=\"post\"\u003eLog4j \u003c/a\u003eaffecting businesses, daily life, and entire \u003ca href=\"https://www.cyberscoop.com/dhs-cyber-alert-subpoena-us/\" target=\"_blank\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://www.cyberscoop.com\" track-metadata-module=\"post\"\u003egovernments\u003c/a\u003e. President Biden even issued an \u003ca href=\"https://www.whitehouse.gov/briefing-room/presidential-actions/2021/05/12/executive-order-on-improving-the-nations-cybersecurity/\" target=\"_blank\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://www.whitehouse.gov\" track-metadata-module=\"post\"\u003eexecutive order\u003c/a\u003e to strengthen software supply-chain security standards.\u003c/p\u003e\u003cp\u003eSolving the software supply chain problem requires players across industries to work together. This is why we co-founded the\u003ca href=\"https://openssf.org/\" target=\"_blank\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://openssf.org\" track-metadata-module=\"post\"\u003e Open Source Security Foundation\u003c/a\u003e (Open SSF). We also proposed \u003ca href=\"https://security.googleblog.com/2021/06/introducing-slsa-end-to-end-framework.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://security.googleblog.com\" track-metadata-module=\"post\"\u003eSLSA\u003c/a\u003e, an industry-wide framework for maintaining the integrity of software artifacts throughout the software supply chain. \u003c/p\u003e\u003cp\u003eOpen source, with its complex dependency trees, continues to remain a prime target for exploitation. In fact, an estimated \u003ca href=\"https://venturebeat.com/2021/04/13/synopsys-84-of-codebases-contain-an-open-source-vulnerability/\" target=\"_blank\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://venturebeat.com\" track-metadata-module=\"post\"\u003e84% of commercial code bases\u003c/a\u003e have at least one open source vulnerability. Today, developers can use our tools such as \u003ca href=\"https://github.com/ossf/allstar\" target=\"_blank\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eAllstar GitHub App\u003c/a\u003e, \u003ca href=\"https://opensource.googleblog.com/2020/11/security-scorecards-for-open-source.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"18\" track-metadata-eventdetail=\"https://opensource.googleblog.com\" track-metadata-module=\"post\"\u003eopen source security score cards\u003c/a\u003e and \u003ca href=\"https://deps.dev/\" target=\"_blank\" track-type=\"inline link\" track-name=\"19\" track-metadata-eventdetail=\"https://deps.dev\" track-metadata-module=\"post\"\u003eOpen Source Insights\u003c/a\u003e to implement security best practices, determine a risk score for open source projects, and visualize a project\u0026#39;s deep dependencies. And several of these same  kinds of open-source innovations are available out of the box to Google Cloud customers. Here are a few examples: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eDetailed \u003ca href=\"https://cloud.google.com/blog/products/identity-security/recommendations-for-apache-log4j2-vulnerability\" track-type=\"inline link\" track-name=\"20\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/identity-security/recommendations-for-apache-log4j2-vulnerability\" track-metadata-module=\"post\"\u003erecommendations\u003c/a\u003e to help mitigate the Apache Log4j vulnerability. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eThe \u003ca href=\"https://cloud.google.com/container-analysis/docs/java-overview\" track-type=\"inline link\" track-name=\"21\" track-metadata-eventdetail=\"https://cloud.google.com/container-analysis/docs/java-overview\" track-metadata-module=\"post\"\u003eJava scanning feature\u003c/a\u003e of Google Cloud \u003ca href=\"https://cloud.google.com/container-analysis/docs/container-scanning-overview\" track-type=\"inline link\" track-name=\"22\" track-metadata-eventdetail=\"https://cloud.google.com/container-analysis/docs/container-scanning-overview\" track-metadata-module=\"post\"\u003eOn-Demand Scanning\u003c/a\u003e, which can be quite handy for developers to identify Linux-based container images that use an impacted version of Log4j. On-Demand Scanning can be used with no charge until December 31, 2021. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCloud Build, our serverless CI/CD service, offers \u003ca href=\"https://cloud.google.com/blog/products/application-development/google-introduces-slsa-framework\" track-type=\"inline link\" track-name=\"23\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/application-development/google-introduces-slsa-framework\" track-metadata-module=\"post\"\u003eSLSA Level 1 compliance\u003c/a\u003e by default. This verifiable build provenance lets you trace a binary to the source code to prevent tampering and prove that the code you’re running is the code you think you’re running. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCloud Build’s new \u003ca href=\"https://cloud.google.com/build/docs/securing-builds/use-provenance-and-binary-authorization\" track-type=\"inline link\" track-name=\"24\" track-metadata-eventdetail=\"https://cloud.google.com/build/docs/securing-builds/use-provenance-and-binary-authorization\" track-metadata-module=\"post\"\u003ebuild integrity feature\u003c/a\u003e improves on this by automatically generating digital signatures, which can be validated before deployment by \u003ca href=\"https://cloud.google.com/binary-authorization\" track-type=\"inline link\" track-name=\"25\" track-metadata-eventdetail=\"https://cloud.google.com/binary-authorization\" track-metadata-module=\"post\"\u003eBinary Authorization\u003c/a\u003e. \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eSimplifying running cloud-native applications\u003c/h3\u003e\u003cp\u003eInnovation is rarely a straight road, there are many wrong turns along the way. Developers need a cost effective runtime, a way to run experiments and fail forward fast. That\u0026#39;s why \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/introducing-gke-autopilot\" track-type=\"inline link\" track-name=\"26\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/containers-kubernetes/introducing-gke-autopilot\" track-metadata-module=\"post\"\u003eGKE Autopilot\u003c/a\u003e takes GKE, the \u003ca href=\"https://cloud.google.com/resources/gartner-solution-scorecard-for-kubernetes-analyst-report\" track-type=\"inline link\" track-name=\"27\" track-metadata-eventdetail=\"https://cloud.google.com/resources/gartner-solution-scorecard-for-kubernetes-analyst-report\" track-metadata-module=\"post\"\u003emost\u003c/a\u003e mature Kubernetes service on the market and further simplifies Kubernetes operations by providing a managed control and data plane, an optimized configuration out-of-the-box, automated scalability, health checks and repairs, and pay-for-use pricing. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“With GKE Autopilot, we can do more with our business. We can continue developing and upgrading our products, rather than focusing on fine-tuning infrastructure.”—\u003cb\u003eJun Sakata, Software Engineer, Site Reliability, \u003ca href=\"https://cloud.google.com/customers/ubie\" track-type=\"inline link\" track-name=\"28\" track-metadata-eventdetail=\"https://cloud.google.com/customers/ubie\" track-metadata-module=\"post\"\u003eUbie\u003c/a\u003e \u003c/b\u003e\u003c/i\u003e\u003c/p\u003e\u003cp\u003eSimpler still is no cluster all. Cloud Run provides developers the freedom to run services from code or container images with no cluster or VM to manage. At the same time, it provides a hypervisor grade secure sandbox environment and several built in DevOps capabilities such as, \u003ca href=\"https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration\" track-type=\"inline link\" track-name=\"29\" track-metadata-eventdetail=\"https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration\" track-metadata-module=\"post\"\u003emulti-versioned deployments, gradual rollouts and rollbacks\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/run/docs/continuous-deployment-with-cloud-build\" track-type=\"inline link\" track-name=\"30\" track-metadata-eventdetail=\"https://cloud.google.com/run/docs/continuous-deployment-with-cloud-build\" track-metadata-module=\"post\"\u003eGitHub\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/run/docs/building/containers\" track-type=\"inline link\" track-name=\"31\" track-metadata-eventdetail=\"https://cloud.google.com/run/docs/building/containers\" track-metadata-module=\"post\"\u003eCloud Build\u003c/a\u003e integrations. This is ideal for web and mobile application development. In 2021, with \u003ca href=\"https://cloud.google.com/blog/products/serverless/the-next-big-evolution-in-cloud-computing\" track-type=\"inline link\" track-name=\"32\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/serverless/the-next-big-evolution-in-cloud-computing\" track-metadata-module=\"post\"\u003eadditions\u003c/a\u003e like \u003ca href=\"https://cloud.google.com/run/docs/about-concurrency\" track-type=\"inline link\" track-name=\"33\" track-metadata-eventdetail=\"https://cloud.google.com/run/docs/about-concurrency\" track-metadata-module=\"post\"\u003ehigher per-instance concurrency\u003c/a\u003e, new \u003ca href=\"https://cloud.google.com/run/docs/configuring/cpu-allocation\" track-type=\"inline link\" track-name=\"34\" track-metadata-eventdetail=\"https://cloud.google.com/run/docs/configuring/cpu-allocation\" track-metadata-module=\"post\"\u003eCPU allocation controls\u003c/a\u003e, and support for \u003ca href=\"https://cloud.google.com/run/docs/deploying\" track-type=\"inline link\" track-name=\"35\" track-metadata-eventdetail=\"https://cloud.google.com/run/docs/deploying\" track-metadata-module=\"post\"\u003estandard Docker images\u003c/a\u003e, the benefits of serverless can now be expanded to a wider range of workloads, including legacy ones. Additionally, with newer cost controls along with billing flexibility like \u003ca href=\"https://cloud.google.com/run/cud\" track-type=\"inline link\" track-name=\"36\" track-metadata-eventdetail=\"https://cloud.google.com/run/cud\" track-metadata-module=\"post\"\u003ecommitted use contracts\u003c/a\u003e and features like \u003ca href=\"https://cloud.google.com/blog/products/serverless/cloud-run-gets-always-on-cpu-allocation\" track-type=\"inline link\" track-name=\"37\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/serverless/cloud-run-gets-always-on-cpu-allocation\" track-metadata-module=\"post\"\u003ealways-on CPU\u003c/a\u003e, it’s possible to run more steady-state pattern workloads cost effectively in a serverless environment.  Best of all, thanks to improvements like these, organizations using Cloud Run have reported reduction in \u003ca href=\"https://cloud.google.com/resources/forrester-cloudrun-benefits-report\" track-type=\"inline link\" track-name=\"38\" track-metadata-eventdetail=\"https://cloud.google.com/resources/forrester-cloudrun-benefits-report\" track-metadata-module=\"post\"\u003edeveloper recruiting costs by 40%\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eCloud Run is also the first platform to provide developers the option to optimize their carbon footprint.  With the news self-service \u003ca href=\"https://cloud.google.com/blog/topics/sustainability/google-cloud-region-picker-helps-you-make-the-green-choice\" track-type=\"inline link\" track-name=\"39\" track-metadata-eventdetail=\"https://cloud.google.com/blog/topics/sustainability/google-cloud-region-picker-helps-you-make-the-green-choice\" track-metadata-module=\"post\"\u003eRegion Picker\u003c/a\u003e you can choose the data center region with the lowest gross carbon cost on which to run your Cloud Run workloads. Further, with just one click, \u003ca href=\"https://cloud.google.com/carbon-footprint\" track-type=\"inline link\" track-name=\"40\" track-metadata-eventdetail=\"https://cloud.google.com/carbon-footprint\" track-metadata-module=\"post\"\u003eGoogle Cloud Carbon Footprint \u003c/a\u003egives you access to the energy-related emissions data for external carbon disclosures. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“With Cloud Run, we only need half the people to manage our systems as compared to before” \u003cb\u003eGoogle Cloud Platform Architect, \u003ca href=\"https://cloud.google.com/resources/forrester-cloudrun-benefits-report\" track-type=\"inline link\" track-name=\"41\" track-metadata-eventdetail=\"https://cloud.google.com/resources/forrester-cloudrun-benefits-report\" track-metadata-module=\"post\"\u003eCosmetics\u003c/a\u003e \u003c/b\u003e\u003c/i\u003e\u003c/p\u003e\u003cp\u003e\u003ci\u003e“Cloud Run is one of the easiest services on Google Cloud Platform you can deploy to. It’s just super simple.” \u003cb\u003eCTO, \u003c/b\u003e\u003ca href=\"https://cloud.google.com/resources/forrester-cloudrun-benefits-report\" track-type=\"inline link\" track-name=\"42\" track-metadata-eventdetail=\"https://cloud.google.com/resources/forrester-cloudrun-benefits-report\" track-metadata-module=\"post\"\u003e\u003cb\u003eHealthcare SaaS\u003c/b\u003e\u003c/a\u003e\u003c/i\u003e\u003c/p\u003e\u003cp\u003eIf you want to give Cloud Run and associated Cloud Functions a try, check out the \u003ca href=\"https://cloud.google.com/blog/products/serverless/serverless-hackathon\" track-type=\"inline link\" track-name=\"43\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/serverless/serverless-hackathon\" track-metadata-module=\"post\"\u003eEasy as Pie Serverless Hackathon\u003c/a\u003e, which offers  over $20,000 USD in cash prizes.\u003c/p\u003e\u003ch3\u003e2022: More to come  \u003c/h3\u003e\u003cp\u003e2021 brought simplification and greater attention to developer productivity. It is essential that developers continue to operate at even higher levels of the stack, without worrying about infrastructure, security, compliance and integrations. This is the Northstar for 2022. In 2022, look for Google Cloud to co-innovate with our ISV partners, developers, and SecOps team to bring you the 10X innovation you need from the cloud that is built for developers.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e2021 was a seminal year for software developers. Every company accelerated their digital and online efforts, while simultaneously moving to remote development. Innovation by driving developer productivity was top of mind for nearly every IT executive we spoke to. Many asked us about Alphabet's long track record of innovation. From Google search to Waymo’s driverless cars,  is there a secret to developing the next big thing? \u003c/p\u003e\u003cp\u003eThe answer is simple: 10X thinking. Look for solutions that help customers drive 10X improvements, through a series of smaller increments that compound to a large impact over time. At Google Cloud, we follow a similar philosophy to help our customers become innovative technology companies. In recent times, we’ve worked closely with partners, customers, and developers on services that help unlock 10X improvements in developer productivity. \u003c/p\u003e\u003cp\u003eSix years ago, we introduced a managed Kubernetes service, Google Kubernetes Engine (GKE). This year, we added \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/introducing-gke-autopilot\"\u003eGKE Autopilot\u003c/a\u003e, which revolutionized Kubernetes management by eliminating all node management operations. Likewise, our \u003ca href=\"https://cloud.google.com/run\"\u003eCloud Run\u003c/a\u003e serverless platform was the first service of its kind, allowing developers to go beyond running small bits of code and run full applications in a serverless environment. From September 2020 to September 2021, Cloud Run deployments more than quadrupled. More recently, we co-founded the \u003ca href=\"https://openssf.org/\" target=\"_blank\"\u003eOpen Source Security Foundation\u003c/a\u003e and began working on secure continuous Integration and delivery (CI/CD) services a year or so ahead of the cybersecurity threats that made it to headlines. \u003c/p\u003e\u003cp\u003eHere are the top developer challenges that customers asked us to solve in 2021: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eDriving distributed developer productivity\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eSecuring the software supply chain\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eSimplifying running of cloud-native applications \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eRead on for more insights. \u003c/p\u003e\u003ch3\u003eDriving distributed developer productivity\u003c/h3\u003e\u003cp\u003eA critical prerequisite for innovation is time. Investments in developer productivity free developers to work on the important things. Traditionally, developers have spent hours downloading and installing tools to their local environments, updating them with the latest versions, or dependencies. \u003ca href=\"https://cloud.google.com/shell/docs/editor-overview\"\u003eCloud Shell Editor\u003c/a\u003e is a full remote development environment with a growing set of built in security capabilities. It comes with developer tools pre-installed, including MySql, Kubernetes, Docker, minikube, Skaffold, etc. Developers just needed a web browser and internet connection to be productive. Developers now have access to \u003ca href=\"https://cloud.google.com/shell/docs/cloud-shell-tutorials/tutorials\"\u003etutorials\u003c/a\u003e right from Cloud Shell Editor, and can try code samples directly in \u003ca href=\"https://cloud.google.com/blog/topics/developers-practitioners/run-code-samples-directly-google-cloud-documentation\"\u003eour documentation\u003c/a\u003e. Additionally, with support for \u003ca href=\"https://cloud.google.com/run/docs/building/containers\"\u003ebuildpacks\u003c/a\u003e, developers can create container images \u003ca href=\"https://cloud.google.com/blog/products/serverless/build-and-deploy-an-app-to-cloud-run-with-a-single-command\"\u003edirectly from source code\u003c/a\u003e, without knowing anything about docker or containers. \u003c/p\u003e\u003ch3\u003eSecuring the software supply chain\u003c/h3\u003e\u003cp\u003eSoftware supply chain vulnerabilities had far reaching consequences in 2021, with events such as \u003ca href=\"https://blogs.microsoft.com/on-the-issues/2020/12/17/cyberattacks-cybersecurity-solarwinds-fireeye/\" target=\"_blank\"\u003eSolarWinds\u003c/a\u003e, \u003ca href=\"https://www.mimecast.com/blog/important-update-from-mimecast/\" target=\"_blank\"\u003eMimecast/Microsoft Exchange\u003c/a\u003e, and \u003ca href=\"https://logging.apache.org/log4j/2.x/\" target=\"_blank\"\u003eLog4j\u003c/a\u003eaffecting businesses, daily life, and entire \u003ca href=\"https://www.cyberscoop.com/dhs-cyber-alert-subpoena-us/\" target=\"_blank\"\u003egovernments\u003c/a\u003e. President Biden even issued an \u003ca href=\"https://www.whitehouse.gov/briefing-room/presidential-actions/2021/05/12/executive-order-on-improving-the-nations-cybersecurity/\" target=\"_blank\"\u003eexecutive order\u003c/a\u003e to strengthen software supply-chain security standards.\u003c/p\u003e\u003cp\u003eSolving the software supply chain problem requires players across industries to work together. This is why we co-founded the\u003ca href=\"https://openssf.org/\" target=\"_blank\"\u003eOpen Source Security Foundation\u003c/a\u003e (Open SSF). We also proposed \u003ca href=\"https://security.googleblog.com/2021/06/introducing-slsa-end-to-end-framework.html\" target=\"_blank\"\u003eSLSA\u003c/a\u003e, an industry-wide framework for maintaining the integrity of software artifacts throughout the software supply chain. \u003c/p\u003e\u003cp\u003eOpen source, with its complex dependency trees, continues to remain a prime target for exploitation. In fact, an estimated \u003ca href=\"https://venturebeat.com/2021/04/13/synopsys-84-of-codebases-contain-an-open-source-vulnerability/\" target=\"_blank\"\u003e84% of commercial code bases\u003c/a\u003e have at least one open source vulnerability. Today, developers can use our tools such as \u003ca href=\"https://github.com/ossf/allstar\" target=\"_blank\"\u003eAllstar GitHub App\u003c/a\u003e, \u003ca href=\"https://opensource.googleblog.com/2020/11/security-scorecards-for-open-source.html\" target=\"_blank\"\u003eopen source security score cards\u003c/a\u003e and \u003ca href=\"https://deps.dev/\" target=\"_blank\"\u003eOpen Source Insights\u003c/a\u003e to implement security best practices, determine a risk score for open source projects, and visualize a project's deep dependencies. And several of these same  kinds of open-source innovations are available out of the box to Google Cloud customers. Here are a few examples: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eDetailed \u003ca href=\"https://cloud.google.com/blog/products/identity-security/recommendations-for-apache-log4j2-vulnerability\"\u003erecommendations\u003c/a\u003e to help mitigate the Apache Log4j vulnerability. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eThe \u003ca href=\"https://cloud.google.com/container-analysis/docs/java-overview\"\u003eJava scanning feature\u003c/a\u003e of Google Cloud \u003ca href=\"https://cloud.google.com/container-analysis/docs/container-scanning-overview\"\u003eOn-Demand Scanning\u003c/a\u003e, which can be quite handy for developers to identify Linux-based container images that use an impacted version of Log4j. On-Demand Scanning can be used with no charge until December 31, 2021. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCloud Build, our serverless CI/CD service, offers \u003ca href=\"https://cloud.google.com/blog/products/application-development/google-introduces-slsa-framework\"\u003eSLSA Level 1 compliance\u003c/a\u003e by default. This verifiable build provenance lets you trace a binary to the source code to prevent tampering and prove that the code you’re running is the code you think you’re running. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCloud Build’s new \u003ca href=\"https://cloud.google.com/build/docs/securing-builds/use-provenance-and-binary-authorization\"\u003ebuild integrity feature\u003c/a\u003e improves on this by automatically generating digital signatures, which can be validated before deployment by \u003ca href=\"https://cloud.google.com/binary-authorization\"\u003eBinary Authorization\u003c/a\u003e. \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eSimplifying running cloud-native applications\u003c/h3\u003e\u003cp\u003eInnovation is rarely a straight road, there are many wrong turns along the way. Developers need a cost effective runtime, a way to run experiments and fail forward fast. That's why \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/introducing-gke-autopilot\"\u003eGKE Autopilot\u003c/a\u003e takes GKE, the \u003ca href=\"https://cloud.google.com/resources/gartner-solution-scorecard-for-kubernetes-analyst-report\"\u003emost\u003c/a\u003e mature Kubernetes service on the market and further simplifies Kubernetes operations by providing a managed control and data plane, an optimized configuration out-of-the-box, automated scalability, health checks and repairs, and pay-for-use pricing. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“With GKE Autopilot, we can do more with our business. We can continue developing and upgrading our products, rather than focusing on fine-tuning infrastructure.”—\u003cb\u003eJun Sakata, Software Engineer, Site Reliability, \u003ca href=\"https://cloud.google.com/customers/ubie\"\u003eUbie\u003c/a\u003e \u003c/b\u003e\u003c/i\u003e\u003c/p\u003e\u003cp\u003eSimpler still is no cluster all. Cloud Run provides developers the freedom to run services from code or container images with no cluster or VM to manage. At the same time, it provides a hypervisor grade secure sandbox environment and several built in DevOps capabilities such as, \u003ca href=\"https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration\"\u003emulti-versioned deployments, gradual rollouts and rollbacks\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/run/docs/continuous-deployment-with-cloud-build\"\u003eGitHub\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/run/docs/building/containers\"\u003eCloud Build\u003c/a\u003e integrations. This is ideal for web and mobile application development. In 2021, with \u003ca href=\"https://cloud.google.com/blog/products/serverless/the-next-big-evolution-in-cloud-computing\"\u003eadditions\u003c/a\u003e like \u003ca href=\"https://cloud.google.com/run/docs/about-concurrency\"\u003ehigher per-instance concurrency\u003c/a\u003e, new \u003ca href=\"https://cloud.google.com/run/docs/configuring/cpu-allocation\"\u003eCPU allocation controls\u003c/a\u003e, and support for \u003ca href=\"https://cloud.google.com/run/docs/deploying\"\u003estandard Docker images\u003c/a\u003e, the benefits of serverless can now be expanded to a wider range of workloads, including legacy ones. Additionally, with newer cost controls along with billing flexibility like \u003ca href=\"https://cloud.google.com/run/cud\"\u003ecommitted use contracts\u003c/a\u003e and features like \u003ca href=\"https://cloud.google.com/blog/products/serverless/cloud-run-gets-always-on-cpu-allocation\"\u003ealways-on CPU\u003c/a\u003e, it’s possible to run more steady-state pattern workloads cost effectively in a serverless environment.  Best of all, thanks to improvements like these, organizations using Cloud Run have reported reduction in \u003ca href=\"https://cloud.google.com/resources/forrester-cloudrun-benefits-report\"\u003edeveloper recruiting costs by 40%\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eCloud Run is also the first platform to provide developers the option to optimize their carbon footprint.  With the news self-service \u003ca href=\"https://cloud.google.com/blog/topics/sustainability/google-cloud-region-picker-helps-you-make-the-green-choice\"\u003eRegion Picker\u003c/a\u003e you can choose the data center region with the lowest gross carbon cost on which to run your Cloud Run workloads. Further, with just one click, \u003ca href=\"https://cloud.google.com/carbon-footprint\"\u003eGoogle Cloud Carbon Footprint\u003c/a\u003egives you access to the energy-related emissions data for external carbon disclosures. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“With Cloud Run, we only need half the people to manage our systems as compared to before” \u003cb\u003eGoogle Cloud Platform Architect, \u003ca href=\"https://cloud.google.com/resources/forrester-cloudrun-benefits-report\"\u003eCosmetics\u003c/a\u003e \u003c/b\u003e\u003c/i\u003e\u003c/p\u003e\u003cp\u003e\u003ci\u003e“Cloud Run is one of the easiest services on Google Cloud Platform you can deploy to. It’s just super simple.” \u003cb\u003eCTO,\u003c/b\u003e\u003ca href=\"https://cloud.google.com/resources/forrester-cloudrun-benefits-report\"\u003e\u003cb\u003eHealthcare SaaS\u003c/b\u003e\u003c/a\u003e\u003c/i\u003e\u003c/p\u003e\u003cp\u003eIf you want to give Cloud Run and associated Cloud Functions a try, check out the \u003ca href=\"https://cloud.google.com/blog/products/serverless/serverless-hackathon\"\u003eEasy as Pie Serverless Hackathon\u003c/a\u003e, which offers  over $20,000 USD in cash prizes.\u003c/p\u003e\u003ch3\u003e2022: More to come  \u003c/h3\u003e\u003cp\u003e2021 brought simplification and greater attention to developer productivity. It is essential that developers continue to operate at even higher levels of the stack, without worrying about infrastructure, security, compliance and integrations. This is the Northstar for 2022. In 2022, look for Google Cloud to co-innovate with our ISV partners, developers, and SecOps team to bring you the 10X innovation you need from the cloud that is built for developers.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_GCP_HLl2OQm.max-2200x2200.png",
      "date_published": "2021-12-23T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eUrs Hölzle\u003c/name\u003e\u003ctitle\u003eSenior Vice President, Technical Infrastructure\u003c/title\u003e\u003cdepartment\u003eGoogle Cloud\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/loon-sre-use-postmortems-to-launch-and-iterate/",
      "title": "Postmortems at Loon: a guiding force for rapid development",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c67=\"\"\u003e\u003cdiv _ngcontent-c67=\"\" innerhtml=\"\u0026lt;p\u0026gt;Founded by Google SRE alumni, it is no surprise that Loon\u0026#39;s Production Engineering/SRE team instituted a culture of blameless postmortems that became a key feature of Loon\u0026#39;s approach to incident response. Blameless postmortems originated as an aerospace practice in the mid-20th century, so it was particularly fitting that they came full circle to be used at a company that melded cutting edge aerospace work with the development of a communications platform and the world\u0026#39;s first stratospheric temporospatial software defined network. The use of postmortems became a standardizing factor across Loon\u0026#39;s teams\u0026amp;#8212; from avionics and manufacturing, to flight operations, to software platforms and network service. This blog post discusses how Loon moved from a heterogeneous approach to postmortems to eventually standardize and share this practice across the organization\u0026amp;#8212; a shift that helped the company move from R\u0026amp;amp;D to commercial service in 2020.\u0026lt;/p\u0026gt;\u0026lt;h2\u0026gt;Background\u0026lt;/h2\u0026gt;\u0026lt;h3\u0026gt;Postmortems\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Many industries have adopted the use of postmortems\u0026amp;#8212; they are fairly common in high-risk fields where mistakes can be fatal or extremely expensive. Postmortems are also widespread in industries and projects where bad processes or assumptions can incur expensive project development costs and avoiding repeat mistakes is a priority. Individual industries and organizations often develop their own postmortem standards or templates so that postmortems are easier to create and digest across teams.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Blameless postmortems likely originated in the healthcare and aerospace industries in the mid-20th century. Because of the high cost of failure, these industries needed to create a culture of transparency and continuous improvement that could only come from openly discussing failure. As the original SRE book states, blameless postmortems are key to \u0026amp;#34;an environment where every \u0026#39;mistake\u0026#39; is seen as an opportunity to strengthen the system.\u0026amp;#34;\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The goal of a postmortem is to document an incident or event in order to foster learning from it, both among the affected teams and beyond. The postmortem usually includes a timeline of what happened, the solutions implemented, the incident\u0026#39;s impact, the investigation into root causes, and changes or follow-ups to stop it from happening again. To facilitate learning, SRE\u0026#39;s postmortem format includes both what went well\u0026amp;#8212; acknowledging the successes that should be maintained and expanded\u0026amp;#8212; and what went poorly and needs to be changed. In this way, postmortem action items are key to prioritizing work that ensures the same failures don\u0026#39;t happen again.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Loon\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Loon aimed to supply internet access to unserved and underserved populations around the world by providing connectivity via stratospheric balloons. These high altitude \u0026amp;#8220;flying cell towers\u0026amp;#8221; covered a much wider footprint than a terrestrial tower, and could be deployed (and repositioned) into the most remote corners of the earth without expensive overland transportation and installation. As the first company to attempt anything like this, Loon dealt with a number of systems that were complex, challenging, or novel: superpressure balloons designed to stay aloft for hundreds of days, wind-dependant steering, a software defined network consisting of constantly moving nodes, and extremes of temperature and weather at 20km above Earth\u0026#39;s surface.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Prod Team\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;The initial high-risk operations of Loon\u0026#39;s mission were avionic: could we launch and steer balloons carrying a networking payload long enough to reach and serve the targeted region? As such, the earliest failure reports within Loon (which weren\u0026#39;t officially called \u0026amp;#34;postmortems\u0026amp;#34; at the time) mostly involved balloon construction or flight, and drew on the experience of team members who had worked in the Avionics, Reliability Engineering, and/or Flight Safety fields. As Loon\u0026#39;s systems evolved and matured, they started to require operational reliability, as well. Just before graduating from a purely R\u0026amp;amp;D project in Google\u0026#39;s \u0026amp;#34;moonshot factory\u0026amp;#34; incubator X to a company with commercial goals, Loon started building a Site Reliability Engineering (SRE) team known internally as Prod Team.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In order to effectively offer internet connectivity to users, Loon had to solve network serving failures with the same rigor as hardware failures. Prod Team took the lead on a number of practices to improve network reliability. The Prod Team had three primary goals:\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Ensure that the fleet\u0026#39;s automation, management, and safety-critical systems were built and operated to meet the high safety bar of the aviation industry.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Lead the integration of the communications services (e.g., LTE) end to end.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Own the mission of fielding and providing a reliable commercial service (Loon Library) in the real world.\u0026amp;#160;\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;h2\u0026gt;Postmortems at Loon\u0026lt;/h2\u0026gt;\u0026lt;h3\u0026gt;The Early Days\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Postmortems were one tool for reaching Prod Team\u0026#39;s (SRE\u0026#39;s) goals. Prod Team often interacted with SREs in other infrastructure support teams that the Loon service connected to, such as the team developing the Evolved Packet Core (EPC), our telco partner counterparts, and teams that handle edge network connectivity. Postmortems provided a common tool for sharing incident information across all these teams, and could even span multiple companies when upstream problems impacted customers.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;At Loon, postmortems served the following goals:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Document and transcribe the events, actions, and remedies related to an incident.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Provide a feedback loop to rectify problems.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Indicate where to build better safeguards and alerts.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Break down silos between teams in order to facilitate cross-functional knowledge sharing and accelerate development.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Identify macro themes and blind spots over the longer term.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;The combination of aerospace and high tech brought two strong practices of writing postmortems, but also the challenge of how to own, investigate, or follow up on problems that crossed those boundaries, or when it wasn\u0026#39;t clear where the system fault lay.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Loon\u0026#39;s teams across hardware, software, and operations orgs used postmortems, as was standard practice in their fields for incident response. The Flight Operations Team, which handled the day-to-day operations of steering launched balloons, captured in-flight issues in a tracking system. The tracking system was part of the anomaly resolution system devised to identify and resolve root cause problems. Seeking to complement the anomaly resolution system, the Flight Operations Team incorporated the SRE software team\u0026#39;s postmortem format for incidents that needed further investigation\u0026amp;#8212; for example, failure to avoid a storm system, deviations from the simulated (expected) flight path that led to an incident, and flight operator actions that directly or indirectly caused an incident. Given that most incidents spanned multiple teams (e.g., when automation failed to catch an incorrect command sent by a flight operator, which resulted in a hardware failure), utilizing a consistent postmortem format across teams simplified collaboration.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The Aviation and Systems Safety Team, which focused on safety related to the flight system and flight process, also brought their own tradition and best practices of postmortems. Their motto, \u0026amp;#34;Own our Safety\u0026amp;#34;, brought a commitment to continually improving safety performance and building a positive safety culture across the company. This was one of the strengths of Loon\u0026#39;s culture: all the organizations were aligned not just on our audacious vision to \u0026amp;#34;connect people everywhere\u0026amp;#34;, but also on doing so safely and effectively. However, because industry standards for postmortems and how to handle different types of problems varied across teams, there was some divergence in process. We proactively encouraged teams to share postmortems between teams, between orgs, and across the company so that anyone could provide feedback and insight into an incident. In that way, anyone at Loon could contribute to a postmortem, see how an incident was handled, and learn about the breadth of challenges that Loon was solving.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Challenges\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;While everyone agreed that postmortems were an important practice, in a fast moving start-up culture, it was a struggle to comprehensively follow through on action items. This probably comes as no surprise to developers in similar environments\u0026amp;#8212; when the platform or services that require investment are rapidly changing or being replaced, it\u0026#39;s hard to spend resources on not repeating the same mistakes. Ideally, we would have prioritized postmortems that focused on best practices and learnings that were applicable to multiple generations of the platform, but those weren\u0026#39;t easy to identify at the time of each incident.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Even though the company was not especially large, the novelty of Loon\u0026#39;s platform and interconnectedness of its operations made determining which team was responsible for writing a postmortem and investigating root causes difficult. For example, a 20 minute service disruption on the ground might be caused by a loss of connectivity from the balloon to the backhaul network, a pointing error with the antennae on the payload, insufficient battery levels, or wind that temporarily blew the balloon out of range. Actual causes could be quite nuanced, and often were attributable to interactions between multiple sub-systems. Thus, we had a chicken-and-egg problem: which team should start the postmortem and investigation, and when should they hand off the postmortem to the teams that likely owned the faulty system or process? Not all teams had a culture of postmortems, so the process could stall depending on the system where the root cause originated. For that reason, Loon\u0026#39;s Prod Team/SREs advocated for a company-wide blameless postmortem culture.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Much of how Loon used postmortems, especially in software development and Prod Team, was in line with SRE industry standards. In the early days of Loon, however, there were no service level objectives or agreements (SLO/As). As Loon was an R\u0026amp;amp;D project, we wrote postmortems when a test network failed to boot after launch, or when performance didn\u0026#39;t meet the team\u0026#39;s predictions, rather than for \u0026amp;#34;service outages\u0026amp;#34;. Later on, when Loon supplied commercial service in disaster relief areas in Peru and Kenya, the Prod Team could more clearly identify the types of user-facing incidents that required postmortems due to failure to meet SLAs.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Improving and Standardizing Loon\u0026#39;s Postmortem Processes\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Moving Loon from an R\u0026amp;amp;D model to the model of reliability and safety necessary for a commercial offering required more than simply performing postmortems. Sharing the postmortems openly and widely across Loon was critical to building a culture of continuous improvement and addressing root causes.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;To increase cross-team awareness of incidents, in 2019 we instituted a Postmortem Working Group. In addition to reading and discussing recent postmortems from across the company, the goals of the working group were to make it easier to write postmortems, promote the practice of writing postmortems, increase sharing across teams, and discuss the findings of these incidents in order to learn the patterns of failure. Its founding goal was to \u0026amp;#34;\u0026lt;i\u0026gt;Cultivate a postmortem culture in Loon to encourage thoughtful risk taking, to take advantage of mistakes, and to provide structure to support improvement over time.\u0026lt;/i\u0026gt;\u0026amp;#34; While the volume of postmortems could ebb and flow across weeks and months, over multiple years of commercial service we expected to be able to identify macro-trends that needed to be addressed with the cooperation of multiple teams.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In addition to the Postmortem Working Group, we also created a postmortem mailing list and a repository of all postmortems, and presented a \u0026amp;#34;Lunch \u0026amp;amp; Learn\u0026amp;#34; on blameless postmortems (see example slide below). Prod Team and several other teams\u0026#39; meetings had a standing agenda item to review postmortems of interest from across the company, and we sent a semi-annual email celebrating Loon\u0026#39;s \u0026amp;#34;best-of\u0026amp;#34; recent incidents: the most interesting or educational outages.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eFounded by Google SRE alumni, it is no surprise that Loon\u0026#39;s Production Engineering/SRE team instituted a culture of blameless postmortems that became a key feature of Loon\u0026#39;s approach to incident response. Blameless postmortems originated as an aerospace practice in the mid-20th century, so it was particularly fitting that they came full circle to be used at a company that melded cutting edge aerospace work with the development of a communications platform and the world\u0026#39;s first stratospheric temporospatial software defined network. The use of postmortems became a standardizing factor across Loon\u0026#39;s teams— from avionics and manufacturing, to flight operations, to software platforms and network service. This blog post discusses how Loon moved from a heterogeneous approach to postmortems to eventually standardize and share this practice across the organization— a shift that helped the company move from R\u0026amp;D to commercial service in 2020.\u003c/p\u003e\u003ch2\u003eBackground\u003c/h2\u003e\u003ch3\u003ePostmortems\u003c/h3\u003e\u003cp\u003eMany industries have adopted the use of postmortems— they are fairly common in high-risk fields where mistakes can be fatal or extremely expensive. Postmortems are also widespread in industries and projects where bad processes or assumptions can incur expensive project development costs and avoiding repeat mistakes is a priority. Individual industries and organizations often develop their own postmortem standards or templates so that postmortems are easier to create and digest across teams.\u003c/p\u003e\u003cp\u003eBlameless postmortems likely originated in the healthcare and aerospace industries in the mid-20th century. Because of the high cost of failure, these industries needed to create a culture of transparency and continuous improvement that could only come from openly discussing failure. As the original SRE book states, blameless postmortems are key to \u0026#34;an environment where every \u0026#39;mistake\u0026#39; is seen as an opportunity to strengthen the system.\u0026#34; \u003c/p\u003e\u003cp\u003eThe goal of a postmortem is to document an incident or event in order to foster learning from it, both among the affected teams and beyond. The postmortem usually includes a timeline of what happened, the solutions implemented, the incident\u0026#39;s impact, the investigation into root causes, and changes or follow-ups to stop it from happening again. To facilitate learning, SRE\u0026#39;s postmortem format includes both what went well— acknowledging the successes that should be maintained and expanded— and what went poorly and needs to be changed. In this way, postmortem action items are key to prioritizing work that ensures the same failures don\u0026#39;t happen again.\u003c/p\u003e\u003ch3\u003eLoon\u003c/h3\u003e\u003cp\u003eLoon aimed to supply internet access to unserved and underserved populations around the world by providing connectivity via stratospheric balloons. These high altitude “flying cell towers” covered a much wider footprint than a terrestrial tower, and could be deployed (and repositioned) into the most remote corners of the earth without expensive overland transportation and installation. As the first company to attempt anything like this, Loon dealt with a number of systems that were complex, challenging, or novel: superpressure balloons designed to stay aloft for hundreds of days, wind-dependant steering, a software defined network consisting of constantly moving nodes, and extremes of temperature and weather at 20km above Earth\u0026#39;s surface.\u003c/p\u003e\u003ch3\u003eProd Team\u003c/h3\u003e\u003cp\u003eThe initial high-risk operations of Loon\u0026#39;s mission were avionic: could we launch and steer balloons carrying a networking payload long enough to reach and serve the targeted region? As such, the earliest failure reports within Loon (which weren\u0026#39;t officially called \u0026#34;postmortems\u0026#34; at the time) mostly involved balloon construction or flight, and drew on the experience of team members who had worked in the Avionics, Reliability Engineering, and/or Flight Safety fields. As Loon\u0026#39;s systems evolved and matured, they started to require operational reliability, as well. Just before graduating from a purely R\u0026amp;D project in Google\u0026#39;s \u0026#34;moonshot factory\u0026#34; incubator X to a company with commercial goals, Loon started building a Site Reliability Engineering (SRE) team known internally as Prod Team. \u003c/p\u003e\u003cp\u003eIn order to effectively offer internet connectivity to users, Loon had to solve network serving failures with the same rigor as hardware failures. Prod Team took the lead on a number of practices to improve network reliability. The Prod Team had three primary goals: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eEnsure that the fleet\u0026#39;s automation, management, and safety-critical systems were built and operated to meet the high safety bar of the aviation industry.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eLead the integration of the communications services (e.g., LTE) end to end.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eOwn the mission of fielding and providing a reliable commercial service (Loon Library) in the real world.  \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2\u003ePostmortems at Loon\u003c/h2\u003e\u003ch3\u003eThe Early Days\u003c/h3\u003e\u003cp\u003ePostmortems were one tool for reaching Prod Team\u0026#39;s (SRE\u0026#39;s) goals. Prod Team often interacted with SREs in other infrastructure support teams that the Loon service connected to, such as the team developing the Evolved Packet Core (EPC), our telco partner counterparts, and teams that handle edge network connectivity. Postmortems provided a common tool for sharing incident information across all these teams, and could even span multiple companies when upstream problems impacted customers.\u003c/p\u003e\u003cp\u003eAt Loon, postmortems served the following goals:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eDocument and transcribe the events, actions, and remedies related to an incident.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eProvide a feedback loop to rectify problems.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eIndicate where to build better safeguards and alerts.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eBreak down silos between teams in order to facilitate cross-functional knowledge sharing and accelerate development.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eIdentify macro themes and blind spots over the longer term. \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThe combination of aerospace and high tech brought two strong practices of writing postmortems, but also the challenge of how to own, investigate, or follow up on problems that crossed those boundaries, or when it wasn\u0026#39;t clear where the system fault lay.\u003c/p\u003e\u003cp\u003eLoon\u0026#39;s teams across hardware, software, and operations orgs used postmortems, as was standard practice in their fields for incident response. The Flight Operations Team, which handled the day-to-day operations of steering launched balloons, captured in-flight issues in a tracking system. The tracking system was part of the anomaly resolution system devised to identify and resolve root cause problems. Seeking to complement the anomaly resolution system, the Flight Operations Team incorporated the SRE software team\u0026#39;s postmortem format for incidents that needed further investigation— for example, failure to avoid a storm system, deviations from the simulated (expected) flight path that led to an incident, and flight operator actions that directly or indirectly caused an incident. Given that most incidents spanned multiple teams (e.g., when automation failed to catch an incorrect command sent by a flight operator, which resulted in a hardware failure), utilizing a consistent postmortem format across teams simplified collaboration.\u003c/p\u003e\u003cp\u003eThe Aviation and Systems Safety Team, which focused on safety related to the flight system and flight process, also brought their own tradition and best practices of postmortems. Their motto, \u0026#34;Own our Safety\u0026#34;, brought a commitment to continually improving safety performance and building a positive safety culture across the company. This was one of the strengths of Loon\u0026#39;s culture: all the organizations were aligned not just on our audacious vision to \u0026#34;connect people everywhere\u0026#34;, but also on doing so safely and effectively. However, because industry standards for postmortems and how to handle different types of problems varied across teams, there was some divergence in process. We proactively encouraged teams to share postmortems between teams, between orgs, and across the company so that anyone could provide feedback and insight into an incident. In that way, anyone at Loon could contribute to a postmortem, see how an incident was handled, and learn about the breadth of challenges that Loon was solving. \u003c/p\u003e\u003ch3\u003eChallenges\u003c/h3\u003e\u003cp\u003eWhile everyone agreed that postmortems were an important practice, in a fast moving start-up culture, it was a struggle to comprehensively follow through on action items. This probably comes as no surprise to developers in similar environments— when the platform or services that require investment are rapidly changing or being replaced, it\u0026#39;s hard to spend resources on not repeating the same mistakes. Ideally, we would have prioritized postmortems that focused on best practices and learnings that were applicable to multiple generations of the platform, but those weren\u0026#39;t easy to identify at the time of each incident.\u003c/p\u003e\u003cp\u003eEven though the company was not especially large, the novelty of Loon\u0026#39;s platform and interconnectedness of its operations made determining which team was responsible for writing a postmortem and investigating root causes difficult. For example, a 20 minute service disruption on the ground might be caused by a loss of connectivity from the balloon to the backhaul network, a pointing error with the antennae on the payload, insufficient battery levels, or wind that temporarily blew the balloon out of range. Actual causes could be quite nuanced, and often were attributable to interactions between multiple sub-systems. Thus, we had a chicken-and-egg problem: which team should start the postmortem and investigation, and when should they hand off the postmortem to the teams that likely owned the faulty system or process? Not all teams had a culture of postmortems, so the process could stall depending on the system where the root cause originated. For that reason, Loon\u0026#39;s Prod Team/SREs advocated for a company-wide blameless postmortem culture. \u003c/p\u003e\u003cp\u003eMuch of how Loon used postmortems, especially in software development and Prod Team, was in line with SRE industry standards. In the early days of Loon, however, there were no service level objectives or agreements (SLO/As). As Loon was an R\u0026amp;D project, we wrote postmortems when a test network failed to boot after launch, or when performance didn\u0026#39;t meet the team\u0026#39;s predictions, rather than for \u0026#34;service outages\u0026#34;. Later on, when Loon supplied commercial service in disaster relief areas in Peru and Kenya, the Prod Team could more clearly identify the types of user-facing incidents that required postmortems due to failure to meet SLAs.\u003c/p\u003e\u003ch3\u003eImproving and Standardizing Loon\u0026#39;s Postmortem Processes\u003c/h3\u003e\u003cp\u003eMoving Loon from an R\u0026amp;D model to the model of reliability and safety necessary for a commercial offering required more than simply performing postmortems. Sharing the postmortems openly and widely across Loon was critical to building a culture of continuous improvement and addressing root causes. \u003c/p\u003e\u003cp\u003eTo increase cross-team awareness of incidents, in 2019 we instituted a Postmortem Working Group. In addition to reading and discussing recent postmortems from across the company, the goals of the working group were to make it easier to write postmortems, promote the practice of writing postmortems, increase sharing across teams, and discuss the findings of these incidents in order to learn the patterns of failure. Its founding goal was to \u0026#34;\u003ci\u003eCultivate a postmortem culture in Loon to encourage thoughtful risk taking, to take advantage of mistakes, and to provide structure to support improvement over time.\u003c/i\u003e\u0026#34; While the volume of postmortems could ebb and flow across weeks and months, over multiple years of commercial service we expected to be able to identify macro-trends that needed to be addressed with the cooperation of multiple teams.\u003c/p\u003e\u003cp\u003eIn addition to the Postmortem Working Group, we also created a postmortem mailing list and a repository of all postmortems, and presented a \u0026#34;Lunch \u0026amp; Learn\u0026#34; on blameless postmortems (see example slide below). Prod Team and several other teams\u0026#39; meetings had a standing agenda item to review postmortems of interest from across the company, and we sent a semi-annual email celebrating Loon\u0026#39;s \u0026#34;best-of\u0026#34; recent incidents: the most interesting or educational outages.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eFounded by Google SRE alumni, it is no surprise that Loon's Production Engineering/SRE team instituted a culture of blameless postmortems that became a key feature of Loon's approach to incident response. Blameless postmortems originated as an aerospace practice in the mid-20th century, so it was particularly fitting that they came full circle to be used at a company that melded cutting edge aerospace work with the development of a communications platform and the world's first stratospheric temporospatial software defined network. The use of postmortems became a standardizing factor across Loon's teams— from avionics and manufacturing, to flight operations, to software platforms and network service. This blog post discusses how Loon moved from a heterogeneous approach to postmortems to eventually standardize and share this practice across the organization— a shift that helped the company move from R\u0026amp;D to commercial service in 2020.\u003c/p\u003e\u003ch2\u003eBackground\u003c/h2\u003e\u003ch3\u003ePostmortems\u003c/h3\u003e\u003cp\u003eMany industries have adopted the use of postmortems— they are fairly common in high-risk fields where mistakes can be fatal or extremely expensive. Postmortems are also widespread in industries and projects where bad processes or assumptions can incur expensive project development costs and avoiding repeat mistakes is a priority. Individual industries and organizations often develop their own postmortem standards or templates so that postmortems are easier to create and digest across teams.\u003c/p\u003e\u003cp\u003eBlameless postmortems likely originated in the healthcare and aerospace industries in the mid-20th century. Because of the high cost of failure, these industries needed to create a culture of transparency and continuous improvement that could only come from openly discussing failure. As the original SRE book states, blameless postmortems are key to \"an environment where every 'mistake' is seen as an opportunity to strengthen the system.\" \u003c/p\u003e\u003cp\u003eThe goal of a postmortem is to document an incident or event in order to foster learning from it, both among the affected teams and beyond. The postmortem usually includes a timeline of what happened, the solutions implemented, the incident's impact, the investigation into root causes, and changes or follow-ups to stop it from happening again. To facilitate learning, SRE's postmortem format includes both what went well— acknowledging the successes that should be maintained and expanded— and what went poorly and needs to be changed. In this way, postmortem action items are key to prioritizing work that ensures the same failures don't happen again.\u003c/p\u003e\u003ch3\u003eLoon\u003c/h3\u003e\u003cp\u003eLoon aimed to supply internet access to unserved and underserved populations around the world by providing connectivity via stratospheric balloons. These high altitude “flying cell towers” covered a much wider footprint than a terrestrial tower, and could be deployed (and repositioned) into the most remote corners of the earth without expensive overland transportation and installation. As the first company to attempt anything like this, Loon dealt with a number of systems that were complex, challenging, or novel: superpressure balloons designed to stay aloft for hundreds of days, wind-dependant steering, a software defined network consisting of constantly moving nodes, and extremes of temperature and weather at 20km above Earth's surface.\u003c/p\u003e\u003ch3\u003eProd Team\u003c/h3\u003e\u003cp\u003eThe initial high-risk operations of Loon's mission were avionic: could we launch and steer balloons carrying a networking payload long enough to reach and serve the targeted region? As such, the earliest failure reports within Loon (which weren't officially called \"postmortems\" at the time) mostly involved balloon construction or flight, and drew on the experience of team members who had worked in the Avionics, Reliability Engineering, and/or Flight Safety fields. As Loon's systems evolved and matured, they started to require operational reliability, as well. Just before graduating from a purely R\u0026amp;D project in Google's \"moonshot factory\" incubator X to a company with commercial goals, Loon started building a Site Reliability Engineering (SRE) team known internally as Prod Team. \u003c/p\u003e\u003cp\u003eIn order to effectively offer internet connectivity to users, Loon had to solve network serving failures with the same rigor as hardware failures. Prod Team took the lead on a number of practices to improve network reliability. The Prod Team had three primary goals: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eEnsure that the fleet's automation, management, and safety-critical systems were built and operated to meet the high safety bar of the aviation industry.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eLead the integration of the communications services (e.g., LTE) end to end.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eOwn the mission of fielding and providing a reliable commercial service (Loon Library) in the real world.  \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2\u003ePostmortems at Loon\u003c/h2\u003e\u003ch3\u003eThe Early Days\u003c/h3\u003e\u003cp\u003ePostmortems were one tool for reaching Prod Team's (SRE's) goals. Prod Team often interacted with SREs in other infrastructure support teams that the Loon service connected to, such as the team developing the Evolved Packet Core (EPC), our telco partner counterparts, and teams that handle edge network connectivity. Postmortems provided a common tool for sharing incident information across all these teams, and could even span multiple companies when upstream problems impacted customers.\u003c/p\u003e\u003cp\u003eAt Loon, postmortems served the following goals:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eDocument and transcribe the events, actions, and remedies related to an incident.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eProvide a feedback loop to rectify problems.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eIndicate where to build better safeguards and alerts.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eBreak down silos between teams in order to facilitate cross-functional knowledge sharing and accelerate development.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eIdentify macro themes and blind spots over the longer term. \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThe combination of aerospace and high tech brought two strong practices of writing postmortems, but also the challenge of how to own, investigate, or follow up on problems that crossed those boundaries, or when it wasn't clear where the system fault lay.\u003c/p\u003e\u003cp\u003eLoon's teams across hardware, software, and operations orgs used postmortems, as was standard practice in their fields for incident response. The Flight Operations Team, which handled the day-to-day operations of steering launched balloons, captured in-flight issues in a tracking system. The tracking system was part of the anomaly resolution system devised to identify and resolve root cause problems. Seeking to complement the anomaly resolution system, the Flight Operations Team incorporated the SRE software team's postmortem format for incidents that needed further investigation— for example, failure to avoid a storm system, deviations from the simulated (expected) flight path that led to an incident, and flight operator actions that directly or indirectly caused an incident. Given that most incidents spanned multiple teams (e.g., when automation failed to catch an incorrect command sent by a flight operator, which resulted in a hardware failure), utilizing a consistent postmortem format across teams simplified collaboration.\u003c/p\u003e\u003cp\u003eThe Aviation and Systems Safety Team, which focused on safety related to the flight system and flight process, also brought their own tradition and best practices of postmortems. Their motto, \"Own our Safety\", brought a commitment to continually improving safety performance and building a positive safety culture across the company. This was one of the strengths of Loon's culture: all the organizations were aligned not just on our audacious vision to \"connect people everywhere\", but also on doing so safely and effectively. However, because industry standards for postmortems and how to handle different types of problems varied across teams, there was some divergence in process. We proactively encouraged teams to share postmortems between teams, between orgs, and across the company so that anyone could provide feedback and insight into an incident. In that way, anyone at Loon could contribute to a postmortem, see how an incident was handled, and learn about the breadth of challenges that Loon was solving. \u003c/p\u003e\u003ch3\u003eChallenges\u003c/h3\u003e\u003cp\u003eWhile everyone agreed that postmortems were an important practice, in a fast moving start-up culture, it was a struggle to comprehensively follow through on action items. This probably comes as no surprise to developers in similar environments— when the platform or services that require investment are rapidly changing or being replaced, it's hard to spend resources on not repeating the same mistakes. Ideally, we would have prioritized postmortems that focused on best practices and learnings that were applicable to multiple generations of the platform, but those weren't easy to identify at the time of each incident.\u003c/p\u003e\u003cp\u003eEven though the company was not especially large, the novelty of Loon's platform and interconnectedness of its operations made determining which team was responsible for writing a postmortem and investigating root causes difficult. For example, a 20 minute service disruption on the ground might be caused by a loss of connectivity from the balloon to the backhaul network, a pointing error with the antennae on the payload, insufficient battery levels, or wind that temporarily blew the balloon out of range. Actual causes could be quite nuanced, and often were attributable to interactions between multiple sub-systems. Thus, we had a chicken-and-egg problem: which team should start the postmortem and investigation, and when should they hand off the postmortem to the teams that likely owned the faulty system or process? Not all teams had a culture of postmortems, so the process could stall depending on the system where the root cause originated. For that reason, Loon's Prod Team/SREs advocated for a company-wide blameless postmortem culture. \u003c/p\u003e\u003cp\u003eMuch of how Loon used postmortems, especially in software development and Prod Team, was in line with SRE industry standards. In the early days of Loon, however, there were no service level objectives or agreements (SLO/As). As Loon was an R\u0026amp;D project, we wrote postmortems when a test network failed to boot after launch, or when performance didn't meet the team's predictions, rather than for \"service outages\". Later on, when Loon supplied commercial service in disaster relief areas in Peru and Kenya, the Prod Team could more clearly identify the types of user-facing incidents that required postmortems due to failure to meet SLAs.\u003c/p\u003e\u003ch3\u003eImproving and Standardizing Loon's Postmortem Processes\u003c/h3\u003e\u003cp\u003eMoving Loon from an R\u0026amp;D model to the model of reliability and safety necessary for a commercial offering required more than simply performing postmortems. Sharing the postmortems openly and widely across Loon was critical to building a culture of continuous improvement and addressing root causes. \u003c/p\u003e\u003cp\u003eTo increase cross-team awareness of incidents, in 2019 we instituted a Postmortem Working Group. In addition to reading and discussing recent postmortems from across the company, the goals of the working group were to make it easier to write postmortems, promote the practice of writing postmortems, increase sharing across teams, and discuss the findings of these incidents in order to learn the patterns of failure. Its founding goal was to \"\u003ci\u003eCultivate a postmortem culture in Loon to encourage thoughtful risk taking, to take advantage of mistakes, and to provide structure to support improvement over time.\u003c/i\u003e\" While the volume of postmortems could ebb and flow across weeks and months, over multiple years of commercial service we expected to be able to identify macro-trends that needed to be addressed with the cooperation of multiple teams.\u003c/p\u003e\u003cp\u003eIn addition to the Postmortem Working Group, we also created a postmortem mailing list and a repository of all postmortems, and presented a \"Lunch \u0026amp; Learn\" on blameless postmortems (see example slide below). Prod Team and several other teams' meetings had a standing agenda item to review postmortems of interest from across the company, and we sent a semi-annual email celebrating Loon's \"best-of\" recent incidents: the most interesting or educational outages.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"loon.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/loon.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eOnce we had a standardized postmortem template in place, we could adopt and reuse it to document commercial service field tests. By recording a timeline and incidents, defining a process and space to determine root causes of problems, recording measurements and metrics, and providing the structure for action item tracking, we brought the benefits of postmortem retrospectives to prospective tasks. \u003c/p\u003e\u003cp\u003eWhen Loon began commercial trials in countries like Peru and Kenya, we conducted numerous field tests. These tests required engineers from Loon and/or the telco partner to travel to remote locations to measure the strength of the LTE signal on the ground. Prod Team proactively used the postmortem template to document the field tests. It provided a useful format to record the log of test events, results that did and did not match expectations, and links to further investigations into those failures. As a cutting edge project in a highly variable operating environment, using the postmortem template as our default testing template was an acknowledgement that we were in a state of constant and rapid iteration and improvement. These trials took place in early to mid 2020, under the sudden specter of Covid and the subsequent shift towards working from home. The structured communications at the core of Loon's postmortem structure were particularly helpful as we moved from in-person coordination rooms to WFH.\u003c/p\u003e\u003ch3\u003eWhat Loon Learned from Standardizing Postmortems\u003c/h3\u003e\u003cp\u003ePostmortems are widely used in various industries because they are effective. At Loon, we saw that even fast moving startups and R\u0026amp;D projects should invest early in a transparent and blameless postmortem culture. That culture should include a clear process for writing postmortems, clear guidelines for when to conduct a postmortem, and a staffed commitment to follow up on action items. \u003c/p\u003e\u003cp\u003eMeta-reviews across postmortems and outages revealed several trends. \u003c/p\u003e\u003cp\u003eThe many points of failure we observed across the range of postmortems were indicative of both the complexity of Loon's systems and the complexity of some of its supporting infrastructure. Postmortems are equally adept at finding flaky tests and fragile processes vs. hardware failures or satellite network outages. These are complexities familiar to many startups, where postmortems can help manage the tradeoff between making changes safely vs. moving quickly and trying many new things.\u003c/p\u003e\u003cp\u003eLoon was still operating a superhero culture: across a wide range of issues, a small set of experts were repeatedly called upon to fix the system. This dynamic is common in startups, and not meant as a pejorative, but was markedly different from the system maturity that many of Prod Team/SRE were used to. Once we identified this pattern, our plan for commercial service was to staff a 24x7 oncall rotation, complemented by Program Managers driving intention processes to de-risk production\u003c/p\u003e\u003cp\u003ePostmortems provided a space to ask questions like, \"What other issues could pop up in this realm?\", which prompted us to solve for the broader case of problems rather than specific problems we'd already seen. This practice also stopped people from brushing off problems in the name of development speed, or from dismissing issues because they \"just concerned a prototype\".\u003c/p\u003e\u003ch2\u003eTips and Takeaways\u003c/h2\u003e\u003cp\u003eWhile the specifics of Loon's journey to standardize postmortems tell the story of one company, we have some tips and takeaways that should be applicable at most organizations.\u003c/p\u003e\u003ch3\u003eTip 1: Adopting a blameless postmortem culture requires everyone to participate\u003c/h3\u003e\u003cp\u003eAlthough the initiative of writing postmortems often originates with a software team, if you want every team to adopt the practice, we suggest trying the following:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eGive a talk about postmortems and how and why they could benefit all.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eForm a postmortem working group.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eInvite people representing different teams to be part of the postmortem working group. They will give insights into what could work better for their respective teams.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDon't make the postmortem working group responsible for writing the postmortems— this approach doesn't scale. Reviewing and consulting on postmortems may be in scope of their duties, especially while new teams are adopting this practice.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eTip 2: Define a lightweight postmortem process\u003c/h3\u003e\u003cp\u003eEspecially during adoption, you want teams to see the benefits of postmortems, not the burden of writing them. Creating a postmortem template with minimum requirements can be helpful.\u003c/p\u003e\u003ch3\u003eTip 3: Define a clear owner for postmortems\u003c/h3\u003e\u003cp\u003eWho should write a postmortem and when? For software teams with an oncall rotation, the answer is clear: the person who was oncall during the incident is the owner, and we write postmortems when a service interruption breached SLOs. But when the service has no SLOs, or when a team doesn't have an oncall rotation, you need defined criteria. Bonus points if the outage involves multiple systems and teams. The following exercises can help in this area:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eReflect on these topics from the point of view of each team, and from the point of view of the interaction between teams.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eFor each team, define what type of incident(s) should trigger a postmortem.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eWithin the team, define who should own writing each postmortem. Avoid putting the entire burden on the same person frequently; consider forming a rotation.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eTip 4: Encourage blameless postmortems and make people proud of them\u003c/h3\u003e\u003cp\u003eConsider some activities that can help foster the blameless postmortem culture:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eWrite a report of the best postmortems over a given period and circulate them broadly.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eConduct training on how to write postmortems.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eTrain managers and encourage them to prioritize postmortems on their teams.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2\u003eConclusion\u003c/h2\u003e\u003cp\u003eWhen Loon shut down, addressing all these points was still a work in progress. We don't have a teachable moment of “this postmortem process will solve your failures”, because postmortems don't do that. However, we could see where postmortems stopped us from needing to deal with the same failures repeatedly… and where sometimes we did experience repeat incidents because the AIs from the first postmortem weren't prioritized enough. And so this piece of writing— effectively, a postmortem on Loon's postmortems—serves up a familiar lesson: postmortems work, but only as well as they are widely accepted and adhered to.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Genric_GCP_upA1oyz.max-2200x2200.png",
      "date_published": "2021-12-07T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eGiselle Font\u003c/name\u003e\u003ctitle\u003eSite Reliability Engineer, Google Cloud\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/terraform-gitops-with-google-cloud-build-and-storage/",
      "title": "Ensuring scale and compliance of your Terraform Deployment with Cloud Build",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://www.terraform.io/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Terraform\u0026lt;/a\u0026gt; is an open source Infrastructure as Code tool that is popular with platform developers building reusable cloud automation. The \u0026lt;a href=\u0026#34;https://registry.terraform.io/providers/hashicorp/google/latest/docs\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Terraform Provider for Google Cloud Platform\u0026lt;/a\u0026gt; continues to add support for the latest Google Cloud features, such as \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/topics/anthos/using-terraform-to-enable-config-sync-on-a-gke-cluster\u0026#34;\u0026gt;Anthos on GKE\u0026lt;/a\u0026gt;, and our teams continue to expand Terraform integrations including \u0026lt;a href=\u0026#34;https://cloud.google.com/foundation-toolkit\u0026#34;\u0026gt;Cloud Foundation Toolkit\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://github.com/GoogleCloudPlatform/terraform-validator#terraform-validator\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Terraform Validator\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;How do teams use Terraform on Google Cloud? While the simplest approach is to run \u0026lt;code\u0026gt;terraform init\u0026lt;/code\u0026gt;, \u0026lt;code\u0026gt;plan\u0026lt;/code\u0026gt; and \u0026lt;code\u0026gt;apply\u0026lt;/code\u0026gt; directly from your terminal,\u0026amp;#160; it cannot be recommended for automating your production deployments. First, there is a decision on how to store your Terraform \u0026lt;a href=\u0026#34;https://www.terraform.io/docs/language/state/index.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;state\u0026lt;/a\u0026gt; in a way that is secure, compliant and enables team collaboration. Secondly there\u0026amp;#8217;s a question of scale and reliability. Over the course of even the simplest cloud deployment, Terraform can end up making thousands of Create/Read/Update/Delete API calls to the endpoints used by the Terraform providers, some of which will inevitably hit quota issues or need to be retried for other reasons. For platform administrators, who are looking to ensure the best deployment practices for their curated Terraform solutions,\u0026amp;#160; while benefiting from the simplicity of Google Cloud Console, there\u0026amp;#8217;s \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/management-tools/private-catalog-uses-terraform-to-update-available-solutions\u0026#34;\u0026gt;Terraform Private Catalog integration\u0026lt;/a\u0026gt; that we enabled earlier this year.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Outside of Private Catalog, \u0026lt;a href=\u0026#34;https://cloud.google.com/build\u0026#34;\u0026gt;Cloud Build\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/storage\u0026#34;\u0026gt;Cloud Storage\u0026lt;/a\u0026gt; have been the recommended approach to use Terraform on Google Cloud. Using a remote\u0026lt;a href=\u0026#34;https://www.terraform.io/docs/language/settings/backends/index.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt; backend\u0026lt;/a\u0026gt; prevents race conditions and simplifies sharing reusable modules between different configurations. With Cloud Build you can configure a GitOps CI/CD pipeline to automatically \u0026lt;code\u0026gt;plan\u0026lt;/code\u0026gt; and \u0026lt;code\u0026gt;apply\u0026lt;/code\u0026gt; your Terraform configuration when changes are pushed into the repo.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;These are widely popularized benefits explored in \u0026lt;a href=\u0026#34;https://cloud.google.com/architecture/managing-infrastructure-as-code\u0026#34;\u0026gt;Managing infrastructure as code with Terraform, Cloud Build, and GitOps\u0026lt;/a\u0026gt;. In addition, there are lesser known advantages of Cloud Build, particularly for enterprise customers: Cloud Build\u0026amp;#8217;s concurrency capabilities and VPC-SC support, Cloud Storage versioning, security and compliance. Let\u0026amp;#8217;s explore these benefits in more detail.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Cloud Build\u0026amp;#8217;s ability to scale makes it capable to process multiple Terraform deployments across the regions globally and simultaneously. By default, Cloud Build supports 30 concurrent builds, with additional builds queued and processed after the running builds complete. In some cases it may not be enough. Customers who initiate parallel deployments to multiple zones, or, those who provision infrastructure on behalf of multiple tenants, often require running more concurrent deployments to complete all of them within the allotted deployment window. Cloud Build private pool feature allows up to \u0026lt;a href=\u0026#34;https://cloud.google.com/build/quotas\u0026#34;\u0026gt;100 concurrent builds\u0026lt;/a\u0026gt; which may be further adjusted upon request. This is an example of creating a private pool and then using it when submitting a build:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e\u003ca href=\"https://www.terraform.io/\" target=\"_blank\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://www.terraform.io\" track-metadata-module=\"post\"\u003eTerraform\u003c/a\u003e is an open source Infrastructure as Code tool that is popular with platform developers building reusable cloud automation. The \u003ca href=\"https://registry.terraform.io/providers/hashicorp/google/latest/docs\" target=\"_blank\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://registry.terraform.io\" track-metadata-module=\"post\"\u003eTerraform Provider for Google Cloud Platform\u003c/a\u003e continues to add support for the latest Google Cloud features, such as \u003ca href=\"https://cloud.google.com/blog/topics/anthos/using-terraform-to-enable-config-sync-on-a-gke-cluster\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/blog/topics/anthos/using-terraform-to-enable-config-sync-on-a-gke-cluster\" track-metadata-module=\"post\"\u003eAnthos on GKE\u003c/a\u003e, and our teams continue to expand Terraform integrations including \u003ca href=\"https://cloud.google.com/foundation-toolkit\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/foundation-toolkit\" track-metadata-module=\"post\"\u003eCloud Foundation Toolkit\u003c/a\u003e and \u003ca href=\"https://github.com/GoogleCloudPlatform/terraform-validator#terraform-validator\" target=\"_blank\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eTerraform Validator\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eHow do teams use Terraform on Google Cloud? While the simplest approach is to run \u003ccode\u003eterraform init\u003c/code\u003e, \u003ccode\u003eplan\u003c/code\u003e and \u003ccode\u003eapply\u003c/code\u003e directly from your terminal,  it cannot be recommended for automating your production deployments. First, there is a decision on how to store your Terraform \u003ca href=\"https://www.terraform.io/docs/language/state/index.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://www.terraform.io\" track-metadata-module=\"post\"\u003estate\u003c/a\u003e in a way that is secure, compliant and enables team collaboration. Secondly there’s a question of scale and reliability. Over the course of even the simplest cloud deployment, Terraform can end up making thousands of Create/Read/Update/Delete API calls to the endpoints used by the Terraform providers, some of which will inevitably hit quota issues or need to be retried for other reasons. For platform administrators, who are looking to ensure the best deployment practices for their curated Terraform solutions,  while benefiting from the simplicity of Google Cloud Console, there’s \u003ca href=\"https://cloud.google.com/blog/products/management-tools/private-catalog-uses-terraform-to-update-available-solutions\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/management-tools/private-catalog-uses-terraform-to-update-available-solutions\" track-metadata-module=\"post\"\u003eTerraform Private Catalog integration\u003c/a\u003e that we enabled earlier this year.\u003c/p\u003e\u003cp\u003eOutside of Private Catalog, \u003ca href=\"https://cloud.google.com/build\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/build\" track-metadata-module=\"post\"\u003eCloud Build\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/storage\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/storage\" track-metadata-module=\"post\"\u003eCloud Storage\u003c/a\u003e have been the recommended approach to use Terraform on Google Cloud. Using a remote\u003ca href=\"https://www.terraform.io/docs/language/settings/backends/index.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://www.terraform.io\" track-metadata-module=\"post\"\u003e backend\u003c/a\u003e prevents race conditions and simplifies sharing reusable modules between different configurations. With Cloud Build you can configure a GitOps CI/CD pipeline to automatically \u003ccode\u003eplan\u003c/code\u003e and \u003ccode\u003eapply\u003c/code\u003e your Terraform configuration when changes are pushed into the repo. \u003c/p\u003e\u003cp\u003eThese are widely popularized benefits explored in \u003ca href=\"https://cloud.google.com/architecture/managing-infrastructure-as-code\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/architecture/managing-infrastructure-as-code\" track-metadata-module=\"post\"\u003eManaging infrastructure as code with Terraform, Cloud Build, and GitOps\u003c/a\u003e. In addition, there are lesser known advantages of Cloud Build, particularly for enterprise customers: Cloud Build’s concurrency capabilities and VPC-SC support, Cloud Storage versioning, security and compliance. Let’s explore these benefits in more detail.\u003c/p\u003e\u003cp\u003eCloud Build’s ability to scale makes it capable to process multiple Terraform deployments across the regions globally and simultaneously. By default, Cloud Build supports 30 concurrent builds, with additional builds queued and processed after the running builds complete. In some cases it may not be enough. Customers who initiate parallel deployments to multiple zones, or, those who provision infrastructure on behalf of multiple tenants, often require running more concurrent deployments to complete all of them within the allotted deployment window. Cloud Build private pool feature allows up to \u003ca href=\"https://cloud.google.com/build/quotas\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/build/quotas\" track-metadata-module=\"post\"\u003e100 concurrent builds\u003c/a\u003e which may be further adjusted upon request. This is an example of creating a private pool and then using it when submitting a build:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003ca href=\"https://www.terraform.io/\" target=\"_blank\"\u003eTerraform\u003c/a\u003e is an open source Infrastructure as Code tool that is popular with platform developers building reusable cloud automation. The \u003ca href=\"https://registry.terraform.io/providers/hashicorp/google/latest/docs\" target=\"_blank\"\u003eTerraform Provider for Google Cloud Platform\u003c/a\u003e continues to add support for the latest Google Cloud features, such as \u003ca href=\"https://cloud.google.com/blog/topics/anthos/using-terraform-to-enable-config-sync-on-a-gke-cluster\"\u003eAnthos on GKE\u003c/a\u003e, and our teams continue to expand Terraform integrations including \u003ca href=\"https://cloud.google.com/foundation-toolkit\"\u003eCloud Foundation Toolkit\u003c/a\u003e and \u003ca href=\"https://github.com/GoogleCloudPlatform/terraform-validator#terraform-validator\" target=\"_blank\"\u003eTerraform Validator\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eHow do teams use Terraform on Google Cloud? While the simplest approach is to run \u003ccode\u003eterraform init\u003c/code\u003e, \u003ccode\u003eplan\u003c/code\u003e and \u003ccode\u003eapply\u003c/code\u003e directly from your terminal,  it cannot be recommended for automating your production deployments. First, there is a decision on how to store your Terraform \u003ca href=\"https://www.terraform.io/docs/language/state/index.html\" target=\"_blank\"\u003estate\u003c/a\u003e in a way that is secure, compliant and enables team collaboration. Secondly there’s a question of scale and reliability. Over the course of even the simplest cloud deployment, Terraform can end up making thousands of Create/Read/Update/Delete API calls to the endpoints used by the Terraform providers, some of which will inevitably hit quota issues or need to be retried for other reasons. For platform administrators, who are looking to ensure the best deployment practices for their curated Terraform solutions,  while benefiting from the simplicity of Google Cloud Console, there’s \u003ca href=\"https://cloud.google.com/blog/products/management-tools/private-catalog-uses-terraform-to-update-available-solutions\"\u003eTerraform Private Catalog integration\u003c/a\u003e that we enabled earlier this year.\u003c/p\u003e\u003cp\u003eOutside of Private Catalog, \u003ca href=\"https://cloud.google.com/build\"\u003eCloud Build\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/storage\"\u003eCloud Storage\u003c/a\u003e have been the recommended approach to use Terraform on Google Cloud. Using a remote\u003ca href=\"https://www.terraform.io/docs/language/settings/backends/index.html\" target=\"_blank\"\u003ebackend\u003c/a\u003e prevents race conditions and simplifies sharing reusable modules between different configurations. With Cloud Build you can configure a GitOps CI/CD pipeline to automatically \u003ccode\u003eplan\u003c/code\u003e and \u003ccode\u003eapply\u003c/code\u003e your Terraform configuration when changes are pushed into the repo. \u003c/p\u003e\u003cp\u003eThese are widely popularized benefits explored in \u003ca href=\"https://cloud.google.com/architecture/managing-infrastructure-as-code\"\u003eManaging infrastructure as code with Terraform, Cloud Build, and GitOps\u003c/a\u003e. In addition, there are lesser known advantages of Cloud Build, particularly for enterprise customers: Cloud Build’s concurrency capabilities and VPC-SC support, Cloud Storage versioning, security and compliance. Let’s explore these benefits in more detail.\u003c/p\u003e\u003cp\u003eCloud Build’s ability to scale makes it capable to process multiple Terraform deployments across the regions globally and simultaneously. By default, Cloud Build supports 30 concurrent builds, with additional builds queued and processed after the running builds complete. In some cases it may not be enough. Customers who initiate parallel deployments to multiple zones, or, those who provision infrastructure on behalf of multiple tenants, often require running more concurrent deployments to complete all of them within the allotted deployment window. Cloud Build private pool feature allows up to \u003ca href=\"https://cloud.google.com/build/quotas\"\u003e100 concurrent builds\u003c/a\u003e which may be further adjusted upon request. This is an example of creating a private pool and then using it when submitting a build:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eA full step by step example of creating a private pool and submitting 80+ Terraform deployments with Cloud Build simultaneously is available \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-builders-community/tree/master/terraform/examples/infra_at_scale\" target=\"_blank\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eUsing Cloud Build removes the need to build a custom high-scale Terraform provisioning service and provides \u003ca href=\"https://cloud.google.com/build/docs/view-build-results\"\u003eobservability and diagnostics\u003c/a\u003e for each of the build instances launched and their results. \u003c/p\u003e\u003cp\u003eUsing Cloud Build with private pools enables recommended security features, such as \u003ca href=\"https://cloud.google.com/build/docs/private-pools/using-vpc-service-controls\"\u003eVPC Service Controls\u003c/a\u003ethat allows setting secure perimeter to protect against data exfiltration, with additional restrictions to further restrict it to using the specified private pools. This makes it unnecessary to configure a dedicated \u003ca href=\"https://en.wikipedia.org/wiki/Bastion_host\" target=\"_blank\"\u003ebastion host\u003c/a\u003e inside the perimeter, which improves the overall security posture.\u003c/p\u003eBeyond just using Cloud Storage for remote storage, additional reasons to use Cloud Storage include versioning, security and compliance. Enabling versioning protects against state file corruption and allows you to view earlier versions. Versioning can be enabled with \u003ccode\u003egsutil\u003c/code\u003e command:\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIn addition to versioning, you can use \u003ca href=\"https://cloud.google.com/security/encryption/customer-supplied-encryption-keys\"\u003eCustomer-Supplied Encryption Keys\u003c/a\u003e to encrypt the Terraform state file. After you generated the key you can specify it as encryption_key parameter of your backend object:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eOnce encrypted you can still view the contents of your state by \u003ca href=\"https://cloud.google.com/storage/docs/encryption/customer-supplied-keys#gsutil\"\u003eadding encryption_key option to boto configuration file\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eFinally, Cloud Storage is one of the Google Cloud services covered by \u003ca href=\"https://cloud.google.com/security/compliance/fedramp\"\u003eFedRAMP High\u003c/a\u003e, which is important for enterprises  that are seeking their own FedRAMP on top of Google Cloud (for more details see \u003ca href=\"https://cloud.google.com/security/compliance\"\u003eCompliance resource center\u003c/a\u003e).\u003c/p\u003e\u003cp\u003eTo summarize, using Cloud Build and Cloud Storage for your Terraform deployments enable high scalability, security and compliance with simpler configuration and via familiar \u003ccode\u003egcloud\u003c/code\u003e and Google Cloud console interface. Please check out this \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-builders-community/tree/master/terraform/examples/infra_at_scale\" target=\"_blank\"\u003esample\u003c/a\u003e for step by step guidance.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/cloud-build-private-pools-offers-cicd-for-private-networks/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/devops.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eIntroducing Cloud Build private pools: Secure CI/CD for private networks\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eWith new private pools, you can use Google Cloud’s hosted Cloud Build CI/CD service on resources in your private network or in other clouds.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_D_Rnd3.max-2200x2200.jpg",
      "date_published": "2021-12-06T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eAlex Bulankou\u003c/name\u003e\u003ctitle\u003eEngineering Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/supercharge-your-devops-practice-with-sre-principles/",
      "title": "Want to supercharge your DevOps practice? Research says try SRE",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eReliability matters. When users can’t access your application, if it’s slow to respond, or it behaves unexpectedly, they don’t get the value that you intend to provide. That’s why at Google we like to say that \u003ca href=\"https://sre.google/workbook/reaching-beyond/\" target=\"_blank\"\u003e\u003ci\u003ereliability is the most important feature of any system\u003c/i\u003e\u003c/a\u003e. Its impact can be seen all the way to the bottom line, as downtime comes with steep costs—to revenue, to reputation, and to user loyalty. \u003c/p\u003e\u003cp\u003eFrom the beginning of the \u003ca href=\"https://www.devops-research.com/research.html\" target=\"_blank\"\u003eDevOps Research and Assessment\u003c/a\u003e (DORA) project, we’ve recognized the importance of delivering a consistent experience to users. We measure this with the \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/using-the-four-keys-to-measure-your-devops-performance\"\u003eFour Key\u003c/a\u003e metrics—two metrics that track the velocity of deploying new releases, balanced against two that capture the initial stability of those releases. A team that rates well on all four metrics is not only good at shipping code, they’re shipping code that’s good. \u003c/p\u003e\u003cp\u003eHowever, these four signals, which focus on the path to a deployment and its immediate effects, are less diagnostic of subsequent success throughout the lifespan of a release. In 2018, DORA began to study the ongoing stability of software delivered as a service (as typified by web applications), which we captured in an additional metric for availability, to explore the impact of technical operations on organizational performance. This year, we expanded our inquiry into this area, starting by renaming availability to reliability. Reliability (sometimes abbreviated as r9y) is a more general term that encompasses dimensions including response latency and content validity, as well as availability.\u003c/p\u003e\u003cp\u003eIn the \u003ca href=\"https://cloud.google.com/devops/state-of-devops/\"\u003e2021 State of DevOps Report’s\u003c/a\u003e cluster analysis, teams were segmented into four groups based on the Four Key metrics of software delivery. At first glance, we found that the application of reliability practices is not directly correlated to software delivery performance —  teams that score well on delivery metrics may not be the same as those who consistently practice modern operations. However, in combination, software delivery performance and reliability engineering exert a powerful influence on organizational outcomes: elite software delivery teams that also meet their reliability goals are 1.8 times more likely to report better business outcomes.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"SRE.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/SRE.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eHow Google achieves reliability: SRE\u003c/h3\u003e\u003cp\u003eIn Google’s early days, we took a traditional approach to technical operations; the bulk of the work involved manual interventions in reaction to discrete problems. However, as our products began to rapidly acquire users across the globe, we realized that this approach wasn’t sustainable. It couldn’t scale to match the increasing size and complexity of our systems, and even attempting to keep up would require an untenable investment in our operations workforce. So, for the past 15+ years, we’ve been practicing and iterating on an approach called \u003ca href=\"http://sre.google\" target=\"_blank\"\u003eSite Reliability Engineering\u003c/a\u003e (SRE). \u003c/p\u003e\u003cp\u003eSRE provides a framework for measurement, prioritization, and information sharing to help teams balance between the velocity of feature releases and the predictable behavior of deployed services. It emphasizes the use of automation to reduce risk and to free up engineering capacity for strategic work. This may sound a lot like a description of DevOps; indeed, these disciplines have many shared values. That similarity meant that when, in 2016, Google published the \u003ca href=\"http://sre.google/books\" target=\"_blank\"\u003efirst book on Site Reliability Engineering\u003c/a\u003e, it made waves in the DevOps community as practitioners recognized a like-minded movement. It also caused some confusion: some have framed DevOps and SRE as being in conflict or competition with each other.\u003c/p\u003e\u003cp\u003eOur view is that, having arisen from similar challenges and espousing similar objectives, DevOps and SRE can be mutually compatible. We posited that, metaphorically, “\u003ca href=\"https://youtu.be/uTEL8Ff1Zvk\" target=\"_blank\"\u003e\u003ccode\u003eclass SRE implements DevOps\u003c/code\u003e\u003c/a\u003e''—SRE provides a way to realize DevOps objectives. Inspired by these communities’ continued growth and ongoing exchange of ideas, we sought to investigate their relationship further. This year, we expanded the scope of data collection to assess the extent of SRE adoption across the industry, and to learn how such modern operational practices interact with DORA’s model of software delivery performance.\u003c/p\u003e\u003cp\u003eStarting from the \u003ca href=\"http://sre.google/books\" target=\"_blank\"\u003epublished literature on SRE\u003c/a\u003e, we added the key elements of the framework as items in our survey of practitioners. We took care to avoid as much as possible any jargon, instead preferring plain language to describe how modern operations teams go about their work. Respondents reported on such practices as: defining reliability in terms of user-visible behavior; the use of automation to allow engineers to focus on strategic work; and having well-defined, well-practiced protocols for incident response. \u003c/p\u003e\u003cp\u003eAlong the way, we found that using SRE to implement DevOps is much more widely practiced than we thought. SRE, and related disciplines like Facebook’s Production Engineering, have a reputation for being niche disciplines, practiced only by a handful of tech giants. To the contrary, we found that SRE is used in some capacity by a majority of the teams in the DORA survey, with 52% of respondents reporting the use of one or more SRE practices.\u003c/p\u003e\u003ch3\u003eSRE is a force multiplier for software delivery excellence\u003c/h3\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph_with_image\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cfigure class=\"article-image--wrap-medium \"\u003e\u003cimg alt=\"SRE 1.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/SRE_1.1203064715921295.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eAnalyzing the results, we found compelling evidence that SRE is an effective approach to modern operations across the spectrum of organizations. In addition to driving better business outcomes, SRE helps focus efforts—teams that achieve their reliability goals report that they are able to spend more time coding, as they’re less consumed by reacting to incidents. These findings are consistent with the observation that \u003ca href=\"https://cloud.google.com/resources/roi-of-devops-transformation-whitepaper\"\u003ehaving reliable services can directly impact revenue\u003c/a\u003e, as well as offering engineers greater flexibility to use their time to improve their systems, rather than simply repairing them.\u003c/p\u003e\u003cp\u003eBut while SRE is widely used and has demonstrable benefits, few respondents indicated that their teams have fully implemented every SRE technique we examined. Increased application of SRE has benefits at all levels: within every cluster of software delivery performance, teams that also meet their reliability goals outperform other members of their cluster in regard to business outcomes. \u003c/p\u003e\u003ch3\u003eOn the SRE road to DevOps excellence\u003c/h3\u003e\u003cp\u003eSRE is more than a toolset; it’s also a cultural mindset about the role of operations staff. SRE is a learning discipline, aimed at understanding information and continuously iterating in response. Accordingly, adopting SRE takes time, and success requires starting small, and applying an iterative approach to SRE itself.\u003c/p\u003e\u003cp\u003eHere are some ways to get started:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eFind free books and articles at \u003ca href=\"http://sre.google\"\u003esre.google\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eJoin a conversation with fellow practitioners, at all different stages of SRE implementation, at \u003ca href=\"http://bit.ly/reliability-discuss\"\u003ebit.ly/reliability-discuss\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eSpeak to your GCP account manager about our professional service offerings \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003eApply to the \u003ca href=\"https://cloud.google.com/awards/devops/?eligible_for_cloud_free_trial=true\"\u003eDevOps awards\u003c/a\u003e to show how your organization is implementing award winning SRE practices along with the DORA principles!\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/original_images/DevOps_BlogHeader_C_Rnd3_n7MW7mI.jpg",
      "date_published": "2021-11-29T18:00:00Z",
      "author": {
        "name": "\u003cname\u003eDave Stanke\u003c/name\u003e\u003ctitle\u003eDeveloper Relations Engineer\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/topics/retail/unlocking-the-power-of-modern-devops/",
      "title": "Empowering DevOps to foster customer loyalty in modern retail with MongoDB Atlas on Google Cloud",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c60=\"\"\u003e\u003cdiv _ngcontent-c60=\"\" innerhtml=\"\u0026lt;p\u0026gt;Consumer demands are becoming more complex, driven by high expectations for personalized experiences that strike the right chord at the perfect time. One study from McKinsey found that\u0026lt;a href=\u0026#34;https://www.mckinsey.com/business-functions/marketing-and-sales/our-insights/the-value-of-getting-personalization-right-or-wrong-is-multiplying\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt; nearly three-quarters of consumers demand personalization\u0026lt;/a\u0026gt; when interacting with retailers.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Retailers old and new of any size must embrace the challenges head on and learn to capture customer loyalty. While each business has a unique journey toward modernizing its business, all of them share something in common: Effective approaches to DevOps and data analytics underpin their success.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Retailers sometimes struggle to change previous retail models into the much more intimate, personalized, and real-time retail experiences that consumers now want, whether shopping in-store or online. At the same time, retailers and many newcomers are jumping all in, and devising exceptional experiences that transform shopper experiences and elevate expectations even further.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;MongoDB and Google Cloud have been helping retailers of all sizes better address quickly changing market opportunities. As retailers continue to need more powerful systems of engagement and data analytics, the combination of MongoDB Atlas and Google Cloud solutions offer retailers such as 1-800-FLOWERS.COM, Inc. a solid mix of proven IT infrastructure and expertise.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Maximizing data value for developers\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;DevOps is increasingly tasked with creating experiences that will bring customers to a retail website, and guide them through the purchasing process. Along the way, they need to build in steps that keep customers fully engaged in the buying process and discourage things like cart abandonment. A successful build depends a lot on how much quality data is available about customer shopping experiences and how easy it is for DevOps teams to derive insights from that information.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud is very much a developer\u0026amp;#8217;s cloud, and we at MongoDB are very much a developer\u0026amp;#8217;s database. We like the breadth of Google Cloud services, which pair well with our products. Our collaboration with Google Cloud feels very natural both in terms of the technology we develop and how we are approaching serving our clients\u0026amp;#8217; needs. Together, we give DevOps teams at retailers a modern toolkit to maximize the value of their work.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The cloud-based environment supported by Google Cloud and MongoDB Atlas increases the speed and success of experimentation and ultimately delivers solutions with the greatest impact. With agile environments like ours, teams experiment much faster, leading to more innovative shopping experiences that differentiate a retailer from their competitors.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Any cloud solution has to be usable for retailers of all sizes so that they can develop services according to their unique needs, expertise, and visions. The goal should be to empower a retailer\u0026amp;#8217;s DevOps team to be as self-sufficient as possible, and not have to rely on a third-party every time changes need to be made.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In an industry facing extremely tight margins\u0026amp;#8212;and where a two percent efficiency gain or 2x acceleration of time to market can make or break the success of a project\u0026amp;#8212;gaining any edge is essential for retailers. Google Cloud and MongoDB provide that edge to retailers, as well as to other companies across industries.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Cultivating a vision at 1-800-FLOWERS.COM, Inc.\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;1-800-FLOWERS.COM, Inc. is an exceptional example of what can be achieved when going all in with modern data and DevOps solutions. Chief Technology Officer Abi Sachdeva, has pursued emerging technologies to support its business teams with the latest technologies to drive value for its customers.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Abi has been laser-focused on delivering new personalized experiences by continually innovating customer-facing services. Driven by a commitment to foster engagement across its industry-leading brands through a centralized customer experience, 1-800-FLOWERS.COM, Inc. built an e-commerce platform that is inclusive of both products and resources aimed at improving how people express themselves.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;To best manage all the eCommerce environments associated and ensure outstanding customer service, 1-800-FLOWERS.COM, Inc. with MongoDB and Google Cloud to revolutionize its DevOps.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026amp;#8220;With the help of MongoDB and Google Cloud, we transformed people, processes, and our technology. It has been a very stable experience requiring little administrative work,\u0026amp;#8221; says Abi. \u0026amp;#8220;Traditional technologies weighed us down in the past. MongoDB and Google Cloud deliver data models and DevOps solutions that accelerate our development and deployment.\u0026amp;#8221;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;MongoDB Atlas , Inc. with aggregation pipelines and a distributed system design that help it to scale quickly, while Google Cloud made its new approach to agile and DevOps a reality.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;he speed and agility that come with cloud services, companies like 1-800-FLOWERS.COM, Inc.\u0026amp;#160; keep up with the constantly changing customer preferences. With proven cloud solutions that at once increase overall IT effectiveness and decrease the burdens on IT teams, 1-800-FLOWERS.COM, Inc.\u0026amp;#160; is better positioned to constantly experiment, innovate, and deliver experiences that delight customers.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026amp;#8220;The fully managed MongoDB Atlas database on Google Cloud has unlocked tremendous potential in our IT architecture,\u0026amp;#8221; says Abi. \u0026amp;#8220;From agility in scaling and improved resource management to seamless global clusters and premium monitoring, MongoDB and Google Cloud reduce complexity and allow our teams to stay lean and focused on innovation rather than infrastructure.\u0026amp;#8221;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Looking toward the holidays and beyond\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;The very same systems that encourage experimentation and innovation can position retailers and other companies to excel in during and long after the holiday season. Companies need elasticity, scalability, and agility to facilitate experimentation and to navigate the turbulent external factors across their marketplace.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Every holiday season is challenging for retailers, but current supply chain concerns combined with massive changes to how people shop as a result of the COVID-19 pandemic will make 2021 a particularly important year for the industry. I believe that companies that have increased their backend elasticity and improved their DevOps culture will fare especially well amid the market upheaval.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;As organizations modernize IT, it will be increasingly important to pair the possibilities of software and infrastructure to enable smaller DevOps teams to act independently and quickly. This improves culture across the business as people are more empowered and supported.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In addition, I encourage DevOps professionals to place more importance on understanding customers, business values, and to be people-first in their approaches to work. By combining this level of business experience with great coding skills, smaller teams can bolster a retailer\u0026amp;#8217;s performance this holiday season and beyond.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;We are proud to work with Google Cloud to develop and deliver new ways for DevOps in retail and other industries to experiment, innovate, and deploy groundbreaking experiences that transform how people achieve their goals.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;To learn more about the future of retail innovation,\u0026lt;a href=\u0026#34;https://www.youtube.com/watch?v=waNVXeHtzOs\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt; watch this video\u0026lt;/a\u0026gt; featuring members of the 1-800-FLOWERS.COM, Inc., MongoDB, and Google Cloud teams.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eConsumer demands are becoming more complex, driven by high expectations for personalized experiences that strike the right chord at the perfect time. One study from McKinsey found that\u003ca href=\"https://www.mckinsey.com/business-functions/marketing-and-sales/our-insights/the-value-of-getting-personalization-right-or-wrong-is-multiplying\" target=\"_blank\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://www.mckinsey.com\" track-metadata-module=\"post\"\u003e nearly three-quarters of consumers demand personalization\u003c/a\u003e when interacting with retailers.\u003c/p\u003e\u003cp\u003eRetailers old and new of any size must embrace the challenges head on and learn to capture customer loyalty. While each business has a unique journey toward modernizing its business, all of them share something in common: Effective approaches to DevOps and data analytics underpin their success.\u003c/p\u003e\u003cp\u003eRetailers sometimes struggle to change previous retail models into the much more intimate, personalized, and real-time retail experiences that consumers now want, whether shopping in-store or online. At the same time, retailers and many newcomers are jumping all in, and devising exceptional experiences that transform shopper experiences and elevate expectations even further.\u003c/p\u003e\u003cp\u003eMongoDB and Google Cloud have been helping retailers of all sizes better address quickly changing market opportunities. As retailers continue to need more powerful systems of engagement and data analytics, the combination of MongoDB Atlas and Google Cloud solutions offer retailers such as 1-800-FLOWERS.COM, Inc. a solid mix of proven IT infrastructure and expertise.\u003c/p\u003e\u003ch3\u003eMaximizing data value for developers\u003c/h3\u003e\u003cp\u003eDevOps is increasingly tasked with creating experiences that will bring customers to a retail website, and guide them through the purchasing process. Along the way, they need to build in steps that keep customers fully engaged in the buying process and discourage things like cart abandonment. A successful build depends a lot on how much quality data is available about customer shopping experiences and how easy it is for DevOps teams to derive insights from that information.\u003c/p\u003e\u003cp\u003eGoogle Cloud is very much a developer’s cloud, and we at MongoDB are very much a developer’s database. We like the breadth of Google Cloud services, which pair well with our products. Our collaboration with Google Cloud feels very natural both in terms of the technology we develop and how we are approaching serving our clients’ needs. Together, we give DevOps teams at retailers a modern toolkit to maximize the value of their work.\u003c/p\u003e\u003cp\u003eThe cloud-based environment supported by Google Cloud and MongoDB Atlas increases the speed and success of experimentation and ultimately delivers solutions with the greatest impact. With agile environments like ours, teams experiment much faster, leading to more innovative shopping experiences that differentiate a retailer from their competitors.\u003c/p\u003e\u003cp\u003eAny cloud solution has to be usable for retailers of all sizes so that they can develop services according to their unique needs, expertise, and visions. The goal should be to empower a retailer’s DevOps team to be as self-sufficient as possible, and not have to rely on a third-party every time changes need to be made.\u003c/p\u003e\u003cp\u003eIn an industry facing extremely tight margins—and where a two percent efficiency gain or 2x acceleration of time to market can make or break the success of a project—gaining any edge is essential for retailers. Google Cloud and MongoDB provide that edge to retailers, as well as to other companies across industries.\u003c/p\u003e\u003ch3\u003eCultivating a vision at 1-800-FLOWERS.COM, Inc.\u003c/h3\u003e\u003cp\u003e1-800-FLOWERS.COM, Inc. is an exceptional example of what can be achieved when going all in with modern data and DevOps solutions. Chief Technology Officer Abi Sachdeva, has pursued emerging technologies to support its business teams with the latest technologies to drive value for its customers.\u003c/p\u003e\u003cp\u003eAbi has been laser-focused on delivering new personalized experiences by continually innovating customer-facing services. Driven by a commitment to foster engagement across its industry-leading brands through a centralized customer experience, 1-800-FLOWERS.COM, Inc. built an e-commerce platform that is inclusive of both products and resources aimed at improving how people express themselves.\u003c/p\u003e\u003cp\u003eTo best manage all the eCommerce environments associated and ensure outstanding customer service, 1-800-FLOWERS.COM, Inc. with MongoDB and Google Cloud to revolutionize its DevOps.\u003c/p\u003e\u003cp\u003e“With the help of MongoDB and Google Cloud, we transformed people, processes, and our technology. It has been a very stable experience requiring little administrative work,” says Abi. “Traditional technologies weighed us down in the past. MongoDB and Google Cloud deliver data models and DevOps solutions that accelerate our development and deployment.”\u003c/p\u003e\u003cp\u003eMongoDB Atlas , Inc. with aggregation pipelines and a distributed system design that help it to scale quickly, while Google Cloud made its new approach to agile and DevOps a reality.\u003c/p\u003e\u003cp\u003ehe speed and agility that come with cloud services, companies like 1-800-FLOWERS.COM, Inc.  keep up with the constantly changing customer preferences. With proven cloud solutions that at once increase overall IT effectiveness and decrease the burdens on IT teams, 1-800-FLOWERS.COM, Inc.  is better positioned to constantly experiment, innovate, and deliver experiences that delight customers.\u003c/p\u003e\u003cp\u003e“The fully managed MongoDB Atlas database on Google Cloud has unlocked tremendous potential in our IT architecture,” says Abi. “From agility in scaling and improved resource management to seamless global clusters and premium monitoring, MongoDB and Google Cloud reduce complexity and allow our teams to stay lean and focused on innovation rather than infrastructure.”\u003c/p\u003e\u003ch3\u003eLooking toward the holidays and beyond\u003c/h3\u003e\u003cp\u003eThe very same systems that encourage experimentation and innovation can position retailers and other companies to excel in during and long after the holiday season. Companies need elasticity, scalability, and agility to facilitate experimentation and to navigate the turbulent external factors across their marketplace.\u003c/p\u003e\u003cp\u003eEvery holiday season is challenging for retailers, but current supply chain concerns combined with massive changes to how people shop as a result of the COVID-19 pandemic will make 2021 a particularly important year for the industry. I believe that companies that have increased their backend elasticity and improved their DevOps culture will fare especially well amid the market upheaval.\u003c/p\u003e\u003cp\u003eAs organizations modernize IT, it will be increasingly important to pair the possibilities of software and infrastructure to enable smaller DevOps teams to act independently and quickly. This improves culture across the business as people are more empowered and supported.\u003c/p\u003e\u003cp\u003eIn addition, I encourage DevOps professionals to place more importance on understanding customers, business values, and to be people-first in their approaches to work. By combining this level of business experience with great coding skills, smaller teams can bolster a retailer’s performance this holiday season and beyond.\u003c/p\u003e\u003cp\u003eWe are proud to work with Google Cloud to develop and deliver new ways for DevOps in retail and other industries to experiment, innovate, and deploy groundbreaking experiences that transform how people achieve their goals.\u003c/p\u003e\u003cp\u003eTo learn more about the future of retail innovation,\u003ca href=\"https://www.youtube.com/watch?v=waNVXeHtzOs\" target=\"_blank\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://www.youtube.com\" track-metadata-module=\"post\"\u003e watch this video\u003c/a\u003e featuring members of the 1-800-FLOWERS.COM, Inc., MongoDB, and Google Cloud teams.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eConsumer demands are becoming more complex, driven by high expectations for personalized experiences that strike the right chord at the perfect time. One study from McKinsey found that\u003ca href=\"https://www.mckinsey.com/business-functions/marketing-and-sales/our-insights/the-value-of-getting-personalization-right-or-wrong-is-multiplying\" target=\"_blank\"\u003enearly three-quarters of consumers demand personalization\u003c/a\u003e when interacting with retailers.\u003c/p\u003e\u003cp\u003eRetailers old and new of any size must embrace the challenges head on and learn to capture customer loyalty. While each business has a unique journey toward modernizing its business, all of them share something in common: Effective approaches to DevOps and data analytics underpin their success.\u003c/p\u003e\u003cp\u003eRetailers sometimes struggle to change previous retail models into the much more intimate, personalized, and real-time retail experiences that consumers now want, whether shopping in-store or online. At the same time, retailers and many newcomers are jumping all in, and devising exceptional experiences that transform shopper experiences and elevate expectations even further.\u003c/p\u003e\u003cp\u003eMongoDB and Google Cloud have been helping retailers of all sizes better address quickly changing market opportunities. As retailers continue to need more powerful systems of engagement and data analytics, the combination of MongoDB Atlas and Google Cloud solutions offer retailers such as 1-800-FLOWERS.COM, Inc. a solid mix of proven IT infrastructure and expertise.\u003c/p\u003e\u003ch3\u003eMaximizing data value for developers\u003c/h3\u003e\u003cp\u003eDevOps is increasingly tasked with creating experiences that will bring customers to a retail website, and guide them through the purchasing process. Along the way, they need to build in steps that keep customers fully engaged in the buying process and discourage things like cart abandonment. A successful build depends a lot on how much quality data is available about customer shopping experiences and how easy it is for DevOps teams to derive insights from that information.\u003c/p\u003e\u003cp\u003eGoogle Cloud is very much a developer’s cloud, and we at MongoDB are very much a developer’s database. We like the breadth of Google Cloud services, which pair well with our products. Our collaboration with Google Cloud feels very natural both in terms of the technology we develop and how we are approaching serving our clients’ needs. Together, we give DevOps teams at retailers a modern toolkit to maximize the value of their work.\u003c/p\u003e\u003cp\u003eThe cloud-based environment supported by Google Cloud and MongoDB Atlas increases the speed and success of experimentation and ultimately delivers solutions with the greatest impact. With agile environments like ours, teams experiment much faster, leading to more innovative shopping experiences that differentiate a retailer from their competitors.\u003c/p\u003e\u003cp\u003eAny cloud solution has to be usable for retailers of all sizes so that they can develop services according to their unique needs, expertise, and visions. The goal should be to empower a retailer’s DevOps team to be as self-sufficient as possible, and not have to rely on a third-party every time changes need to be made.\u003c/p\u003e\u003cp\u003eIn an industry facing extremely tight margins—and where a two percent efficiency gain or 2x acceleration of time to market can make or break the success of a project—gaining any edge is essential for retailers. Google Cloud and MongoDB provide that edge to retailers, as well as to other companies across industries.\u003c/p\u003e\u003ch3\u003eCultivating a vision at 1-800-FLOWERS.COM, Inc.\u003c/h3\u003e\u003cp\u003e1-800-FLOWERS.COM, Inc. is an exceptional example of what can be achieved when going all in with modern data and DevOps solutions. Chief Technology Officer Abi Sachdeva, has pursued emerging technologies to support its business teams with the latest technologies to drive value for its customers.\u003c/p\u003e\u003cp\u003eAbi has been laser-focused on delivering new personalized experiences by continually innovating customer-facing services. Driven by a commitment to foster engagement across its industry-leading brands through a centralized customer experience, 1-800-FLOWERS.COM, Inc. built an e-commerce platform that is inclusive of both products and resources aimed at improving how people express themselves.\u003c/p\u003e\u003cp\u003eTo best manage all the eCommerce environments associated and ensure outstanding customer service, 1-800-FLOWERS.COM, Inc. with MongoDB and Google Cloud to revolutionize its DevOps.\u003c/p\u003e\u003cp\u003e“With the help of MongoDB and Google Cloud, we transformed people, processes, and our technology. It has been a very stable experience requiring little administrative work,” says Abi. “Traditional technologies weighed us down in the past. MongoDB and Google Cloud deliver data models and DevOps solutions that accelerate our development and deployment.”\u003c/p\u003e\u003cp\u003eMongoDB Atlas , Inc. with aggregation pipelines and a distributed system design that help it to scale quickly, while Google Cloud made its new approach to agile and DevOps a reality.\u003c/p\u003e\u003cp\u003ehe speed and agility that come with cloud services, companies like 1-800-FLOWERS.COM, Inc.  keep up with the constantly changing customer preferences. With proven cloud solutions that at once increase overall IT effectiveness and decrease the burdens on IT teams, 1-800-FLOWERS.COM, Inc.  is better positioned to constantly experiment, innovate, and deliver experiences that delight customers.\u003c/p\u003e\u003cp\u003e“The fully managed MongoDB Atlas database on Google Cloud has unlocked tremendous potential in our IT architecture,” says Abi. “From agility in scaling and improved resource management to seamless global clusters and premium monitoring, MongoDB and Google Cloud reduce complexity and allow our teams to stay lean and focused on innovation rather than infrastructure.”\u003c/p\u003e\u003ch3\u003eLooking toward the holidays and beyond\u003c/h3\u003e\u003cp\u003eThe very same systems that encourage experimentation and innovation can position retailers and other companies to excel in during and long after the holiday season. Companies need elasticity, scalability, and agility to facilitate experimentation and to navigate the turbulent external factors across their marketplace.\u003c/p\u003e\u003cp\u003eEvery holiday season is challenging for retailers, but current supply chain concerns combined with massive changes to how people shop as a result of the COVID-19 pandemic will make 2021 a particularly important year for the industry. I believe that companies that have increased their backend elasticity and improved their DevOps culture will fare especially well amid the market upheaval.\u003c/p\u003e\u003cp\u003eAs organizations modernize IT, it will be increasingly important to pair the possibilities of software and infrastructure to enable smaller DevOps teams to act independently and quickly. This improves culture across the business as people are more empowered and supported.\u003c/p\u003e\u003cp\u003eIn addition, I encourage DevOps professionals to place more importance on understanding customers, business values, and to be people-first in their approaches to work. By combining this level of business experience with great coding skills, smaller teams can bolster a retailer’s performance this holiday season and beyond.\u003c/p\u003e\u003cp\u003eWe are proud to work with Google Cloud to develop and deliver new ways for DevOps in retail and other industries to experiment, innovate, and deploy groundbreaking experiences that transform how people achieve their goals.\u003c/p\u003e\u003cp\u003eTo learn more about the future of retail innovation,\u003ca href=\"https://www.youtube.com/watch?v=waNVXeHtzOs\" target=\"_blank\"\u003ewatch this video\u003c/a\u003e featuring members of the 1-800-FLOWERS.COM, Inc., MongoDB, and Google Cloud teams.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/topics/retail/how-one-retailer-migrated-its-ecommerce-platform-to-google-cloud/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/google_flowers.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eDelivering smiles and sparking innovation at 1-800-FLOWERS.COM, Inc.\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eSee how gift retailer 1-800-FLOWERS.COM, Inc., migrated its customer touchpoints to cloud, including GKE and BigQuery, to build a microse...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/retail_GV8DIe0.max-2200x2200.jpg",
      "date_published": "2021-11-23T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eMark Porter\u003c/name\u003e\u003ctitle\u003eCTO, MongoDB\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/sabre-leverages-google-cloud-and-site-reliability-engineering/",
      "title": "How Sabre is using SRE to lead a successful digital transformation",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c69=\"\"\u003e\u003cdiv _ngcontent-c69=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;\u0026lt;b\u0026gt;Editor\u0026amp;#8217;s note\u0026lt;/b\u0026gt;: Today we hear from Kenny Kon, an SRE Director at Sabre. Kenny shares about how they have been able to successfully adopt Google\u0026amp;#8217;s SRE framework by leveraging their partnership with Google Cloud.\u0026amp;#160;\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;As a leader in the travel industry, Sabre Corporation is driving innovation in the global travel industry and developing solutions that help airlines, hotels, and travel agencies transform the traveler experience and satisfy the ever-evolving needs of its customers.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In order to build these solutions, we joined forces with Google Cloud as our preferred cloud provider to accelerate our digital transformation. We chose Google because they understand the industry we are in as they also manage travel products such as Google Travel. Google also created \u0026lt;a href=\u0026#34;http://cloud.google.com/sre\u0026#34;\u0026gt;SRE (Site Reliability Engineering)\u0026lt;/a\u0026gt;, and operates with SRE principles at the Google scale, which is what intrigued us the most.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Initially we started with a multi-cloud model, but that didn\u0026amp;#8217;t help us move faster so we consolidated to just Google Cloud. To speed our transformation along, we have adopted Google SRE (Site Reliability Engineering) practices which enables us to balance reliability and speed. We have been able to make this transformation with the direct help of Google Cloud\u0026amp;#8217;s \u0026lt;a href=\u0026#34;https://cloud.google.com/consulting\u0026#34;\u0026gt;Professional Services Organization (PSO)\u0026lt;/a\u0026gt; along with Google Cloud\u0026amp;#8217;s tooling, like \u0026lt;a href=\u0026#34;https://cloud.google.com/monitoring\u0026#34;\u0026gt;Cloud Monitoring\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/logging\u0026#34;\u0026gt;Cloud Logging\u0026lt;/a\u0026gt;, and operating on \u0026lt;a href=\u0026#34;https://cloud.google.com/kubernetes-engine\u0026#34;\u0026gt;Google Kubernetes Engine (GKE)\u0026lt;/a\u0026gt;, and \u0026lt;a href=\u0026#34;https://cloud.google.com/spanner\u0026#34;\u0026gt;Cloud Spanner\u0026lt;/a\u0026gt;.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In adopting SRE at Sabre, we\u0026amp;#8217;d like to highlight three key takeaways from the journey:\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;1. Find colleagues who are also passionate about shifting culture and adopting SRE\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Create a community within your organization who is dedicated to the SRE journey and motivated to make things happen. As we adopted SRE at Sabre I saw more and more people rallying and coming together to support the culture change. With some momentum built it was great to bring shared experiences to the team as we all spoke in the same language talking about SLOs, SLIs, and about how we measure things.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Some of the ways in which we built our community was by hosting monthly brown bag sessions. This is an informal gathering where teams come in and share their experiences and challenges, or teach on specific SRE topics such as SLOs or toil. We also created a \u0026lt;a href=\u0026#34;https://gdg.community.dev/gdg-cloud-southlake/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;public Google Developer Group (GDG)\u0026lt;/a\u0026gt; and have hosted several Google SRE subject matter experts to speak on SRE principles and best practices.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;2. Get your mid level leadership stakeholders on board\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;We know how important \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/sre-success-starts-with-getting-leadership-on-board\u0026#34;\u0026gt;getting leadership buy in\u0026lt;/a\u0026gt; is to creating a successful SRE movement within an organization. That top-level buy-in is highly important to get resources and drive transformation across the organization, but what is sometimes missed is making it a priority to get mid-level leadership on board as well. It\u0026amp;#8217;s difficult to enact change from the ground up starting with practitioners at the bottom, and it\u0026amp;#8217;s also difficult to just have leadership buy in, as once it gets down to the middle, things may fall apart. It is imperative to have mid-level leaders on board as well, as they directly affect the culture and decisions of their teams. To avoid resistance, it is also important that the mid-level leadership (product, operations and engineering managers), i.e. people managers, will understand the motivations behind change so they will be onboard. Without that understanding, it will hinder mid-level leadership\u0026amp;#8217;s ability to communicate changes to the practitioners level and can impact the teams\u0026#39; goal and allocated bandwidth.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;3. Don\u0026amp;#8217;t be afraid to get help from professionals\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Adopting SRE at a large organization is no simple feat. Partnering with \u0026lt;a href=\u0026#34;https://services.google.com/fh/files/misc/pso_sre_google_cloud.pdf\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Google\u0026amp;#8217;s SRE consulting experts\u0026lt;/a\u0026gt; has brought about a huge shift at Sabre. The value PSO brings is not just training, it\u0026#39;s also listening. We\u0026amp;#8217;ve had experienced Googlers who understand our problems and have been at our stage in the SRE journey listen, analyze and tailor the approach specific to our team\u0026#39;s goals. PSO helped us by shifting our engineering teams to be more customer centric, and aligning our product, operations, and development teams. But most importantly, they\u0026amp;#8217;ve helped to make our current teams happier, because they\u0026#39;re not spinning their wheels, waiting around on blocked requests.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;When we partnered with PSO we were aware of who the key stakeholders in our organization are: the mid-level leadership and people managers. We made sure to bring them into our PSO discussions and decision making sessions and as a result, helped us to get more traction and solve the gap we had, enabling the middle-level and bringing them on board.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Some of the actions we have taken with help from our PSO SRE partners include adding a \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/how-sre-teams-are-organized-and-how-to-get-started\u0026#34;\u0026gt;tiers of service\u0026lt;/a\u0026gt; approach, improving incident management through \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/management-tools/shrinking-the-time-to-mitigate-production-incidents\u0026#34;\u0026gt;wheels of misfortune (WoM)\u0026lt;/a\u0026gt;, defining \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/management-tools/practical-guide-to-setting-slos\u0026#34;\u0026gt;critical user journeys (CUJs)\u0026lt;/a\u0026gt;, and implementing \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/management-tools/sre-error-budgets-and-maintenance-windows\u0026#34;\u0026gt;error budgets\u0026lt;/a\u0026gt;.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Since putting these SRE practices into place, our business is more aligned to customer experience. We now invest org resources according to the needs of our customers and with that have reduced silos across our teams. Our Ops team is much happier since they can move faster and not have to block requests. SRE has taught us a common language, a common framework. Moreover, it gives this whole discipline a culture and meaning.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e\u003ci\u003e\u003cb\u003eEditor’s note\u003c/b\u003e: Today we hear from Kenny Kon, an SRE Director at Sabre. Kenny shares about how they have been able to successfully adopt Google’s SRE framework by leveraging their partnership with Google Cloud. \u003c/i\u003e\u003c/p\u003e\u003cp\u003eAs a leader in the travel industry, Sabre Corporation is driving innovation in the global travel industry and developing solutions that help airlines, hotels, and travel agencies transform the traveler experience and satisfy the ever-evolving needs of its customers. \u003c/p\u003e\u003cp\u003eIn order to build these solutions, we joined forces with Google Cloud as our preferred cloud provider to accelerate our digital transformation. We chose Google because they understand the industry we are in as they also manage travel products such as Google Travel. Google also created \u003ca href=\"http://cloud.google.com/sre\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"http://cloud.google.com/sre\" track-metadata-module=\"post\"\u003eSRE (Site Reliability Engineering)\u003c/a\u003e, and operates with SRE principles at the Google scale, which is what intrigued us the most.\u003c/p\u003e\u003cp\u003eInitially we started with a multi-cloud model, but that didn’t help us move faster so we consolidated to just Google Cloud. To speed our transformation along, we have adopted Google SRE (Site Reliability Engineering) practices which enables us to balance reliability and speed. We have been able to make this transformation with the direct help of Google Cloud’s \u003ca href=\"https://cloud.google.com/consulting\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/consulting\" track-metadata-module=\"post\"\u003eProfessional Services Organization (PSO)\u003c/a\u003e along with Google Cloud’s tooling, like \u003ca href=\"https://cloud.google.com/monitoring\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/monitoring\" track-metadata-module=\"post\"\u003eCloud Monitoring\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/logging\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/logging\" track-metadata-module=\"post\"\u003eCloud Logging\u003c/a\u003e, and operating on \u003ca href=\"https://cloud.google.com/kubernetes-engine\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/kubernetes-engine\" track-metadata-module=\"post\"\u003eGoogle Kubernetes Engine (GKE)\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/spanner\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/spanner\" track-metadata-module=\"post\"\u003eCloud Spanner\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eIn adopting SRE at Sabre, we’d like to highlight three key takeaways from the journey: \u003c/p\u003e\u003ch3\u003e1. Find colleagues who are also passionate about shifting culture and adopting SRE\u003c/h3\u003e\u003cp\u003eCreate a community within your organization who is dedicated to the SRE journey and motivated to make things happen. As we adopted SRE at Sabre I saw more and more people rallying and coming together to support the culture change. With some momentum built it was great to bring shared experiences to the team as we all spoke in the same language talking about SLOs, SLIs, and about how we measure things. \u003c/p\u003e\u003cp\u003eSome of the ways in which we built our community was by hosting monthly brown bag sessions. This is an informal gathering where teams come in and share their experiences and challenges, or teach on specific SRE topics such as SLOs or toil. We also created a \u003ca href=\"https://gdg.community.dev/gdg-cloud-southlake/\" target=\"_blank\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://gdg.community.dev\" track-metadata-module=\"post\"\u003epublic Google Developer Group (GDG)\u003c/a\u003e and have hosted several Google SRE subject matter experts to speak on SRE principles and best practices. \u003c/p\u003e\u003ch3\u003e2. Get your mid level leadership stakeholders on board\u003c/h3\u003e\u003cp\u003eWe know how important \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/sre-success-starts-with-getting-leadership-on-board\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/sre-success-starts-with-getting-leadership-on-board\" track-metadata-module=\"post\"\u003egetting leadership buy in\u003c/a\u003e is to creating a successful SRE movement within an organization. That top-level buy-in is highly important to get resources and drive transformation across the organization, but what is sometimes missed is making it a priority to get mid-level leadership on board as well. It’s difficult to enact change from the ground up starting with practitioners at the bottom, and it’s also difficult to just have leadership buy in, as once it gets down to the middle, things may fall apart. It is imperative to have mid-level leaders on board as well, as they directly affect the culture and decisions of their teams. To avoid resistance, it is also important that the mid-level leadership (product, operations and engineering managers), i.e. people managers, will understand the motivations behind change so they will be onboard. Without that understanding, it will hinder mid-level leadership’s ability to communicate changes to the practitioners level and can impact the teams\u0026#39; goal and allocated bandwidth.\u003c/p\u003e\u003ch3\u003e3. Don’t be afraid to get help from professionals\u003c/h3\u003e\u003cp\u003eAdopting SRE at a large organization is no simple feat. Partnering with \u003ca href=\"https://services.google.com/fh/files/misc/pso_sre_google_cloud.pdf\" target=\"_blank\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://services.google.com\" track-metadata-module=\"post\"\u003eGoogle’s SRE consulting experts\u003c/a\u003e has brought about a huge shift at Sabre. The value PSO brings is not just training, it\u0026#39;s also listening. We’ve had experienced Googlers who understand our problems and have been at our stage in the SRE journey listen, analyze and tailor the approach specific to our team\u0026#39;s goals. PSO helped us by shifting our engineering teams to be more customer centric, and aligning our product, operations, and development teams. But most importantly, they’ve helped to make our current teams happier, because they\u0026#39;re not spinning their wheels, waiting around on blocked requests.\u003c/p\u003e\u003cp\u003eWhen we partnered with PSO we were aware of who the key stakeholders in our organization are: the mid-level leadership and people managers. We made sure to bring them into our PSO discussions and decision making sessions and as a result, helped us to get more traction and solve the gap we had, enabling the middle-level and bringing them on board.\u003c/p\u003e\u003cp\u003eSome of the actions we have taken with help from our PSO SRE partners include adding a \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/how-sre-teams-are-organized-and-how-to-get-started\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/how-sre-teams-are-organized-and-how-to-get-started\" track-metadata-module=\"post\"\u003etiers of service\u003c/a\u003e approach, improving incident management through \u003ca href=\"https://cloud.google.com/blog/products/management-tools/shrinking-the-time-to-mitigate-production-incidents\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/management-tools/shrinking-the-time-to-mitigate-production-incidents\" track-metadata-module=\"post\"\u003ewheels of misfortune (WoM)\u003c/a\u003e, defining \u003ca href=\"https://cloud.google.com/blog/products/management-tools/practical-guide-to-setting-slos\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/management-tools/practical-guide-to-setting-slos\" track-metadata-module=\"post\"\u003ecritical user journeys (CUJs)\u003c/a\u003e, and implementing \u003ca href=\"https://cloud.google.com/blog/products/management-tools/sre-error-budgets-and-maintenance-windows\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/management-tools/sre-error-budgets-and-maintenance-windows\" track-metadata-module=\"post\"\u003eerror budgets\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eSince putting these SRE practices into place, our business is more aligned to customer experience. We now invest org resources according to the needs of our customers and with that have reduced silos across our teams. Our Ops team is much happier since they can move faster and not have to block requests. SRE has taught us a common language, a common framework. Moreover, it gives this whole discipline a culture and meaning.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003ci\u003e\u003cb\u003eEditor’s note\u003c/b\u003e: Today we hear from Kenny Kon, an SRE Director at Sabre. Kenny shares about how they have been able to successfully adopt Google’s SRE framework by leveraging their partnership with Google Cloud. \u003c/i\u003e\u003c/p\u003e\u003cp\u003eAs a leader in the travel industry, Sabre Corporation is driving innovation in the global travel industry and developing solutions that help airlines, hotels, and travel agencies transform the traveler experience and satisfy the ever-evolving needs of its customers. \u003c/p\u003e\u003cp\u003eIn order to build these solutions, we joined forces with Google Cloud as our preferred cloud provider to accelerate our digital transformation. We chose Google because they understand the industry we are in as they also manage travel products such as Google Travel. Google also created \u003ca href=\"http://cloud.google.com/sre\"\u003eSRE (Site Reliability Engineering)\u003c/a\u003e, and operates with SRE principles at the Google scale, which is what intrigued us the most.\u003c/p\u003e\u003cp\u003eInitially we started with a multi-cloud model, but that didn’t help us move faster so we consolidated to just Google Cloud. To speed our transformation along, we have adopted Google SRE (Site Reliability Engineering) practices which enables us to balance reliability and speed. We have been able to make this transformation with the direct help of Google Cloud’s \u003ca href=\"https://cloud.google.com/consulting\"\u003eProfessional Services Organization (PSO)\u003c/a\u003e along with Google Cloud’s tooling, like \u003ca href=\"https://cloud.google.com/monitoring\"\u003eCloud Monitoring\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/logging\"\u003eCloud Logging\u003c/a\u003e, and operating on \u003ca href=\"https://cloud.google.com/kubernetes-engine\"\u003eGoogle Kubernetes Engine (GKE)\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/spanner\"\u003eCloud Spanner\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eIn adopting SRE at Sabre, we’d like to highlight three key takeaways from the journey: \u003c/p\u003e\u003ch3\u003e1. Find colleagues who are also passionate about shifting culture and adopting SRE\u003c/h3\u003e\u003cp\u003eCreate a community within your organization who is dedicated to the SRE journey and motivated to make things happen. As we adopted SRE at Sabre I saw more and more people rallying and coming together to support the culture change. With some momentum built it was great to bring shared experiences to the team as we all spoke in the same language talking about SLOs, SLIs, and about how we measure things. \u003c/p\u003e\u003cp\u003eSome of the ways in which we built our community was by hosting monthly brown bag sessions. This is an informal gathering where teams come in and share their experiences and challenges, or teach on specific SRE topics such as SLOs or toil. We also created a \u003ca href=\"https://gdg.community.dev/gdg-cloud-southlake/\" target=\"_blank\"\u003epublic Google Developer Group (GDG)\u003c/a\u003e and have hosted several Google SRE subject matter experts to speak on SRE principles and best practices. \u003c/p\u003e\u003ch3\u003e2. Get your mid level leadership stakeholders on board\u003c/h3\u003e\u003cp\u003eWe know how important \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/sre-success-starts-with-getting-leadership-on-board\"\u003egetting leadership buy in\u003c/a\u003e is to creating a successful SRE movement within an organization. That top-level buy-in is highly important to get resources and drive transformation across the organization, but what is sometimes missed is making it a priority to get mid-level leadership on board as well. It’s difficult to enact change from the ground up starting with practitioners at the bottom, and it’s also difficult to just have leadership buy in, as once it gets down to the middle, things may fall apart. It is imperative to have mid-level leaders on board as well, as they directly affect the culture and decisions of their teams. To avoid resistance, it is also important that the mid-level leadership (product, operations and engineering managers), i.e. people managers, will understand the motivations behind change so they will be onboard. Without that understanding, it will hinder mid-level leadership’s ability to communicate changes to the practitioners level and can impact the teams' goal and allocated bandwidth.\u003c/p\u003e\u003ch3\u003e3. Don’t be afraid to get help from professionals\u003c/h3\u003e\u003cp\u003eAdopting SRE at a large organization is no simple feat. Partnering with \u003ca href=\"https://services.google.com/fh/files/misc/pso_sre_google_cloud.pdf\" target=\"_blank\"\u003eGoogle’s SRE consulting experts\u003c/a\u003e has brought about a huge shift at Sabre. The value PSO brings is not just training, it's also listening. We’ve had experienced Googlers who understand our problems and have been at our stage in the SRE journey listen, analyze and tailor the approach specific to our team's goals. PSO helped us by shifting our engineering teams to be more customer centric, and aligning our product, operations, and development teams. But most importantly, they’ve helped to make our current teams happier, because they're not spinning their wheels, waiting around on blocked requests.\u003c/p\u003e\u003cp\u003eWhen we partnered with PSO we were aware of who the key stakeholders in our organization are: the mid-level leadership and people managers. We made sure to bring them into our PSO discussions and decision making sessions and as a result, helped us to get more traction and solve the gap we had, enabling the middle-level and bringing them on board.\u003c/p\u003e\u003cp\u003eSome of the actions we have taken with help from our PSO SRE partners include adding a \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/how-sre-teams-are-organized-and-how-to-get-started\"\u003etiers of service\u003c/a\u003e approach, improving incident management through \u003ca href=\"https://cloud.google.com/blog/products/management-tools/shrinking-the-time-to-mitigate-production-incidents\"\u003ewheels of misfortune (WoM)\u003c/a\u003e, defining \u003ca href=\"https://cloud.google.com/blog/products/management-tools/practical-guide-to-setting-slos\"\u003ecritical user journeys (CUJs)\u003c/a\u003e, and implementing \u003ca href=\"https://cloud.google.com/blog/products/management-tools/sre-error-budgets-and-maintenance-windows\"\u003eerror budgets\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eSince putting these SRE practices into place, our business is more aligned to customer experience. We now invest org resources according to the needs of our customers and with that have reduced silos across our teams. Our Ops team is much happier since they can move faster and not have to block requests. SRE has taught us a common language, a common framework. Moreover, it gives this whole discipline a culture and meaning.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/four-steps-to-jumpstarting-your-sre-practice/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_B_Rnd3.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eFour steps to jumpstarting your SRE practice\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eOnce you have leadership buy-in, there are some things you can do to get the SRE ball rolling, fast.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/devops.max-2200x2200.jpg",
      "date_published": "2021-11-22T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eKenny Kon\u003c/name\u003e\u003ctitle\u003eSRE Director at Sabre\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/networking/hosting-a-website-on-google-cloud-from-start-to-finish/",
      "title": "Foundations of a scalable website on GCP",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eStarting a website can be hard, we get it. There are many vendors you have to work with and steps to tie together. What DNS records do I need to add? How do I enable DNSSEC? Is my website secure and safe from cyber attacks? These types of questions plague millions of website operators globally. We are excited to share that it is possible to manage all of these steps in one location using Google Cloud.\u003c/p\u003e\u003cp\u003eGoogle Cloud offers you the ability to manage the entire lifecycle of a website from start to finish. You no longer have to worry about managing different subscriptions and understanding the integration between vendors. Leveraging the Google Cloud offering will allow for you to have a scalable, reliable, and safe deployment. Additionally, there are extra benefits that you can take advantage of, like getting Google Managed SSL certificates for free and taking advantage of best in class DDoS protection with our Cloud Armor solution.\u003c/p\u003e\u003ch3\u003eArchitecture diagram\u003c/h3\u003e\u003cp\u003eThe following architecture diagram illustrates all of the components of the solution.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"architecture diagram.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/architecture_diagram.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eKey components of the solution:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eCloud Domains\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCloud DNS\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCompute and Storage\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eGlobal HTTPs Load Balancer\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCloud Armor\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCloud CDN\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eBuying a Domain on Google Cloud\u003c/h3\u003e\u003cp\u003ePurchasing and verifying a domain can be a tricky process with many steps. Cloud Domains makes this easy and straightforward to manage. Cloud Domains integrates seamlessly with Cloud DNS making the management even easier. There is full API support which allows for programmatic management if you are managing a larger portfolio. \u003c/p\u003e\u003ch3\u003eManaging DNS with Google Cloud\u003c/h3\u003e\u003cp\u003eOur Cloud DNS solution is a managed DNS infrastructure which is scalable and highly available. Easy management of private and public DNS zones makes this a one stop shop for DNS management. Public DNS records are anycasted globally using Google’s distributed network. It is easy and straightforward to enable DNSSEC which will help protect your end users from malicious actors.  \u003c/p\u003e\u003ch3\u003eInitializing Compute and setting up static object storage\u003c/h3\u003e\u003cp\u003eRunning your backends on Google Cloud compute has numerous advantages. You can use a managed instance group to run your websites. Managed instance groups allow for a highly scalable and efficient deployment. When demand goes up the number of instances will scale seamlessly, and likewise if demand falls the active compute can scale down. This allows for you to only be running what you need at a given moment. You can easily create multi-zone deployments which increases reliability and performance. With full API support, automation and management is easy and fast. Using a managed instance group allows for you to automatically and safely deploy updates with a variety of customizations available.\u003c/p\u003e\u003cp\u003eFor static objects you can store them in our Cloud Storage solution. This is perfect for content like images and videos which are not constantly changing. You can store large quantities of data which is available worldwide. It is easy to transfer content into Cloud Storage with multiple tools available.\u003c/p\u003e\u003ch3\u003eSetting up an external https load balancer\u003c/h3\u003e\u003cp\u003eThe external https load balancer is a global proxy-based layer 7 solution that serves as the entry point for all of your traffic onto Google’s network. Our advanced load balancing solution allows for integrated traffic management and is highly customizable to fit your needs. You can leverage a Google managed SSL certificate for easy deployment and ongoing management.\u003c/p\u003e\u003ch3\u003eSecuring your traffic with Cloud Armor\u003c/h3\u003e\u003cp\u003eCloud Armor is Google’s best in class DDoS defense solution and Web Application Firewall (WAF). You can rest easier knowing that Google’s network has your back. We have a long history of mitigating some of the most complicated and largest DDoS attacks on record ( blog link). With Cloud Armor you can additionally take advantage of preconfigured WAF rules (Mod Security Rule Set 3.02), adaptive protection, and recently rate limiting. All of this ensures that your website stays online and is protected from attacks.\u003c/p\u003e\u003ch3\u003eCaching static content with Cloud CDN\u003c/h3\u003e\u003cp\u003eFor content that is cacheable like images or short videos, you can use Cloud CDN to enable fast and cost efficient delivery. Google has Cloud CDN pops all over the world which will help ensure that users from the regions that matter to you have a seamless and fast experience. Cloud CDN is easy to enable and get started with. \u003c/p\u003e\u003ch3\u003eYoutube video\u003c/h3\u003e\u003cp\u003eIf you would like to see a further overview of the architecture and components of this solution as well as a detailed configuration walkthrough please check out this \u003ca href=\"https://www.youtube.com/watch?v=I5qLiG0vIGE\" target=\"_blank\"\u003evideo\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eFor more information on any of these solutions please check out their respective documentation hubs:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/domains/docs/overview\"\u003eCloud Domains\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/dns/docs/overview/\"\u003eCloud DNS\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/compute/docs/instance-groups\"\u003eManaged Instance Group\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/storage/docs\"\u003eCloud Storage\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/load-balancing/docs/https\"\u003eExternal HTTPs Load Balancer\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/armor/docs\"\u003eCloud Armor\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/cdn/docs/overview\"\u003eCloud CDN\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/networking/cloud-domains-is-generally-available/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/google_domain.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eCloud Domains, now GA, makes it easy to register and manage custom domains\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eCloud Domains, now generally available, makes performing domain-related tasks in Google Cloud simple.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/original_images/GCP_Networking_7oH4Ie3.jpg",
      "date_published": "2021-11-18T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eArman Rye\u003c/name\u003e\u003ctitle\u003eCustomer Engineer\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/topics/hybrid-cloud/introducing-anthos-for-vms-and-other-app-modernization-tools/",
      "title": "Introducing Anthos for VMs and tools to simplify the developer experience",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv _ngcontent-c20=\"\" innerhtml=\"\u0026lt;p\u0026gt;When it comes to software development using Google Cloud, we have three guiding principles. First, developing on Google Cloud needs to be open\u0026amp;#8212;we rely heavily on open-source technologies so that it\u0026#39;s easier to move apps between environments, recruit skilled developers, and access the latest innovations sooner. Second, developing for Google Cloud should also be easy\u0026amp;#8212;we strive to offer intuitive, integrated tools that run well wherever you build your code, while minimizing your operational overhead. Finally, running on Google Cloud should be transformative\u0026amp;#8212;we offer services that help unleash your imagination, along with best practices and professional services to help you bring your ideas to life.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Today, at \u0026lt;a href=\u0026#34;https://cloud.withgoogle.com/next\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Google Cloud Next \u0026amp;#8216;21\u0026lt;/a\u0026gt;, we announced a variety of new tools and capabilities to deliver on those principles.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Opening Anthos to virtual machines\u0026amp;#160;\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Since announcing Anthos, our open-source-based platform for hybrid and mutlicloud deployments in 2018, we have continued to receive strong reception from customers and partners. In fact, in Q2 2021, Anthos compute under management grew more than 500% year-over-year. Anthos unifies the management of infrastructure and applications across on-premises, edge, and multiple public clouds, as well as ensuring consistent operation at scale. Based on Google Kubernetes Engine (GKE), Anthos was originally designed to run applications in containers. To help you make that transition, we automated the process to migrate and modernize existing apps using \u0026lt;a href=\u0026#34;https://cloud.google.com/migrate/anthos\u0026#34;\u0026gt;Migrate for Anthos and GKE\u0026lt;/a\u0026gt; from various virtual machine environments to containers.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;While we have seen many customers make the leap to containerization, some are not quite ready to move completely off of virtual machines (VMs). They want a unified development platform where developers can build, modify, and deploy applications residing in both containers and VMs in a common, shared environment. Today, we are announcing \u0026lt;a href=\u0026#34;http://cloud.google.com/anthos\u0026#34;\u0026gt;Anthos for Virtual Machines\u0026lt;/a\u0026gt; in preview, allowing you to standardize on Kubernetes while continuing to run some workloads that cannot be easily containerized in virtual machines. Anthos for VMs will help platform developers standardize on an operation model, process and tooling; enable incremental modernization efforts; and support traditional workloads like Virtual Network Functions (VNFs) or stateful monolithic workloads.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;You can take advantage of Anthos for VMs in two ways \u0026amp;#8211; either by attaching your vSphere VMs, or shifting your VMs as-is. For customers with active VMware environments, the Anthos control plane can now connect to your vSphere environment and attach your vSphere VMs, allowing you to apply consistent security and policies across clusters, gain visibility into the health and performance of your services, and manage traffic for both VMs and containers. Alternately, Anthos for VMs allows you to shift VMs as-is onto Anthos with \u0026lt;a href=\u0026#34;https://kubevirt.io/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;KubeVirt\u0026lt;/a\u0026gt;, an open-source virtualization API for Kubernetes. Now you can build, modify, and deploy applications residing in both application containers as well as VMs on a common, shared Anthos environment. This is a great option for organizations that prefer to use open-source virtualization, as those same organizations often prefer to run \u0026lt;a href=\u0026#34;https://cloud.google.com/anthos/clusters/docs/bare-metal/1.6/concepts/about-bare-metal\u0026#34;\u0026gt;Anthos on bare metal\u0026lt;/a\u0026gt;. To help get started, we provide you with a \u0026lt;a href=\u0026#34;https://cloud.google.com/anthos\u0026#34;\u0026gt;fit assessment tool\u0026lt;/a\u0026gt; to identify which approach to take.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Taking your Anthos experience further\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;We\u0026amp;#8217;re also making it easier for you to manage containerized workloads already running in other clouds through Anthos. While you can already run containers in AWS and Azure from Anthos, we\u0026amp;#8217;re taking this a step further with the new \u0026lt;a href=\u0026#34;https://cloud.google.com/anthos/clusters/docs/multi-cloud\u0026#34;\u0026gt;Anthos Multi-Cloud API\u0026lt;/a\u0026gt;. Generally available in Q4 \u0026amp;#8216;21, this new API lets you provision and manage GKE clusters running on AWS or Azure infrastructure directly from the command line interface or the Google Cloud Console, all while being managed by a central control plane. This gives you a single API to manage all your container deployments regardless of which major public cloud you\u0026#39;re using, thus minimizing the time you spend jumping between user interfaces to accomplish day-to-day management tasks like creating, managing, and updating clusters.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Over the past year, we\u0026amp;#8217;ve brought some of the innovations originally developed for hybrid and multicloud use cases in Anthos back to GKE running in Google Cloud. Specifically, \u0026lt;a href=\u0026#34;https://cloud.google.com/anthos/config-management\u0026#34;\u0026gt;Anthos Config Management\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/anthos/service-mesh\u0026#34;\u0026gt;Anthos Service Mesh\u0026lt;/a\u0026gt; are now generally available for GKE as standalone services with pay-as-you-go pricing. GKE customers can now use Anthos Config Management to take advantage of config and policy automation at a low incremental per-cluster cost, and use Anthos Service Mesh to enable next-level security and networking on container-based microservices.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Last but not least, we are excited to announce that starting today, Anthos Service Mesh is generally available to support a hybrid mesh. This gives you the flexibility to have a common mesh that spans both your Google Cloud and on-prem deployments.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Customers like \u0026lt;a href=\u0026#34;http://www.westerndigital.com\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Western Digital\u0026lt;/a\u0026gt; have already experienced many benefits from adopting Anthos as their application modernization platform:\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;\u0026amp;#34;As a global storage leader with sophisticated manufacturing facilities around the world, Western Digital sees cloud technology as an enabler of our key business priorities: reducing time to deliver products and services, rationalizing our entire application footprint, and meeting customer demand for IoT and edge applications,\u0026amp;#8221;\u0026lt;/i\u0026gt; said Jahidul Khandaker, senior vice president and CIO, Western Digital. \u0026lt;i\u0026gt;\u0026amp;#8220;Anthos is our unified management platform of choice\u0026amp;#8212;it gives us insights across our Google Cloud and on-premises environments, while keeping the doors open for a multi-cloud future. Anthos has delivered several advantages for our developers: a richer user experience, greater security, and enhanced flexibility to manage factory applications\u0026amp;#8212;no matter where they reside\u0026amp;#8212;on-prem, in the cloud or a mix of both.\u0026amp;#34;\u0026lt;/i\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Easy does it\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;In addition to being an open platform, we strive to make Google Cloud easy to use for operators as well as developers. For example, earlier this year\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/containers-kubernetes/introducing-gke-autopilot\u0026#34;\u0026gt;we introduced GKE Autopilot\u0026lt;/a\u0026gt;, a mode of operations in GKE that empowers you to simplify operations by offloading the management of infrastructure, control plane, and nodes. With GKE Autopilot, customers like\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/customers/ubie\u0026#34;\u0026gt;Ubie\u0026lt;/a\u0026gt;, a Japanese-based healthcare technology company, have eliminated the need to configure and maintain infrastructure, which helped their development teams focus on making healthcare more accessible.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;With Cloud Run, our serverless compute platform, you can abstract away infrastructure management entirely. This year, our focus has been on bringing the simplicity of Cloud Run to more workloads, like traditional applications written in Java Spring Boot, ASP.NET, and Django, among others. Along with a new second generation execution environment for enhanced network and CPU performance, we\u0026amp;#8217;ve added\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/serverless/introducing-committed-use-discounts-for-cloud-run\u0026#34;\u0026gt;committed-use discounts\u0026lt;/a\u0026gt;\u0026amp;#160;and introduced\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/serverless/cloud-run-gets-always-on-cpu-allocation\u0026#34;\u0026gt;new CPU allocation controls and price\u0026lt;/a\u0026gt;, allowing you to save up to 17% and 25%, respectively, on your compute bill. New\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/topics/developers-practitioners/introducing-new-connectors-workflows\u0026#34;\u0026gt;connectors\u0026lt;/a\u0026gt;\u0026amp;#160;for Workflows,\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/serverless/cloud-functions-integrates-with-google-secret-manager\u0026#34;\u0026gt;integration\u0026lt;/a\u0026gt;\u0026amp;#160;between Cloud Functions and Secret Manager, and support for\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/serverless/cloud-functions-supports-min-instances\u0026#34;\u0026gt;min instances\u0026lt;/a\u0026gt;\u0026amp;#160;are just a few of the other ways we\u0026amp;#8217;ve made it easier to build modern, serverless apps.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Easy for developers\u0026amp;#160;\u0026lt;/h3\u0026gt;Developers spend a lot of time inside their integrated development environments (IDEs), writing code. Last year we announced\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/shell\u0026#34;\u0026gt;Cloud Shell Editor\u0026lt;/a\u0026gt;, which makes the process of writing code as seamless as possible. It comes with your favorite developer tools (e.g., docker, minikube, skaffold, and many more) preinstalled, and this year, we added ~100 live tutorials to it\u0026amp;#8212;no more switching between the documentation, the terminal, and your code!\u0026amp;#160;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Once that code is ready, you want building it and deploying it to be as seamless as possible. Today we are announcing\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/build/docs/hybrid/overview\u0026#34;\u0026gt;Cloud Build Hybrid\u0026lt;/a\u0026gt;, which lets you build, test, and deploy across clouds and on-prem systems, so developers get consistent CI/CD tooling across their environments, and platform engineers don\u0026#39;t have to worry about maintaining and scaling their systems. Cloud Build is also integrated with\u0026amp;#160;\u0026lt;a href=\u0026#34;https://docs.google.com/document/d/1Z4vYdjF66UTOJgIpaDlDnXOuDCV6YulMhvNDjgoFiYo/edit?resourcekey=0-Vxxrly14dbfaBHg21HnOfg#\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Artifact Registry\u0026lt;/a\u0026gt;, which now allows you to store not only in containers, but also language-specific artifacts in one place. Finally, with the recently launched\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/overview\u0026#34;\u0026gt;Google Cloud Deploy\u0026lt;/a\u0026gt;, which is a managed, continuous delivery service initially for GKE, we\u0026amp;#8217;re making it easy to scale your pipelines across your organization.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Easy for operators\u0026lt;/h3\u0026gt;When your applications are up and running, you need to observe and analyze them for better operations and business insights. While we already offer a fully managed metrics and alerting service with\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/monitoring\u0026#34;\u0026gt;Cloud Monitoring\u0026lt;/a\u0026gt;, some Kubernetes users want to continue using open-source Prometheus without the scaling and management headaches. This is precisely why today we are announcing the preview of\u0026amp;#160;\u0026lt;a href=\u0026#34;http://cloud.google.com/monitoring\u0026#34;\u0026gt;Managed Service for Prometheus\u0026lt;/a\u0026gt;, helping you avoid vendor lock-in and delivering compatibility with your existing Prometheus alerts, workflows, and Grafana dashboards. Now you have all of the benefits of Prometheus, minus the management hassle.\u0026amp;#160;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;To give you easy diagnostics and deeper insights from across your business and systems, today we also combined\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/logging\u0026#34;\u0026gt;Cloud Logging\u0026lt;/a\u0026gt;\u0026amp;#160;with the performance and power of BigQuery to introduce\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/log-analytics\u0026#34;\u0026gt;Log Analytics\u0026lt;/a\u0026gt;. Currently in preview, Log Analytics allows you to rapidly store, manage, and analyze log data. This enables you to effectively move your operations from a reactive to proactive model.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Zero-trust simplified for application developers\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;We also make it easy for developers to build secure applications from the get-go, whether they\u0026amp;#8217;re writing code, running it through the CI/CD pipeline, or in production. This zero-trust software supply chain is made possible by fully managed services that provide you with a consistent way to define and enforce policy, establish provenance, and prevent modification or tampering.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;And we\u0026amp;#8217;re continuing to enhance our\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/identity-security/applying-zero-trust-to-user-access-and-production-services\u0026#34;\u0026gt;zero-trust software supply chain capabilities\u0026lt;/a\u0026gt;\u0026amp;#160;with new features. For example, developers can now scan\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/identity-security/scan-for-vulnerabilities-early-to-shift-security-left-in-cicd\u0026#34;\u0026gt;containers for vulnerabilities\u0026lt;/a\u0026gt;\u0026amp;#160;using the simple \u0026amp;#8220;gcloud artifacts docker images scan\u0026amp;#8221; command. Now generally available, we\u0026amp;#8217;re also announcing that you can pair Cloud Run with Binary Authorization and, in a few clicks, ensure that only trusted container images make it to production. In addition, Binary Authorization now integrates with Cloud Build to automatically generate digital signatures and make it easy to set up deploy-time constraints that ensure only images signed by Cloud Build are sanctioned. Learn more about how we are making security easier\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/identity-security/next21-how-google-cloud-secures-the-world\u0026#34;\u0026gt;here\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Transform your cloud with Google\u0026lt;/h3\u0026gt;No matter where you are along the journey to transform your applications, we are here to partner with you. Whether its with the new product functionality we described today at Next, research and best practices such as the\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/devops/state-of-devops/\u0026#34;\u0026gt;2021 Accelerate State of DevOps report\u0026lt;/a\u0026gt;\u0026amp;#160;from Cloud\u0026amp;#8217;s DevOps Research and Assessment (DORA) team, or professional services such as the\u0026amp;#160;\u0026lt;a href=\u0026#34;https://cloud.google.com/camp\u0026#34;\u0026gt;Google Cloud Application Modernization Program (CAMP)\u0026lt;/a\u0026gt;, we\u0026amp;#8217;re here to help.\u0026lt;br\u0026gt;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\" _nghost-c20=\"\"\u003e\u003cp\u003eWhen it comes to software development using Google Cloud, we have three guiding principles. First, developing on Google Cloud needs to be open—we rely heavily on open-source technologies so that it\u0026#39;s easier to move apps between environments, recruit skilled developers, and access the latest innovations sooner. Second, developing for Google Cloud should also be easy—we strive to offer intuitive, integrated tools that run well wherever you build your code, while minimizing your operational overhead. Finally, running on Google Cloud should be transformative—we offer services that help unleash your imagination, along with best practices and professional services to help you bring your ideas to life. \u003c/p\u003e\u003cp\u003eToday, at \u003ca href=\"https://cloud.withgoogle.com/next\" target=\"_blank\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.withgoogle.com\" track-metadata-module=\"post\"\u003eGoogle Cloud Next ‘21\u003c/a\u003e, we announced a variety of new tools and capabilities to deliver on those principles. \u003c/p\u003e\u003ch3\u003eOpening Anthos to virtual machines \u003c/h3\u003e\u003cp\u003eSince announcing Anthos, our open-source-based platform for hybrid and mutlicloud deployments in 2018, we have continued to receive strong reception from customers and partners. In fact, in Q2 2021, Anthos compute under management grew more than 500% year-over-year. Anthos unifies the management of infrastructure and applications across on-premises, edge, and multiple public clouds, as well as ensuring consistent operation at scale. Based on Google Kubernetes Engine (GKE), Anthos was originally designed to run applications in containers. To help you make that transition, we automated the process to migrate and modernize existing apps using \u003ca href=\"https://cloud.google.com/migrate/anthos\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/migrate/anthos\" track-metadata-module=\"post\"\u003eMigrate for Anthos and GKE\u003c/a\u003e from various virtual machine environments to containers. \u003c/p\u003e\u003cp\u003eWhile we have seen many customers make the leap to containerization, some are not quite ready to move completely off of virtual machines (VMs). They want a unified development platform where developers can build, modify, and deploy applications residing in both containers and VMs in a common, shared environment. Today, we are announcing \u003ca href=\"http://cloud.google.com/anthos\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"http://cloud.google.com/anthos\" track-metadata-module=\"post\"\u003eAnthos for Virtual Machines\u003c/a\u003e in preview, allowing you to standardize on Kubernetes while continuing to run some workloads that cannot be easily containerized in virtual machines. Anthos for VMs will help platform developers standardize on an operation model, process and tooling; enable incremental modernization efforts; and support traditional workloads like Virtual Network Functions (VNFs) or stateful monolithic workloads. \u003c/p\u003e\u003cp\u003eYou can take advantage of Anthos for VMs in two ways – either by attaching your vSphere VMs, or shifting your VMs as-is. For customers with active VMware environments, the Anthos control plane can now connect to your vSphere environment and attach your vSphere VMs, allowing you to apply consistent security and policies across clusters, gain visibility into the health and performance of your services, and manage traffic for both VMs and containers. Alternately, Anthos for VMs allows you to shift VMs as-is onto Anthos with \u003ca href=\"https://kubevirt.io/\" target=\"_blank\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://kubevirt.io\" track-metadata-module=\"post\"\u003eKubeVirt\u003c/a\u003e, an open-source virtualization API for Kubernetes. Now you can build, modify, and deploy applications residing in both application containers as well as VMs on a common, shared Anthos environment. This is a great option for organizations that prefer to use open-source virtualization, as those same organizations often prefer to run \u003ca href=\"https://cloud.google.com/anthos/clusters/docs/bare-metal/1.6/concepts/about-bare-metal\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/anthos/clusters/docs/bare-metal/1.6/concepts/about-bare-metal\" track-metadata-module=\"post\"\u003eAnthos on bare metal\u003c/a\u003e. To help get started, we provide you with a \u003ca href=\"https://cloud.google.com/anthos\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/anthos\" track-metadata-module=\"post\"\u003efit assessment tool\u003c/a\u003e to identify which approach to take. \u003c/p\u003e\u003ch3\u003eTaking your Anthos experience further\u003c/h3\u003e\u003cp\u003eWe’re also making it easier for you to manage containerized workloads already running in other clouds through Anthos. While you can already run containers in AWS and Azure from Anthos, we’re taking this a step further with the new \u003ca href=\"https://cloud.google.com/anthos/clusters/docs/multi-cloud\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/anthos/clusters/docs/multi-cloud\" track-metadata-module=\"post\"\u003eAnthos Multi-Cloud API\u003c/a\u003e. Generally available in Q4 ‘21, this new API lets you provision and manage GKE clusters running on AWS or Azure infrastructure directly from the command line interface or the Google Cloud Console, all while being managed by a central control plane. This gives you a single API to manage all your container deployments regardless of which major public cloud you\u0026#39;re using, thus minimizing the time you spend jumping between user interfaces to accomplish day-to-day management tasks like creating, managing, and updating clusters. \u003c/p\u003e\u003cp\u003eOver the past year, we’ve brought some of the innovations originally developed for hybrid and multicloud use cases in Anthos back to GKE running in Google Cloud. Specifically, \u003ca href=\"https://cloud.google.com/anthos/config-management\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/anthos/config-management\" track-metadata-module=\"post\"\u003eAnthos Config Management\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/anthos/service-mesh\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/anthos/service-mesh\" track-metadata-module=\"post\"\u003eAnthos Service Mesh\u003c/a\u003e are now generally available for GKE as standalone services with pay-as-you-go pricing. GKE customers can now use Anthos Config Management to take advantage of config and policy automation at a low incremental per-cluster cost, and use Anthos Service Mesh to enable next-level security and networking on container-based microservices.\u003c/p\u003e\u003cp\u003eLast but not least, we are excited to announce that starting today, Anthos Service Mesh is generally available to support a hybrid mesh. This gives you the flexibility to have a common mesh that spans both your Google Cloud and on-prem deployments. \u003c/p\u003e\u003cp\u003eCustomers like \u003ca href=\"http://www.westerndigital.com\" target=\"_blank\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"http://www.westerndigital.com\" track-metadata-module=\"post\"\u003eWestern Digital\u003c/a\u003e have already experienced many benefits from adopting Anthos as their application modernization platform:\u003c/p\u003e\u003cp\u003e\u003ci\u003e\u0026#34;As a global storage leader with sophisticated manufacturing facilities around the world, Western Digital sees cloud technology as an enabler of our key business priorities: reducing time to deliver products and services, rationalizing our entire application footprint, and meeting customer demand for IoT and edge applications,”\u003c/i\u003e said Jahidul Khandaker, senior vice president and CIO, Western Digital. \u003ci\u003e“Anthos is our unified management platform of choice—it gives us insights across our Google Cloud and on-premises environments, while keeping the doors open for a multi-cloud future. Anthos has delivered several advantages for our developers: a richer user experience, greater security, and enhanced flexibility to manage factory applications—no matter where they reside—on-prem, in the cloud or a mix of both.\u0026#34;\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eEasy does it\u003c/h3\u003e\u003cp\u003eIn addition to being an open platform, we strive to make Google Cloud easy to use for operators as well as developers. For example, earlier this year \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/introducing-gke-autopilot\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/containers-kubernetes/introducing-gke-autopilot\" track-metadata-module=\"post\"\u003ewe introduced GKE Autopilot\u003c/a\u003e, a mode of operations in GKE that empowers you to simplify operations by offloading the management of infrastructure, control plane, and nodes. With GKE Autopilot, customers like \u003ca href=\"https://cloud.google.com/customers/ubie\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/customers/ubie\" track-metadata-module=\"post\"\u003eUbie\u003c/a\u003e, a Japanese-based healthcare technology company, have eliminated the need to configure and maintain infrastructure, which helped their development teams focus on making healthcare more accessible.\u003c/p\u003e\u003cp\u003eWith Cloud Run, our serverless compute platform, you can abstract away infrastructure management entirely. This year, our focus has been on bringing the simplicity of Cloud Run to more workloads, like traditional applications written in Java Spring Boot, ASP.NET, and Django, among others. Along with a new second generation execution environment for enhanced network and CPU performance, we’ve added \u003ca href=\"https://cloud.google.com/blog/products/serverless/introducing-committed-use-discounts-for-cloud-run\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/serverless/introducing-committed-use-discounts-for-cloud-run\" track-metadata-module=\"post\"\u003ecommitted-use discounts\u003c/a\u003e and introduced \u003ca href=\"https://cloud.google.com/blog/products/serverless/cloud-run-gets-always-on-cpu-allocation\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/serverless/cloud-run-gets-always-on-cpu-allocation\" track-metadata-module=\"post\"\u003enew CPU allocation controls and price\u003c/a\u003e, allowing you to save up to 17% and 25%, respectively, on your compute bill. New \u003ca href=\"https://cloud.google.com/blog/topics/developers-practitioners/introducing-new-connectors-workflows\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://cloud.google.com/blog/topics/developers-practitioners/introducing-new-connectors-workflows\" track-metadata-module=\"post\"\u003econnectors\u003c/a\u003e for Workflows, \u003ca href=\"https://cloud.google.com/blog/products/serverless/cloud-functions-integrates-with-google-secret-manager\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/serverless/cloud-functions-integrates-with-google-secret-manager\" track-metadata-module=\"post\"\u003eintegration\u003c/a\u003e between Cloud Functions and Secret Manager, and support for \u003ca href=\"https://cloud.google.com/blog/products/serverless/cloud-functions-supports-min-instances\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/serverless/cloud-functions-supports-min-instances\" track-metadata-module=\"post\"\u003emin instances\u003c/a\u003e are just a few of the other ways we’ve made it easier to build modern, serverless apps. \u003c/p\u003e\u003ch3\u003eEasy for developers \u003c/h3\u003e\u003cp\u003eDevelopers spend a lot of time inside their integrated development environments (IDEs), writing code. Last year we announced \u003ca href=\"https://cloud.google.com/shell\" track-type=\"inline link\" track-name=\"18\" track-metadata-eventdetail=\"https://cloud.google.com/shell\" track-metadata-module=\"post\"\u003eCloud Shell Editor\u003c/a\u003e, which makes the process of writing code as seamless as possible. It comes with your favorite developer tools (e.g., docker, minikube, skaffold, and many more) preinstalled, and this year, we added ~100 live tutorials to it—no more switching between the documentation, the terminal, and your code! \u003c/p\u003e\u003cp\u003eOnce that code is ready, you want building it and deploying it to be as seamless as possible. Today we are announcing \u003ca href=\"https://cloud.google.com/build/docs/hybrid/overview\" track-type=\"inline link\" track-name=\"19\" track-metadata-eventdetail=\"https://cloud.google.com/build/docs/hybrid/overview\" track-metadata-module=\"post\"\u003eCloud Build Hybrid\u003c/a\u003e, which lets you build, test, and deploy across clouds and on-prem systems, so developers get consistent CI/CD tooling across their environments, and platform engineers don\u0026#39;t have to worry about maintaining and scaling their systems. Cloud Build is also integrated with \u003ca href=\"https://docs.google.com/document/d/1Z4vYdjF66UTOJgIpaDlDnXOuDCV6YulMhvNDjgoFiYo/edit?resourcekey=0-Vxxrly14dbfaBHg21HnOfg#\" target=\"_blank\" track-type=\"inline link\" track-name=\"20\" track-metadata-eventdetail=\"https://docs.google.com\" track-metadata-module=\"post\"\u003eArtifact Registry\u003c/a\u003e, which now allows you to store not only in containers, but also language-specific artifacts in one place. Finally, with the recently launched \u003ca href=\"https://cloud.google.com/deploy/docs/overview\" track-type=\"inline link\" track-name=\"21\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/overview\" track-metadata-module=\"post\"\u003eGoogle Cloud Deploy\u003c/a\u003e, which is a managed, continuous delivery service initially for GKE, we’re making it easy to scale your pipelines across your organization.\u003c/p\u003e\u003ch3\u003eEasy for operators\u003c/h3\u003e\u003cp\u003eWhen your applications are up and running, you need to observe and analyze them for better operations and business insights. While we already offer a fully managed metrics and alerting service with \u003ca href=\"https://cloud.google.com/monitoring\" track-type=\"inline link\" track-name=\"22\" track-metadata-eventdetail=\"https://cloud.google.com/monitoring\" track-metadata-module=\"post\"\u003eCloud Monitoring\u003c/a\u003e, some Kubernetes users want to continue using open-source Prometheus without the scaling and management headaches. This is precisely why today we are announcing the preview of \u003ca href=\"http://cloud.google.com/monitoring\" track-type=\"inline link\" track-name=\"23\" track-metadata-eventdetail=\"http://cloud.google.com/monitoring\" track-metadata-module=\"post\"\u003eManaged Service for Prometheus\u003c/a\u003e, helping you avoid vendor lock-in and delivering compatibility with your existing Prometheus alerts, workflows, and Grafana dashboards. Now you have all of the benefits of Prometheus, minus the management hassle. \u003c/p\u003e\u003cp\u003eTo give you easy diagnostics and deeper insights from across your business and systems, today we also combined \u003ca href=\"https://cloud.google.com/logging\" track-type=\"inline link\" track-name=\"24\" track-metadata-eventdetail=\"https://cloud.google.com/logging\" track-metadata-module=\"post\"\u003eCloud Logging\u003c/a\u003e with the performance and power of BigQuery to introduce \u003ca href=\"https://cloud.google.com/logging/docs/log-analytics\" track-type=\"inline link\" track-name=\"25\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/log-analytics\" track-metadata-module=\"post\"\u003eLog Analytics\u003c/a\u003e. Currently in preview, Log Analytics allows you to rapidly store, manage, and analyze log data. This enables you to effectively move your operations from a reactive to proactive model. \u003c/p\u003e\u003ch3\u003eZero-trust simplified for application developers\u003c/h3\u003e\u003cp\u003eWe also make it easy for developers to build secure applications from the get-go, whether they’re writing code, running it through the CI/CD pipeline, or in production. This zero-trust software supply chain is made possible by fully managed services that provide you with a consistent way to define and enforce policy, establish provenance, and prevent modification or tampering. \u003c/p\u003e\u003cp\u003eAnd we’re continuing to enhance our \u003ca href=\"https://cloud.google.com/blog/products/identity-security/applying-zero-trust-to-user-access-and-production-services\" track-type=\"inline link\" track-name=\"26\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/identity-security/applying-zero-trust-to-user-access-and-production-services\" track-metadata-module=\"post\"\u003ezero-trust software supply chain capabilities\u003c/a\u003e with new features. For example, developers can now scan \u003ca href=\"https://cloud.google.com/blog/products/identity-security/scan-for-vulnerabilities-early-to-shift-security-left-in-cicd\" track-type=\"inline link\" track-name=\"27\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/identity-security/scan-for-vulnerabilities-early-to-shift-security-left-in-cicd\" track-metadata-module=\"post\"\u003econtainers for vulnerabilities\u003c/a\u003e using the simple “gcloud artifacts docker images scan” command. Now generally available, we’re also announcing that you can pair Cloud Run with Binary Authorization and, in a few clicks, ensure that only trusted container images make it to production. In addition, Binary Authorization now integrates with Cloud Build to automatically generate digital signatures and make it easy to set up deploy-time constraints that ensure only images signed by Cloud Build are sanctioned. Learn more about how we are making security easier \u003ca href=\"https://cloud.google.com/blog/products/identity-security/next21-how-google-cloud-secures-the-world\" track-type=\"inline link\" track-name=\"28\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/identity-security/next21-how-google-cloud-secures-the-world\" track-metadata-module=\"post\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\u003ch3\u003eTransform your cloud with Google\u003c/h3\u003e\u003cp\u003eNo matter where you are along the journey to transform your applications, we are here to partner with you. Whether its with the new product functionality we described today at Next, research and best practices such as the \u003ca href=\"https://cloud.google.com/devops/state-of-devops/\" track-type=\"inline link\" track-name=\"29\" track-metadata-eventdetail=\"https://cloud.google.com/devops/state-of-devops/\" track-metadata-module=\"post\"\u003e2021 Accelerate State of DevOps report\u003c/a\u003e from Cloud’s DevOps Research and Assessment (DORA) team, or professional services such as the \u003ca href=\"https://cloud.google.com/camp\" track-type=\"inline link\" track-name=\"30\" track-metadata-eventdetail=\"https://cloud.google.com/camp\" track-metadata-module=\"post\"\u003eGoogle Cloud Application Modernization Program (CAMP)\u003c/a\u003e, we’re here to help.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWhen it comes to software development using Google Cloud, we have three guiding principles. First, developing on Google Cloud needs to be open—we rely heavily on open-source technologies so that it's easier to move apps between environments, recruit skilled developers, and access the latest innovations sooner. Second, developing for Google Cloud should also be easy—we strive to offer intuitive, integrated tools that run well wherever you build your code, while minimizing your operational overhead. Finally, running on Google Cloud should be transformative—we offer services that help unleash your imagination, along with best practices and professional services to help you bring your ideas to life. \u003c/p\u003e\u003cp\u003eToday, at \u003ca href=\"https://cloud.withgoogle.com/next\" target=\"_blank\"\u003eGoogle Cloud Next ‘21\u003c/a\u003e, we announced a variety of new tools and capabilities to deliver on those principles. \u003c/p\u003e\u003ch3\u003eOpening Anthos to virtual machines \u003c/h3\u003e\u003cp\u003eSince announcing Anthos, our open-source-based platform for hybrid and mutlicloud deployments in 2018, we have continued to receive strong reception from customers and partners. In fact, in Q2 2021, Anthos compute under management grew more than 500% year-over-year. Anthos unifies the management of infrastructure and applications across on-premises, edge, and multiple public clouds, as well as ensuring consistent operation at scale. Based on Google Kubernetes Engine (GKE), Anthos was originally designed to run applications in containers. To help you make that transition, we automated the process to migrate and modernize existing apps using \u003ca href=\"https://cloud.google.com/migrate/anthos\"\u003eMigrate for Anthos and GKE\u003c/a\u003e from various virtual machine environments to containers. \u003c/p\u003e\u003cp\u003eWhile we have seen many customers make the leap to containerization, some are not quite ready to move completely off of virtual machines (VMs). They want a unified development platform where developers can build, modify, and deploy applications residing in both containers and VMs in a common, shared environment. Today, we are announcing \u003ca href=\"http://cloud.google.com/anthos\"\u003eAnthos for Virtual Machines\u003c/a\u003e in preview, allowing you to standardize on Kubernetes while continuing to run some workloads that cannot be easily containerized in virtual machines. Anthos for VMs will help platform developers standardize on an operation model, process and tooling; enable incremental modernization efforts; and support traditional workloads like Virtual Network Functions (VNFs) or stateful monolithic workloads. \u003c/p\u003e\u003cp\u003eYou can take advantage of Anthos for VMs in two ways – either by attaching your vSphere VMs, or shifting your VMs as-is. For customers with active VMware environments, the Anthos control plane can now connect to your vSphere environment and attach your vSphere VMs, allowing you to apply consistent security and policies across clusters, gain visibility into the health and performance of your services, and manage traffic for both VMs and containers. Alternately, Anthos for VMs allows you to shift VMs as-is onto Anthos with \u003ca href=\"https://kubevirt.io/\" target=\"_blank\"\u003eKubeVirt\u003c/a\u003e, an open-source virtualization API for Kubernetes. Now you can build, modify, and deploy applications residing in both application containers as well as VMs on a common, shared Anthos environment. This is a great option for organizations that prefer to use open-source virtualization, as those same organizations often prefer to run \u003ca href=\"https://cloud.google.com/anthos/clusters/docs/bare-metal/1.6/concepts/about-bare-metal\"\u003eAnthos on bare metal\u003c/a\u003e. To help get started, we provide you with a \u003ca href=\"https://cloud.google.com/anthos\"\u003efit assessment tool\u003c/a\u003e to identify which approach to take. \u003c/p\u003e\u003ch3\u003eTaking your Anthos experience further\u003c/h3\u003e\u003cp\u003eWe’re also making it easier for you to manage containerized workloads already running in other clouds through Anthos. While you can already run containers in AWS and Azure from Anthos, we’re taking this a step further with the new \u003ca href=\"https://cloud.google.com/anthos/clusters/docs/multi-cloud\"\u003eAnthos Multi-Cloud API\u003c/a\u003e. Generally available in Q4 ‘21, this new API lets you provision and manage GKE clusters running on AWS or Azure infrastructure directly from the command line interface or the Google Cloud Console, all while being managed by a central control plane. This gives you a single API to manage all your container deployments regardless of which major public cloud you're using, thus minimizing the time you spend jumping between user interfaces to accomplish day-to-day management tasks like creating, managing, and updating clusters. \u003c/p\u003e\u003cp\u003eOver the past year, we’ve brought some of the innovations originally developed for hybrid and multicloud use cases in Anthos back to GKE running in Google Cloud. Specifically, \u003ca href=\"https://cloud.google.com/anthos/config-management\"\u003eAnthos Config Management\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/anthos/service-mesh\"\u003eAnthos Service Mesh\u003c/a\u003e are now generally available for GKE as standalone services with pay-as-you-go pricing. GKE customers can now use Anthos Config Management to take advantage of config and policy automation at a low incremental per-cluster cost, and use Anthos Service Mesh to enable next-level security and networking on container-based microservices.\u003c/p\u003e\u003cp\u003eLast but not least, we are excited to announce that starting today, Anthos Service Mesh is generally available to support a hybrid mesh. This gives you the flexibility to have a common mesh that spans both your Google Cloud and on-prem deployments. \u003c/p\u003e\u003cp\u003eCustomers like \u003ca href=\"http://www.westerndigital.com\" target=\"_blank\"\u003eWestern Digital\u003c/a\u003e have already experienced many benefits from adopting Anthos as their application modernization platform:\u003c/p\u003e\u003cp\u003e\u003ci\u003e\"As a global storage leader with sophisticated manufacturing facilities around the world, Western Digital sees cloud technology as an enabler of our key business priorities: reducing time to deliver products and services, rationalizing our entire application footprint, and meeting customer demand for IoT and edge applications,”\u003c/i\u003e said Jahidul Khandaker, senior vice president and CIO, Western Digital. \u003ci\u003e“Anthos is our unified management platform of choice—it gives us insights across our Google Cloud and on-premises environments, while keeping the doors open for a multi-cloud future. Anthos has delivered several advantages for our developers: a richer user experience, greater security, and enhanced flexibility to manage factory applications—no matter where they reside—on-prem, in the cloud or a mix of both.\"\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch3\u003eEasy does it\u003c/h3\u003e\u003cp\u003eIn addition to being an open platform, we strive to make Google Cloud easy to use for operators as well as developers. For example, earlier this year \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/introducing-gke-autopilot\"\u003ewe introduced GKE Autopilot\u003c/a\u003e, a mode of operations in GKE that empowers you to simplify operations by offloading the management of infrastructure, control plane, and nodes. With GKE Autopilot, customers like \u003ca href=\"https://cloud.google.com/customers/ubie\"\u003eUbie\u003c/a\u003e, a Japanese-based healthcare technology company, have eliminated the need to configure and maintain infrastructure, which helped their development teams focus on making healthcare more accessible.\u003c/p\u003e\u003cp\u003eWith Cloud Run, our serverless compute platform, you can abstract away infrastructure management entirely. This year, our focus has been on bringing the simplicity of Cloud Run to more workloads, like traditional applications written in Java Spring Boot, ASP.NET, and Django, among others. Along with a new second generation execution environment for enhanced network and CPU performance, we’ve added \u003ca href=\"https://cloud.google.com/blog/products/serverless/introducing-committed-use-discounts-for-cloud-run\"\u003ecommitted-use discounts\u003c/a\u003e and introduced \u003ca href=\"https://cloud.google.com/blog/products/serverless/cloud-run-gets-always-on-cpu-allocation\"\u003enew CPU allocation controls and price\u003c/a\u003e, allowing you to save up to 17% and 25%, respectively, on your compute bill. New \u003ca href=\"https://cloud.google.com/blog/topics/developers-practitioners/introducing-new-connectors-workflows\"\u003econnectors\u003c/a\u003e for Workflows, \u003ca href=\"https://cloud.google.com/blog/products/serverless/cloud-functions-integrates-with-google-secret-manager\"\u003eintegration\u003c/a\u003e between Cloud Functions and Secret Manager, and support for \u003ca href=\"https://cloud.google.com/blog/products/serverless/cloud-functions-supports-min-instances\"\u003emin instances\u003c/a\u003e are just a few of the other ways we’ve made it easier to build modern, serverless apps. \u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch3\u003eEasy for developers \u003c/h3\u003eDevelopers spend a lot of time inside their integrated development environments (IDEs), writing code. Last year we announced \u003ca href=\"https://cloud.google.com/shell\"\u003eCloud Shell Editor\u003c/a\u003e, which makes the process of writing code as seamless as possible. It comes with your favorite developer tools (e.g., docker, minikube, skaffold, and many more) preinstalled, and this year, we added ~100 live tutorials to it—no more switching between the documentation, the terminal, and your code! \u003cp\u003e\u003c/p\u003e\u003cp\u003eOnce that code is ready, you want building it and deploying it to be as seamless as possible. Today we are announcing \u003ca href=\"https://cloud.google.com/build/docs/hybrid/overview\"\u003eCloud Build Hybrid\u003c/a\u003e, which lets you build, test, and deploy across clouds and on-prem systems, so developers get consistent CI/CD tooling across their environments, and platform engineers don't have to worry about maintaining and scaling their systems. Cloud Build is also integrated with \u003ca href=\"https://docs.google.com/document/d/1Z4vYdjF66UTOJgIpaDlDnXOuDCV6YulMhvNDjgoFiYo/edit?resourcekey=0-Vxxrly14dbfaBHg21HnOfg#\" target=\"_blank\"\u003eArtifact Registry\u003c/a\u003e, which now allows you to store not only in containers, but also language-specific artifacts in one place. Finally, with the recently launched \u003ca href=\"https://cloud.google.com/deploy/docs/overview\"\u003eGoogle Cloud Deploy\u003c/a\u003e, which is a managed, continuous delivery service initially for GKE, we’re making it easy to scale your pipelines across your organization.\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch3\u003eEasy for operators\u003c/h3\u003eWhen your applications are up and running, you need to observe and analyze them for better operations and business insights. While we already offer a fully managed metrics and alerting service with \u003ca href=\"https://cloud.google.com/monitoring\"\u003eCloud Monitoring\u003c/a\u003e, some Kubernetes users want to continue using open-source Prometheus without the scaling and management headaches. This is precisely why today we are announcing the preview of \u003ca href=\"http://cloud.google.com/monitoring\"\u003eManaged Service for Prometheus\u003c/a\u003e, helping you avoid vendor lock-in and delivering compatibility with your existing Prometheus alerts, workflows, and Grafana dashboards. Now you have all of the benefits of Prometheus, minus the management hassle. \u003cp\u003e\u003c/p\u003e\u003cp\u003eTo give you easy diagnostics and deeper insights from across your business and systems, today we also combined \u003ca href=\"https://cloud.google.com/logging\"\u003eCloud Logging\u003c/a\u003e with the performance and power of BigQuery to introduce \u003ca href=\"https://cloud.google.com/logging/docs/log-analytics\"\u003eLog Analytics\u003c/a\u003e. Currently in preview, Log Analytics allows you to rapidly store, manage, and analyze log data. This enables you to effectively move your operations from a reactive to proactive model. \u003c/p\u003e\u003ch3\u003eZero-trust simplified for application developers\u003c/h3\u003e\u003cp\u003eWe also make it easy for developers to build secure applications from the get-go, whether they’re writing code, running it through the CI/CD pipeline, or in production. This zero-trust software supply chain is made possible by fully managed services that provide you with a consistent way to define and enforce policy, establish provenance, and prevent modification or tampering. \u003c/p\u003e\u003cp\u003eAnd we’re continuing to enhance our \u003ca href=\"https://cloud.google.com/blog/products/identity-security/applying-zero-trust-to-user-access-and-production-services\"\u003ezero-trust software supply chain capabilities\u003c/a\u003e with new features. For example, developers can now scan \u003ca href=\"https://cloud.google.com/blog/products/identity-security/scan-for-vulnerabilities-early-to-shift-security-left-in-cicd\"\u003econtainers for vulnerabilities\u003c/a\u003e using the simple “gcloud artifacts docker images scan” command. Now generally available, we’re also announcing that you can pair Cloud Run with Binary Authorization and, in a few clicks, ensure that only trusted container images make it to production. In addition, Binary Authorization now integrates with Cloud Build to automatically generate digital signatures and make it easy to set up deploy-time constraints that ensure only images signed by Cloud Build are sanctioned. Learn more about how we are making security easier \u003ca href=\"https://cloud.google.com/blog/products/identity-security/next21-how-google-cloud-secures-the-world\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\u003ch3\u003eTransform your cloud with Google\u003c/h3\u003eNo matter where you are along the journey to transform your applications, we are here to partner with you. Whether its with the new product functionality we described today at Next, research and best practices such as the \u003ca href=\"https://cloud.google.com/devops/state-of-devops/\"\u003e2021 Accelerate State of DevOps report\u003c/a\u003e from Cloud’s DevOps Research and Assessment (DORA) team, or professional services such as the \u003ca href=\"https://cloud.google.com/camp\"\u003eGoogle Cloud Application Modernization Program (CAMP)\u003c/a\u003e, we’re here to help.\u003cbr/\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/CloudNext21_11.max-2200x2200.jpg",
      "date_published": "2021-10-13T12:00:00Z",
      "author": {
        "name": "\u003cname\u003eChen Goldberg\u003c/name\u003e\u003ctitle\u003eVP of Engineering, Application Modernization Platform\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/application-development/node-python-and-javarepos-are-generally-available/",
      "title": "Artifact Registry for language packages now generally available",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c48=\"\"\u003e\u003cdiv _ngcontent-c48=\"\" innerhtml=\"\u0026lt;p\u0026gt;Using a centralized, private repository to host your internal code as a package not only enables code reuse, but also simplifies and secures your existing software delivery pipeline. By using the same formats and tools as you would in the open-source ecosystem, you can leverage the same advantages, simplify your build, and keep your business logic and applications secure.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Language repository formats, now generally available\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;As of today, support for language repositories in \u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/\u0026#34;\u0026gt;Artifact Registry is now generally available\u0026lt;/a\u0026gt;, allowing you to store all your language-specific artifacts in one place. Supported package types include:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/java\u0026#34;\u0026gt;Java\u0026lt;/a\u0026gt; packages\u0026amp;#160; (using the Maven repository format)\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/nodejs\u0026#34;\u0026gt;Node.js\u0026lt;/a\u0026gt; packages (using the npm repository format)\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/python\u0026#34;\u0026gt;Python\u0026lt;/a\u0026gt; packages (using the PyPI repository format)\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;h3\u0026gt;OS repository formats in preview\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Additionally, support for new repository formats for Linux distributions is in public preview, allowing developers to create private internal-only packages and securely use them across multiple applications deployed to Linux environments. New supported artifact formats include:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/os-packages/debian\u0026#34;\u0026gt;Debian\u0026lt;/a\u0026gt; packages (using the Apt repository format)\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/os-packages/rpm\u0026#34;\u0026gt;RPM\u0026lt;/a\u0026gt; packages (using the Yum repository format)\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;This is in addition to existing container images and Helm charts (using the Docker repository format).\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Your own secure supply chain\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Storing your packages in Artifact Registry not only enables code reuse, but also simplifies and secures your existing build pipeline. In addition to bringing your internal packages to a managed repository, using Artifact Registry also allows you to take additional steps to improve the security of your software delivery pipeline:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Use \u0026lt;a href=\u0026#34;https://cloud.google.com/container-analysis/docs/container-scanning-overview\u0026#34;\u0026gt;Container Analysis\u0026lt;/a\u0026gt; to scan containers that use your private packages for vulnerabilities\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Include your repositories in a \u0026lt;a href=\u0026#34;https://cloud.google.com/vpc\u0026#34;\u0026gt;Virtual Private Cloud\u0026lt;/a\u0026gt; to control access\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Monitor repository usage with \u0026lt;a href=\u0026#34;https://cloud.google.com/logging/docs/audit\u0026#34;\u0026gt;Cloud Audit Logs\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Use the \u0026lt;a href=\u0026#34;https://github.com/GoogleCloudPlatform/cloud-builders-community/tree/master/binauthz-attestation\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;binauthz-attestation\u0026lt;/a\u0026gt; builder with \u0026lt;a href=\u0026#34;https://cloud.google.com/build\u0026#34;\u0026gt;Cloud Build\u0026lt;/a\u0026gt; to create attestations that \u0026lt;a href=\u0026#34;https://cloud.google.com/binary-authorization\u0026#34;\u0026gt;Binary Authorization\u0026lt;/a\u0026gt; verifies before allowing container deployment\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Use\u0026amp;#160; Cloud Identity and Access Management (IAM) for \u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/access-control\u0026#34;\u0026gt;repository access control\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;h3\u0026gt;Seamless authentication\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;With credential helpers to authenticate access for installers based on \u0026lt;a href=\u0026#34;https://cloud.google.com/iam\u0026#34;\u0026gt;Cloud Identity and Access Management (IAM)\u0026lt;/a\u0026gt; permissions, using Artifact Registry to host your packages makes authentication to private repositories easy. By managing IAM groups, administrators can control access to repositories via the same tools used across Google Cloud.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Regional repositories lower cost and enable data compliance\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Artifact Registry provides \u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/repo-locations\u0026#34;\u0026gt;regional support\u0026lt;/a\u0026gt;, enabling you to manage and host artifacts in the regions where your deployments occur, reducing latency and cost. By implementing regional repositories, you can also comply with your local data sovereignty and security requirements.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Get started today\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;These repository formats are now generally available to all Artifact Registry customers. Pricing for language repositories is the same as container pricing; see the \u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/pricing\u0026#34;\u0026gt;pricing documentation\u0026lt;/a\u0026gt; for details. To get started using language and OS repositories, try the quickstarts in the Artifact Registry documentation.\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/nodejs\u0026#34;\u0026gt;Node.js\u0026lt;/a\u0026gt; Quickstart Guide\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/python\u0026#34;\u0026gt;Python\u0026lt;/a\u0026gt; Quickstart Guide\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/java\u0026#34;\u0026gt;Java\u0026lt;/a\u0026gt; Quickstart Guide\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/os-packages/debian/apt-quickstart\u0026#34;\u0026gt;Apt\u0026lt;/a\u0026gt; Quickstart Guide\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/os-packages/rpm/yum-quickstart\u0026#34;\u0026gt;RPM\u0026lt;/a\u0026gt; Quickstart Guide\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\"\u003e\u003cp\u003eUsing a centralized, private repository to host your internal code as a package not only enables code reuse, but also simplifies and secures your existing software delivery pipeline. By using the same formats and tools as you would in the open-source ecosystem, you can leverage the same advantages, simplify your build, and keep your business logic and applications secure.\u003c/p\u003e\u003ch3\u003eLanguage repository formats, now generally available\u003c/h3\u003e\u003cp\u003eAs of today, support for language repositories in \u003ca href=\"https://cloud.google.com/artifact-registry/\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/\" track-metadata-module=\"post\"\u003eArtifact Registry is now generally available\u003c/a\u003e, allowing you to store all your language-specific artifacts in one place. Supported package types include:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/java\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/java\" track-metadata-module=\"post\"\u003eJava\u003c/a\u003e packages  (using the Maven repository format)\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/nodejs\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/nodejs\" track-metadata-module=\"post\"\u003eNode.js\u003c/a\u003e packages (using the npm repository format)\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/python\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/python\" track-metadata-module=\"post\"\u003ePython\u003c/a\u003e packages (using the PyPI repository format)\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eOS repository formats in preview\u003c/h3\u003e\u003cp\u003eAdditionally, support for new repository formats for Linux distributions is in public preview, allowing developers to create private internal-only packages and securely use them across multiple applications deployed to Linux environments. New supported artifact formats include:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/os-packages/debian\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/os-packages/debian\" track-metadata-module=\"post\"\u003eDebian\u003c/a\u003e packages (using the Apt repository format)\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/os-packages/rpm\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/os-packages/rpm\" track-metadata-module=\"post\"\u003eRPM\u003c/a\u003e packages (using the Yum repository format)\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThis is in addition to existing container images and Helm charts (using the Docker repository format). \u003c/p\u003e\u003cp\u003eYour own secure supply chain\u003c/p\u003e\u003cp\u003eStoring your packages in Artifact Registry not only enables code reuse, but also simplifies and secures your existing build pipeline. In addition to bringing your internal packages to a managed repository, using Artifact Registry also allows you to take additional steps to improve the security of your software delivery pipeline:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eUse \u003ca href=\"https://cloud.google.com/container-analysis/docs/container-scanning-overview\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/container-analysis/docs/container-scanning-overview\" track-metadata-module=\"post\"\u003eContainer Analysis\u003c/a\u003e to scan containers that use your private packages for vulnerabilities\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eInclude your repositories in a \u003ca href=\"https://cloud.google.com/vpc\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/vpc\" track-metadata-module=\"post\"\u003eVirtual Private Cloud\u003c/a\u003e to control access\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eMonitor repository usage with \u003ca href=\"https://cloud.google.com/logging/docs/audit\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/audit\" track-metadata-module=\"post\"\u003eCloud Audit Logs\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eUse the \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-builders-community/tree/master/binauthz-attestation\" target=\"_blank\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003ebinauthz-attestation\u003c/a\u003e builder with \u003ca href=\"https://cloud.google.com/build\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/build\" track-metadata-module=\"post\"\u003eCloud Build\u003c/a\u003e to create attestations that \u003ca href=\"https://cloud.google.com/binary-authorization\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/binary-authorization\" track-metadata-module=\"post\"\u003eBinary Authorization\u003c/a\u003e verifies before allowing container deployment\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eUse  Cloud Identity and Access Management (IAM) for \u003ca href=\"https://cloud.google.com/artifact-registry/docs/access-control\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/access-control\" track-metadata-module=\"post\"\u003erepository access control\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eSeamless authentication\u003c/h3\u003e\u003cp\u003eWith credential helpers to authenticate access for installers based on \u003ca href=\"https://cloud.google.com/iam\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://cloud.google.com/iam\" track-metadata-module=\"post\"\u003eCloud Identity and Access Management (IAM)\u003c/a\u003e permissions, using Artifact Registry to host your packages makes authentication to private repositories easy. By managing IAM groups, administrators can control access to repositories via the same tools used across Google Cloud.\u003c/p\u003e\u003ch3\u003eRegional repositories lower cost and enable data compliance\u003c/h3\u003e\u003cp\u003eArtifact Registry provides \u003ca href=\"https://cloud.google.com/artifact-registry/docs/repo-locations\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/repo-locations\" track-metadata-module=\"post\"\u003eregional support\u003c/a\u003e, enabling you to manage and host artifacts in the regions where your deployments occur, reducing latency and cost. By implementing regional repositories, you can also comply with your local data sovereignty and security requirements.\u003c/p\u003e\u003ch3\u003eGet started today\u003c/h3\u003e\u003cp\u003eThese repository formats are now generally available to all Artifact Registry customers. Pricing for language repositories is the same as container pricing; see the \u003ca href=\"https://cloud.google.com/artifact-registry/pricing\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/pricing\" track-metadata-module=\"post\"\u003epricing documentation\u003c/a\u003e for details. To get started using language and OS repositories, try the quickstarts in the Artifact Registry documentation.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/nodejs\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/nodejs\" track-metadata-module=\"post\"\u003eNode.js\u003c/a\u003e Quickstart Guide\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/python\" track-type=\"inline link\" track-name=\"18\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/python\" track-metadata-module=\"post\"\u003ePython\u003c/a\u003e Quickstart Guide\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/java\" track-type=\"inline link\" track-name=\"19\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/java\" track-metadata-module=\"post\"\u003eJava\u003c/a\u003e Quickstart Guide\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/os-packages/debian/apt-quickstart\" track-type=\"inline link\" track-name=\"20\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/os-packages/debian/apt-quickstart\" track-metadata-module=\"post\"\u003eApt\u003c/a\u003e Quickstart Guide\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/os-packages/rpm/yum-quickstart\" track-type=\"inline link\" track-name=\"21\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/os-packages/rpm/yum-quickstart\" track-metadata-module=\"post\"\u003eRPM\u003c/a\u003e Quickstart Guide\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eUsing a centralized, private repository to host your internal code as a package not only enables code reuse, but also simplifies and secures your existing software delivery pipeline. By using the same formats and tools as you would in the open-source ecosystem, you can leverage the same advantages, simplify your build, and keep your business logic and applications secure.\u003c/p\u003e\u003ch3\u003eLanguage repository formats, now generally available\u003c/h3\u003e\u003cp\u003eAs of today, support for language repositories in \u003ca href=\"https://cloud.google.com/artifact-registry/\"\u003eArtifact Registry is now generally available\u003c/a\u003e, allowing you to store all your language-specific artifacts in one place. Supported package types include:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/java\"\u003eJava\u003c/a\u003e packages  (using the Maven repository format)\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/nodejs\"\u003eNode.js\u003c/a\u003e packages (using the npm repository format)\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/python\"\u003ePython\u003c/a\u003e packages (using the PyPI repository format)\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eOS repository formats in preview\u003c/h3\u003e\u003cp\u003eAdditionally, support for new repository formats for Linux distributions is in public preview, allowing developers to create private internal-only packages and securely use them across multiple applications deployed to Linux environments. New supported artifact formats include:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/os-packages/debian\"\u003eDebian\u003c/a\u003e packages (using the Apt repository format)\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/os-packages/rpm\"\u003eRPM\u003c/a\u003e packages (using the Yum repository format)\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThis is in addition to existing container images and Helm charts (using the Docker repository format). \u003c/p\u003e\u003cp\u003eYour own secure supply chain\u003c/p\u003e\u003cp\u003eStoring your packages in Artifact Registry not only enables code reuse, but also simplifies and secures your existing build pipeline. In addition to bringing your internal packages to a managed repository, using Artifact Registry also allows you to take additional steps to improve the security of your software delivery pipeline:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eUse \u003ca href=\"https://cloud.google.com/container-analysis/docs/container-scanning-overview\"\u003eContainer Analysis\u003c/a\u003e to scan containers that use your private packages for vulnerabilities\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eInclude your repositories in a \u003ca href=\"https://cloud.google.com/vpc\"\u003eVirtual Private Cloud\u003c/a\u003e to control access\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eMonitor repository usage with \u003ca href=\"https://cloud.google.com/logging/docs/audit\"\u003eCloud Audit Logs\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eUse the \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-builders-community/tree/master/binauthz-attestation\" target=\"_blank\"\u003ebinauthz-attestation\u003c/a\u003e builder with \u003ca href=\"https://cloud.google.com/build\"\u003eCloud Build\u003c/a\u003e to create attestations that \u003ca href=\"https://cloud.google.com/binary-authorization\"\u003eBinary Authorization\u003c/a\u003e verifies before allowing container deployment\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eUse  Cloud Identity and Access Management (IAM) for \u003ca href=\"https://cloud.google.com/artifact-registry/docs/access-control\"\u003erepository access control\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eSeamless authentication\u003c/h3\u003e\u003cp\u003eWith credential helpers to authenticate access for installers based on \u003ca href=\"https://cloud.google.com/iam\"\u003eCloud Identity and Access Management (IAM)\u003c/a\u003e permissions, using Artifact Registry to host your packages makes authentication to private repositories easy. By managing IAM groups, administrators can control access to repositories via the same tools used across Google Cloud.\u003c/p\u003e\u003ch3\u003eRegional repositories lower cost and enable data compliance\u003c/h3\u003e\u003cp\u003eArtifact Registry provides \u003ca href=\"https://cloud.google.com/artifact-registry/docs/repo-locations\"\u003eregional support\u003c/a\u003e, enabling you to manage and host artifacts in the regions where your deployments occur, reducing latency and cost. By implementing regional repositories, you can also comply with your local data sovereignty and security requirements.\u003c/p\u003e\u003ch3\u003eGet started today\u003c/h3\u003e\u003cp\u003eThese repository formats are now generally available to all Artifact Registry customers. Pricing for language repositories is the same as container pricing; see the \u003ca href=\"https://cloud.google.com/artifact-registry/pricing\"\u003epricing documentation\u003c/a\u003e for details. To get started using language and OS repositories, try the quickstarts in the Artifact Registry documentation.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/nodejs\"\u003eNode.js\u003c/a\u003e Quickstart Guide\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/python\"\u003ePython\u003c/a\u003e Quickstart Guide\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/java\"\u003eJava\u003c/a\u003e Quickstart Guide\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/os-packages/debian/apt-quickstart\"\u003eApt\u003c/a\u003e Quickstart Guide\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/os-packages/rpm/yum-quickstart\"\u003eRPM\u003c/a\u003e Quickstart Guide\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/application-development/artifact-registry-adds-node-python-and-java-repositories/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_7fdTm09.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eNode, Python and Java repositories now available in Artifact Registry\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eExpanded language support lets you store Java, Node and Python artifacts in Artifact Registry, for a more secure software supply chain.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/appdev.max-2200x2200.jpg",
      "date_published": "2021-10-07T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eDustin Ingram\u003c/name\u003e\u003ctitle\u003eSenior Developer Advocate\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/topics/anthos/using-terraform-to-enable-config-connector-on-a-gke-cluster/",
      "title": "Deploy Anthos on GKE with Terraform Part 3: Enabling Cloud Resources Provisioning",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIn the previous two parts of the series (\u003ca href=\"https://cloud.google.com/blog/topics/anthos/using-terraform-to-enable-config-sync-on-a-gke-cluster\"\u003e1\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/blog/topics/anthos/using-terraform-to-enable-policy-controller-on-a-gke-cluster\"\u003e2\u003c/a\u003e) we discussed how new features in \u003ca href=\"https://registry.terraform.io/providers/hashicorp/google/latest/docs\" target=\"_blank\"\u003eTerraform Provider for GCP\u003c/a\u003e make it easier for platform administrators to extend their Terraform automation to add \u003ca href=\"https://cloud.google.com/anthos/config-management\"\u003eAnthos Config Management (ACM)\u003c/a\u003e features to their GKE clusters. Using familiar Terraform resource syntax, you can add \u003ccode\u003egoogle_gke_hub_feature\u003c/code\u003e and \u003ccode\u003egoogle_gke_hub_feature_membership\u003c/code\u003e resource with \u003ccode\u003econfigmanagement\u003c/code\u003e section to enable Config Sync for GitOps integration and \u003ccode\u003epolicy_controller\u003c/code\u003e section for policy validation.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eSo far the cluster in our example was only used to host the configuration consisting of Kubernetes native resources - containerized Wordpress application powered by in-cluster MySQL database. We are getting all the advantages of Kubernetes: continuous \u003ca href=\"https://cloud.google.com/config-connector/docs/concepts/reconciliation\"\u003ereconciliation\u003c/a\u003e and drift correction, \u003ca href=\"https://en.wikipedia.org/wiki/Eventual_consistency\" target=\"_blank\"\u003eeventual consistency,\u003c/a\u003e order independence and \u003ca href=\"https://en.wikipedia.org/wiki/Idempotence\" target=\"_blank\"\u003eidempotence\u003c/a\u003e. We are also deriving benefits from GitOps approach using the repo as the source of truth, enabling reviewable and version-controlled workflow.\u003c/p\u003e\u003cp\u003eNow let’s take it even further. \u003cb\u003eWe’ll demonstrate how\u003c/b\u003e \u003ca href=\"https://cloud.google.com/blog/topics/developers-practitioners/build-platform-krm-part-1-whats-platform\"\u003e\u003cb\u003ethe same model\u003c/b\u003e\u003c/a\u003e \u003cb\u003ecan be expanded to create and manage not just native Kubernetes resources (Kubernetes service accounts, pods, deployments) but also GCP cloud resources - Cloud databases, storage buckets, VM instances and\u003c/b\u003e \u003ca href=\"https://cloud.google.com/config-connector/docs/reference/overview\"\u003emany other GCP resources\u003c/a\u003e. Since \u003ca href=\"https://cloud.google.com/config-connector/docs/overview\"\u003eConfig Connector\u003c/a\u003e was \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/config-connector-bridges-kubernetes-gcp-resources\"\u003elaunched\u003c/a\u003e in 2020, many Kuberentes shops have embraced its convenient way of managing GCP resources. Now that we have enabled Terraform support for Anthos features, combined with a Terraform configuration \u003ca href=\"https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/container_cluster#config_connector_config\" target=\"_blank\"\u003eoption\u003c/a\u003e to install Config Connector on the cluster,  the full GitOps workflow and Kubernetes lifecycle spanning native and cloud resources can be enabled during cluster creation.\u003c/p\u003e\u003cp\u003eIn our \u003ca href=\"https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/master/examples/acm-terraform-blog-part3/terraform/gke.tf\" target=\"_blank\"\u003eexample\u003c/a\u003e, we are enabling Config Connector using the \u003ccode\u003econfig_connector\u003c/code\u003e setting in the \u003ccode\u003egke\u003c/code\u003e Terraform module. We also use the \u003ca href=\"https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity\"\u003e\u003ccode\u003eworkload-identity\u003c/code\u003e\u003c/a\u003e module to create a GCP service account that will be used to make the changes to K8s resources and bind it to Kubernetes Service Account (\u003ccode\u003ecnrm-controller-manager\u003c/code\u003e in \u003ccode\u003ecnrm-system namespace\u003c/code\u003e). You can choose the appropriate permissions to GCP service account -  in our examples we are giving it the \u003ccode\u003eowner\u003c/code\u003e role for simplicity.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eLet’s review what changed in this part in the repo that is synchronized with our cluster via Config Sync. In  \u003ca href=\"https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/tree/master/examples/acm-terraform-blog-part1/config-root\" target=\"_blank\"\u003ethe first part\u003c/a\u003e, we added a collection of configs, all native Kubernetes objects. These configs provisioned an in-cluster Wordpress application with an in-cluster MySQL database. In the second part, we added a set of rules used by PolicyController to audit our cluster. In this part, we start by  adding a \u003ca href=\"https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/master/examples/acm-terraform-blog-part3/config-root/configconnector.yaml\" target=\"_blank\"\u003econfig\u003c/a\u003e representing an instance of the Config Connector addon. While the addon is enabled on the cluster, this config instance is required to activate it. It specifies the settings, such as \u003ccode\u003emode\u003c/code\u003e (cluster or namespace) and GCP service account, linking it to the cnrmsa account that we created above using the \u003ccode\u003eworkload-identity\u003c/code\u003e module.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eAnd now we can create GCP resources in addition to in-cluster native resources directly in our K8s configuration. We are configuring an \u003ca href=\"https://cloud.google.com/config-connector/docs/reference/resource-docs/sql/sqldatabase\"\u003eSQLDatabase\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/config-connector/docs/reference/resource-docs/sql/sqlinstance\"\u003eSQLInstance\u003c/a\u003e resources:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eas well as \u003ca href=\"https://cloud.google.com/config-connector/docs/reference/resource-docs/sql/sqluser\"\u003eSQLUser\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/config-connector/docs/reference/resource-docs/iam/iampolicy\"\u003eIAMPolicy\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/config-connector/docs/reference/resource-docs/iam/iampolicymember\"\u003eIAMPolicyMember\u003c/a\u003e (see complete example \u003ca href=\"https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/blob/master/examples/acm-terraform-blog-part3/config-root/wordpress-bundle.yaml\" target=\"_blank\"\u003ehere\u003c/a\u003e). Overall, \u003ca href=\"https://cloud.google.com/config-connector/docs/reference/overview\"\u003emore than 130 resources are now supported with Config Connector\u003c/a\u003e covering many of the most popular GCP configuration patterns.\u003c/p\u003e\u003cp\u003eYou will notice that this configuration is expanded and parameterized for our specific project. How did we specify the parameter values? While many tools can be used, including \u003ca href=\"https://helm.sh/\" target=\"_blank\"\u003eHelm\u003c/a\u003e and \u003ca href=\"https://kustomize.io/\" target=\"_blank\"\u003eKustomize\u003c/a\u003e and some of them used together, we recommend \u003ca href=\"https://cloud.google.com/architecture/managing-cloud-infrastructure-using-kpt\"\u003eKpt\u003c/a\u003e that fully embraces the principles of \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/understanding-configuration-as-data-in-kubernetes\"\u003econfiguration-as-data\u003c/a\u003e. In this example we used set-project-id kpt function to specify project id on the config-root directory before submitting the change to Git.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eThis \u003ca href=\"https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/tree/master/examples/acm-terraform-blog-part3\" target=\"_blank\"\u003erepo\u003c/a\u003e provides a complete example of provisioning a cluster that is synchronized with a repo that contains a WordPress configuration powered, this time, by GCP MySQL database.\u003c/p\u003e\u003cp\u003eThis was the third and the final article of the three part series that showcased Terraform support for ACM features and how it simplifies cluster provisioning for platform administrators.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/topics/anthos/using-terraform-to-enable-config-sync-on-a-gke-cluster/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Anthos.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eDeploy Anthos on GKE with Terraform part 1: GitOps with Config Sync\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eIt is now simple to use Terraform to configure Anthos features on your GKE clusters. This is the first part of the 3 part series that des...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/original_images/Google_Cloud_Anthos_A.jpg",
      "date_published": "2021-10-06T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eSteven Linde\u003c/name\u003e\u003ctitle\u003eEngineering Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/google-cloud-deploy-automates-deploys-to-gke/",
      "title": "Introducing Google Cloud Deploy: Managed continuous delivery to GKE",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle-page\u003e\u003cmain id=\"jump-content\"\u003e\u003carticle\u003e\u003carticle-header-block\u003e\u003c/article-header-block\u003e\u003carticle-aspect-image-block\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003e#gcp\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/article-aspect-image-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-author-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003e S. Bogdan \u003c/p\u003e\u003cp\u003e Product Manager \u003c/p\u003e\u003c/div\u003e\u003cp\u003e\u003cspan\u003e September 22, 2021 \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-author-block\u003e\u003c/div\u003e\u003carticle-cta _nghost-c13=\"\"\u003e\u003cdiv _ngcontent-c13=\"\"\u003e\u003ch4 _ngcontent-c13=\"\"\u003e\u003cspan _ngcontent-c13=\"\"\u003eNext ’21 registration is open\u003c/span\u003e\u003c/h4\u003e\u003cp _ngcontent-c13=\"\"\u003e\u003cspan _ngcontent-c13=\"\"\u003eJoin us October 12–14, 2021, for our digital flagship event\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003ca _ngcontent-c13=\"\" clicktracker=\"\" rel=\"external\" track-metadata-module=\"article cta\" track-type=\"button\" track-name=\"Next21 registration\" track-metadata-eventdetail=\"https://cloud.withgoogle.com/next/register?utm_source=google\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY21-Q4-global-ES903-onlineevent-er-next-2021\u0026amp;utm_content=blog-next-21-registration\" href=\"https://cloud.withgoogle.com/next/register?utm_source=google\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY21-Q4-global-ES903-onlineevent-er-next-2021\u0026amp;utm_content=blog-next-21-registration\"\u003e\u003cspan _ngcontent-c13=\"\"\u003eRegister now\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-cta\u003e\u003c/div\u003e\u003carticle-share-block\u003e\u003c/article-share-block\u003e\u003carticle-sticky-share-block\u003e\u003c/article-sticky-share-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-content-stream-block\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c15=\"\"\u003e\u003cdiv _ngcontent-c15=\"\" innerhtml=\"\u0026lt;p\u0026gt;Continuous delivery is frequently top-of-mind for organizations adopting \u0026lt;a href=\u0026#34;https://cloud.google.com/kubernetes-engine\u0026#34;\u0026gt;Google Kubernetes Engine\u0026lt;/a\u0026gt; (GKE). However, continuous delivery \u0026amp;#8212;deploying container image artifacts into your various environments\u0026amp;#8212;remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;It doesn\u0026amp;#8217;t have to be this way.\u0026amp;#160;\u0026lt;/p\u0026gt;Today, we are pleased to announce \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy\u0026#34;\u0026gt;Google Cloud Deploy\u0026lt;/a\u0026gt;, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eContinuous delivery is frequently top-of-mind for organizations adopting \u003ca href=\"https://cloud.google.com/kubernetes-engine\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/kubernetes-engine\" track-metadata-module=\"post\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE). However, continuous delivery —deploying container image artifacts into your various environments—remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u003c/p\u003e\u003cp\u003eIt doesn’t have to be this way. \u003c/p\u003e\u003cp\u003eToday, we are pleased to announce \u003ca href=\"https://cloud.google.com/deploy\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/deploy\" track-metadata-module=\"post\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c15=\"\"\u003e\u003cdiv _ngcontent-c15=\"\" innerhtml=\"\u0026lt;h3\u0026gt;Solving for continuous delivery challenges\u0026lt;br\u0026gt;\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Let\u0026amp;#8217;s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Cost of ownership\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Time and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current\u0026amp;#8212;to say nothing of maintenance\u0026amp;#8212;is resource-intensive and takes time away from the core business.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;\u0026amp;#8220;We can\u0026amp;#8217;t afford to be innovating in continuous delivery,\u0026amp;#8221; one customer told us. \u0026amp;#8220;We want an opinionated product that supports best practices out of the box.\u0026amp;#8221;\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy addresses cost of ownership head-on.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;As a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy also provides structure. \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\u0026#34;\u0026gt;Delivery pipelines\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology\u0026#34;\u0026gt;targets\u0026lt;/a\u0026gt; are defined \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/config-files\u0026#34;\u0026gt;declaratively\u0026lt;/a\u0026gt; and are \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/pipeline-instances\u0026#34;\u0026gt;stored alongside each release\u0026lt;/a\u0026gt;. That means if your delivery pipeline changes, the release\u0026amp;#8217;s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003cbr/\u003e\u003c/h3\u003e\u003cp\u003eGoogle Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u003c/p\u003e\u003cp\u003eLet’s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eTime and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current—to say nothing of maintenance—is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“We can’t afford to be innovating in continuous delivery,” one customer told us. “We want an opinionated product that supports best practices out of the box.”\u003c/i\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy addresses cost of ownership head-on.\u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\" track-metadata-module=\"post\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology\" track-metadata-module=\"post\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/config-files\" track-metadata-module=\"post\"\u003edeclaratively\u003c/a\u003e and are \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/pipeline-instances\" track-metadata-module=\"post\"\u003estored alongside each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c15=\"\"\u003e\u003cp\u003eWe have found that a variety of GKE roles and personas interact with continuous delivery processes. A DevOps engineer may be focused on release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/deploying-application\" track-metadata-module=\"post\"\u003epromotion and rollback\u003c/a\u003e decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003cbr/\u003e\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c15=\"\"\u003e\u003cdiv _ngcontent-c15=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Security and audit\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Lots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn\u0026amp;#8217;t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Throughout, Google Cloud Deploy enables fine-grained restriction, with \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/iam-roles-permissions\u0026#34;\u0026gt;discrete resource access control\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/execution-environment\u0026#34;\u0026gt;execution-level security\u0026lt;/a\u0026gt;. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\u0026#34;\u0026gt;approvals\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Auditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u0026lt;a href=\u0026#34;https://cloud.google.com/audit-logs\u0026#34;\u0026gt;Cloud Audit Logs\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/audit-logs\u0026#34;\u0026gt;audits\u0026lt;/a\u0026gt; user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Integration\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Whether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating\u0026#34;\u0026gt;embraces the GKE delivery tooling ecosystems\u0026lt;/a\u0026gt; in three ways: connectivity to CI systems, support for leading configuration (\u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology#render\u0026#34;\u0026gt;rendering\u0026lt;/a\u0026gt;) tooling, and \u0026lt;a href=\u0026#34;https://cloud.google.com/pubsub\u0026#34;\u0026gt;Pub/Sub\u0026lt;/a\u0026gt; notifications to enable third-party integrations.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\u0026#34;\u0026gt;Connecting Google Cloud Deploy\u0026lt;/a\u0026gt; to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple\u0026amp;#160;\u0026lt;i\u0026gt;`\u0026lt;/i\u0026gt;\u0026lt;i\u0026gt;gcloud beta deploy releases create`.\u0026lt;/i\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e\u003cb\u003eSecurity and audit\u003c/b\u003e\u003c/p\u003e\u003cp\u003eLots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained restriction, with \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\" track-metadata-module=\"post\"\u003ediscrete resource access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/execution-environment\" track-metadata-module=\"post\"\u003eexecution-level security\u003c/a\u003e. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\" track-metadata-module=\"post\"\u003eapprovals\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/audit-logs\" track-metadata-module=\"post\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/audit-logs\" track-metadata-module=\"post\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntegration\u003c/b\u003e\u003c/p\u003e\u003cp\u003eWhether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating\" track-metadata-module=\"post\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: connectivity to CI systems, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology#render\" track-metadata-module=\"post\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://cloud.google.com/pubsub\" track-metadata-module=\"post\"\u003ePub/Sub\u003c/a\u003e notifications to enable third-party integrations.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\" track-metadata-module=\"post\"\u003eConnecting Google Cloud Deploy\u003c/a\u003e to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple \u003ci\u003e`\u003c/i\u003e\u003ci\u003egcloud beta deploy releases create`.\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c15=\"\"\u003e\u003cdiv _ngcontent-c15=\"\" innerhtml=\"\u0026lt;p\u0026gt;Delivering to Kubernetes often changes over time. To help, Google Cloud Deploy\u0026amp;#160; leverages \u0026lt;a href=\u0026#34;https://skaffold.dev/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Skaffold\u0026lt;/a\u0026gt;, allowing you to \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/skaffold\u0026#34;\u0026gt;standardize your configuration\u0026lt;/a\u0026gt; between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u0026lt;a href=\u0026#34;https://helm.sh/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Helm\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://kustomize.io/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Kustomize\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://kpt.dev/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;kpt\u0026lt;/a\u0026gt;). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Finally, to facilitate other integrations, such as a \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\u0026#34;\u0026gt;post-deployment test execution\u0026lt;/a\u0026gt; or \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\u0026#34;\u0026gt;third party approval workflows\u0026lt;/a\u0026gt;, Google Cloud Deploy \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\u0026#34;\u0026gt;emits Pub/Sub messages\u0026lt;/a\u0026gt; throughout a \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\u0026#34;\u0026gt;release\u0026amp;#8217;s lifecycle\u0026lt;/a\u0026gt;.\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;The future\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Comprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it\u0026amp;#8217;s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we\u0026amp;#8217;re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In the meantime, to get started with the Preview, check out the \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy\u0026#34;\u0026gt;product page\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs\u0026#34;\u0026gt;documentation\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/quickstart-basic\u0026#34;\u0026gt;quickstart\u0026lt;/a\u0026gt;, and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/tutorials\u0026#34;\u0026gt;tutorials\u0026lt;/a\u0026gt;. Finally, If you have feedback on Google Cloud Deploy, you can \u0026lt;a href=\u0026#34;https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;join the conversation\u0026lt;/a\u0026gt;. We look forward to hearing from you!\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eDelivering to Kubernetes often changes over time. To help, Google Cloud Deploy  leverages \u003ca href=\"https://skaffold.dev/\" target=\"_blank\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://skaffold.dev\" track-metadata-module=\"post\"\u003eSkaffold\u003c/a\u003e, allowing you to \u003ca href=\"https://cloud.google.com/deploy/docs/skaffold\" track-type=\"inline link\" track-name=\"18\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/skaffold\" track-metadata-module=\"post\"\u003estandardize your configuration\u003c/a\u003e between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u003ca href=\"https://helm.sh/\" target=\"_blank\" track-type=\"inline link\" track-name=\"19\" track-metadata-eventdetail=\"https://helm.sh\" track-metadata-module=\"post\"\u003eHelm\u003c/a\u003e, \u003ca href=\"https://kustomize.io/\" target=\"_blank\" track-type=\"inline link\" track-name=\"20\" track-metadata-eventdetail=\"https://kustomize.io\" track-metadata-module=\"post\"\u003eKustomize\u003c/a\u003e, \u003ca href=\"https://kpt.dev/\" target=\"_blank\" track-type=\"inline link\" track-name=\"21\" track-metadata-eventdetail=\"https://kpt.dev\" track-metadata-module=\"post\"\u003ekpt\u003c/a\u003e). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u003c/p\u003e\u003cp\u003eFinally, to facilitate other integrations, such as a \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\" track-type=\"inline link\" track-name=\"22\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\" track-metadata-module=\"post\"\u003epost-deployment test execution\u003c/a\u003e or \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\" track-type=\"inline link\" track-name=\"23\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\" track-metadata-module=\"post\"\u003ethird party approval workflows\u003c/a\u003e, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\" track-type=\"inline link\" track-name=\"24\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\" track-metadata-module=\"post\"\u003eemits Pub/Sub messages\u003c/a\u003e throughout a \u003ca href=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\" track-type=\"inline link\" track-name=\"25\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\" track-metadata-module=\"post\"\u003erelease’s lifecycle\u003c/a\u003e.\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we’re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u003c/p\u003e\u003cp\u003eIn the meantime, to get started with the Preview, check out the \u003ca href=\"https://cloud.google.com/deploy\" track-type=\"inline link\" track-name=\"26\" track-metadata-eventdetail=\"https://cloud.google.com/deploy\" track-metadata-module=\"post\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\" track-type=\"inline link\" track-name=\"27\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs\" track-metadata-module=\"post\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\" track-type=\"inline link\" track-name=\"28\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/quickstart-basic\" track-metadata-module=\"post\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\" track-type=\"inline link\" track-name=\"29\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/tutorials\" track-metadata-module=\"post\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\" track-type=\"inline link\" track-name=\"30\" track-metadata-eventdetail=\"https://www.googlecloudcommunity.com\" track-metadata-module=\"post\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-video-block _nghost-c12=\"\"\u003e\u003cp _ngcontent-c12=\"\"\u003e\u003ciframe _ngcontent-c12=\"\" allow=\"encrypted-media\" allowfullscreen=\"\" frameborder=\"0\" height=\"100%\" position=\"absolute\" width=\"100%\" src=\"https://www.youtube.com/embed/Il8FlhR9jKM?enablejsapi=1\u0026amp;\"\u003e\u003c/iframe\u003e\u003c/p\u003e\u003c/article-video-block\u003e\u003c/div\u003e\u003c/article-content-stream-block\u003e\u003carticle-tag-list-block\u003e\u003c/article-tag-list-block\u003e\u003c/div\u003e\u003csection\u003e\u003carticle-up-1to3-block _nghost-c14=\"\"\u003e\u003c/article-up-1to3-block\u003e\u003c/section\u003e\u003c/div\u003e\u003c/article\u003e\u003c/main\u003e\u003c/article-page\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eContinuous delivery is frequently top-of-mind for organizations adopting \u003ca href=\"https://cloud.google.com/kubernetes-engine\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE). However, continuous delivery —deploying container image artifacts into your various environments—remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u003c/p\u003e\u003cp\u003eIt doesn’t have to be this way. \u003c/p\u003eToday, we are pleased to announce \u003ca href=\"https://cloud.google.com/deploy\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_2.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 2.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_2.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003cbr/\u003e\u003c/h3\u003e\u003cp\u003eGoogle Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u003c/p\u003e\u003cp\u003eLet’s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eTime and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current—to say nothing of maintenance—is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“We can’t afford to be innovating in continuous delivery,” one customer told us. “We want an opinionated product that supports best practices out of the box.”\u003c/i\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy addresses cost of ownership head-on.\u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\"\u003edeclaratively\u003c/a\u003e and are \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\"\u003estored alongside each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/cloud-deploy-pp-blog-post-3.gif\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy GIF\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/cloud-deploy-pp-blog-post-3.gif\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWe have found that a variety of GKE roles and personas interact with continuous delivery processes. A DevOps engineer may be focused on release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application\"\u003epromotion and rollback\u003c/a\u003e decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_1.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 1.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_1.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003eContextualized deployment approvals\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003cb\u003eSecurity and audit\u003c/b\u003e\u003c/p\u003e\u003cp\u003eLots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained restriction, with \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\"\u003ediscrete resource access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\"\u003eexecution-level security\u003c/a\u003e. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\"\u003eapprovals\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntegration\u003c/b\u003e\u003c/p\u003e\u003cp\u003eWhether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: connectivity to CI systems, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\"\u003ePub/Sub\u003c/a\u003e notifications to enable third-party integrations.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\"\u003eConnecting Google Cloud Deploy\u003c/a\u003e to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple \u003ci\u003e`\u003c/i\u003e\u003ci\u003egcloud beta deploy releases create`.\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deployt_3_efyUGIq.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 3.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deployt_3_efyUGIq.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eDelivering to Kubernetes often changes over time. To help, Google Cloud Deploy  leverages \u003ca href=\"https://skaffold.dev/\" target=\"_blank\"\u003eSkaffold\u003c/a\u003e, allowing you to \u003ca href=\"https://cloud.google.com/deploy/docs/skaffold\"\u003estandardize your configuration\u003c/a\u003e between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u003ca href=\"https://helm.sh/\" target=\"_blank\"\u003eHelm\u003c/a\u003e, \u003ca href=\"https://kustomize.io/\" target=\"_blank\"\u003eKustomize\u003c/a\u003e, \u003ca href=\"https://kpt.dev/\" target=\"_blank\"\u003ekpt\u003c/a\u003e). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u003c/p\u003e\u003cp\u003eFinally, to facilitate other integrations, such as a \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\"\u003epost-deployment test execution\u003c/a\u003e or \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\"\u003ethird party approval workflows\u003c/a\u003e, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\"\u003eemits Pub/Sub messages\u003c/a\u003e throughout a \u003ca href=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\"\u003erelease’s lifecycle\u003c/a\u003e.\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we’re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u003c/p\u003e\u003cp\u003eIn the meantime, to get started with the Preview, check out the \u003ca href=\"https://cloud.google.com/deploy\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-video\"\u003e\u003cdiv class=\"article-module article-video \"\u003e\u003cfigure\u003e\u003ca class=\"h-c-video h-c-video--marquee\" data-glue-modal-disabled-on-mobile=\"true\" data-glue-modal-trigger=\"uni-modal-Il8FlhR9jKM-\" href=\"https://youtube.com/watch?v=Il8FlhR9jKM\"\u003e\u003cimg alt=\"Introducing Cloud Deploy\" src=\"//img.youtube.com/vi/Il8FlhR9jKM/maxresdefault.jpg\"/\u003e\u003csvg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" role=\"img\"\u003e\u003cuse xlink:href=\"#mi-youtube-icon\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv class=\"h-c-modal--video\" data-glue-modal=\"uni-modal-Il8FlhR9jKM-\" data-glue-modal-close-label=\"Close Dialog\"\u003e\u003ca class=\"glue-yt-video\" data-glue-yt-video-autoplay=\"true\" data-glue-yt-video-height=\"99%\" data-glue-yt-video-vid=\"Il8FlhR9jKM\" data-glue-yt-video-width=\"100%\" href=\"https://youtube.com/watch?v=Il8FlhR9jKM\" ng-cloak=\"\"\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/announcing-dora-2021-accelerate-state-of-devops-report/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/SODR2021_1920x1080.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e2021 Accelerate State of DevOps report addresses burnout, team performance\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eThe SODR is continually one of the most downloaded assets on the GCP website. We are releasing the updated version of the report with new...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/gcp_ZPje3k8.max-2200x2200.jpg",
      "date_published": "2021-09-22T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eS. Bogdan\u003c/name\u003e\u003ctitle\u003eProduct Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/google-cloud-deploy-automates-deploys-to-gke/",
      "title": "Introducing Google Cloud Deploy: Managed continuous delivery to GKE",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle-page\u003e\u003cmain id=\"jump-content\"\u003e\u003carticle\u003e\u003carticle-header-block\u003e\u003c/article-header-block\u003e\u003carticle-aspect-image-block\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003e#gcp\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/article-aspect-image-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-author-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003e S. Bogdan \u003c/p\u003e\u003cp\u003e Product Manager \u003c/p\u003e\u003c/div\u003e\u003cp\u003e\u003cspan\u003e September 22, 2021 \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-author-block\u003e\u003c/div\u003e\u003carticle-cta _nghost-c46=\"\"\u003e\u003cdiv _ngcontent-c46=\"\"\u003e\u003ch4 _ngcontent-c46=\"\"\u003e\u003cspan _ngcontent-c46=\"\"\u003eNext ’21 registration is open\u003c/span\u003e\u003c/h4\u003e\u003cp _ngcontent-c46=\"\"\u003e\u003cspan _ngcontent-c46=\"\"\u003eJoin us October 12–14, 2021, for our digital flagship event\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003ca _ngcontent-c46=\"\" clicktracker=\"\" rel=\"external\" track-metadata-module=\"article cta\" track-type=\"button\" track-name=\"Next21 registration\" track-metadata-eventdetail=\"https://cloud.withgoogle.com/next/register?utm_source=google\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY21-Q4-global-ES903-onlineevent-er-next-2021\u0026amp;utm_content=blog-next-21-registration\" href=\"https://cloud.withgoogle.com/next/register?utm_source=google\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY21-Q4-global-ES903-onlineevent-er-next-2021\u0026amp;utm_content=blog-next-21-registration\"\u003e\u003cspan _ngcontent-c46=\"\"\u003eRegister now\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-cta\u003e\u003c/div\u003e\u003carticle-share-block\u003e\u003c/article-share-block\u003e\u003carticle-sticky-share-block\u003e\u003c/article-sticky-share-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-content-stream-block\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c48=\"\"\u003e\u003cdiv _ngcontent-c48=\"\" innerhtml=\"\u0026lt;p\u0026gt;Continuous delivery is frequently top-of-mind for organizations adopting \u0026lt;a href=\u0026#34;https://cloud.google.com/kubernetes-engine\u0026#34;\u0026gt;Google Kubernetes Engine\u0026lt;/a\u0026gt; (GKE). However, continuous delivery \u0026amp;#8212;deploying container image artifacts into your various environments\u0026amp;#8212;remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;It doesn\u0026amp;#8217;t have to be this way.\u0026amp;#160;\u0026lt;/p\u0026gt;Today, we are pleased to announce \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy\u0026#34;\u0026gt;Google Cloud Deploy\u0026lt;/a\u0026gt;, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eContinuous delivery is frequently top-of-mind for organizations adopting \u003ca href=\"https://cloud.google.com/kubernetes-engine\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/kubernetes-engine\" track-metadata-module=\"post\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE). However, continuous delivery —deploying container image artifacts into your various environments—remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u003c/p\u003e\u003cp\u003eIt doesn’t have to be this way. \u003c/p\u003e\u003cp\u003eToday, we are pleased to announce \u003ca href=\"https://cloud.google.com/deploy\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/deploy\" track-metadata-module=\"post\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c48=\"\"\u003e\u003cdiv _ngcontent-c48=\"\" innerhtml=\"\u0026lt;h3\u0026gt;Solving for continuous delivery challenges\u0026lt;br\u0026gt;\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Let\u0026amp;#8217;s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Cost of ownership\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Time and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current\u0026amp;#8212;to say nothing of maintenance\u0026amp;#8212;is resource-intensive and takes time away from the core business.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;\u0026amp;#8220;We can\u0026amp;#8217;t afford to be innovating in continuous delivery,\u0026amp;#8221; one customer told us. \u0026amp;#8220;We want an opinionated product that supports best practices out of the box.\u0026amp;#8221;\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy addresses cost of ownership head-on.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;As a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy also provides structure. \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\u0026#34;\u0026gt;Delivery pipelines\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology\u0026#34;\u0026gt;targets\u0026lt;/a\u0026gt; are defined \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/config-files\u0026#34;\u0026gt;declaratively\u0026lt;/a\u0026gt; and are \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/pipeline-instances\u0026#34;\u0026gt;stored alongside each release\u0026lt;/a\u0026gt;. That means if your delivery pipeline changes, the release\u0026amp;#8217;s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003cbr/\u003e\u003c/h3\u003e\u003cp\u003eGoogle Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u003c/p\u003e\u003cp\u003eLet’s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eTime and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current—to say nothing of maintenance—is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“We can’t afford to be innovating in continuous delivery,” one customer told us. “We want an opinionated product that supports best practices out of the box.”\u003c/i\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy addresses cost of ownership head-on.\u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\" track-metadata-module=\"post\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology\" track-metadata-module=\"post\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/config-files\" track-metadata-module=\"post\"\u003edeclaratively\u003c/a\u003e and are \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/pipeline-instances\" track-metadata-module=\"post\"\u003estored alongside each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c48=\"\"\u003e\u003cp\u003eWe have found that a variety of GKE roles and personas interact with continuous delivery processes. A DevOps engineer may be focused on release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/deploying-application\" track-metadata-module=\"post\"\u003epromotion and rollback\u003c/a\u003e decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003cbr/\u003e\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c48=\"\"\u003e\u003cdiv _ngcontent-c48=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Security and audit\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Lots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn\u0026amp;#8217;t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Throughout, Google Cloud Deploy enables fine-grained restriction, with \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/iam-roles-permissions\u0026#34;\u0026gt;discrete resource access control\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/execution-environment\u0026#34;\u0026gt;execution-level security\u0026lt;/a\u0026gt;. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\u0026#34;\u0026gt;approvals\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Auditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u0026lt;a href=\u0026#34;https://cloud.google.com/audit-logs\u0026#34;\u0026gt;Cloud Audit Logs\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/audit-logs\u0026#34;\u0026gt;audits\u0026lt;/a\u0026gt; user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Integration\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Whether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating\u0026#34;\u0026gt;embraces the GKE delivery tooling ecosystems\u0026lt;/a\u0026gt; in three ways: connectivity to CI systems, support for leading configuration (\u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology#render\u0026#34;\u0026gt;rendering\u0026lt;/a\u0026gt;) tooling, and \u0026lt;a href=\u0026#34;https://cloud.google.com/pubsub\u0026#34;\u0026gt;Pub/Sub\u0026lt;/a\u0026gt; notifications to enable third-party integrations.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\u0026#34;\u0026gt;Connecting Google Cloud Deploy\u0026lt;/a\u0026gt; to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple\u0026amp;#160;\u0026lt;i\u0026gt;`\u0026lt;/i\u0026gt;\u0026lt;i\u0026gt;gcloud beta deploy releases create`.\u0026lt;/i\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e\u003cb\u003eSecurity and audit\u003c/b\u003e\u003c/p\u003e\u003cp\u003eLots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained restriction, with \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\" track-metadata-module=\"post\"\u003ediscrete resource access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/execution-environment\" track-metadata-module=\"post\"\u003eexecution-level security\u003c/a\u003e. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\" track-metadata-module=\"post\"\u003eapprovals\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/audit-logs\" track-metadata-module=\"post\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/audit-logs\" track-metadata-module=\"post\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntegration\u003c/b\u003e\u003c/p\u003e\u003cp\u003eWhether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating\" track-metadata-module=\"post\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: connectivity to CI systems, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology#render\" track-metadata-module=\"post\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://cloud.google.com/pubsub\" track-metadata-module=\"post\"\u003ePub/Sub\u003c/a\u003e notifications to enable third-party integrations.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\" track-metadata-module=\"post\"\u003eConnecting Google Cloud Deploy\u003c/a\u003e to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple \u003ci\u003e`\u003c/i\u003e\u003ci\u003egcloud beta deploy releases create`.\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c48=\"\"\u003e\u003cdiv _ngcontent-c48=\"\" innerhtml=\"\u0026lt;p\u0026gt;Delivering to Kubernetes often changes over time. To help, Google Cloud Deploy\u0026amp;#160; leverages \u0026lt;a href=\u0026#34;https://skaffold.dev/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Skaffold\u0026lt;/a\u0026gt;, allowing you to \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/skaffold\u0026#34;\u0026gt;standardize your configuration\u0026lt;/a\u0026gt; between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u0026lt;a href=\u0026#34;https://helm.sh/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Helm\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://kustomize.io/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Kustomize\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://kpt.dev/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;kpt\u0026lt;/a\u0026gt;). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Finally, to facilitate other integrations, such as a \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\u0026#34;\u0026gt;post-deployment test execution\u0026lt;/a\u0026gt; or \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\u0026#34;\u0026gt;third party approval workflows\u0026lt;/a\u0026gt;, Google Cloud Deploy \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\u0026#34;\u0026gt;emits Pub/Sub messages\u0026lt;/a\u0026gt; throughout a \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\u0026#34;\u0026gt;release\u0026amp;#8217;s lifecycle\u0026lt;/a\u0026gt;.\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;The future\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Comprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it\u0026amp;#8217;s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we\u0026amp;#8217;re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In the meantime, to get started with the Preview, check out the \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy\u0026#34;\u0026gt;product page\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs\u0026#34;\u0026gt;documentation\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/quickstart-basic\u0026#34;\u0026gt;quickstart\u0026lt;/a\u0026gt;, and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/tutorials\u0026#34;\u0026gt;tutorials\u0026lt;/a\u0026gt;. Finally, If you have feedback on Google Cloud Deploy, you can \u0026lt;a href=\u0026#34;https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;join the conversation\u0026lt;/a\u0026gt;. We look forward to hearing from you!\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eDelivering to Kubernetes often changes over time. To help, Google Cloud Deploy  leverages \u003ca href=\"https://skaffold.dev/\" target=\"_blank\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://skaffold.dev\" track-metadata-module=\"post\"\u003eSkaffold\u003c/a\u003e, allowing you to \u003ca href=\"https://cloud.google.com/deploy/docs/skaffold\" track-type=\"inline link\" track-name=\"18\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/skaffold\" track-metadata-module=\"post\"\u003estandardize your configuration\u003c/a\u003e between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u003ca href=\"https://helm.sh/\" target=\"_blank\" track-type=\"inline link\" track-name=\"19\" track-metadata-eventdetail=\"https://helm.sh\" track-metadata-module=\"post\"\u003eHelm\u003c/a\u003e, \u003ca href=\"https://kustomize.io/\" target=\"_blank\" track-type=\"inline link\" track-name=\"20\" track-metadata-eventdetail=\"https://kustomize.io\" track-metadata-module=\"post\"\u003eKustomize\u003c/a\u003e, \u003ca href=\"https://kpt.dev/\" target=\"_blank\" track-type=\"inline link\" track-name=\"21\" track-metadata-eventdetail=\"https://kpt.dev\" track-metadata-module=\"post\"\u003ekpt\u003c/a\u003e). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u003c/p\u003e\u003cp\u003eFinally, to facilitate other integrations, such as a \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\" track-type=\"inline link\" track-name=\"22\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\" track-metadata-module=\"post\"\u003epost-deployment test execution\u003c/a\u003e or \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\" track-type=\"inline link\" track-name=\"23\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\" track-metadata-module=\"post\"\u003ethird party approval workflows\u003c/a\u003e, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\" track-type=\"inline link\" track-name=\"24\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\" track-metadata-module=\"post\"\u003eemits Pub/Sub messages\u003c/a\u003e throughout a \u003ca href=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\" track-type=\"inline link\" track-name=\"25\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\" track-metadata-module=\"post\"\u003erelease’s lifecycle\u003c/a\u003e.\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we’re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u003c/p\u003e\u003cp\u003eIn the meantime, to get started with the Preview, check out the \u003ca href=\"https://cloud.google.com/deploy\" track-type=\"inline link\" track-name=\"26\" track-metadata-eventdetail=\"https://cloud.google.com/deploy\" track-metadata-module=\"post\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\" track-type=\"inline link\" track-name=\"27\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs\" track-metadata-module=\"post\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\" track-type=\"inline link\" track-name=\"28\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/quickstart-basic\" track-metadata-module=\"post\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\" track-type=\"inline link\" track-name=\"29\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/tutorials\" track-metadata-module=\"post\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\" track-type=\"inline link\" track-name=\"30\" track-metadata-eventdetail=\"https://www.googlecloudcommunity.com\" track-metadata-module=\"post\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-video-block _nghost-c45=\"\"\u003e\u003cp _ngcontent-c45=\"\"\u003e\u003ciframe _ngcontent-c45=\"\" allow=\"encrypted-media\" allowfullscreen=\"\" frameborder=\"0\" height=\"100%\" position=\"absolute\" width=\"100%\" src=\"https://www.youtube.com/embed/Il8FlhR9jKM?enablejsapi=1\u0026amp;\"\u003e\u003c/iframe\u003e\u003c/p\u003e\u003c/article-video-block\u003e\u003c/div\u003e\u003c/article-content-stream-block\u003e\u003carticle-tag-list-block\u003e\u003c/article-tag-list-block\u003e\u003c/div\u003e\u003csection\u003e\u003carticle-up-1to3-block _nghost-c47=\"\"\u003e\u003c/article-up-1to3-block\u003e\u003c/section\u003e\u003c/div\u003e\u003c/article\u003e\u003c/main\u003e\u003c/article-page\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eContinuous delivery is frequently top-of-mind for organizations adopting \u003ca href=\"https://cloud.google.com/kubernetes-engine\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE). However, continuous delivery —deploying container image artifacts into your various environments—remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u003c/p\u003e\u003cp\u003eIt doesn’t have to be this way. \u003c/p\u003eToday, we are pleased to announce \u003ca href=\"https://cloud.google.com/deploy\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_2.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 2.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_2.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003cbr/\u003e\u003c/h3\u003e\u003cp\u003eGoogle Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u003c/p\u003e\u003cp\u003eLet’s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eTime and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current—to say nothing of maintenance—is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“We can’t afford to be innovating in continuous delivery,” one customer told us. “We want an opinionated product that supports best practices out of the box.”\u003c/i\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy addresses cost of ownership head-on.\u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\"\u003edeclaratively\u003c/a\u003e and are \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\"\u003estored alongside each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/cloud-deploy-pp-blog-post-3.gif\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy GIF\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/cloud-deploy-pp-blog-post-3.gif\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWe have found that a variety of GKE roles and personas interact with continuous delivery processes. A DevOps engineer may be focused on release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application\"\u003epromotion and rollback\u003c/a\u003e decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_1.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 1.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_1.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003eContextualized deployment approvals\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003cb\u003eSecurity and audit\u003c/b\u003e\u003c/p\u003e\u003cp\u003eLots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained restriction, with \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\"\u003ediscrete resource access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\"\u003eexecution-level security\u003c/a\u003e. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\"\u003eapprovals\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntegration\u003c/b\u003e\u003c/p\u003e\u003cp\u003eWhether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: connectivity to CI systems, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\"\u003ePub/Sub\u003c/a\u003e notifications to enable third-party integrations.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\"\u003eConnecting Google Cloud Deploy\u003c/a\u003e to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple \u003ci\u003e`\u003c/i\u003e\u003ci\u003egcloud beta deploy releases create`.\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deployt_3_efyUGIq.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 3.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deployt_3_efyUGIq.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eDelivering to Kubernetes often changes over time. To help, Google Cloud Deploy  leverages \u003ca href=\"https://skaffold.dev/\" target=\"_blank\"\u003eSkaffold\u003c/a\u003e, allowing you to \u003ca href=\"https://cloud.google.com/deploy/docs/skaffold\"\u003estandardize your configuration\u003c/a\u003e between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u003ca href=\"https://helm.sh/\" target=\"_blank\"\u003eHelm\u003c/a\u003e, \u003ca href=\"https://kustomize.io/\" target=\"_blank\"\u003eKustomize\u003c/a\u003e, \u003ca href=\"https://kpt.dev/\" target=\"_blank\"\u003ekpt\u003c/a\u003e). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u003c/p\u003e\u003cp\u003eFinally, to facilitate other integrations, such as a \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\"\u003epost-deployment test execution\u003c/a\u003e or \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\"\u003ethird party approval workflows\u003c/a\u003e, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\"\u003eemits Pub/Sub messages\u003c/a\u003e throughout a \u003ca href=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\"\u003erelease’s lifecycle\u003c/a\u003e.\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we’re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u003c/p\u003e\u003cp\u003eIn the meantime, to get started with the Preview, check out the \u003ca href=\"https://cloud.google.com/deploy\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-video\"\u003e\u003cdiv class=\"article-module article-video \"\u003e\u003cfigure\u003e\u003ca class=\"h-c-video h-c-video--marquee\" data-glue-modal-disabled-on-mobile=\"true\" data-glue-modal-trigger=\"uni-modal-Il8FlhR9jKM-\" href=\"https://youtube.com/watch?v=Il8FlhR9jKM\"\u003e\u003cimg alt=\"Introducing Cloud Deploy\" src=\"//img.youtube.com/vi/Il8FlhR9jKM/maxresdefault.jpg\"/\u003e\u003csvg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" role=\"img\"\u003e\u003cuse xlink:href=\"#mi-youtube-icon\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv class=\"h-c-modal--video\" data-glue-modal=\"uni-modal-Il8FlhR9jKM-\" data-glue-modal-close-label=\"Close Dialog\"\u003e\u003ca class=\"glue-yt-video\" data-glue-yt-video-autoplay=\"true\" data-glue-yt-video-height=\"99%\" data-glue-yt-video-vid=\"Il8FlhR9jKM\" data-glue-yt-video-width=\"100%\" href=\"https://youtube.com/watch?v=Il8FlhR9jKM\" ng-cloak=\"\"\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/announcing-dora-2021-accelerate-state-of-devops-report/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/SODR2021_1920x1080.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e2021 Accelerate State of DevOps report addresses burnout, team performance\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eThe SODR is continually one of the most downloaded assets on the GCP website. We are releasing the updated version of the report with new...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/gcp_ZPje3k8.max-2200x2200.jpg",
      "date_published": "2021-09-22T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eS. Bogdan\u003c/name\u003e\u003ctitle\u003eProduct Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/google-cloud-deploy-automates-deploys-to-gke/",
      "title": "Introducing Google Cloud Deploy: Managed continuous delivery to GKE",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eContinuous delivery is frequently top-of-mind for organizations adopting \u003ca href=\"https://cloud.google.com/kubernetes-engine\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE). However, continuous delivery —deploying container image artifacts into your various environments—remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u003c/p\u003e\u003cp\u003eIt doesn’t have to be this way. \u003c/p\u003eToday, we are pleased to announce \u003ca href=\"https://cloud.google.com/deploy\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_2.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 2.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_2.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003cbr/\u003e\u003c/h3\u003e\u003cp\u003eGoogle Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u003c/p\u003e\u003cp\u003eLet’s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eTime and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current—to say nothing of maintenance—is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“We can’t afford to be innovating in continuous delivery,” one customer told us. “We want an opinionated product that supports best practices out of the box.”\u003c/i\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy addresses cost of ownership head-on.\u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\"\u003edeclaratively\u003c/a\u003e and are \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\"\u003estored alongside each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/cloud-deploy-pp-blog-post-3.gif\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy GIF\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/cloud-deploy-pp-blog-post-3.gif\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWe have found that a variety of GKE roles and personas interact with continuous delivery processes. A DevOps engineer may be focused on release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application\"\u003epromotion and rollback\u003c/a\u003e decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_1.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 1.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_1.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003eContextualized deployment approvals\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003cb\u003eSecurity and audit\u003c/b\u003e\u003c/p\u003e\u003cp\u003eLots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained restriction, with \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\"\u003ediscrete resource access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\"\u003eexecution-level security\u003c/a\u003e. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\"\u003eapprovals\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntegration\u003c/b\u003e\u003c/p\u003e\u003cp\u003eWhether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: connectivity to CI systems, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\"\u003ePub/Sub\u003c/a\u003e notifications to enable third-party integrations.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\"\u003eConnecting Google Cloud Deploy\u003c/a\u003e to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple \u003ci\u003e`\u003c/i\u003e\u003ci\u003egcloud beta deploy releases create`.\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deployt_3_efyUGIq.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 3.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deployt_3_efyUGIq.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eDelivering to Kubernetes often changes over time. To help, Google Cloud Deploy  leverages \u003ca href=\"https://skaffold.dev/\" target=\"_blank\"\u003eSkaffold\u003c/a\u003e, allowing you to \u003ca href=\"https://cloud.google.com/deploy/docs/skaffold\"\u003estandardize your configuration\u003c/a\u003e between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u003ca href=\"https://helm.sh/\" target=\"_blank\"\u003eHelm\u003c/a\u003e, \u003ca href=\"https://kustomize.io/\" target=\"_blank\"\u003eKustomize\u003c/a\u003e, \u003ca href=\"https://kpt.dev/\" target=\"_blank\"\u003ekpt\u003c/a\u003e). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u003c/p\u003e\u003cp\u003eFinally, to facilitate other integrations, such as a \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\"\u003epost-deployment test execution\u003c/a\u003e or \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\"\u003ethird party approval workflows\u003c/a\u003e, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\"\u003eemits Pub/Sub messages\u003c/a\u003e throughout a \u003ca href=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\"\u003erelease’s lifecycle\u003c/a\u003e.\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we’re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u003c/p\u003e\u003cp\u003eIn the meantime, to get started with the Preview, check out the \u003ca href=\"https://cloud.google.com/deploy\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-video\"\u003e\u003cdiv class=\"article-module article-video \"\u003e\u003cfigure\u003e\u003ca class=\"h-c-video h-c-video--marquee\" data-glue-modal-disabled-on-mobile=\"true\" data-glue-modal-trigger=\"uni-modal-Il8FlhR9jKM-\" href=\"https://youtube.com/watch?v=Il8FlhR9jKM\"\u003e\u003cimg alt=\"Introducing Cloud Deploy\" src=\"//img.youtube.com/vi/Il8FlhR9jKM/maxresdefault.jpg\"/\u003e\u003csvg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" role=\"img\"\u003e\u003cuse xlink:href=\"#mi-youtube-icon\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv class=\"h-c-modal--video\" data-glue-modal=\"uni-modal-Il8FlhR9jKM-\" data-glue-modal-close-label=\"Close Dialog\"\u003e\u003ca class=\"glue-yt-video\" data-glue-yt-video-autoplay=\"true\" data-glue-yt-video-height=\"99%\" data-glue-yt-video-vid=\"Il8FlhR9jKM\" data-glue-yt-video-width=\"100%\" href=\"https://youtube.com/watch?v=Il8FlhR9jKM\" ng-cloak=\"\"\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/announcing-dora-2021-accelerate-state-of-devops-report/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/SODR2021_1920x1080.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e2021 Accelerate State of DevOps report addresses burnout, team performance\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eThe SODR is continually one of the most downloaded assets on the GCP website. We are releasing the updated version of the report with new...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/original_images/gcp_ZPje3k8.jpg",
      "date_published": "2021-09-22T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eS. Bogdan\u003c/name\u003e\u003ctitle\u003eProduct Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/google-cloud-deploy-automates-deploys-to-gke/",
      "title": "Introducing Google Cloud Deploy: Managed continuous delivery to GKE",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle-page\u003e\u003cmain id=\"jump-content\"\u003e\u003carticle\u003e\u003carticle-header-block\u003e\u003c/article-header-block\u003e\u003carticle-aspect-image-block\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003e#gcp\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/article-aspect-image-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-author-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003e S. Bogdan \u003c/p\u003e\u003cp\u003e Product Manager \u003c/p\u003e\u003c/div\u003e\u003cp\u003e\u003cspan\u003e September 22, 2021 \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-author-block\u003e\u003c/div\u003e\u003carticle-cta _nghost-c17=\"\"\u003e\u003cdiv _ngcontent-c17=\"\"\u003e\u003ch4 _ngcontent-c17=\"\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eNext ’21 registration is open\u003c/span\u003e\u003c/h4\u003e\u003cp _ngcontent-c17=\"\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eJoin us October 12–14, 2021, for our digital flagship event\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003ca _ngcontent-c17=\"\" clicktracker=\"\" rel=\"external\" track-metadata-module=\"article cta\" track-type=\"button\" track-name=\"Next21 registration\" track-metadata-eventdetail=\"https://cloud.withgoogle.com/next/register?utm_source=google\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY21-Q4-global-ES903-onlineevent-er-next-2021\u0026amp;utm_content=blog-next-21-registration\" href=\"https://cloud.withgoogle.com/next/register?utm_source=google\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY21-Q4-global-ES903-onlineevent-er-next-2021\u0026amp;utm_content=blog-next-21-registration\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eRegister now\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-cta\u003e\u003c/div\u003e\u003carticle-share-block\u003e\u003c/article-share-block\u003e\u003carticle-sticky-share-block\u003e\u003c/article-sticky-share-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-content-stream-block\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Continuous delivery is frequently top-of-mind for organizations adopting \u0026lt;a href=\u0026#34;https://cloud.google.com/kubernetes-engine\u0026#34;\u0026gt;Google Kubernetes Engine\u0026lt;/a\u0026gt; (GKE). However, continuous delivery \u0026amp;#8212;deploying container image artifacts into your various environments\u0026amp;#8212;remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;It doesn\u0026amp;#8217;t have to be this way.\u0026amp;#160;\u0026lt;/p\u0026gt;Today, we are pleased to announce \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy\u0026#34;\u0026gt;Google Cloud Deploy\u0026lt;/a\u0026gt;, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eContinuous delivery is frequently top-of-mind for organizations adopting \u003ca href=\"https://cloud.google.com/kubernetes-engine\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/kubernetes-engine\" track-metadata-module=\"post\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE). However, continuous delivery —deploying container image artifacts into your various environments—remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u003c/p\u003e\u003cp\u003eIt doesn’t have to be this way. \u003c/p\u003e\u003cp\u003eToday, we are pleased to announce \u003ca href=\"https://cloud.google.com/deploy\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/deploy\" track-metadata-module=\"post\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;h3\u0026gt;Solving for continuous delivery challenges\u0026lt;br\u0026gt;\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Let\u0026amp;#8217;s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Cost of ownership\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Time and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current\u0026amp;#8212;to say nothing of maintenance\u0026amp;#8212;is resource-intensive and takes time away from the core business.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;\u0026amp;#8220;We can\u0026amp;#8217;t afford to be innovating in continuous delivery,\u0026amp;#8221; one customer told us. \u0026amp;#8220;We want an opinionated product that supports best practices out of the box.\u0026amp;#8221;\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy addresses cost of ownership head-on.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;As a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy also provides structure. \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\u0026#34;\u0026gt;Delivery pipelines\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology\u0026#34;\u0026gt;targets\u0026lt;/a\u0026gt; are defined \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/config-files\u0026#34;\u0026gt;declaratively\u0026lt;/a\u0026gt; and are \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/pipeline-instances\u0026#34;\u0026gt;stored alongside each release\u0026lt;/a\u0026gt;. That means if your delivery pipeline changes, the release\u0026amp;#8217;s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003cbr/\u003e\u003c/h3\u003e\u003cp\u003eGoogle Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u003c/p\u003e\u003cp\u003eLet’s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eTime and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current—to say nothing of maintenance—is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“We can’t afford to be innovating in continuous delivery,” one customer told us. “We want an opinionated product that supports best practices out of the box.”\u003c/i\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy addresses cost of ownership head-on.\u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\" track-metadata-module=\"post\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology\" track-metadata-module=\"post\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/config-files\" track-metadata-module=\"post\"\u003edeclaratively\u003c/a\u003e and are \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/pipeline-instances\" track-metadata-module=\"post\"\u003estored alongside each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cp\u003eWe have found that a variety of GKE roles and personas interact with continuous delivery processes. A DevOps engineer may be focused on release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/deploying-application\" track-metadata-module=\"post\"\u003epromotion and rollback\u003c/a\u003e decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003cbr/\u003e\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Security and audit\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Lots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn\u0026amp;#8217;t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Throughout, Google Cloud Deploy enables fine-grained restriction, with \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/iam-roles-permissions\u0026#34;\u0026gt;discrete resource access control\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/execution-environment\u0026#34;\u0026gt;execution-level security\u0026lt;/a\u0026gt;. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\u0026#34;\u0026gt;approvals\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Auditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u0026lt;a href=\u0026#34;https://cloud.google.com/audit-logs\u0026#34;\u0026gt;Cloud Audit Logs\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/audit-logs\u0026#34;\u0026gt;audits\u0026lt;/a\u0026gt; user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Integration\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Whether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating\u0026#34;\u0026gt;embraces the GKE delivery tooling ecosystems\u0026lt;/a\u0026gt; in three ways: connectivity to CI systems, support for leading configuration (\u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology#render\u0026#34;\u0026gt;rendering\u0026lt;/a\u0026gt;) tooling, and \u0026lt;a href=\u0026#34;https://cloud.google.com/pubsub\u0026#34;\u0026gt;Pub/Sub\u0026lt;/a\u0026gt; notifications to enable third-party integrations.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\u0026#34;\u0026gt;Connecting Google Cloud Deploy\u0026lt;/a\u0026gt; to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple\u0026amp;#160;\u0026lt;i\u0026gt;`\u0026lt;/i\u0026gt;\u0026lt;i\u0026gt;gcloud beta deploy releases create`.\u0026lt;/i\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e\u003cb\u003eSecurity and audit\u003c/b\u003e\u003c/p\u003e\u003cp\u003eLots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained restriction, with \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\" track-metadata-module=\"post\"\u003ediscrete resource access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/execution-environment\" track-metadata-module=\"post\"\u003eexecution-level security\u003c/a\u003e. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\" track-metadata-module=\"post\"\u003eapprovals\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/audit-logs\" track-metadata-module=\"post\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/audit-logs\" track-metadata-module=\"post\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntegration\u003c/b\u003e\u003c/p\u003e\u003cp\u003eWhether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating\" track-metadata-module=\"post\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: connectivity to CI systems, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology#render\" track-metadata-module=\"post\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://cloud.google.com/pubsub\" track-metadata-module=\"post\"\u003ePub/Sub\u003c/a\u003e notifications to enable third-party integrations.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\" track-metadata-module=\"post\"\u003eConnecting Google Cloud Deploy\u003c/a\u003e to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple \u003ci\u003e`\u003c/i\u003e\u003ci\u003egcloud beta deploy releases create`.\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Delivering to Kubernetes often changes over time. To help, Google Cloud Deploy\u0026amp;#160; leverages \u0026lt;a href=\u0026#34;https://skaffold.dev/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Skaffold\u0026lt;/a\u0026gt;, allowing you to \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/skaffold\u0026#34;\u0026gt;standardize your configuration\u0026lt;/a\u0026gt; between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u0026lt;a href=\u0026#34;https://helm.sh/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Helm\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://kustomize.io/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Kustomize\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://kpt.dev/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;kpt\u0026lt;/a\u0026gt;). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Finally, to facilitate other integrations, such as a \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\u0026#34;\u0026gt;post-deployment test execution\u0026lt;/a\u0026gt; or \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\u0026#34;\u0026gt;third party approval workflows\u0026lt;/a\u0026gt;, Google Cloud Deploy \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\u0026#34;\u0026gt;emits Pub/Sub messages\u0026lt;/a\u0026gt; throughout a \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\u0026#34;\u0026gt;release\u0026amp;#8217;s lifecycle\u0026lt;/a\u0026gt;.\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;The future\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Comprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it\u0026amp;#8217;s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we\u0026amp;#8217;re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In the meantime, to get started with the Preview, check out the \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy\u0026#34;\u0026gt;product page\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs\u0026#34;\u0026gt;documentation\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/quickstart-basic\u0026#34;\u0026gt;quickstart\u0026lt;/a\u0026gt;, and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/tutorials\u0026#34;\u0026gt;tutorials\u0026lt;/a\u0026gt;. Finally, If you have feedback on Google Cloud Deploy, you can \u0026lt;a href=\u0026#34;https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;join the conversation\u0026lt;/a\u0026gt;. We look forward to hearing from you!\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eDelivering to Kubernetes often changes over time. To help, Google Cloud Deploy  leverages \u003ca href=\"https://skaffold.dev/\" target=\"_blank\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://skaffold.dev\" track-metadata-module=\"post\"\u003eSkaffold\u003c/a\u003e, allowing you to \u003ca href=\"https://cloud.google.com/deploy/docs/skaffold\" track-type=\"inline link\" track-name=\"18\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/skaffold\" track-metadata-module=\"post\"\u003estandardize your configuration\u003c/a\u003e between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u003ca href=\"https://helm.sh/\" target=\"_blank\" track-type=\"inline link\" track-name=\"19\" track-metadata-eventdetail=\"https://helm.sh\" track-metadata-module=\"post\"\u003eHelm\u003c/a\u003e, \u003ca href=\"https://kustomize.io/\" target=\"_blank\" track-type=\"inline link\" track-name=\"20\" track-metadata-eventdetail=\"https://kustomize.io\" track-metadata-module=\"post\"\u003eKustomize\u003c/a\u003e, \u003ca href=\"https://kpt.dev/\" target=\"_blank\" track-type=\"inline link\" track-name=\"21\" track-metadata-eventdetail=\"https://kpt.dev\" track-metadata-module=\"post\"\u003ekpt\u003c/a\u003e). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u003c/p\u003e\u003cp\u003eFinally, to facilitate other integrations, such as a \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\" track-type=\"inline link\" track-name=\"22\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\" track-metadata-module=\"post\"\u003epost-deployment test execution\u003c/a\u003e or \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\" track-type=\"inline link\" track-name=\"23\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\" track-metadata-module=\"post\"\u003ethird party approval workflows\u003c/a\u003e, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\" track-type=\"inline link\" track-name=\"24\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\" track-metadata-module=\"post\"\u003eemits Pub/Sub messages\u003c/a\u003e throughout a \u003ca href=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\" track-type=\"inline link\" track-name=\"25\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\" track-metadata-module=\"post\"\u003erelease’s lifecycle\u003c/a\u003e.\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we’re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u003c/p\u003e\u003cp\u003eIn the meantime, to get started with the Preview, check out the \u003ca href=\"https://cloud.google.com/deploy\" track-type=\"inline link\" track-name=\"26\" track-metadata-eventdetail=\"https://cloud.google.com/deploy\" track-metadata-module=\"post\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\" track-type=\"inline link\" track-name=\"27\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs\" track-metadata-module=\"post\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\" track-type=\"inline link\" track-name=\"28\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/quickstart-basic\" track-metadata-module=\"post\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\" track-type=\"inline link\" track-name=\"29\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/tutorials\" track-metadata-module=\"post\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\" track-type=\"inline link\" track-name=\"30\" track-metadata-eventdetail=\"https://www.googlecloudcommunity.com\" track-metadata-module=\"post\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-video-block _nghost-c16=\"\"\u003e\u003cp _ngcontent-c16=\"\"\u003e\u003ciframe _ngcontent-c16=\"\" allow=\"encrypted-media\" allowfullscreen=\"\" frameborder=\"0\" height=\"100%\" position=\"absolute\" width=\"100%\" src=\"https://www.youtube.com/embed/Il8FlhR9jKM?enablejsapi=1\u0026amp;\"\u003e\u003c/iframe\u003e\u003c/p\u003e\u003c/article-video-block\u003e\u003c/div\u003e\u003c/article-content-stream-block\u003e\u003carticle-tag-list-block\u003e\u003c/article-tag-list-block\u003e\u003c/div\u003e\u003csection\u003e\u003carticle-up-1to3-block _nghost-c18=\"\"\u003e\u003c/article-up-1to3-block\u003e\u003c/section\u003e\u003c/div\u003e\u003c/article\u003e\u003c/main\u003e\u003c/article-page\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eContinuous delivery is frequently top-of-mind for organizations adopting \u003ca href=\"https://cloud.google.com/kubernetes-engine\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE). However, continuous delivery —deploying container image artifacts into your various environments—remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u003c/p\u003e\u003cp\u003eIt doesn’t have to be this way. \u003c/p\u003eToday, we are pleased to announce \u003ca href=\"https://cloud.google.com/deploy\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_2.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 2.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_2.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003cbr/\u003e\u003c/h3\u003e\u003cp\u003eGoogle Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u003c/p\u003e\u003cp\u003eLet’s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eTime and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current—to say nothing of maintenance—is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“We can’t afford to be innovating in continuous delivery,” one customer told us. “We want an opinionated product that supports best practices out of the box.”\u003c/i\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy addresses cost of ownership head-on.\u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\"\u003edeclaratively\u003c/a\u003e and are \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\"\u003estored alongside each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/cloud-deploy-pp-blog-post-3.gif\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy GIF\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/cloud-deploy-pp-blog-post-3.gif\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWe have found that a variety of GKE roles and personas interact with continuous delivery processes. A DevOps engineer may be focused on release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application\"\u003epromotion and rollback\u003c/a\u003e decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_1.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 1.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_1.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003eContextualized deployment approvals\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003cb\u003eSecurity and audit\u003c/b\u003e\u003c/p\u003e\u003cp\u003eLots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained restriction, with \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\"\u003ediscrete resource access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\"\u003eexecution-level security\u003c/a\u003e. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\"\u003eapprovals\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntegration\u003c/b\u003e\u003c/p\u003e\u003cp\u003eWhether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: connectivity to CI systems, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\"\u003ePub/Sub\u003c/a\u003e notifications to enable third-party integrations.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\"\u003eConnecting Google Cloud Deploy\u003c/a\u003e to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple \u003ci\u003e`\u003c/i\u003e\u003ci\u003egcloud beta deploy releases create`.\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deployt_3_efyUGIq.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 3.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deployt_3_efyUGIq.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eDelivering to Kubernetes often changes over time. To help, Google Cloud Deploy  leverages \u003ca href=\"https://skaffold.dev/\" target=\"_blank\"\u003eSkaffold\u003c/a\u003e, allowing you to \u003ca href=\"https://cloud.google.com/deploy/docs/skaffold\"\u003estandardize your configuration\u003c/a\u003e between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u003ca href=\"https://helm.sh/\" target=\"_blank\"\u003eHelm\u003c/a\u003e, \u003ca href=\"https://kustomize.io/\" target=\"_blank\"\u003eKustomize\u003c/a\u003e, \u003ca href=\"https://kpt.dev/\" target=\"_blank\"\u003ekpt\u003c/a\u003e). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u003c/p\u003e\u003cp\u003eFinally, to facilitate other integrations, such as a \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\"\u003epost-deployment test execution\u003c/a\u003e or \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\"\u003ethird party approval workflows\u003c/a\u003e, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\"\u003eemits Pub/Sub messages\u003c/a\u003e throughout a \u003ca href=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\"\u003erelease’s lifecycle\u003c/a\u003e.\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we’re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u003c/p\u003e\u003cp\u003eIn the meantime, to get started with the Preview, check out the \u003ca href=\"https://cloud.google.com/deploy\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-video\"\u003e\u003cdiv class=\"article-module article-video \"\u003e\u003cfigure\u003e\u003ca class=\"h-c-video h-c-video--marquee\" data-glue-modal-disabled-on-mobile=\"true\" data-glue-modal-trigger=\"uni-modal-Il8FlhR9jKM-\" href=\"https://youtube.com/watch?v=Il8FlhR9jKM\"\u003e\u003cimg alt=\"Introducing Cloud Deploy\" src=\"//img.youtube.com/vi/Il8FlhR9jKM/maxresdefault.jpg\"/\u003e\u003csvg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" role=\"img\"\u003e\u003cuse xlink:href=\"#mi-youtube-icon\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv class=\"h-c-modal--video\" data-glue-modal=\"uni-modal-Il8FlhR9jKM-\" data-glue-modal-close-label=\"Close Dialog\"\u003e\u003ca class=\"glue-yt-video\" data-glue-yt-video-autoplay=\"true\" data-glue-yt-video-height=\"99%\" data-glue-yt-video-vid=\"Il8FlhR9jKM\" data-glue-yt-video-width=\"100%\" href=\"https://youtube.com/watch?v=Il8FlhR9jKM\" ng-cloak=\"\"\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/announcing-dora-2021-accelerate-state-of-devops-report/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/SODR2021_1920x1080.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e2021 Accelerate State of DevOps report addresses burnout, team performance\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eThe SODR is continually one of the most downloaded assets on the GCP website. We are releasing the updated version of the report with new...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/gcp_ZPje3k8.max-2200x2200.jpg",
      "date_published": "2021-09-22T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eS. Bogdan\u003c/name\u003e\u003ctitle\u003eProduct Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/google-cloud-deploy-automates-deploys-to-gke/",
      "title": "Introducing Google Cloud Deploy: Managed continuous delivery to GKE",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle-page\u003e\u003cmain id=\"jump-content\"\u003e\u003carticle\u003e\u003carticle-header-block\u003e\u003c/article-header-block\u003e\u003carticle-aspect-image-block\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003e#gcp\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/article-aspect-image-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-author-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003e S. Bogdan \u003c/p\u003e\u003cp\u003e Product Manager \u003c/p\u003e\u003c/div\u003e\u003cp\u003e\u003cspan\u003e September 22, 2021 \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-author-block\u003e\u003c/div\u003e\u003carticle-cta _nghost-c38=\"\"\u003e\u003cdiv _ngcontent-c38=\"\"\u003e\u003ch4 _ngcontent-c38=\"\"\u003e\u003cspan _ngcontent-c38=\"\"\u003eNext ’21 registration is open\u003c/span\u003e\u003c/h4\u003e\u003cp _ngcontent-c38=\"\"\u003e\u003cspan _ngcontent-c38=\"\"\u003eJoin us October 12–14, 2021, for our digital flagship event\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003ca _ngcontent-c38=\"\" clicktracker=\"\" rel=\"external\" track-metadata-module=\"article cta\" track-type=\"button\" track-name=\"Next21 registration\" track-metadata-eventdetail=\"https://cloud.withgoogle.com/next/register?utm_source=google\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY21-Q4-global-ES903-onlineevent-er-next-2021\u0026amp;utm_content=blog-next-21-registration\" href=\"https://cloud.withgoogle.com/next/register?utm_source=google\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY21-Q4-global-ES903-onlineevent-er-next-2021\u0026amp;utm_content=blog-next-21-registration\"\u003e\u003cspan _ngcontent-c38=\"\"\u003eRegister now\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-cta\u003e\u003c/div\u003e\u003carticle-share-block\u003e\u003c/article-share-block\u003e\u003carticle-sticky-share-block\u003e\u003c/article-sticky-share-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-content-stream-block\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c40=\"\"\u003e\u003cdiv _ngcontent-c40=\"\" innerhtml=\"\u0026lt;p\u0026gt;Continuous delivery is frequently top-of-mind for organizations adopting \u0026lt;a href=\u0026#34;https://cloud.google.com/kubernetes-engine\u0026#34;\u0026gt;Google Kubernetes Engine\u0026lt;/a\u0026gt; (GKE). However, continuous delivery \u0026amp;#8212;deploying container image artifacts into your various environments\u0026amp;#8212;remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;It doesn\u0026amp;#8217;t have to be this way.\u0026amp;#160;\u0026lt;/p\u0026gt;Today, we are pleased to announce \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy\u0026#34;\u0026gt;Google Cloud Deploy\u0026lt;/a\u0026gt;, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eContinuous delivery is frequently top-of-mind for organizations adopting \u003ca href=\"https://cloud.google.com/kubernetes-engine\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/kubernetes-engine\" track-metadata-module=\"post\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE). However, continuous delivery —deploying container image artifacts into your various environments—remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u003c/p\u003e\u003cp\u003eIt doesn’t have to be this way. \u003c/p\u003e\u003cp\u003eToday, we are pleased to announce \u003ca href=\"https://cloud.google.com/deploy\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/deploy\" track-metadata-module=\"post\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c40=\"\"\u003e\u003cdiv _ngcontent-c40=\"\" innerhtml=\"\u0026lt;h3\u0026gt;Solving for continuous delivery challenges\u0026lt;br\u0026gt;\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Let\u0026amp;#8217;s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Cost of ownership\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Time and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current\u0026amp;#8212;to say nothing of maintenance\u0026amp;#8212;is resource-intensive and takes time away from the core business.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;\u0026amp;#8220;We can\u0026amp;#8217;t afford to be innovating in continuous delivery,\u0026amp;#8221; one customer told us. \u0026amp;#8220;We want an opinionated product that supports best practices out of the box.\u0026amp;#8221;\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy addresses cost of ownership head-on.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;As a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy also provides structure. \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\u0026#34;\u0026gt;Delivery pipelines\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology\u0026#34;\u0026gt;targets\u0026lt;/a\u0026gt; are defined \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/config-files\u0026#34;\u0026gt;declaratively\u0026lt;/a\u0026gt; and are \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/pipeline-instances\u0026#34;\u0026gt;stored alongside each release\u0026lt;/a\u0026gt;. That means if your delivery pipeline changes, the release\u0026amp;#8217;s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003cbr/\u003e\u003c/h3\u003e\u003cp\u003eGoogle Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u003c/p\u003e\u003cp\u003eLet’s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eTime and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current—to say nothing of maintenance—is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“We can’t afford to be innovating in continuous delivery,” one customer told us. “We want an opinionated product that supports best practices out of the box.”\u003c/i\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy addresses cost of ownership head-on.\u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\" track-metadata-module=\"post\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology\" track-metadata-module=\"post\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/config-files\" track-metadata-module=\"post\"\u003edeclaratively\u003c/a\u003e and are \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/pipeline-instances\" track-metadata-module=\"post\"\u003estored alongside each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c40=\"\"\u003e\u003cp\u003eWe have found that a variety of GKE roles and personas interact with continuous delivery processes. A DevOps engineer may be focused on release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/deploying-application\" track-metadata-module=\"post\"\u003epromotion and rollback\u003c/a\u003e decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003cbr/\u003e\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c40=\"\"\u003e\u003cdiv _ngcontent-c40=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Security and audit\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Lots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn\u0026amp;#8217;t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Throughout, Google Cloud Deploy enables fine-grained restriction, with \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/iam-roles-permissions\u0026#34;\u0026gt;discrete resource access control\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/execution-environment\u0026#34;\u0026gt;execution-level security\u0026lt;/a\u0026gt;. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\u0026#34;\u0026gt;approvals\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Auditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u0026lt;a href=\u0026#34;https://cloud.google.com/audit-logs\u0026#34;\u0026gt;Cloud Audit Logs\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/audit-logs\u0026#34;\u0026gt;audits\u0026lt;/a\u0026gt; user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Integration\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Whether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating\u0026#34;\u0026gt;embraces the GKE delivery tooling ecosystems\u0026lt;/a\u0026gt; in three ways: connectivity to CI systems, support for leading configuration (\u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology#render\u0026#34;\u0026gt;rendering\u0026lt;/a\u0026gt;) tooling, and \u0026lt;a href=\u0026#34;https://cloud.google.com/pubsub\u0026#34;\u0026gt;Pub/Sub\u0026lt;/a\u0026gt; notifications to enable third-party integrations.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\u0026#34;\u0026gt;Connecting Google Cloud Deploy\u0026lt;/a\u0026gt; to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple\u0026amp;#160;\u0026lt;i\u0026gt;`\u0026lt;/i\u0026gt;\u0026lt;i\u0026gt;gcloud beta deploy releases create`.\u0026lt;/i\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e\u003cb\u003eSecurity and audit\u003c/b\u003e\u003c/p\u003e\u003cp\u003eLots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained restriction, with \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\" track-metadata-module=\"post\"\u003ediscrete resource access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/execution-environment\" track-metadata-module=\"post\"\u003eexecution-level security\u003c/a\u003e. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\" track-metadata-module=\"post\"\u003eapprovals\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/audit-logs\" track-metadata-module=\"post\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/audit-logs\" track-metadata-module=\"post\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntegration\u003c/b\u003e\u003c/p\u003e\u003cp\u003eWhether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating\" track-metadata-module=\"post\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: connectivity to CI systems, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology#render\" track-metadata-module=\"post\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://cloud.google.com/pubsub\" track-metadata-module=\"post\"\u003ePub/Sub\u003c/a\u003e notifications to enable third-party integrations.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\" track-metadata-module=\"post\"\u003eConnecting Google Cloud Deploy\u003c/a\u003e to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple \u003ci\u003e`\u003c/i\u003e\u003ci\u003egcloud beta deploy releases create`.\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c40=\"\"\u003e\u003cdiv _ngcontent-c40=\"\" innerhtml=\"\u0026lt;p\u0026gt;Delivering to Kubernetes often changes over time. To help, Google Cloud Deploy\u0026amp;#160; leverages \u0026lt;a href=\u0026#34;https://skaffold.dev/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Skaffold\u0026lt;/a\u0026gt;, allowing you to \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/skaffold\u0026#34;\u0026gt;standardize your configuration\u0026lt;/a\u0026gt; between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u0026lt;a href=\u0026#34;https://helm.sh/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Helm\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://kustomize.io/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Kustomize\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://kpt.dev/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;kpt\u0026lt;/a\u0026gt;). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Finally, to facilitate other integrations, such as a \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\u0026#34;\u0026gt;post-deployment test execution\u0026lt;/a\u0026gt; or \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\u0026#34;\u0026gt;third party approval workflows\u0026lt;/a\u0026gt;, Google Cloud Deploy \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\u0026#34;\u0026gt;emits Pub/Sub messages\u0026lt;/a\u0026gt; throughout a \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\u0026#34;\u0026gt;release\u0026amp;#8217;s lifecycle\u0026lt;/a\u0026gt;.\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;The future\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Comprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it\u0026amp;#8217;s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we\u0026amp;#8217;re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In the meantime, to get started with the Preview, check out the \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy\u0026#34;\u0026gt;product page\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs\u0026#34;\u0026gt;documentation\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/quickstart-basic\u0026#34;\u0026gt;quickstart\u0026lt;/a\u0026gt;, and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/tutorials\u0026#34;\u0026gt;tutorials\u0026lt;/a\u0026gt;. Finally, If you have feedback on Google Cloud Deploy, you can \u0026lt;a href=\u0026#34;https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;join the conversation\u0026lt;/a\u0026gt;. We look forward to hearing from you!\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eDelivering to Kubernetes often changes over time. To help, Google Cloud Deploy  leverages \u003ca href=\"https://skaffold.dev/\" target=\"_blank\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://skaffold.dev\" track-metadata-module=\"post\"\u003eSkaffold\u003c/a\u003e, allowing you to \u003ca href=\"https://cloud.google.com/deploy/docs/skaffold\" track-type=\"inline link\" track-name=\"18\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/skaffold\" track-metadata-module=\"post\"\u003estandardize your configuration\u003c/a\u003e between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u003ca href=\"https://helm.sh/\" target=\"_blank\" track-type=\"inline link\" track-name=\"19\" track-metadata-eventdetail=\"https://helm.sh\" track-metadata-module=\"post\"\u003eHelm\u003c/a\u003e, \u003ca href=\"https://kustomize.io/\" target=\"_blank\" track-type=\"inline link\" track-name=\"20\" track-metadata-eventdetail=\"https://kustomize.io\" track-metadata-module=\"post\"\u003eKustomize\u003c/a\u003e, \u003ca href=\"https://kpt.dev/\" target=\"_blank\" track-type=\"inline link\" track-name=\"21\" track-metadata-eventdetail=\"https://kpt.dev\" track-metadata-module=\"post\"\u003ekpt\u003c/a\u003e). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u003c/p\u003e\u003cp\u003eFinally, to facilitate other integrations, such as a \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\" track-type=\"inline link\" track-name=\"22\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\" track-metadata-module=\"post\"\u003epost-deployment test execution\u003c/a\u003e or \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\" track-type=\"inline link\" track-name=\"23\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\" track-metadata-module=\"post\"\u003ethird party approval workflows\u003c/a\u003e, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\" track-type=\"inline link\" track-name=\"24\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\" track-metadata-module=\"post\"\u003eemits Pub/Sub messages\u003c/a\u003e throughout a \u003ca href=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\" track-type=\"inline link\" track-name=\"25\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\" track-metadata-module=\"post\"\u003erelease’s lifecycle\u003c/a\u003e.\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we’re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u003c/p\u003e\u003cp\u003eIn the meantime, to get started with the Preview, check out the \u003ca href=\"https://cloud.google.com/deploy\" track-type=\"inline link\" track-name=\"26\" track-metadata-eventdetail=\"https://cloud.google.com/deploy\" track-metadata-module=\"post\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\" track-type=\"inline link\" track-name=\"27\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs\" track-metadata-module=\"post\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\" track-type=\"inline link\" track-name=\"28\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/quickstart-basic\" track-metadata-module=\"post\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\" track-type=\"inline link\" track-name=\"29\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/tutorials\" track-metadata-module=\"post\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\" track-type=\"inline link\" track-name=\"30\" track-metadata-eventdetail=\"https://www.googlecloudcommunity.com\" track-metadata-module=\"post\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-video-block _nghost-c37=\"\"\u003e\u003cp _ngcontent-c37=\"\"\u003e\u003ciframe _ngcontent-c37=\"\" allow=\"encrypted-media\" allowfullscreen=\"\" frameborder=\"0\" height=\"100%\" position=\"absolute\" width=\"100%\" src=\"https://www.youtube.com/embed/Il8FlhR9jKM?enablejsapi=1\u0026amp;\"\u003e\u003c/iframe\u003e\u003c/p\u003e\u003c/article-video-block\u003e\u003c/div\u003e\u003c/article-content-stream-block\u003e\u003carticle-tag-list-block\u003e\u003c/article-tag-list-block\u003e\u003c/div\u003e\u003csection\u003e\u003carticle-up-1to3-block _nghost-c39=\"\"\u003e\u003c/article-up-1to3-block\u003e\u003c/section\u003e\u003c/div\u003e\u003c/article\u003e\u003c/main\u003e\u003c/article-page\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eContinuous delivery is frequently top-of-mind for organizations adopting \u003ca href=\"https://cloud.google.com/kubernetes-engine\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE). However, continuous delivery —deploying container image artifacts into your various environments—remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u003c/p\u003e\u003cp\u003eIt doesn’t have to be this way. \u003c/p\u003eToday, we are pleased to announce \u003ca href=\"https://cloud.google.com/deploy\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_2.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 2.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_2.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003cbr/\u003e\u003c/h3\u003e\u003cp\u003eGoogle Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u003c/p\u003e\u003cp\u003eLet’s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eTime and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current—to say nothing of maintenance—is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“We can’t afford to be innovating in continuous delivery,” one customer told us. “We want an opinionated product that supports best practices out of the box.”\u003c/i\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy addresses cost of ownership head-on.\u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\"\u003edeclaratively\u003c/a\u003e and are \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\"\u003estored alongside each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/cloud-deploy-pp-blog-post-3.gif\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy GIF\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/cloud-deploy-pp-blog-post-3.gif\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWe have found that a variety of GKE roles and personas interact with continuous delivery processes. A DevOps engineer may be focused on release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application\"\u003epromotion and rollback\u003c/a\u003e decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_1.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 1.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_1.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003eContextualized deployment approvals\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003cb\u003eSecurity and audit\u003c/b\u003e\u003c/p\u003e\u003cp\u003eLots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained restriction, with \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\"\u003ediscrete resource access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\"\u003eexecution-level security\u003c/a\u003e. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\"\u003eapprovals\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntegration\u003c/b\u003e\u003c/p\u003e\u003cp\u003eWhether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: connectivity to CI systems, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\"\u003ePub/Sub\u003c/a\u003e notifications to enable third-party integrations.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\"\u003eConnecting Google Cloud Deploy\u003c/a\u003e to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple \u003ci\u003e`\u003c/i\u003e\u003ci\u003egcloud beta deploy releases create`.\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deployt_3_efyUGIq.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 3.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deployt_3_efyUGIq.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eDelivering to Kubernetes often changes over time. To help, Google Cloud Deploy  leverages \u003ca href=\"https://skaffold.dev/\" target=\"_blank\"\u003eSkaffold\u003c/a\u003e, allowing you to \u003ca href=\"https://cloud.google.com/deploy/docs/skaffold\"\u003estandardize your configuration\u003c/a\u003e between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u003ca href=\"https://helm.sh/\" target=\"_blank\"\u003eHelm\u003c/a\u003e, \u003ca href=\"https://kustomize.io/\" target=\"_blank\"\u003eKustomize\u003c/a\u003e, \u003ca href=\"https://kpt.dev/\" target=\"_blank\"\u003ekpt\u003c/a\u003e). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u003c/p\u003e\u003cp\u003eFinally, to facilitate other integrations, such as a \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\"\u003epost-deployment test execution\u003c/a\u003e or \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\"\u003ethird party approval workflows\u003c/a\u003e, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\"\u003eemits Pub/Sub messages\u003c/a\u003e throughout a \u003ca href=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\"\u003erelease’s lifecycle\u003c/a\u003e.\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we’re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u003c/p\u003e\u003cp\u003eIn the meantime, to get started with the Preview, check out the \u003ca href=\"https://cloud.google.com/deploy\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-video\"\u003e\u003cdiv class=\"article-module article-video \"\u003e\u003cfigure\u003e\u003ca class=\"h-c-video h-c-video--marquee\" data-glue-modal-disabled-on-mobile=\"true\" data-glue-modal-trigger=\"uni-modal-Il8FlhR9jKM-\" href=\"https://youtube.com/watch?v=Il8FlhR9jKM\"\u003e\u003cimg alt=\"Introducing Cloud Deploy\" src=\"//img.youtube.com/vi/Il8FlhR9jKM/maxresdefault.jpg\"/\u003e\u003csvg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" role=\"img\"\u003e\u003cuse xlink:href=\"#mi-youtube-icon\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv class=\"h-c-modal--video\" data-glue-modal=\"uni-modal-Il8FlhR9jKM-\" data-glue-modal-close-label=\"Close Dialog\"\u003e\u003ca class=\"glue-yt-video\" data-glue-yt-video-autoplay=\"true\" data-glue-yt-video-height=\"99%\" data-glue-yt-video-vid=\"Il8FlhR9jKM\" data-glue-yt-video-width=\"100%\" href=\"https://youtube.com/watch?v=Il8FlhR9jKM\" ng-cloak=\"\"\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/announcing-dora-2021-accelerate-state-of-devops-report/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/SODR2021_1920x1080.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e2021 Accelerate State of DevOps report addresses burnout, team performance\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eThe SODR is continually one of the most downloaded assets on the GCP website. We are releasing the updated version of the report with new...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/gcp_ZPje3k8.max-2200x2200.jpg",
      "date_published": "2021-09-22T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eS. Bogdan\u003c/name\u003e\u003ctitle\u003eProduct Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/the-five-phases-of-organizational-reliability/",
      "title": "What’s your org’s reliability mindset? Insights from Google SREs",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003ci\u003eEditor’s note: There’s more to ensuring a product’s reliability than following a bunch of prescriptive rules. Today, we hear from some Google SREs—Vartika Agarwal, Senior Technical Program Manager, Development; Tracy Ferrell, Senior SRE Manager; Mahesh Palekar, Director SRE; and Magi Agrama, Senior Technical Program Manager, SRE—about how to evaluate your team’s current reliability mindset, and what you want it to be.\u003c/i\u003e\u003c/p\u003e\u003chr/\u003e\u003cp\u003eHaving a reliable software product can improve users’ trust in your organization, the effectiveness of your development processes, and the quality of your products overall. More than ever, product reliability is front and center, as outages negatively impact customers and their businesses. But in an effort to develop new features, many organizations limit their reliability efforts to what happens after an outage, and tactically solve for the immediate problems that sparked it. They often fail to realize that they can move quickly while still improving their product’s reliability.\u003c/p\u003e\u003cp\u003eAt Google, we’ve given a lot of thought to product reliability—and several of its aspects are well understood, for example product or system design. What people think about less is the culture and the mindset of the organization that creates a reliable product in the first place. We believe that the reliability of a product is a property of the architecture of its system, processes, culture, as well as the mindset of the product team or organization that built it. In other words, reliability should be woven into the fabric of an organization, not just the result of a strong design ethos. \u003c/p\u003e\u003cp\u003eIn this blog post, we discuss the lessons we’ve learned relevant to organizational or product leads who have the ability to influence the culture of the entire product team, from (but not limited to) engineering, product management, marketing, reliability engineering, and support organizations.\u003c/p\u003e\u003ch3\u003eGoals\u003c/h3\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eReliability should be woven into the fabric of how an organization executes. At Google, we’ve developed a terminology to categorize and describe your organization’s reliability mindset, to help you understand how intentional your organization is in this respect. Our ultimate goal is to help you improve and adopt product reliability practices that will permeate the ethos of the organization.\u003c/p\u003e\u003cp\u003eBy identifying these reliability phases, we do not mean to offer a prescriptive list of things to do that will improve your product’s reliability. Nor should they be read as a set of mandated principles that everyone should apply, or be used to publicly label a team, spurring competition between teams. Rather, leaders should consider these phases as a way to help them develop their team’s culture, on the road to sustainably building reliable products.  \u003c/p\u003e\u003ch3\u003eThe organizational reliability continuum\u003c/h3\u003e\u003cp\u003eBased on our observations here at Google, there are five basic stages of organizational reliability, and they are based on the classic organizational model of absent, reactive, proactive, strategic and visionary. These phases describe the mindset of an organization at a point in time, and each one of them is characterized by a series of attributes, and is appropriate for different classes of workloads.\u003c/p\u003e\u003cp\u003eAbsent: Reliability is a secondary consideration for the organization. \u003cbr/\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eA feature launch is the key organizational metric and is the focus for incentives\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eThe majority of issues are found by users or testers. This organization is not aware of their long-term reliability risks. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDeveloper velocity is rarely exchanged for reliability.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003ci\u003eThis reliability phase maybe appropriate for products and projects that are still under development.\u003c/i\u003e\u003c/p\u003e\u003cp\u003e\u003cb\u003eReactive\u003c/b\u003e\u003cb\u003e:\u003c/b\u003eResponses to reliability issues/risks are tied to recent outages with sporadic follow-through and rarely are there longer-term investments in fixing system issues.\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eTeams have some reliability metrics defined and react when required.\u003c/li\u003e\u003cli\u003eThey write postmortems for outages and create action items for tactical fixes.\u003c/li\u003e\u003cli\u003eReasonable availability is maintained through heroic efforts by a few individuals or teams \u003c/li\u003e\u003cli\u003eDeveloper productivity is throttled due to a temporary shift in priority on reliability work due to outages. Feature development may be frozen for a short period of time.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003ci\u003eThis level is appropriate for products/projects in pre-launch or in a stable long-term maintenance phase.\u003c/i\u003e\u003c/p\u003e\u003cp\u003e\u003cb\u003eProactive:\u003c/b\u003e\u003cb\u003e\u003c/b\u003ePotential reliability risks are identified and addressed through regular organizational processes.\u003cbr/\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eRisks are regularly reviewed and prioritized.\u003c/li\u003e\u003cli\u003eTeams proactively manage dependencies and review their reliability metrics (SLOs)\u003c/li\u003e\u003cli\u003eNew designs are assessed for known risks and failure modes early on. Graceful degradation is a basic requirement.\u003c/li\u003e\u003cli\u003eThe business understands the need to continuously invest in reliability and maintain its balance with developer velocity. \u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003ci\u003eMost services/products should be at this level; particularly if they have a large blast radius or are critical to the business.\u003c/i\u003e\u003c/p\u003e\u003cb\u003eStrategic:\u003c/b\u003eOrganizations at this level manage classes of risk via systemic changes to  architectures, products and processes.\u003cbr/\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eReliability is inherent and ingrained in how the organization designs, operates and develops software. Reliability is systemic.\u003c/li\u003e\u003cli\u003eComplexity is addressed holistically through product architecture. Dependencies are constantly reduced or improved.\u003c/li\u003e\u003cli\u003eThe cross-functional organization can sustain reliability and developer velocity simultaneously.\u003c/li\u003e\u003cli\u003eOrganizations widely celebrate quality and stability milestones.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003ci\u003eThis level is appropriate for services and products that need very high availability to meet business-critical needs.\u003c/i\u003e\u003c/p\u003e\u003cb\u003eVisionary:\u003c/b\u003eThe organization has reached the highest order of reliability and is able to drive broader reliability efforts within and outside the company (e.g., writing papers, sharing knowledge), based on their best practices and experiences. \u003cbr/\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003eReliability knowledge exists broadly across all engineers and teams at a fairly advanced level and is carried forward as they move across organizations.\u003c/li\u003e\u003cli\u003eSystems are self-healing.\u003c/li\u003e\u003cli\u003eArchitectural improvements for reliability positively impact productivity (release velocity) due to reduction of maintenance work/toil.\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003ci\u003eVery few services or products are at this level, and when they are, are industry leading.\u003c/i\u003e\u003c/p\u003e\u003cp\u003e\u003ci\u003e\u003c/i\u003e\u003c/p\u003e\u003ch3\u003e\u003ci\u003e\u003ci\u003e\u003ci\u003e\u003ci\u003e\u003ci\u003e\u003ci\u003e\u003ci\u003e\u003ci\u003e\u003ci\u003e\u003ci\u003eWhere should you be on the reliability spectrum?\u003c/i\u003e\u003c/i\u003e\u003c/i\u003e\u003c/i\u003e\u003c/i\u003e\u003c/i\u003e\u003c/i\u003e\u003c/i\u003e\u003c/i\u003e\u003c/i\u003e\u003c/h3\u003e\u003cp\u003e\u003ci\u003e\u003ci\u003eIt is very important to understand your organization does not necessarily need to be at the strategic or visionary phase. There is a significant cost associated with moving from one phase to another and a cost to remain very high on this curve. In our experience, being proactive is a healthy level to target and is ideal for most products. \u003c/i\u003e\u003c/i\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003ci\u003e\u003ci\u003eTo illustrate this point, here is a simple graph of where various Google product teams are on the organizational reliability spectrum; as you can see, it produces a standard bell-curve distribution. While many Google’s product teams have a reactive or proactive reliability culture, most can be described as proactive. You, as an organizational leader, must consciously decide to be at a level based on the product requirements and client expectations.\u003c/i\u003e\u003c/i\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Googles_Reliability_culture.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Google’s Reliability culture.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Googles_Reliability_culture.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eFurther, it’s common to have attributes across several phases, for example, an organization may be largely reactive with a few proactive attributes. Team culture will wax and wane between phases, as it takes effort to maintain a strategic reliability culture. However, as more of the organization embraces and celebrates reliability as a key feature, the cost of maintenance decreases. \u003c/p\u003e\u003cp\u003eThe key to success is making an honest assessment of what phase you’re in, and then doing concerted work to move to the phase that makes sense for your product. If your organization is in the absent or reactive phase, remember that many products in nascent stages of their life cycle may be comfortable there (in both the startup and long term maintenance of a stable product).\u003c/p\u003e\u003ch3\u003eReliability phases in action\u003c/h3\u003e\u003cp\u003eTo illustrate the reliability phases in practice, it is interesting to look at examples of organizations and how they have progressed or regressed through them.  \u003c/p\u003e\u003cp\u003eIt should be noted that all companies and teams are different and the progress through these phases can take varying amounts of time. It is not uncommon to take two to three years to move into a truly proactive state. In a proactive state all parts of the organization contribute to reliability without worrying that it will negatively impact feature velocity. Staying in the proactive phase also takes time and effort.\u003c/p\u003e\u003cp\u003e\u003cb\u003eNobody can be a hero forever\u003c/b\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eOne infrastructure services team started small with a few well understood APIs. One key member of the team, a product architect, understood the system well and ensured that things ran smoothly by ensuring design decisions were sound and being at each major incident to rapidly mitigate the issue. This was the one person who understood the entire system and was able to predict what can and cannot impact its stability. But when they left the team, the system complexity grew by leaps and bounds. Suddenly there were many critical user-facing and internal outages. \u003c/p\u003e\u003cp\u003eOrganizational leaders initiated both short and long-term reliability programs to restore stability. They focused on reducing the blast radius and the impact of global outages. Leadership recognized that to sustain this trajectory, they recognized that they had to go beyond engineering solutions and implement cultural changes such as recognizing reliability as their number-one feature. This led to broad training around reliability best practices, incorporating reliability in architectural/design reviews and recognizing and rewarding reliability beyond hero moments. \u003c/p\u003e\u003cp\u003eAs a result, the organization evolved from a reactive to a strategic reliability mindset, aided by setting reliability as their number-one feature, recognizing and rewarding long-term reliability improvements, and adopting the systemic belief that reliability is everyone’s responsibility—not just that of a few heroes.\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Googles_Reliability_culture_4.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Google’s Reliability culture 4.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Googles_Reliability_culture_4.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eIf you think you are done, think again\u003c/h3\u003e\u003cp\u003eEnd users are highly dependent on the reliability of this product and it ties directly to user trust. For this reason, reliability was top of mind for one Google organization for years, and the product was held as the gold standard of reliability by other Google teams. The org was deemed visionary in its reliability processes and work. \u003c/p\u003e\u003cp\u003eHowever, over the years, new products were added to the base service. The high level of reliability did not come as freely and easily as it did with the simpler product. Reliability was impacted at the cost of developer velocity and the organization moved to a more reactive reliability mindset.\u003c/p\u003e\u003cp\u003eTo turn the ship around, the organization’s leaders had to be intentional about their reliability posture and overall practices, for example, how much they thought about and prioritized reliability. It took several years to move the team back to a strategic mindset. \u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Googles_Reliability_culture_3.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Google’s Reliability culture 3.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Googles_Reliability_culture_3.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eEmbrace reliability principles from the start\u003c/h3\u003e\u003cp\u003eAnother team with a new user-facing product was focused on adding features and growing their user base. Before they knew it, the product took off and saw exponential growth.\u003c/p\u003e\u003cp\u003eUnfortunately, their laser-focus on managing user requirements and growing user adoption led to high technical debt and reliability issues. Since the service didn’t start off with reliability as a primary focus, it was very hard to incorporate it after the fact. \u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eMuch of the code had to be re-written and re-architected to reach a sustainable state. The team’s leaders incentivized attention to reliability throughout the organization, from product management through to development and UX domains, constantly reminding the organization about the importance of reliability to the long-term success of the product. This mindshift took years to set in.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"Google’s Reliability culture 2.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Googles_Reliability_culture_2.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eConclusion\u003c/h3\u003e\u003cp\u003eIt is important that cross-functional organizations be honest about their reliability journeys and determine what is appropriate for their business and product. It is not uncommon for organizations to move from one level to another and then back again as the product matures, stabilizes and then is sunset for the next generation. Getting to a strategic level can be 4+ years in the making and require very high levels of investment from all aspects of the business.  Leaders should ensure their product requires this level of continued investment.\u003c/p\u003e\u003cp\u003eWe encourage you to study your culture of reliability, assess what phase you are in, determine where you should be on the continuum and carefully and thoughtfully move there. Changing culture is hard and can not be done by edicts or penalties. Most of all, remember that this is a journey and the business is ever-evolving; you cannot set reliability on the shelf and expect it to maintain itself in perpetuity.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/evaluating-where-your-team-lies-on-the-sre-spectrum/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eAre we there yet? Thoughts on assessing an SRE team’s maturity\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eExamining the key indicators that signal a mature SRE team.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://cloud.google.com/blog/static/assets/GCP_Twitter_Card-2000×1000.png",
      "date_published": "2021-09-22T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eGoogle Site Reliability Engineering team \u003c/name\u003e\u003ctitle\u003e\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/google-cloud-deploy-automates-deploys-to-gke/",
      "title": "Introducing Google Cloud Deploy: Managed continuous delivery to GKE",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle-page\u003e\u003cmain id=\"jump-content\"\u003e\u003carticle\u003e\u003carticle-header-block\u003e\u003c/article-header-block\u003e\u003carticle-aspect-image-block\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003e#gcp\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/article-aspect-image-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-author-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003e S. Bogdan \u003c/p\u003e\u003cp\u003e Product Manager \u003c/p\u003e\u003c/div\u003e\u003cp\u003e\u003cspan\u003e September 22, 2021 \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-author-block\u003e\u003c/div\u003e\u003carticle-cta _nghost-c17=\"\"\u003e\u003cdiv _ngcontent-c17=\"\"\u003e\u003ch4 _ngcontent-c17=\"\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eNext ’21 registration is open\u003c/span\u003e\u003c/h4\u003e\u003cp _ngcontent-c17=\"\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eJoin us October 12–14, 2021, for our digital flagship event\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003ca _ngcontent-c17=\"\" clicktracker=\"\" rel=\"external\" track-metadata-module=\"article cta\" track-type=\"button\" track-name=\"Next21 registration\" track-metadata-eventdetail=\"https://cloud.withgoogle.com/next/register?utm_source=google\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY21-Q4-global-ES903-onlineevent-er-next-2021\u0026amp;utm_content=blog-next-21-registration\" href=\"https://cloud.withgoogle.com/next/register?utm_source=google\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY21-Q4-global-ES903-onlineevent-er-next-2021\u0026amp;utm_content=blog-next-21-registration\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eRegister now\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-cta\u003e\u003c/div\u003e\u003carticle-share-block\u003e\u003c/article-share-block\u003e\u003carticle-sticky-share-block\u003e\u003c/article-sticky-share-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-content-stream-block\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Continuous delivery is frequently top-of-mind for organizations adopting \u0026lt;a href=\u0026#34;https://cloud.google.com/kubernetes-engine\u0026#34;\u0026gt;Google Kubernetes Engine\u0026lt;/a\u0026gt; (GKE). However, continuous delivery \u0026amp;#8212;deploying container image artifacts into your various environments\u0026amp;#8212;remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;It doesn\u0026amp;#8217;t have to be this way.\u0026amp;#160;\u0026lt;/p\u0026gt;Today, we are pleased to announce \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy\u0026#34;\u0026gt;Google Cloud Deploy\u0026lt;/a\u0026gt;, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eContinuous delivery is frequently top-of-mind for organizations adopting \u003ca href=\"https://cloud.google.com/kubernetes-engine\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/kubernetes-engine\" track-metadata-module=\"post\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE). However, continuous delivery —deploying container image artifacts into your various environments—remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u003c/p\u003e\u003cp\u003eIt doesn’t have to be this way. \u003c/p\u003e\u003cp\u003eToday, we are pleased to announce \u003ca href=\"https://cloud.google.com/deploy\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/deploy\" track-metadata-module=\"post\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;h3\u0026gt;Solving for continuous delivery challenges\u0026lt;br\u0026gt;\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Let\u0026amp;#8217;s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Cost of ownership\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Time and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current\u0026amp;#8212;to say nothing of maintenance\u0026amp;#8212;is resource-intensive and takes time away from the core business.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;\u0026amp;#8220;We can\u0026amp;#8217;t afford to be innovating in continuous delivery,\u0026amp;#8221; one customer told us. \u0026amp;#8220;We want an opinionated product that supports best practices out of the box.\u0026amp;#8221;\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy addresses cost of ownership head-on.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;As a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy also provides structure. \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\u0026#34;\u0026gt;Delivery pipelines\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology\u0026#34;\u0026gt;targets\u0026lt;/a\u0026gt; are defined \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/config-files\u0026#34;\u0026gt;declaratively\u0026lt;/a\u0026gt; and are \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/pipeline-instances\u0026#34;\u0026gt;stored alongside each release\u0026lt;/a\u0026gt;. That means if your delivery pipeline changes, the release\u0026amp;#8217;s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003cbr/\u003e\u003c/h3\u003e\u003cp\u003eGoogle Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u003c/p\u003e\u003cp\u003eLet’s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eTime and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current—to say nothing of maintenance—is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“We can’t afford to be innovating in continuous delivery,” one customer told us. “We want an opinionated product that supports best practices out of the box.”\u003c/i\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy addresses cost of ownership head-on.\u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\" track-metadata-module=\"post\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology\" track-metadata-module=\"post\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/config-files\" track-metadata-module=\"post\"\u003edeclaratively\u003c/a\u003e and are \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/pipeline-instances\" track-metadata-module=\"post\"\u003estored alongside each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cp\u003eWe have found that a variety of GKE roles and personas interact with continuous delivery processes. A DevOps engineer may be focused on release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/deploying-application\" track-metadata-module=\"post\"\u003epromotion and rollback\u003c/a\u003e decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003cbr/\u003e\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Security and audit\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Lots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn\u0026amp;#8217;t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Throughout, Google Cloud Deploy enables fine-grained restriction, with \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/iam-roles-permissions\u0026#34;\u0026gt;discrete resource access control\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/execution-environment\u0026#34;\u0026gt;execution-level security\u0026lt;/a\u0026gt;. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\u0026#34;\u0026gt;approvals\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Auditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u0026lt;a href=\u0026#34;https://cloud.google.com/audit-logs\u0026#34;\u0026gt;Cloud Audit Logs\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/audit-logs\u0026#34;\u0026gt;audits\u0026lt;/a\u0026gt; user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Integration\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Whether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating\u0026#34;\u0026gt;embraces the GKE delivery tooling ecosystems\u0026lt;/a\u0026gt; in three ways: connectivity to CI systems, support for leading configuration (\u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology#render\u0026#34;\u0026gt;rendering\u0026lt;/a\u0026gt;) tooling, and \u0026lt;a href=\u0026#34;https://cloud.google.com/pubsub\u0026#34;\u0026gt;Pub/Sub\u0026lt;/a\u0026gt; notifications to enable third-party integrations.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\u0026#34;\u0026gt;Connecting Google Cloud Deploy\u0026lt;/a\u0026gt; to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple\u0026amp;#160;\u0026lt;i\u0026gt;`\u0026lt;/i\u0026gt;\u0026lt;i\u0026gt;gcloud beta deploy releases create`.\u0026lt;/i\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e\u003cb\u003eSecurity and audit\u003c/b\u003e\u003c/p\u003e\u003cp\u003eLots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained restriction, with \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\" track-metadata-module=\"post\"\u003ediscrete resource access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/execution-environment\" track-metadata-module=\"post\"\u003eexecution-level security\u003c/a\u003e. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\" track-metadata-module=\"post\"\u003eapprovals\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/audit-logs\" track-metadata-module=\"post\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/audit-logs\" track-metadata-module=\"post\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntegration\u003c/b\u003e\u003c/p\u003e\u003cp\u003eWhether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating\" track-metadata-module=\"post\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: connectivity to CI systems, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology#render\" track-metadata-module=\"post\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://cloud.google.com/pubsub\" track-metadata-module=\"post\"\u003ePub/Sub\u003c/a\u003e notifications to enable third-party integrations.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\" track-metadata-module=\"post\"\u003eConnecting Google Cloud Deploy\u003c/a\u003e to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple \u003ci\u003e`\u003c/i\u003e\u003ci\u003egcloud beta deploy releases create`.\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Delivering to Kubernetes often changes over time. To help, Google Cloud Deploy\u0026amp;#160; leverages \u0026lt;a href=\u0026#34;https://skaffold.dev/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Skaffold\u0026lt;/a\u0026gt;, allowing you to \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/skaffold\u0026#34;\u0026gt;standardize your configuration\u0026lt;/a\u0026gt; between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u0026lt;a href=\u0026#34;https://helm.sh/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Helm\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://kustomize.io/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Kustomize\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://kpt.dev/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;kpt\u0026lt;/a\u0026gt;). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Finally, to facilitate other integrations, such as a \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\u0026#34;\u0026gt;post-deployment test execution\u0026lt;/a\u0026gt; or \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\u0026#34;\u0026gt;third party approval workflows\u0026lt;/a\u0026gt;, Google Cloud Deploy \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\u0026#34;\u0026gt;emits Pub/Sub messages\u0026lt;/a\u0026gt; throughout a \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\u0026#34;\u0026gt;release\u0026amp;#8217;s lifecycle\u0026lt;/a\u0026gt;.\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;The future\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Comprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it\u0026amp;#8217;s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we\u0026amp;#8217;re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In the meantime, to get started with the Preview, check out the \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy\u0026#34;\u0026gt;product page\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs\u0026#34;\u0026gt;documentation\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/quickstart-basic\u0026#34;\u0026gt;quickstart\u0026lt;/a\u0026gt;, and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/tutorials\u0026#34;\u0026gt;tutorials\u0026lt;/a\u0026gt;. Finally, If you have feedback on Google Cloud Deploy, you can \u0026lt;a href=\u0026#34;https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;join the conversation\u0026lt;/a\u0026gt;. We look forward to hearing from you!\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eDelivering to Kubernetes often changes over time. To help, Google Cloud Deploy  leverages \u003ca href=\"https://skaffold.dev/\" target=\"_blank\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://skaffold.dev\" track-metadata-module=\"post\"\u003eSkaffold\u003c/a\u003e, allowing you to \u003ca href=\"https://cloud.google.com/deploy/docs/skaffold\" track-type=\"inline link\" track-name=\"18\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/skaffold\" track-metadata-module=\"post\"\u003estandardize your configuration\u003c/a\u003e between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u003ca href=\"https://helm.sh/\" target=\"_blank\" track-type=\"inline link\" track-name=\"19\" track-metadata-eventdetail=\"https://helm.sh\" track-metadata-module=\"post\"\u003eHelm\u003c/a\u003e, \u003ca href=\"https://kustomize.io/\" target=\"_blank\" track-type=\"inline link\" track-name=\"20\" track-metadata-eventdetail=\"https://kustomize.io\" track-metadata-module=\"post\"\u003eKustomize\u003c/a\u003e, \u003ca href=\"https://kpt.dev/\" target=\"_blank\" track-type=\"inline link\" track-name=\"21\" track-metadata-eventdetail=\"https://kpt.dev\" track-metadata-module=\"post\"\u003ekpt\u003c/a\u003e). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u003c/p\u003e\u003cp\u003eFinally, to facilitate other integrations, such as a \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\" track-type=\"inline link\" track-name=\"22\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\" track-metadata-module=\"post\"\u003epost-deployment test execution\u003c/a\u003e or \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\" track-type=\"inline link\" track-name=\"23\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\" track-metadata-module=\"post\"\u003ethird party approval workflows\u003c/a\u003e, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\" track-type=\"inline link\" track-name=\"24\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\" track-metadata-module=\"post\"\u003eemits Pub/Sub messages\u003c/a\u003e throughout a \u003ca href=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\" track-type=\"inline link\" track-name=\"25\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\" track-metadata-module=\"post\"\u003erelease’s lifecycle\u003c/a\u003e.\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we’re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u003c/p\u003e\u003cp\u003eIn the meantime, to get started with the Preview, check out the \u003ca href=\"https://cloud.google.com/deploy\" track-type=\"inline link\" track-name=\"26\" track-metadata-eventdetail=\"https://cloud.google.com/deploy\" track-metadata-module=\"post\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\" track-type=\"inline link\" track-name=\"27\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs\" track-metadata-module=\"post\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\" track-type=\"inline link\" track-name=\"28\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/quickstart-basic\" track-metadata-module=\"post\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\" track-type=\"inline link\" track-name=\"29\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/tutorials\" track-metadata-module=\"post\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\" track-type=\"inline link\" track-name=\"30\" track-metadata-eventdetail=\"https://www.googlecloudcommunity.com\" track-metadata-module=\"post\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-video-block _nghost-c16=\"\"\u003e\u003cp _ngcontent-c16=\"\"\u003e\u003ciframe _ngcontent-c16=\"\" allow=\"encrypted-media\" allowfullscreen=\"\" frameborder=\"0\" height=\"100%\" position=\"absolute\" width=\"100%\" src=\"https://www.youtube.com/embed/Il8FlhR9jKM?enablejsapi=1\u0026amp;\"\u003e\u003c/iframe\u003e\u003c/p\u003e\u003c/article-video-block\u003e\u003c/div\u003e\u003c/article-content-stream-block\u003e\u003carticle-tag-list-block\u003e\u003c/article-tag-list-block\u003e\u003c/div\u003e\u003csection\u003e\u003carticle-up-1to3-block _nghost-c18=\"\"\u003e\u003c/article-up-1to3-block\u003e\u003c/section\u003e\u003c/div\u003e\u003c/article\u003e\u003c/main\u003e\u003c/article-page\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eContinuous delivery is frequently top-of-mind for organizations adopting \u003ca href=\"https://cloud.google.com/kubernetes-engine\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE). However, continuous delivery —deploying container image artifacts into your various environments—remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u003c/p\u003e\u003cp\u003eIt doesn’t have to be this way. \u003c/p\u003eToday, we are pleased to announce \u003ca href=\"https://cloud.google.com/deploy\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_2.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 2.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_2.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003cbr/\u003e\u003c/h3\u003e\u003cp\u003eGoogle Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u003c/p\u003e\u003cp\u003eLet’s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eTime and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current—to say nothing of maintenance—is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“We can’t afford to be innovating in continuous delivery,” one customer told us. “We want an opinionated product that supports best practices out of the box.”\u003c/i\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy addresses cost of ownership head-on.\u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\"\u003edeclaratively\u003c/a\u003e and are \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\"\u003estored alongside each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/cloud-deploy-pp-blog-post-3.gif\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy GIF\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/cloud-deploy-pp-blog-post-3.gif\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWe have found that a variety of GKE roles and personas interact with continuous delivery processes. A DevOps engineer may be focused on release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application\"\u003epromotion and rollback\u003c/a\u003e decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_1.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 1.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_1.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003eContextualized deployment approvals\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003cb\u003eSecurity and audit\u003c/b\u003e\u003c/p\u003e\u003cp\u003eLots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained restriction, with \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\"\u003ediscrete resource access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\"\u003eexecution-level security\u003c/a\u003e. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\"\u003eapprovals\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntegration\u003c/b\u003e\u003c/p\u003e\u003cp\u003eWhether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: connectivity to CI systems, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\"\u003ePub/Sub\u003c/a\u003e notifications to enable third-party integrations.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\"\u003eConnecting Google Cloud Deploy\u003c/a\u003e to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple \u003ci\u003e`\u003c/i\u003e\u003ci\u003egcloud beta deploy releases create`.\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deployt_3_efyUGIq.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 3.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deployt_3_efyUGIq.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eDelivering to Kubernetes often changes over time. To help, Google Cloud Deploy  leverages \u003ca href=\"https://skaffold.dev/\" target=\"_blank\"\u003eSkaffold\u003c/a\u003e, allowing you to \u003ca href=\"https://cloud.google.com/deploy/docs/skaffold\"\u003estandardize your configuration\u003c/a\u003e between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u003ca href=\"https://helm.sh/\" target=\"_blank\"\u003eHelm\u003c/a\u003e, \u003ca href=\"https://kustomize.io/\" target=\"_blank\"\u003eKustomize\u003c/a\u003e, \u003ca href=\"https://kpt.dev/\" target=\"_blank\"\u003ekpt\u003c/a\u003e). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u003c/p\u003e\u003cp\u003eFinally, to facilitate other integrations, such as a \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\"\u003epost-deployment test execution\u003c/a\u003e or \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\"\u003ethird party approval workflows\u003c/a\u003e, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\"\u003eemits Pub/Sub messages\u003c/a\u003e throughout a \u003ca href=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\"\u003erelease’s lifecycle\u003c/a\u003e.\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we’re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u003c/p\u003e\u003cp\u003eIn the meantime, to get started with the Preview, check out the \u003ca href=\"https://cloud.google.com/deploy\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-video\"\u003e\u003cdiv class=\"article-module article-video \"\u003e\u003cfigure\u003e\u003ca class=\"h-c-video h-c-video--marquee\" data-glue-modal-disabled-on-mobile=\"true\" data-glue-modal-trigger=\"uni-modal-Il8FlhR9jKM-\" href=\"https://youtube.com/watch?v=Il8FlhR9jKM\"\u003e\u003cimg alt=\"Introducing Cloud Deploy\" src=\"//img.youtube.com/vi/Il8FlhR9jKM/maxresdefault.jpg\"/\u003e\u003csvg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" role=\"img\"\u003e\u003cuse xlink:href=\"#mi-youtube-icon\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv class=\"h-c-modal--video\" data-glue-modal=\"uni-modal-Il8FlhR9jKM-\" data-glue-modal-close-label=\"Close Dialog\"\u003e\u003ca class=\"glue-yt-video\" data-glue-yt-video-autoplay=\"true\" data-glue-yt-video-height=\"99%\" data-glue-yt-video-vid=\"Il8FlhR9jKM\" data-glue-yt-video-width=\"100%\" href=\"https://youtube.com/watch?v=Il8FlhR9jKM\" ng-cloak=\"\"\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/announcing-dora-2021-accelerate-state-of-devops-report/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/SODR2021_1920x1080.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e2021 Accelerate State of DevOps report addresses burnout, team performance\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eThe SODR is continually one of the most downloaded assets on the GCP website. We are releasing the updated version of the report with new...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/gcp_ZPje3k8.max-2200x2200.jpg",
      "date_published": "2021-09-22T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eS. Bogdan\u003c/name\u003e\u003ctitle\u003eProduct Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/google-cloud-deploy-automates-deploys-to-gke/",
      "title": "Introducing Google Cloud Deploy: Managed continuous delivery to GKE",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle-page\u003e\u003cmain id=\"jump-content\"\u003e\u003carticle\u003e\u003carticle-header-block\u003e\u003c/article-header-block\u003e\u003carticle-aspect-image-block\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003e#gcp\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/article-aspect-image-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-author-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003e S. Bogdan \u003c/p\u003e\u003cp\u003e Product Manager \u003c/p\u003e\u003c/div\u003e\u003cp\u003e\u003cspan\u003e September 22, 2021 \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-author-block\u003e\u003c/div\u003e\u003carticle-cta _nghost-c50=\"\"\u003e\u003cdiv _ngcontent-c50=\"\"\u003e\u003ch4 _ngcontent-c50=\"\"\u003e\u003cspan _ngcontent-c50=\"\"\u003eNext ’21 registration is open\u003c/span\u003e\u003c/h4\u003e\u003cp _ngcontent-c50=\"\"\u003e\u003cspan _ngcontent-c50=\"\"\u003eJoin us October 12–14, 2021, for our digital flagship event\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003ca _ngcontent-c50=\"\" clicktracker=\"\" rel=\"external\" track-metadata-module=\"article cta\" track-type=\"button\" track-name=\"Next21 registration\" track-metadata-eventdetail=\"https://cloud.withgoogle.com/next/register?utm_source=google\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY21-Q4-global-ES903-onlineevent-er-next-2021\u0026amp;utm_content=blog-next-21-registration\" href=\"https://cloud.withgoogle.com/next/register?utm_source=google\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY21-Q4-global-ES903-onlineevent-er-next-2021\u0026amp;utm_content=blog-next-21-registration\"\u003e\u003cspan _ngcontent-c50=\"\"\u003eRegister now\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-cta\u003e\u003c/div\u003e\u003carticle-share-block\u003e\u003c/article-share-block\u003e\u003carticle-sticky-share-block\u003e\u003c/article-sticky-share-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-content-stream-block\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c52=\"\"\u003e\u003cdiv _ngcontent-c52=\"\" innerhtml=\"\u0026lt;p\u0026gt;Continuous delivery is frequently top-of-mind for organizations adopting \u0026lt;a href=\u0026#34;https://cloud.google.com/kubernetes-engine\u0026#34;\u0026gt;Google Kubernetes Engine\u0026lt;/a\u0026gt; (GKE). However, continuous delivery \u0026amp;#8212;deploying container image artifacts into your various environments\u0026amp;#8212;remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;It doesn\u0026amp;#8217;t have to be this way.\u0026amp;#160;\u0026lt;/p\u0026gt;Today, we are pleased to announce \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy\u0026#34;\u0026gt;Google Cloud Deploy\u0026lt;/a\u0026gt;, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eContinuous delivery is frequently top-of-mind for organizations adopting \u003ca href=\"https://cloud.google.com/kubernetes-engine\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/kubernetes-engine\" track-metadata-module=\"post\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE). However, continuous delivery —deploying container image artifacts into your various environments—remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u003c/p\u003e\u003cp\u003eIt doesn’t have to be this way. \u003c/p\u003e\u003cp\u003eToday, we are pleased to announce \u003ca href=\"https://cloud.google.com/deploy\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/deploy\" track-metadata-module=\"post\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c52=\"\"\u003e\u003cdiv _ngcontent-c52=\"\" innerhtml=\"\u0026lt;h3\u0026gt;Solving for continuous delivery challenges\u0026lt;br\u0026gt;\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Let\u0026amp;#8217;s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Cost of ownership\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Time and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current\u0026amp;#8212;to say nothing of maintenance\u0026amp;#8212;is resource-intensive and takes time away from the core business.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;\u0026amp;#8220;We can\u0026amp;#8217;t afford to be innovating in continuous delivery,\u0026amp;#8221; one customer told us. \u0026amp;#8220;We want an opinionated product that supports best practices out of the box.\u0026amp;#8221;\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy addresses cost of ownership head-on.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;As a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy also provides structure. \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\u0026#34;\u0026gt;Delivery pipelines\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology\u0026#34;\u0026gt;targets\u0026lt;/a\u0026gt; are defined \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/config-files\u0026#34;\u0026gt;declaratively\u0026lt;/a\u0026gt; and are \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/pipeline-instances\u0026#34;\u0026gt;stored alongside each release\u0026lt;/a\u0026gt;. That means if your delivery pipeline changes, the release\u0026amp;#8217;s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003cbr/\u003e\u003c/h3\u003e\u003cp\u003eGoogle Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u003c/p\u003e\u003cp\u003eLet’s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eTime and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current—to say nothing of maintenance—is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“We can’t afford to be innovating in continuous delivery,” one customer told us. “We want an opinionated product that supports best practices out of the box.”\u003c/i\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy addresses cost of ownership head-on.\u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\" track-metadata-module=\"post\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology\" track-metadata-module=\"post\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/config-files\" track-metadata-module=\"post\"\u003edeclaratively\u003c/a\u003e and are \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/pipeline-instances\" track-metadata-module=\"post\"\u003estored alongside each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c52=\"\"\u003e\u003cp\u003eWe have found that a variety of GKE roles and personas interact with continuous delivery processes. A DevOps engineer may be focused on release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/deploying-application\" track-metadata-module=\"post\"\u003epromotion and rollback\u003c/a\u003e decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003cbr/\u003e\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c52=\"\"\u003e\u003cdiv _ngcontent-c52=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Security and audit\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Lots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn\u0026amp;#8217;t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Throughout, Google Cloud Deploy enables fine-grained restriction, with \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/iam-roles-permissions\u0026#34;\u0026gt;discrete resource access control\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/execution-environment\u0026#34;\u0026gt;execution-level security\u0026lt;/a\u0026gt;. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\u0026#34;\u0026gt;approvals\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Auditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u0026lt;a href=\u0026#34;https://cloud.google.com/audit-logs\u0026#34;\u0026gt;Cloud Audit Logs\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/audit-logs\u0026#34;\u0026gt;audits\u0026lt;/a\u0026gt; user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Integration\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Whether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating\u0026#34;\u0026gt;embraces the GKE delivery tooling ecosystems\u0026lt;/a\u0026gt; in three ways: connectivity to CI systems, support for leading configuration (\u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology#render\u0026#34;\u0026gt;rendering\u0026lt;/a\u0026gt;) tooling, and \u0026lt;a href=\u0026#34;https://cloud.google.com/pubsub\u0026#34;\u0026gt;Pub/Sub\u0026lt;/a\u0026gt; notifications to enable third-party integrations.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\u0026#34;\u0026gt;Connecting Google Cloud Deploy\u0026lt;/a\u0026gt; to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple\u0026amp;#160;\u0026lt;i\u0026gt;`\u0026lt;/i\u0026gt;\u0026lt;i\u0026gt;gcloud beta deploy releases create`.\u0026lt;/i\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e\u003cb\u003eSecurity and audit\u003c/b\u003e\u003c/p\u003e\u003cp\u003eLots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained restriction, with \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\" track-metadata-module=\"post\"\u003ediscrete resource access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/execution-environment\" track-metadata-module=\"post\"\u003eexecution-level security\u003c/a\u003e. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\" track-metadata-module=\"post\"\u003eapprovals\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/audit-logs\" track-metadata-module=\"post\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/audit-logs\" track-metadata-module=\"post\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntegration\u003c/b\u003e\u003c/p\u003e\u003cp\u003eWhether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating\" track-metadata-module=\"post\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: connectivity to CI systems, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology#render\" track-metadata-module=\"post\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://cloud.google.com/pubsub\" track-metadata-module=\"post\"\u003ePub/Sub\u003c/a\u003e notifications to enable third-party integrations.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\" track-metadata-module=\"post\"\u003eConnecting Google Cloud Deploy\u003c/a\u003e to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple \u003ci\u003e`\u003c/i\u003e\u003ci\u003egcloud beta deploy releases create`.\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c52=\"\"\u003e\u003cdiv _ngcontent-c52=\"\" innerhtml=\"\u0026lt;p\u0026gt;Delivering to Kubernetes often changes over time. To help, Google Cloud Deploy\u0026amp;#160; leverages \u0026lt;a href=\u0026#34;https://skaffold.dev/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Skaffold\u0026lt;/a\u0026gt;, allowing you to \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/skaffold\u0026#34;\u0026gt;standardize your configuration\u0026lt;/a\u0026gt; between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u0026lt;a href=\u0026#34;https://helm.sh/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Helm\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://kustomize.io/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Kustomize\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://kpt.dev/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;kpt\u0026lt;/a\u0026gt;). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Finally, to facilitate other integrations, such as a \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\u0026#34;\u0026gt;post-deployment test execution\u0026lt;/a\u0026gt; or \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\u0026#34;\u0026gt;third party approval workflows\u0026lt;/a\u0026gt;, Google Cloud Deploy \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\u0026#34;\u0026gt;emits Pub/Sub messages\u0026lt;/a\u0026gt; throughout a \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\u0026#34;\u0026gt;release\u0026amp;#8217;s lifecycle\u0026lt;/a\u0026gt;.\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;The future\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Comprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it\u0026amp;#8217;s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we\u0026amp;#8217;re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In the meantime, to get started with the Preview, check out the \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy\u0026#34;\u0026gt;product page\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs\u0026#34;\u0026gt;documentation\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/quickstart-basic\u0026#34;\u0026gt;quickstart\u0026lt;/a\u0026gt;, and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/tutorials\u0026#34;\u0026gt;tutorials\u0026lt;/a\u0026gt;. Finally, If you have feedback on Google Cloud Deploy, you can \u0026lt;a href=\u0026#34;https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;join the conversation\u0026lt;/a\u0026gt;. We look forward to hearing from you!\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eDelivering to Kubernetes often changes over time. To help, Google Cloud Deploy  leverages \u003ca href=\"https://skaffold.dev/\" target=\"_blank\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://skaffold.dev\" track-metadata-module=\"post\"\u003eSkaffold\u003c/a\u003e, allowing you to \u003ca href=\"https://cloud.google.com/deploy/docs/skaffold\" track-type=\"inline link\" track-name=\"18\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/skaffold\" track-metadata-module=\"post\"\u003estandardize your configuration\u003c/a\u003e between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u003ca href=\"https://helm.sh/\" target=\"_blank\" track-type=\"inline link\" track-name=\"19\" track-metadata-eventdetail=\"https://helm.sh\" track-metadata-module=\"post\"\u003eHelm\u003c/a\u003e, \u003ca href=\"https://kustomize.io/\" target=\"_blank\" track-type=\"inline link\" track-name=\"20\" track-metadata-eventdetail=\"https://kustomize.io\" track-metadata-module=\"post\"\u003eKustomize\u003c/a\u003e, \u003ca href=\"https://kpt.dev/\" target=\"_blank\" track-type=\"inline link\" track-name=\"21\" track-metadata-eventdetail=\"https://kpt.dev\" track-metadata-module=\"post\"\u003ekpt\u003c/a\u003e). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u003c/p\u003e\u003cp\u003eFinally, to facilitate other integrations, such as a \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\" track-type=\"inline link\" track-name=\"22\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\" track-metadata-module=\"post\"\u003epost-deployment test execution\u003c/a\u003e or \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\" track-type=\"inline link\" track-name=\"23\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\" track-metadata-module=\"post\"\u003ethird party approval workflows\u003c/a\u003e, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\" track-type=\"inline link\" track-name=\"24\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\" track-metadata-module=\"post\"\u003eemits Pub/Sub messages\u003c/a\u003e throughout a \u003ca href=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\" track-type=\"inline link\" track-name=\"25\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\" track-metadata-module=\"post\"\u003erelease’s lifecycle\u003c/a\u003e.\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we’re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u003c/p\u003e\u003cp\u003eIn the meantime, to get started with the Preview, check out the \u003ca href=\"https://cloud.google.com/deploy\" track-type=\"inline link\" track-name=\"26\" track-metadata-eventdetail=\"https://cloud.google.com/deploy\" track-metadata-module=\"post\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\" track-type=\"inline link\" track-name=\"27\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs\" track-metadata-module=\"post\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\" track-type=\"inline link\" track-name=\"28\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/quickstart-basic\" track-metadata-module=\"post\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\" track-type=\"inline link\" track-name=\"29\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/tutorials\" track-metadata-module=\"post\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\" track-type=\"inline link\" track-name=\"30\" track-metadata-eventdetail=\"https://www.googlecloudcommunity.com\" track-metadata-module=\"post\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-video-block _nghost-c49=\"\"\u003e\u003cp _ngcontent-c49=\"\"\u003e\u003ciframe _ngcontent-c49=\"\" allow=\"encrypted-media\" allowfullscreen=\"\" frameborder=\"0\" height=\"100%\" position=\"absolute\" width=\"100%\" src=\"https://www.youtube.com/embed/Il8FlhR9jKM?enablejsapi=1\u0026amp;\"\u003e\u003c/iframe\u003e\u003c/p\u003e\u003c/article-video-block\u003e\u003c/div\u003e\u003c/article-content-stream-block\u003e\u003carticle-tag-list-block\u003e\u003c/article-tag-list-block\u003e\u003c/div\u003e\u003csection\u003e\u003carticle-up-1to3-block _nghost-c51=\"\"\u003e\u003c/article-up-1to3-block\u003e\u003c/section\u003e\u003c/div\u003e\u003c/article\u003e\u003c/main\u003e\u003c/article-page\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eContinuous delivery is frequently top-of-mind for organizations adopting \u003ca href=\"https://cloud.google.com/kubernetes-engine\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE). However, continuous delivery —deploying container image artifacts into your various environments—remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u003c/p\u003e\u003cp\u003eIt doesn’t have to be this way. \u003c/p\u003eToday, we are pleased to announce \u003ca href=\"https://cloud.google.com/deploy\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_2.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 2.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_2.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003cbr/\u003e\u003c/h3\u003e\u003cp\u003eGoogle Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u003c/p\u003e\u003cp\u003eLet’s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eTime and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current—to say nothing of maintenance—is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“We can’t afford to be innovating in continuous delivery,” one customer told us. “We want an opinionated product that supports best practices out of the box.”\u003c/i\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy addresses cost of ownership head-on.\u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\"\u003edeclaratively\u003c/a\u003e and are \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\"\u003estored alongside each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/cloud-deploy-pp-blog-post-3.gif\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy GIF\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/cloud-deploy-pp-blog-post-3.gif\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWe have found that a variety of GKE roles and personas interact with continuous delivery processes. A DevOps engineer may be focused on release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application\"\u003epromotion and rollback\u003c/a\u003e decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_1.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 1.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_1.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003eContextualized deployment approvals\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003cb\u003eSecurity and audit\u003c/b\u003e\u003c/p\u003e\u003cp\u003eLots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained restriction, with \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\"\u003ediscrete resource access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\"\u003eexecution-level security\u003c/a\u003e. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\"\u003eapprovals\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntegration\u003c/b\u003e\u003c/p\u003e\u003cp\u003eWhether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: connectivity to CI systems, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\"\u003ePub/Sub\u003c/a\u003e notifications to enable third-party integrations.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\"\u003eConnecting Google Cloud Deploy\u003c/a\u003e to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple \u003ci\u003e`\u003c/i\u003e\u003ci\u003egcloud beta deploy releases create`.\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deployt_3_efyUGIq.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 3.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deployt_3_efyUGIq.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eDelivering to Kubernetes often changes over time. To help, Google Cloud Deploy  leverages \u003ca href=\"https://skaffold.dev/\" target=\"_blank\"\u003eSkaffold\u003c/a\u003e, allowing you to \u003ca href=\"https://cloud.google.com/deploy/docs/skaffold\"\u003estandardize your configuration\u003c/a\u003e between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u003ca href=\"https://helm.sh/\" target=\"_blank\"\u003eHelm\u003c/a\u003e, \u003ca href=\"https://kustomize.io/\" target=\"_blank\"\u003eKustomize\u003c/a\u003e, \u003ca href=\"https://kpt.dev/\" target=\"_blank\"\u003ekpt\u003c/a\u003e). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u003c/p\u003e\u003cp\u003eFinally, to facilitate other integrations, such as a \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\"\u003epost-deployment test execution\u003c/a\u003e or \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\"\u003ethird party approval workflows\u003c/a\u003e, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\"\u003eemits Pub/Sub messages\u003c/a\u003e throughout a \u003ca href=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\"\u003erelease’s lifecycle\u003c/a\u003e.\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we’re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u003c/p\u003e\u003cp\u003eIn the meantime, to get started with the Preview, check out the \u003ca href=\"https://cloud.google.com/deploy\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-video\"\u003e\u003cdiv class=\"article-module article-video \"\u003e\u003cfigure\u003e\u003ca class=\"h-c-video h-c-video--marquee\" data-glue-modal-disabled-on-mobile=\"true\" data-glue-modal-trigger=\"uni-modal-Il8FlhR9jKM-\" href=\"https://youtube.com/watch?v=Il8FlhR9jKM\"\u003e\u003cimg alt=\"Introducing Cloud Deploy\" src=\"//img.youtube.com/vi/Il8FlhR9jKM/maxresdefault.jpg\"/\u003e\u003csvg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" role=\"img\"\u003e\u003cuse xlink:href=\"#mi-youtube-icon\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv class=\"h-c-modal--video\" data-glue-modal=\"uni-modal-Il8FlhR9jKM-\" data-glue-modal-close-label=\"Close Dialog\"\u003e\u003ca class=\"glue-yt-video\" data-glue-yt-video-autoplay=\"true\" data-glue-yt-video-height=\"99%\" data-glue-yt-video-vid=\"Il8FlhR9jKM\" data-glue-yt-video-width=\"100%\" href=\"https://youtube.com/watch?v=Il8FlhR9jKM\" ng-cloak=\"\"\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/announcing-dora-2021-accelerate-state-of-devops-report/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/SODR2021_1920x1080.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e2021 Accelerate State of DevOps report addresses burnout, team performance\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eThe SODR is continually one of the most downloaded assets on the GCP website. We are releasing the updated version of the report with new...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/gcp_ZPje3k8.max-2200x2200.jpg",
      "date_published": "2021-09-22T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eS. Bogdan\u003c/name\u003e\u003ctitle\u003eProduct Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/google-cloud-deploy-automates-deploys-to-gke/",
      "title": "Introducing Google Cloud Deploy: Managed continuous delivery to GKE",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle-page\u003e\u003cmain id=\"jump-content\"\u003e\u003carticle\u003e\u003carticle-header-block\u003e\u003c/article-header-block\u003e\u003carticle-aspect-image-block\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003e#gcp\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/article-aspect-image-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-author-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003e S. Bogdan \u003c/p\u003e\u003cp\u003e Product Manager \u003c/p\u003e\u003c/div\u003e\u003cp\u003e\u003cspan\u003e September 22, 2021 \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-author-block\u003e\u003c/div\u003e\u003carticle-cta _nghost-c17=\"\"\u003e\u003cdiv _ngcontent-c17=\"\"\u003e\u003ch4 _ngcontent-c17=\"\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eNext ’21 registration is open\u003c/span\u003e\u003c/h4\u003e\u003cp _ngcontent-c17=\"\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eJoin us October 12–14, 2021, for our digital flagship event\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003ca _ngcontent-c17=\"\" clicktracker=\"\" rel=\"external\" track-metadata-module=\"article cta\" track-type=\"button\" track-name=\"Next21 registration\" track-metadata-eventdetail=\"https://cloud.withgoogle.com/next/register?utm_source=google\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY21-Q4-global-ES903-onlineevent-er-next-2021\u0026amp;utm_content=blog-next-21-registration\" href=\"https://cloud.withgoogle.com/next/register?utm_source=google\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY21-Q4-global-ES903-onlineevent-er-next-2021\u0026amp;utm_content=blog-next-21-registration\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eRegister now\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-cta\u003e\u003c/div\u003e\u003carticle-share-block\u003e\u003c/article-share-block\u003e\u003carticle-sticky-share-block\u003e\u003c/article-sticky-share-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-content-stream-block\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Continuous delivery is frequently top-of-mind for organizations adopting \u0026lt;a href=\u0026#34;https://cloud.google.com/kubernetes-engine\u0026#34;\u0026gt;Google Kubernetes Engine\u0026lt;/a\u0026gt; (GKE). However, continuous delivery \u0026amp;#8212;deploying container image artifacts into your various environments\u0026amp;#8212;remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;It doesn\u0026amp;#8217;t have to be this way.\u0026amp;#160;\u0026lt;/p\u0026gt;Today, we are pleased to announce \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy\u0026#34;\u0026gt;Google Cloud Deploy\u0026lt;/a\u0026gt;, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eContinuous delivery is frequently top-of-mind for organizations adopting \u003ca href=\"https://cloud.google.com/kubernetes-engine\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/kubernetes-engine\" track-metadata-module=\"post\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE). However, continuous delivery —deploying container image artifacts into your various environments—remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u003c/p\u003e\u003cp\u003eIt doesn’t have to be this way. \u003c/p\u003e\u003cp\u003eToday, we are pleased to announce \u003ca href=\"https://cloud.google.com/deploy\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/deploy\" track-metadata-module=\"post\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;h3\u0026gt;Solving for continuous delivery challenges\u0026lt;br\u0026gt;\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Let\u0026amp;#8217;s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Cost of ownership\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Time and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current\u0026amp;#8212;to say nothing of maintenance\u0026amp;#8212;is resource-intensive and takes time away from the core business.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;\u0026amp;#8220;We can\u0026amp;#8217;t afford to be innovating in continuous delivery,\u0026amp;#8221; one customer told us. \u0026amp;#8220;We want an opinionated product that supports best practices out of the box.\u0026amp;#8221;\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy addresses cost of ownership head-on.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;As a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy also provides structure. \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\u0026#34;\u0026gt;Delivery pipelines\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology\u0026#34;\u0026gt;targets\u0026lt;/a\u0026gt; are defined \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/config-files\u0026#34;\u0026gt;declaratively\u0026lt;/a\u0026gt; and are \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/pipeline-instances\u0026#34;\u0026gt;stored alongside each release\u0026lt;/a\u0026gt;. That means if your delivery pipeline changes, the release\u0026amp;#8217;s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u0026lt;b\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003cbr/\u003e\u003c/h3\u003e\u003cp\u003eGoogle Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u003c/p\u003e\u003cp\u003eLet’s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eTime and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current—to say nothing of maintenance—is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“We can’t afford to be innovating in continuous delivery,” one customer told us. “We want an opinionated product that supports best practices out of the box.”\u003c/i\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy addresses cost of ownership head-on.\u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\" track-metadata-module=\"post\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology\" track-metadata-module=\"post\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/config-files\" track-metadata-module=\"post\"\u003edeclaratively\u003c/a\u003e and are \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/pipeline-instances\" track-metadata-module=\"post\"\u003estored alongside each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cp\u003eWe have found that a variety of GKE roles and personas interact with continuous delivery processes. A DevOps engineer may be focused on release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/deploying-application\" track-metadata-module=\"post\"\u003epromotion and rollback\u003c/a\u003e decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003cbr/\u003e\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Security and audit\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Lots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn\u0026amp;#8217;t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Throughout, Google Cloud Deploy enables fine-grained restriction, with \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/iam-roles-permissions\u0026#34;\u0026gt;discrete resource access control\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/execution-environment\u0026#34;\u0026gt;execution-level security\u0026lt;/a\u0026gt;. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\u0026#34;\u0026gt;approvals\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Auditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u0026lt;a href=\u0026#34;https://cloud.google.com/audit-logs\u0026#34;\u0026gt;Cloud Audit Logs\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/audit-logs\u0026#34;\u0026gt;audits\u0026lt;/a\u0026gt; user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Integration\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Whether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud Deploy \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating\u0026#34;\u0026gt;embraces the GKE delivery tooling ecosystems\u0026lt;/a\u0026gt; in three ways: connectivity to CI systems, support for leading configuration (\u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/terminology#render\u0026#34;\u0026gt;rendering\u0026lt;/a\u0026gt;) tooling, and \u0026lt;a href=\u0026#34;https://cloud.google.com/pubsub\u0026#34;\u0026gt;Pub/Sub\u0026lt;/a\u0026gt; notifications to enable third-party integrations.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\u0026#34;\u0026gt;Connecting Google Cloud Deploy\u0026lt;/a\u0026gt; to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple\u0026amp;#160;\u0026lt;i\u0026gt;`\u0026lt;/i\u0026gt;\u0026lt;i\u0026gt;gcloud beta deploy releases create`.\u0026lt;/i\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e\u003cb\u003eSecurity and audit\u003c/b\u003e\u003c/p\u003e\u003cp\u003eLots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained restriction, with \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\" track-metadata-module=\"post\"\u003ediscrete resource access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/execution-environment\" track-metadata-module=\"post\"\u003eexecution-level security\u003c/a\u003e. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\" track-metadata-module=\"post\"\u003eapprovals\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/audit-logs\" track-metadata-module=\"post\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/audit-logs\" track-metadata-module=\"post\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntegration\u003c/b\u003e\u003c/p\u003e\u003cp\u003eWhether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating\" track-metadata-module=\"post\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: connectivity to CI systems, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/terminology#render\" track-metadata-module=\"post\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://cloud.google.com/pubsub\" track-metadata-module=\"post\"\u003ePub/Sub\u003c/a\u003e notifications to enable third-party integrations.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\" track-metadata-module=\"post\"\u003eConnecting Google Cloud Deploy\u003c/a\u003e to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple \u003ci\u003e`\u003c/i\u003e\u003ci\u003egcloud beta deploy releases create`.\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Delivering to Kubernetes often changes over time. To help, Google Cloud Deploy\u0026amp;#160; leverages \u0026lt;a href=\u0026#34;https://skaffold.dev/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Skaffold\u0026lt;/a\u0026gt;, allowing you to \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/skaffold\u0026#34;\u0026gt;standardize your configuration\u0026lt;/a\u0026gt; between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u0026lt;a href=\u0026#34;https://helm.sh/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Helm\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://kustomize.io/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Kustomize\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://kpt.dev/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;kpt\u0026lt;/a\u0026gt;). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Finally, to facilitate other integrations, such as a \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\u0026#34;\u0026gt;post-deployment test execution\u0026lt;/a\u0026gt; or \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\u0026#34;\u0026gt;third party approval workflows\u0026lt;/a\u0026gt;, Google Cloud Deploy \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\u0026#34;\u0026gt;emits Pub/Sub messages\u0026lt;/a\u0026gt; throughout a \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\u0026#34;\u0026gt;release\u0026amp;#8217;s lifecycle\u0026lt;/a\u0026gt;.\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;The future\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Comprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it\u0026amp;#8217;s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we\u0026amp;#8217;re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In the meantime, to get started with the Preview, check out the \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy\u0026#34;\u0026gt;product page\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs\u0026#34;\u0026gt;documentation\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/quickstart-basic\u0026#34;\u0026gt;quickstart\u0026lt;/a\u0026gt;, and \u0026lt;a href=\u0026#34;https://cloud.google.com/deploy/docs/tutorials\u0026#34;\u0026gt;tutorials\u0026lt;/a\u0026gt;. Finally, If you have feedback on Google Cloud Deploy, you can \u0026lt;a href=\u0026#34;https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;join the conversation\u0026lt;/a\u0026gt;. We look forward to hearing from you!\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eDelivering to Kubernetes often changes over time. To help, Google Cloud Deploy  leverages \u003ca href=\"https://skaffold.dev/\" target=\"_blank\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://skaffold.dev\" track-metadata-module=\"post\"\u003eSkaffold\u003c/a\u003e, allowing you to \u003ca href=\"https://cloud.google.com/deploy/docs/skaffold\" track-type=\"inline link\" track-name=\"18\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/skaffold\" track-metadata-module=\"post\"\u003estandardize your configuration\u003c/a\u003e between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u003ca href=\"https://helm.sh/\" target=\"_blank\" track-type=\"inline link\" track-name=\"19\" track-metadata-eventdetail=\"https://helm.sh\" track-metadata-module=\"post\"\u003eHelm\u003c/a\u003e, \u003ca href=\"https://kustomize.io/\" target=\"_blank\" track-type=\"inline link\" track-name=\"20\" track-metadata-eventdetail=\"https://kustomize.io\" track-metadata-module=\"post\"\u003eKustomize\u003c/a\u003e, \u003ca href=\"https://kpt.dev/\" target=\"_blank\" track-type=\"inline link\" track-name=\"21\" track-metadata-eventdetail=\"https://kpt.dev\" track-metadata-module=\"post\"\u003ekpt\u003c/a\u003e). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u003c/p\u003e\u003cp\u003eFinally, to facilitate other integrations, such as a \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\" track-type=\"inline link\" track-name=\"22\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\" track-metadata-module=\"post\"\u003epost-deployment test execution\u003c/a\u003e or \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\" track-type=\"inline link\" track-name=\"23\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\" track-metadata-module=\"post\"\u003ethird party approval workflows\u003c/a\u003e, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\" track-type=\"inline link\" track-name=\"24\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\" track-metadata-module=\"post\"\u003eemits Pub/Sub messages\u003c/a\u003e throughout a \u003ca href=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\" track-type=\"inline link\" track-name=\"25\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\" track-metadata-module=\"post\"\u003erelease’s lifecycle\u003c/a\u003e.\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we’re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u003c/p\u003e\u003cp\u003eIn the meantime, to get started with the Preview, check out the \u003ca href=\"https://cloud.google.com/deploy\" track-type=\"inline link\" track-name=\"26\" track-metadata-eventdetail=\"https://cloud.google.com/deploy\" track-metadata-module=\"post\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\" track-type=\"inline link\" track-name=\"27\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs\" track-metadata-module=\"post\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\" track-type=\"inline link\" track-name=\"28\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/quickstart-basic\" track-metadata-module=\"post\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\" track-type=\"inline link\" track-name=\"29\" track-metadata-eventdetail=\"https://cloud.google.com/deploy/docs/tutorials\" track-metadata-module=\"post\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\" track-type=\"inline link\" track-name=\"30\" track-metadata-eventdetail=\"https://www.googlecloudcommunity.com\" track-metadata-module=\"post\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-video-block _nghost-c16=\"\"\u003e\u003cp _ngcontent-c16=\"\"\u003e\u003ciframe _ngcontent-c16=\"\" allow=\"encrypted-media\" allowfullscreen=\"\" frameborder=\"0\" height=\"100%\" position=\"absolute\" width=\"100%\" src=\"https://www.youtube.com/embed/Il8FlhR9jKM?enablejsapi=1\u0026amp;\"\u003e\u003c/iframe\u003e\u003c/p\u003e\u003c/article-video-block\u003e\u003c/div\u003e\u003c/article-content-stream-block\u003e\u003carticle-tag-list-block\u003e\u003c/article-tag-list-block\u003e\u003c/div\u003e\u003csection\u003e\u003carticle-up-1to3-block _nghost-c18=\"\"\u003e\u003c/article-up-1to3-block\u003e\u003c/section\u003e\u003c/div\u003e\u003c/article\u003e\u003c/main\u003e\u003c/article-page\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eContinuous delivery is frequently top-of-mind for organizations adopting \u003ca href=\"https://cloud.google.com/kubernetes-engine\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE). However, continuous delivery —deploying container image artifacts into your various environments—remains complex, particularly in Kubernetes environments. With little in the way of accepted best practices, building and scaling continuous delivery tooling, pipelines, and repeatable processes is hard work that requires a lot of on-the-job experience.\u003c/p\u003e\u003cp\u003eIt doesn’t have to be this way. \u003c/p\u003eToday, we are pleased to announce \u003ca href=\"https://cloud.google.com/deploy\"\u003eGoogle Cloud Deploy\u003c/a\u003e, a managed, opinionated continuous delivery service that makes continuous delivery to GKE easier, faster, and more reliable.\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_2.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 2.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_2.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eSolving for continuous delivery challenges\u003cbr/\u003e\u003c/h3\u003e\u003cp\u003eGoogle Cloud Deploy is the product of discussions with more than 50 customers to better understand the challenges they face doing continuous delivery to GKE. From cloud-native to more traditional businesses, three themes consistently emerged: cost of ownership, security and audit, and integration.\u003c/p\u003e\u003cp\u003eLet’s take a deeper look at these challenges and how we address them with Google Cloud Deploy.\u003c/p\u003e\u003cp\u003e\u003cb\u003eCost of ownership\u003c/b\u003e\u003c/p\u003e\u003cp\u003eTime and again we heard that the operational cost of Kubernetes continuous delivery is high. Identifying best and repeatable practices, scaling delivery tooling and pipelines, and staying current—to say nothing of maintenance—is resource-intensive and takes time away from the core business. \u003c/p\u003e\u003cp\u003e\u003ci\u003e“We can’t afford to be innovating in continuous delivery,” one customer told us. “We want an opinionated product that supports best practices out of the box.”\u003c/i\u003e\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy addresses cost of ownership head-on.\u003c/p\u003e\u003cp\u003eAs a managed service, Google Cloud Deploy eliminates the scaling and maintenance responsibilities that typically come with self-managed continuous delivery solutions. Now you can reclaim the time spent maintaining your continuous delivery tooling and spend it delivering value to your customers. \u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy also provides structure. \u003ca href=\"https://cloud.google.com/deploy/docs/terminology#delivery_pipeline\"\u003eDelivery pipelines\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/terminology\"\u003etargets\u003c/a\u003e are defined \u003ca href=\"https://cloud.google.com/deploy/docs/config-files\"\u003edeclaratively\u003c/a\u003e and are \u003ca href=\"https://cloud.google.com/deploy/docs/pipeline-instances\"\u003estored alongside each release\u003c/a\u003e. That means if your delivery pipeline changes, the release’s path to production remains durable. No more time lost troubleshooting issues on in-flight releases caused by changes made to the delivery pipeline.\u003cb\u003e\u003cbr/\u003e\u003c/b\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/cloud-deploy-pp-blog-post-3.gif\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy GIF\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/original_images/cloud-deploy-pp-blog-post-3.gif\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWe have found that a variety of GKE roles and personas interact with continuous delivery processes. A DevOps engineer may be focused on release \u003ca href=\"https://cloud.google.com/deploy/docs/deploying-application\"\u003epromotion and rollback\u003c/a\u003e decisions, while a business decision maker thinks about delivery pipeline health and velocity. Google Cloud Deploy’s user experience keeps these multiple perspectives in mind, making it easier for various personas to perform contextualized reviews and make decisions, improving efficiency and reducing cost of ownership.\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_1.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 1.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deploy_1.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003eContextualized deployment approvals\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003cb\u003eSecurity and audit\u003c/b\u003e\u003c/p\u003e\u003cp\u003eLots of different users interact with a continuous delivery system, making a variety of decisions. Not all users and decisions carry the same authority, however. Being able to define a delivery pipeline and make updates doesn’t always mean you can create releases, for example, nor does being able to promote a release to staging mean you can approve it to production. Modern continuous delivery is full of security and audit considerations. Restricting who can access what, where, and how is necessary to maintain release integrity and safety.\u003c/p\u003e\u003cp\u003eThroughout, Google Cloud Deploy enables fine-grained restriction, with \u003ca href=\"https://cloud.google.com/deploy/docs/iam-roles-permissions\"\u003ediscrete resource access control\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/deploy/docs/execution-environment\"\u003eexecution-level security\u003c/a\u003e. For additional safeguards against unwanted approvals, you can also take advantage of flow management features such as release promotion, rollback, and \u003ca href=\"https://cloud.google.com/deploy/docs/managing-delivery-pipeline#requiring_approval\"\u003eapprovals\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eAuditing with Google Cloud Deploy works just like it does for other Google Cloud services. \u003ca href=\"https://cloud.google.com/audit-logs\"\u003eCloud Audit Logs\u003c/a\u003e \u003ca href=\"https://cloud.google.com/deploy/docs/audit-logs\"\u003eaudits\u003c/a\u003e user-invoked Google Cloud Deploy activities, providing centralized awareness into who promoted a specific release or made an update to a delivery pipeline.\u003c/p\u003e\u003cp\u003e\u003cb\u003eIntegration\u003c/b\u003e\u003c/p\u003e\u003cp\u003eWhether or not you already have continuous delivery capabilities, you likely already have continuous integration (CI), approval and/or operation workflows, and other systems that intersect with your software delivery practices.\u003c/p\u003e\u003cp\u003eGoogle Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/integrating\"\u003eembraces the GKE delivery tooling ecosystems\u003c/a\u003e in three ways: connectivity to CI systems, support for leading configuration (\u003ca href=\"https://cloud.google.com/deploy/docs/terminology#render\"\u003erendering\u003c/a\u003e) tooling, and \u003ca href=\"https://cloud.google.com/pubsub\"\u003ePub/Sub\u003c/a\u003e notifications to enable third-party integrations.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_your_ci_system\"\u003eConnecting Google Cloud Deploy\u003c/a\u003e to existing CI tools is straightforward. After you build your containers, Google Cloud Deploy creates a delivery pipeline release that initiates the Kubernetes manifest configuration (render) and deployment process to the first environment in a progression sequence. Whether you are using Jenkins, Cloud Build, or another CI tool, this is usually a simple \u003ci\u003e`\u003c/i\u003e\u003ci\u003egcloud beta deploy releases create`.\u003c/i\u003e\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deployt_3_efyUGIq.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Deploy 3.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Deployt_3_efyUGIq.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eDelivering to Kubernetes often changes over time. To help, Google Cloud Deploy  leverages \u003ca href=\"https://skaffold.dev/\" target=\"_blank\"\u003eSkaffold\u003c/a\u003e, allowing you to \u003ca href=\"https://cloud.google.com/deploy/docs/skaffold\"\u003estandardize your configuration\u003c/a\u003e between development and production environments. Organizations new to Kubernetes typically deploy using raw manifests, but as they become more sophisticated, may want to use more advanced tooling (\u003ca href=\"https://helm.sh/\" target=\"_blank\"\u003eHelm\u003c/a\u003e, \u003ca href=\"https://kustomize.io/\" target=\"_blank\"\u003eKustomize\u003c/a\u003e, \u003ca href=\"https://kpt.dev/\" target=\"_blank\"\u003ekpt\u003c/a\u003e). The combination of Google Cloud Deploy and Skaffold lets you transition to these tools without impacting your delivery pipelines.\u003c/p\u003e\u003cp\u003eFinally, to facilitate other integrations, such as a \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_automated_testing\"\u003epost-deployment test execution\u003c/a\u003e or \u003ca href=\"https://cloud.google.com/deploy/docs/integrating#integrating_with_third-party_workflow_management\"\u003ethird party approval workflows\u003c/a\u003e, Google Cloud Deploy \u003ca href=\"https://cloud.google.com/deploy/docs/subscribe-deploy-notifications\"\u003eemits Pub/Sub messages\u003c/a\u003e throughout a \u003ca href=\"https://cloud.google.com/deploy/docs/architecture#how_they_fit_together_to_deliver_your_release\"\u003erelease’s lifecycle\u003c/a\u003e.\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eThe future\u003c/h3\u003e\u003cp\u003eComprehensive, easy-to-use, and cost-effective DevOps tools are key to building an efficient software development team, and it’s our hope that Google Cloud Deploy will help you complete your CI/CD pipelines. And we’re just getting started! Stay tuned as we continue to introduce exciting new capabilities and features to Google Cloud Deploy in the months and quarters to come.\u003c/p\u003e\u003cp\u003eIn the meantime, to get started with the Preview, check out the \u003ca href=\"https://cloud.google.com/deploy\"\u003eproduct page\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs\"\u003edocumentation\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/deploy/docs/quickstart-basic\"\u003equickstart\u003c/a\u003e, and \u003ca href=\"https://cloud.google.com/deploy/docs/tutorials\"\u003etutorials\u003c/a\u003e. Finally, If you have feedback on Google Cloud Deploy, you can \u003ca href=\"https://www.googlecloudcommunity.com/gc/forums/filteredbylabelpage/board-id/cloud-developer-tools/label-name/google%20cloud%20deploy\" target=\"_blank\"\u003ejoin the conversation\u003c/a\u003e. We look forward to hearing from you!\u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-video\"\u003e\u003cdiv class=\"article-module article-video \"\u003e\u003cfigure\u003e\u003ca class=\"h-c-video h-c-video--marquee\" data-glue-modal-disabled-on-mobile=\"true\" data-glue-modal-trigger=\"uni-modal-Il8FlhR9jKM-\" href=\"https://youtube.com/watch?v=Il8FlhR9jKM\"\u003e\u003cimg alt=\"Introducing Cloud Deploy\" src=\"//img.youtube.com/vi/Il8FlhR9jKM/maxresdefault.jpg\"/\u003e\u003csvg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" role=\"img\"\u003e\u003cuse xlink:href=\"#mi-youtube-icon\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv class=\"h-c-modal--video\" data-glue-modal=\"uni-modal-Il8FlhR9jKM-\" data-glue-modal-close-label=\"Close Dialog\"\u003e\u003ca class=\"glue-yt-video\" data-glue-yt-video-autoplay=\"true\" data-glue-yt-video-height=\"99%\" data-glue-yt-video-vid=\"Il8FlhR9jKM\" data-glue-yt-video-width=\"100%\" href=\"https://youtube.com/watch?v=Il8FlhR9jKM\" ng-cloak=\"\"\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/announcing-dora-2021-accelerate-state-of-devops-report/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/SODR2021_1920x1080.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e2021 Accelerate State of DevOps report addresses burnout, team performance\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eThe SODR is continually one of the most downloaded assets on the GCP website. We are releasing the updated version of the report with new...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/gcp_ZPje3k8.max-2200x2200.jpg",
      "date_published": "2021-09-22T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eS. Bogdan\u003c/name\u003e\u003ctitle\u003eProduct Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/announcing-dora-2021-accelerate-state-of-devops-report/",
      "title": "2021 Accelerate State of DevOps report addresses burnout, team performance",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eOver the past seven years, more than 32,000 professionals worldwide have taken part in the \u003ca href=\"https://cloud.google.com/devops\"\u003eAccelerate State of DevOps reports\u003c/a\u003e, making it the largest and longest-running research of its kind. Year over year, the Accelerate State of DevOps reports provide data-driven industry insights that examine the capabilities and practices that drive software delivery as well as operational and organizational performance. That is why Google Cloud’s DevOps Research and Assessment (DORA) team is very excited to announce our \u003ca href=\"https://cloud.google.com/devops/state-of-devops/\"\u003e2021 Accelerate State of DevOps Report\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eOur research continues to illustrate that excellence in software delivery and operational performance drives organizational performance in technology transformations. This year we also investigated the effects of SRE best practices, a secure software supply chain, quality documentation, and multicloud—all while gaining a deeper understanding of how this past year affected team’s culture and burnout.  \u003c/p\u003e\u003cp\u003eRead below to find some of the new findings from this year’s report:\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003ch3\u003eSoftware delivery performance metrics\u003c/h3\u003e\u003cp\u003eBased on key findings from previous Accelerate State of DevOps reports, we again used \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/using-the-four-keys-to-measure-your-devops-performance\"\u003efour metrics\u003c/a\u003e to classify teams as elite, high, medium or low performers based on their software delivery: deployment frequency, lead time for changes, mean-time-to-restore, and change fail rate. This year we saw that elite performers continue to accelerate their pace of software delivery, increasing their lead time for changes from less than one day to less than one hour. Not only that, but elite performers deploy 973x more frequently than low performers, have a 6570x faster lead time to deploy, a 3x lower change failure rate, and an impressive 6570x faster time-to-recover from incidents when failure does happen. You read that right: compared to low performers, elite performers are continually able to empirically demonstrate organizational success with DevOps.\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/SODR_2021_1.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"SODR_2021_1.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/SODR_2021_1.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eThe fifth metric: from availability to reliability\u003c/h3\u003e\u003cp\u003eHistorically we have measured availability rather than reliability, but because availability is a specific focus of reliability engineering, we’ve expanded our measure to reliability so that availability, latency, performance, and scalability are more broadly represented. Specifically, we asked respondents to rate their ability to meet or exceed their reliability targets. We found that teams with varying degrees of delivery performance see better outcomes when they also prioritize operational performance. \u003c/p\u003e\u003ch3\u003e2021 insights: the impact of reliability, COVID and secure software supply chains\u003c/h3\u003e\u003cp\u003eIn addition to measuring the impact of DevOps adoption on software delivery performance, this year’s DORA report also revealed many other new trends. Here’s a sampling. \u003c/p\u003e\u003cp\u003e\u003cb\u003e1) A healthy team culture mitigates burnout during challenging times\u003c/b\u003e\u003c/p\u003e\u003cp\u003eRespondents who worked from home because of the pandemic experienced more burnout than those who stayed in the office (a small portion of our sample). Inclusive teams with a generative culture were half as likely to experience burnout during the COVID-19 pandemic. \u003c/p\u003e\u003cp\u003e\u003cb\u003e2) The highest performers continue to raise the bar\u003c/b\u003e\u003c/p\u003e\u003cp\u003eFor the first time, high and elite performers make up two-thirds of respondents—compared to the \u003ca href=\"https://cloud.google.com/devops\"\u003e2019 report\u003c/a\u003e where low and medium performers made up 56% of respondents. We can confidently say that as the industry continues to accelerate its adoption of DevOps principles teams see meaningful benefits as a result.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/SODR_2021_2.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"SODR_2021_2.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/SODR_2021_2.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cb\u003e3) SRE and DevOps are complementary philosophies \u003c/b\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eExtending from its core principles, \u003ca href=\"https://sre.google/\" target=\"_blank\"\u003eSite Reliability Engineering (SRE)\u003c/a\u003e provides practical techniques, including the service level indicator/service level objective (SLI/SLO) metrics framework. The SRE framework offers definitions on practices and tooling that can enhance a team’s ability to consistently keep promises to their users. Teams that prioritize both delivery and operational excellence report the highest organizational performance. \u003c/p\u003e\u003cp\u003eTo investigate this, we included \u003ca href=\"https://cloud.google.com/products/operations\"\u003eoperations\u003c/a\u003e questions in the survey for the first time this year. The evidence from the survey indicated teams who excel at modern operational practices are 1.4 times more likely to report greater software delivery and operational (SDO) performance  performance, and 1.8 times more likely to report better business outcomes.\u003c/p\u003e\u003cp\u003e\u003cb\u003e4) Cloud adoption continues to drive performance\u003c/b\u003e\u003c/p\u003e\u003cp\u003eTeams continue to move workloads to the cloud and those that leverage \u003ca href=\"https://cloud.google.com/architecture/devops/devops-tech-cloud-infrastructure\"\u003eall five capabilities\u003c/a\u003e of cloud see increases in SDO performance, as well as in organizational performance. Multicloud adoption is also on the rise so that teams can leverage the unique capabilities of each provider. In fact, respondents who use hybrid or multicloud were 1.6 times more likely to exceed their organizational performance targets. \u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/SODR_2021_3.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"SODR_2021_3.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/SODR_2021_3.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cb\u003e5) A secure software supply chain is both essential and drives performance \u003c/b\u003e\u003cp\u003eSecurity can no longer be an afterthought—it must be integrated throughout every stage of the software development lifecycle to build a \u003ca href=\"https://cloud.google.com/blog/products/application-development/best-practices-and-tools-for-software-supply-chain-security\"\u003esecure software supply chain\u003c/a\u003e. Elite performers who met or exceeded their reliability targets were twice as likely to have shifted their security practices left, i.e., implemented security practices earlier on in the software development lifecycle, and deliver reliable software quickly, and safely. \u003c/p\u003e\u003cp\u003e\u003cb\u003e6) Good documentation is foundational for successfully implementing DevOps capabilities\u003c/b\u003e\u003c/p\u003e\u003cp\u003eFor the first time, we measured the quality of internal documentation and its effect on other capabilities and practices. We found documentation is foundational for successfully implementing DevOps capabilities. Teams with high-quality documentation are 3.8x more likely to implement security best practices and 2.5x more likely to fully leverage the cloud to its fullest potential.\u003c/p\u003e\u003ch3\u003eIntroducing the DevOps Awards\u003c/h3\u003e\u003cp\u003eNow that we have shared some of our DevOps best practices with you, we would love to hear about how you are transforming your organization with DevOps. In our first annual DevOps Awards, we’ll recognize Google Cloud customers that have improved their deployment frequency, successfully shifted left on security, or improved their change fail rate percentage, etc. Tell us about the positive impact that DevOps has had on your teams, customers, and organization. Enter your submission \u003ca href=\"https://cloud.google.com/awards/devops\"\u003ehere\u003c/a\u003e today!\u003c/p\u003e\u003cp\u003eThanks to everyone who took our 2021 survey. We hope this Accelerate State of DevOps report helps organizations of all sizes, industries, and regions improve their DevOps capabilities, and we look forward to hearing your thoughts and feedback. To learn more  about the report and implementing DevOps with Google cloud, check out the following resources:\u003cbr/\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://cloud.google.com/devops/state-of-devops/\"\u003eDownload the report\u003c/a\u003e\u003cbr/\u003e\u003c/li\u003e\u003cli\u003eTo find out more about how your organization stacks up against others in your industry, take the\u003ca href=\"https://www.devops-research.com/quickcheck.html\" target=\"_blank\"\u003eDevOps Quick Check\u003c/a\u003e\u003cbr/\u003e\u003c/li\u003e\u003cli\u003eFor customized DevOps solutions for your organization, check out our newly launched\u003ca href=\"http://cloud.google.com/camp\"\u003eCAMP website\u003c/a\u003e\u003cbr/\u003e\u003c/li\u003e\u003cli\u003eLearn more about DevOps capabilities for \u003ca href=\"https://cloud.google.com/devops\"\u003eelite performance\u003c/a\u003e\u003cbr/\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/original_images/SODR2021_1920x1080.png",
      "date_published": "2021-09-21T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eDustin Smith\u003c/name\u003e\u003ctitle\u003eDORA Research Lead\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/how-lowes-improved-incident-response-processes-with-sre/",
      "title": "How Lowe’s SRE reduced its mean time to recovery (MTTR) by over 80 percent",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003ci\u003e\u003cb\u003eEditor’s Note:\u003c/b\u003eIn a \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/how-lowes-leverages-google-sre-practices\"\u003eprevious blog\u003c/a\u003e, we discussed how home improvement retailer Lowe’s was able to increase the number of releases it supports by \u003ca href=\"https://cloud.google.com/sre\"\u003eadopting Google’s Site Reliability Engineering (SRE) framework on Google Cloud\u003c/a\u003e. Lowe’s went from one release every two weeks to 20+ releases daily, helping meet its customer needs faster and more effectively. Today, the Lowe’s SRE team shares how they used SRE principles to decrease their mean-time-to-recovery (MTTR) by over 80 percent.\u003c/i\u003e\u003c/p\u003e\u003cp\u003eThe stakes of managing Lowes.com have never been higher, and that means spotting, troubleshooting and recovering from incidents as quickly as possible, so that customers can continue to do business on our site. \u003c/p\u003e\u003cp\u003eTo do that, it’s crucial to have solid incident engineering practices in place. Resolving an incident means mitigating the impact and/or restoring the service to its previous condition. The average time it takes to do this is called mean time to recovery (MTTR). Tracking this metric helps us stay on top of the overall reliability of our systems at Lowe’s, while simultaneously improving the speed with which we recover. Our goal is to keep the MTTR metric as low as possible, so that failures don’t negatively impact our business. Here are the four areas we addressed to drive holistic improvement in our MTTR.\u003c/p\u003e\u003ch3\u003eLowe’s incident reporting process\u003c/h3\u003e\u003cp\u003eTo reduce MTTR, we created a seamless incident reporting process following SRE principles. Our incident reporting process is a workflow that starts at the time an incident occurs, and ends with an SRE captain who closes the action items after a postmortem report. With this approach, we are able to limit the number of critical incidents. The reporting process involves three core components: monitoring, alerting, and blameless postmortems.\u003cbr/\u003e\u003c/p\u003e\u003cp\u003e\u003cb\u003eMonitoring and alerting\u003c/b\u003e\u003c/p\u003e\u003cp\u003eHaving proper monitoring and alerting in place is crucial when it comes to incident management. Monitoring and alerting tools let you detect issues as soon as they occur, and notify the right person in the shortest possible time to take action. From a measurement standpoint, we track this as our mean time to acknowledge (MTTA). This is the average time it takes from when an alert is triggered, to when work on the issue begins.\u003cbr/\u003e\u003c/p\u003e\u003cp\u003eAt the time of an incident, our \u003ca href=\"https://cloud.google.com/monitoring\"\u003emonitoring and alerting tools\u003c/a\u003e notify the on-call SRE first responder via \u003ca href=\"https://cloud.google.com/monitoring/support/notification-options\"\u003ePagerDuty\u003c/a\u003e in the form of a phone call, text message and email. Our SRE software engineering team has done a lot of automation to enable various \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/sre-fundamentals-sli-vs-slo-vs-sla\"\u003eService Level Indicator (SLI) alerts and Service Level Agreement (SLA)\u003c/a\u003e notifications. The on-call SRE then initiates a triage call with our service/domain stakeholders to resolve the incident. As a result, we reduced our MTTA from 30 minutes in 2019, to one minute – a 97 percent decrease. \u003c/p\u003e\u003cp\u003e\u003cb\u003eBlameless postmortems: learning from incidents\u003c/b\u003e\u003c/p\u003e\u003cp\u003eA postmortem is a written record of an incident, its impact, the actions taken to resolve it, the root cause and the follow-up actions to prevent the incident from recurring (\u003ca href=\"https://sre.google/sre-book/example-postmortem/\" target=\"_blank\"\u003esee example here\u003c/a\u003e). A blameless postmortem builds on that and is a core part of an SRE culture, and our culture at Lowe’s. We ensure that individuals are not singled out, and the outcome for all postmortems are directed toward learnings and process improvement.\u003c/p\u003e\u003cp\u003eFor us, the postmortem process is the biggest part of our incident workflow. When an SRE creates a new postmortem report, the first step is to conduct a \u003ca href=\"https://cloud.google.com/blog/products/gcp/getting-the-most-out-of-shared-postmortems-cre-life-lessons\"\u003epostmortem session\u003c/a\u003e with domain stakeholders to review the report. The postmortem then goes into the review stage and gets reviewed by more stakeholders in our weekly postmortem meeting. In the final stage of this process, the SRE captain will close the report once everyone in the weekly meeting agrees that the report is complete.\u003c/p\u003e\u003cp\u003eTo conduct a successful postmortem, it is critical to keep the focus on identifying gaps and issues with the system and operations processes, rather than an individual, and generate concrete actions to address the problems we’ve identified. To ensure this, we follow a couple of best practices:\u003c/p\u003e\u003col\u003e\u003cli\u003eWe start by gathering the facts from the person who identified the problem, and each SLI owner has to identify a gap or the next SLI upstream owner who created the impact for them.\u003c/li\u003e\u003cli\u003eEvery SLI owner is provided full opportunity to present their case, and identifying the issue is done as a community exercise. \u003c/li\u003e\u003cli\u003eOnce action items and process changes are identified, an owner is nominated to complete the actions, or they will volunteer. \u003c/li\u003e\u003cli\u003eFor easy reference, we publish and store postmortems in our incident knowledge base. This process helps SREs continuously improve as future incidents arise. \u003c/li\u003e\u003c/ol\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003cb\u003eContinuous Improvement \u003c/b\u003e\u003c/p\u003e\u003cp\u003eEncouraging a culture of honest, transparent and direct feedback that you need for blameless postmortems is often an iterative process that needs sponsorship from executives, empowering incident captains to lead the entirety of the discussion and outcomes. Running successful postmortems, and completing action items from them, needs to be recognized and accounted for in SRE performance objective assessment. As shared in \u003ca href=\"https://sre.google/sre-book/postmortem-culture/\" target=\"_blank\"\u003eGoogle’s SRE book\u003c/a\u003e, the best practice is to ensure that writing effective postmortems is a rewarded and celebrated practice, with leadership’s acknowledgement and participation. This is possibly the hardest part to accomplish in an effective postmortem during a cultural transformation unless you have full buy-in from leadership.\u003c/p\u003e\u003cp\u003eHowever, it’s all well worth it. This process is a key part of how we were able to improve our MTTR over time—from two hours in 2019 to just 17 minutes! \u003c/p\u003e\u003cp\u003eOur SRE incident reporting process has also transformed how our company solves issues. By streamlining this workflow from alerting, to solving an issue, to blameless postmortems, we have reduced our MTTR by 82 percent and our MTTA by 97 percent. Most importantly, our team is learning from every incident and becoming better engineers as a result. Visit the \u003ca href=\"https://cloud.google.com/sre\"\u003eSRE Google Cloud website\u003c/a\u003e to learn more about implementing SRE best practices in the cloud.\u003c/p\u003e\u003chr/\u003e\u003cp\u003e\u003ci\u003eAcknowledgement\u003c/i\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003e\u003ci\u003eSpecial thanks to Rahul Mohan Kola Kandy, Vivek Balivada, and the Digital SRE team at Lowe’s for contributing to this blog post.\u003c/i\u003e\u003c/p\u003e\u003cp\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/how-lowes-leverages-google-sre-practices/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/devops.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eHow Lowe’s meets customer demand with Google SRE practices\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eLowe’s has adopted Google SRE practices to help developer and operations teams keep up with ecommerce demand.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/original_images/gcp_ZPje3k8.jpg",
      "date_published": "2021-09-07T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eNishanth Prasad\u003c/name\u003e\u003ctitle\u003eLead Software Engineer, Digital SRE, Lowe’s Companies, Inc.\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/application-development/understanding-artifact-registry-vs-container-registry/",
      "title": "Artifact Registry: the next generation of Container Registry",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eEnterprise application teams need to manage more than just containers in their software supply chain. That’s why we created \u003ca href=\"https://cloud.google.com/artifact-registry\"\u003eArtifact Registry\u003c/a\u003e, a fully-managed service with support for both container images and non-container artifacts.\u003c/p\u003e\u003cp\u003eArtifact Registry improves and extends upon the existing capabilities of \u003ca href=\"https://cloud.google.com/container-registry\"\u003eContainer Registry\u003c/a\u003e, such as customer-managed encryption keys, VPC-SC support, Pub/Sub notifications, and more, providing a foundation for major upgrades in security, scalability and control. While Container Registry is still available and will continue to be supported as a \u003ca href=\"https://cloud.google.com/blog/topics/inside-google-cloud/new-api-stability-tenets-govern-google-enterprise-apis\"\u003eGoogle Enterprise API\u003c/a\u003e, going forward new features will only be available in Artifact Registry, and Container Registry will only receive critical security fixes.\u003c/p\u003e\u003cp\u003eBelow, we’ll highlight the key improvements Artifact Registry provides over Container Registry, as well as the steps to start using it today.\u003c/p\u003e\u003ch3\u003eA unified control plane for container, OS and language repositories\u003c/h3\u003e\u003cp\u003eArtifact Registry includes more than just container images: as a developer, you can store multiple artifact formats, including OS packages for Debian and RPM, as well as language packages for popular languages like Python, Java, and Node. In addition, you can manage them all from a single, unified interface. \u003c/p\u003e\u003ch3\u003eA more granular permission model with Cloud IAM\u003c/h3\u003e\u003cp\u003eArtifact Registry comes with fine-grained access control via \u003ca href=\"https://cloud.google.com/iam\"\u003eCloud IAM\u003c/a\u003e. Unlike Container Registry, this allows you to control access on a per-repository basis, rather than all images stored in a project. This enables you to scope permissions as granularly as possible, for example to specific regions or environments as necessary.\u003c/p\u003e\u003ch3\u003eRepositories in the region of your choice\u003c/h3\u003e\u003cp\u003eArtifact Registry supports the creation of regional repositories, which allows you to put your artifacts and data directly in the location that they'll be used, allowing for higher availability and speed. In Container Registry, you’re limited to “multi-regions”: for example, the closest multi-region for Australia is Asia. However, with Artifact Registry’s regional support, you can create a repository directly in the Sydney data center.\u003c/p\u003e\u003ch3\u003eA pricing model that respects your region\u003c/h3\u003e\u003cp\u003eWhile Artifact Registry’s pricing is still based on a combination of network egress and storage usage, support for regional repositories means that you can choose in what region to host your container repositories. Although per unit storage costs are higher for Artifact Registry, optimizing the locations of your repositories to be hosted in the same region where they are used can result in cost savings, because any network traffic within the same region is not considered egress and is thus free.\u003c/p\u003e\u003ch3\u003ePart of a secure supply chain\u003c/h3\u003e\u003cp\u003eArtifact Registry was designed from the ground up to integrate into our suite of secure supply chain products. This means that it can optionally use \u003ca href=\"https://cloud.google.com/container-analysis/\"\u003eContainer Analysis\u003c/a\u003e to scan your container images for vulnerabilities as they’re uploaded to Artifact Registry, and works directly with \u003ca href=\"https://cloud.google.com/binary-authorization\"\u003eBinary Authorization\u003c/a\u003e to secure your deployments.\u003c/p\u003e\u003ch3\u003eWe’re here to help you migrate\u003c/h3\u003e\u003cp\u003eIf you already use Container Registry, you can take advantage of all the current and upcoming features of container image storage with Artifact Registry by migrating to it. To help, we’ve prepared the following guides:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/transition/transition-from-gcr\"\u003eTransitioning from Container Registry\u003c/a\u003e provides an overview of how to use Artifact Registry instead of Container Registry in a backwards-compatible way\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/docker/copy-from-gcr\"\u003eCopying images from Container Registry\u003c/a\u003e guide you to move container images from an existing repository to an Artifact Registry repository\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eIf you’re currently hosting your container images with a third party, you can begin using Artifact Registry directly, by following the instructions in our guide, \u003ca href=\"https://cloud.google.com/artifact-registry/docs/docker/migrate-external-containers\"\u003eMigrating containers from a third-party registry\u003c/a\u003e, which shows you how to avoid rate limits on image pulls or third-party outages which can disrupt your builds and deployments.\u003c/p\u003e\u003cp\u003eAnd if you're just getting started storing container images, you can begin using Artifact Registry as your image repository right away. To learn how, check out \u003ca href=\"https://cloud.google.com/artifact-registry/docs/docker/quickstart\"\u003eArtifact Registry quickstart for Docker\u003c/a\u003e, a guide to using Artifact Registry as a single location for managing private packages and Docker container images.\u003c/p\u003e\u003ch3\u003eJoin our community \u003c/h3\u003e\u003cp\u003eOur Artifact Registry communities are also great resources to help answer your questions and for guidance on best practices: \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eAsk questions on Stack Overflow using the \u003ca href=\"https://stackoverflow.com/questions/tagged/google-artifact-registry\" target=\"_blank\"\u003egoogle-artifact-registry\u003c/a\u003e tag\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eVisit the \u003ca href=\"https://googlecloud-community.slack.com/\" target=\"_blank\"\u003eGoogle Cloud Slack community\u003c/a\u003e and ask a question in the #artifact-registry channel. If you haven't already joined the Slack community, use \u003ca href=\"https://join.slack.com/t/googlecloud-community/shared_invite/zt-m973j990-IMij2Xh8qKPu7SaHfOcCFg\" target=\"_blank\"\u003ethis form\u003c/a\u003e to sign up.\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/application-development/artifact-registry-adds-node-python-and-java-repositories/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/gcp_Artifact_Registry.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eNode, Python and Java repositories now available in Artifact Registry\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eExpanded language support lets you store Java, Node and Python artifacts in Artifact Registry, for a more secure software supply chain.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/original_images/gcp_Artifact_Registry.jpg",
      "date_published": "2021-08-19T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eDustin Ingram\u003c/name\u003e\u003ctitle\u003eSenior Developer Advocate\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/topics/anthos/using-terraform-to-enable-config-sync-on-a-gke-cluster/",
      "title": "Deploy Anthos on GKE with Terraform part 1: GitOps with Config Sync",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/anthos/config-management\"\u003eAnthos Config Management (ACM)\u003c/a\u003eoffers cloud platform administrators a variety of techniques to streamline cluster configuration. One ACM feature, \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/config-sync-overview\"\u003eConfig Sync\u003c/a\u003e, allows them to use a Git repository to create common configurations that are automatically applied on Kubernetes clusters in their fleet, bringing a familiar code review collaboration process to config management. Another ACM feature, \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/concepts/policy-controller\"\u003ePolicy Controller\u003c/a\u003e, enforces security guardrails in compliance with their organization’s requirements. This blog series explores these offerings and how to get started using them with Terraform.\u003c/p\u003e\u003cp\u003eMany platform administrators prefer \u003ca href=\"https://cloud.google.com/solutions/infrastructure-as-code\"\u003eInfrastructure as Code\u003c/a\u003e to achieve repeatable and predictable deployments. This also applies to configuring ACM features on Kubernetes clusters. \u003c/p\u003e\u003cp\u003eIn the past, platform administrators who used Terraform lacked a smooth transition from HCL to modeling cluster configuration. They had to resort to manual processes that required additional temporary permissions granted to operators to complete provisioning.\u003c/p\u003e\u003cp\u003eThe new \u003ca href=\"https://cloud.google.com/anthos/multicluster-management/reference/rest/v1beta/projects.locations.features\"\u003eGKEHub API\u003c/a\u003e and new resources enabled in \u003ca href=\"https://registry.terraform.io/providers/hashicorp/google/latest/docs\" target=\"_blank\"\u003eTerraform Provider for Google Cloud Platform\u003c/a\u003e —\u003ca href=\"https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/gke_hub_feature\" target=\"_blank\"\u003egoogle_gke_hub_feature\u003c/a\u003e, \u003ca href=\"https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/gke_hub_feature_membership\" target=\"_blank\"\u003egoogle_hub_feature_membership\u003c/a\u003e and \u003ca href=\"https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/gke_hub_membership\" target=\"_blank\"\u003egoogle_gke_hub_membership—\u003c/a\u003emake it possible to automate last mile cluster configuration, including pointing it to a Git repository and turning on the Policy Controller.\u003c/p\u003e\u003cp\u003eFor platform administrators, this solves previous challenges of modeling cluster configuration such as namespaces, services accounts, RBAC, in a Kubernetes idiomatic way, i.e. without the awkward Terraform HCL counterparts. Better still this natural, IaC approach improves auditability and transparency and reduces risk of misconfigurations or security gaps.\u003c/p\u003e\u003cp\u003eIn this 3 part blog series, we’ll show how you can enable Anthos features on GKE. We’ll start with \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/config-sync-overview\"\u003eConfig Sync\u003c/a\u003e to reconcile the cluster state with the specified Git repository. \u003c/p\u003e\u003cp\u003eBased on a GKE cluster resource in your Terraform configuration:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eYou can then enable GKE Hub membership, and the \u003cb\u003econfigmanagement\u003c/b\u003e feature:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eAdditional settings can then be configured for each of the features - \u003cb\u003esync_repo\u003c/b\u003e to point at the repo storing your cluster configurations, \u003cb\u003epoliy_dir\u003c/b\u003e to point at the root of the repo to reconcile, and the specific \u003cb\u003esync_branch\u003c/b\u003e in the repo.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eApplying this configuration with Terraform will enable Config Sync and will automatically synchronize the state of the cluster with the repo, immediately creating the Kubernetes config objects on the cluster. Your pods, deployments, services and other native K8s objects will automatically be created. See this \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/concepts/configs\"\u003earticle\u003c/a\u003e for more details on how to organize configs in a repo.\u003c/p\u003e\u003cp\u003eThe cluster now is fully provisioned and requires no “last mile” configuration steps.\u003c/p\u003e\u003cp\u003eThis \u003ca href=\"https://github.com/terraform-google-modules/terraform-google-kubernetes-engine/tree/master/examples/acm-terraform-blog-part1\" target=\"_blank\"\u003erepo\u003c/a\u003e provides a complete example of provisioning a cluster that is synchronized with a repo that contains a popular WordPress configuration. \u003c/p\u003e\u003cp\u003eIn the next part of the series we’ll show you how you can use Terraform to configure another ACM feature - Policy Controller.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/containers-kubernetes/anthos-config-management-config-controller-available-on-gke/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/GCP_Kubernetes_A.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eGet in sync: Consistent Kubernetes with new Anthos Config Management features\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eAnthos Config Management and Config Controller bring Kubernetes-style declarative policy and config management to GKE environments.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/original_images/Anthos.png",
      "date_published": "2021-08-16T16:30:00Z",
      "author": {
        "name": "\u003cname\u003eAlex Bulankou\u003c/name\u003e\u003ctitle\u003eEngineering Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/containers-kubernetes/anthos-config-management-config-controller-available-on-gke/",
      "title": "Get in sync: Consistent Kubernetes with new Anthos Config Management features",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;h3\u0026gt;Describe your intent with a single resource model\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;The Kubernetes API server includes controllers that make sure your container infrastructure state always matches the state you declare in YAML. For example, Kubernetes can ensure that a load balancer and service proxy are always created, connected to the right pods, and configured properly. But KRM can manage more than just container infrastructure. You can use KRM to deploy and manage resources such as cloud databases, storage, and networks. It can also manage your custom-developed apps and services using \u0026lt;a href=\u0026#34;https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;custom resource definitions\u0026lt;/a\u0026gt;.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Create what you need from a single source of truth\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;With Anthos Config Management, you declare and set configurations once and forget them. You don\u0026amp;#8217;t have to be an expert in KRM or GitOps-style configuration because the hosted Config Controller service takes care of it. Config Controller provisions infrastructure, apps, and cloud services; configures them to meet your desired intent; monitors them for configuration drift; and applies changes every time you push a new resource declaration to your Git repository. Config changes are as easy as a git push\u0026amp;#8212;and easily integrate with your development workflows.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Anthos Config Management uses \u0026lt;a href=\u0026#34;https://cloud.google.com/anthos-config-management/docs/config-sync-overview\u0026#34;\u0026gt;Config Sync\u0026lt;/a\u0026gt; to continuously reconcile the state of your registered clusters and resources\u0026amp;#8212;that means any GKE, Anthos, or \u0026lt;a href=\u0026#34;https://cloud.google.com/anthos/multicluster-management/connect/registering-a-cluster\u0026#34;\u0026gt;other registered\u0026lt;/a\u0026gt; cluster\u0026amp;#8212;and makes sure unvetted changes are never pushed to live clusters. Anthos Config Management reduces the risk of dev or ops teams making any changes outside the Git source of truth by requiring code reviews and rolling back any breaking changes to a good working state. In short, using Anthos Config Management both encourages and enforces best practices.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Repair what breaks for automated compliance\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Anthos Config Management\u0026amp;#8217;s \u0026lt;a href=\u0026#34;https://cloud.google.com/anthos-config-management/docs/concepts/policy-controller\u0026#34;\u0026gt;Policy Controller\u0026lt;/a\u0026gt; makes it easier to create and enforce fully programmable policies across all connected clusters. Policies act as guardrails to prevent any changes to configuration from violating your custom security, operational, or compliance controls. For example, you can set policies to actively block any non-compliant API requests, require every namespace to have a label, prevent pods from running privileged containers, restrict the types of storage volumes a container can mount, and more.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Policy Controller is based on the open source \u0026lt;a href=\u0026#34;https://open-policy-agent.github.io/gatekeeper/website/docs/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Open Policy Agent Gatekeeper\u0026lt;/a\u0026gt; project, augmented by Google Cloud with a ready-to-use \u0026lt;a href=\u0026#34;https://cloud.google.com/anthos-config-management/docs/reference/constraint-template-library\u0026#34;\u0026gt;library of pre-built policies\u0026lt;/a\u0026gt; for the most common security and compliance controls. Customers can establish a secure baseline easily without deep expertise and ACM applies policies to a single cluster (e.g. GKE) or to a distributed set of Anthos clusters on-prem or in other cloud platforms. You can audit and add your own custom policies by allowing your security-savvy experts to \u0026lt;a href=\u0026#34;https://cloud.google.com/anthos-config-management/docs/how-to/write-a-constraint-template\u0026#34;\u0026gt;create constraint templates\u0026lt;/a\u0026gt; which anyone \u0026lt;a href=\u0026#34;https://cloud.google.com/anthos-config-management/docs/how-to/creating-constraints\u0026#34;\u0026gt;can invoke\u0026lt;/a\u0026gt; in different dev or production environments without learning how to write or manage policy code. The \u0026lt;a href=\u0026#34;https://cloud.google.com/anthos-config-management/docs/how-to/auditing-constraints\u0026#34;\u0026gt;audit functionality\u0026lt;/a\u0026gt; included allows platform admins to audit all violations, simplifying compliance reviews.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Configure and control every cluster consistently\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;The hosted service, \u0026lt;a href=\u0026#34;https://cloud.google.com/anthos-config-management/docs/concepts/config-controller-overview\u0026#34;\u0026gt;Config Controller\u0026lt;/a\u0026gt;, which runs Config Connector, Config Sync, and Policy Controller for you, is available in Preview. Config Controller leverages \u0026lt;a href=\u0026#34;https://cloud.google.com/config-connector/docs/overview\u0026#34;\u0026gt;Config Connector,\u0026lt;/a\u0026gt; which lets you manage \u0026lt;a href=\u0026#34;https://cloud.google.com/config-connector/docs/reference/overview\u0026#34;\u0026gt;Google Cloud resources\u0026lt;/a\u0026gt; the same way you manage other Kubernetes resources, with continuous monitoring and self-healing. For example, you can ask Config Connector to create a Cloud SQL instance and a database. Config Connector can manage more than 60 Google Cloud resources, including Bigtable, BigQuery, Pub/Sub, Spanner, Cloud Storage, and Cloud Load Balancer.\u0026lt;/p\u0026gt;\"\u003e\u003ch3\u003eDescribe your intent with a single resource model\u003c/h3\u003e\u003cp\u003eThe Kubernetes API server includes controllers that make sure your container infrastructure state always matches the state you declare in YAML. For example, Kubernetes can ensure that a load balancer and service proxy are always created, connected to the right pods, and configured properly. But KRM can manage more than just container infrastructure. You can use KRM to deploy and manage resources such as cloud databases, storage, and networks. It can also manage your custom-developed apps and services using \u003ca href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\" target=\"_blank\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://kubernetes.io\" track-metadata-module=\"post\"\u003ecustom resource definitions\u003c/a\u003e. \u003c/p\u003e\u003ch3\u003eCreate what you need from a single source of truth\u003c/h3\u003e\u003cp\u003eWith Anthos Config Management, you declare and set configurations once and forget them. You don’t have to be an expert in KRM or GitOps-style configuration because the hosted Config Controller service takes care of it. Config Controller provisions infrastructure, apps, and cloud services; configures them to meet your desired intent; monitors them for configuration drift; and applies changes every time you push a new resource declaration to your Git repository. Config changes are as easy as a git push—and easily integrate with your development workflows. \u003c/p\u003e\u003cp\u003eAnthos Config Management uses \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/config-sync-overview\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/anthos-config-management/docs/config-sync-overview\" track-metadata-module=\"post\"\u003eConfig Sync\u003c/a\u003e to continuously reconcile the state of your registered clusters and resources—that means any GKE, Anthos, or \u003ca href=\"https://cloud.google.com/anthos/multicluster-management/connect/registering-a-cluster\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/anthos/multicluster-management/connect/registering-a-cluster\" track-metadata-module=\"post\"\u003eother registered\u003c/a\u003e cluster—and makes sure unvetted changes are never pushed to live clusters. Anthos Config Management reduces the risk of dev or ops teams making any changes outside the Git source of truth by requiring code reviews and rolling back any breaking changes to a good working state. In short, using Anthos Config Management both encourages and enforces best practices.\u003c/p\u003e\u003ch3\u003eRepair what breaks for automated compliance\u003c/h3\u003e\u003cp\u003eAnthos Config Management’s \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/concepts/policy-controller\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/anthos-config-management/docs/concepts/policy-controller\" track-metadata-module=\"post\"\u003ePolicy Controller\u003c/a\u003e makes it easier to create and enforce fully programmable policies across all connected clusters. Policies act as guardrails to prevent any changes to configuration from violating your custom security, operational, or compliance controls. For example, you can set policies to actively block any non-compliant API requests, require every namespace to have a label, prevent pods from running privileged containers, restrict the types of storage volumes a container can mount, and more.\u003c/p\u003e\u003cp\u003ePolicy Controller is based on the open source \u003ca href=\"https://open-policy-agent.github.io/gatekeeper/website/docs/\" target=\"_blank\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://open-policy-agent.github.io\" track-metadata-module=\"post\"\u003eOpen Policy Agent Gatekeeper\u003c/a\u003e project, augmented by Google Cloud with a ready-to-use \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/reference/constraint-template-library\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/anthos-config-management/docs/reference/constraint-template-library\" track-metadata-module=\"post\"\u003elibrary of pre-built policies\u003c/a\u003e for the most common security and compliance controls. Customers can establish a secure baseline easily without deep expertise and ACM applies policies to a single cluster (e.g. GKE) or to a distributed set of Anthos clusters on-prem or in other cloud platforms. You can audit and add your own custom policies by allowing your security-savvy experts to \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/how-to/write-a-constraint-template\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/anthos-config-management/docs/how-to/write-a-constraint-template\" track-metadata-module=\"post\"\u003ecreate constraint templates\u003c/a\u003e which anyone \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/how-to/creating-constraints\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://cloud.google.com/anthos-config-management/docs/how-to/creating-constraints\" track-metadata-module=\"post\"\u003ecan invoke\u003c/a\u003e in different dev or production environments without learning how to write or manage policy code. The \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/how-to/auditing-constraints\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://cloud.google.com/anthos-config-management/docs/how-to/auditing-constraints\" track-metadata-module=\"post\"\u003eaudit functionality\u003c/a\u003e included allows platform admins to audit all violations, simplifying compliance reviews.\u003c/p\u003e\u003ch3\u003eConfigure and control every cluster consistently\u003c/h3\u003e\u003cp\u003eThe hosted service, \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/concepts/config-controller-overview\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://cloud.google.com/anthos-config-management/docs/concepts/config-controller-overview\" track-metadata-module=\"post\"\u003eConfig Controller\u003c/a\u003e, which runs Config Connector, Config Sync, and Policy Controller for you, is available in Preview. Config Controller leverages \u003ca href=\"https://cloud.google.com/config-connector/docs/overview\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://cloud.google.com/config-connector/docs/overview\" track-metadata-module=\"post\"\u003eConfig Connector,\u003c/a\u003e which lets you manage \u003ca href=\"https://cloud.google.com/config-connector/docs/reference/overview\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://cloud.google.com/config-connector/docs/reference/overview\" track-metadata-module=\"post\"\u003eGoogle Cloud resources\u003c/a\u003e the same way you manage other Kubernetes resources, with continuous monitoring and self-healing. For example, you can ask Config Connector to create a Cloud SQL instance and a database. Config Connector can manage more than 60 Google Cloud resources, including Bigtable, BigQuery, Pub/Sub, Spanner, Cloud Storage, and Cloud Load Balancer.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eFrom large digital-native powerhouses to midsized manufacturing firms, every company today is creating and deploying \u003cb\u003emore software to more places more often\u003c/b\u003e. \u003ca href=\"https://cloud.google.com/anthos/config-management\"\u003eAnthos Config Management\u003c/a\u003e lets you set and enforce consistent configurations and policies for your Kubernetes resources—wherever you build and run them—and manage Google Cloud services the same way. \u003c/p\u003e\u003cp\u003eToday, as a part of Anthos Config Management, we are introducing \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/concepts/config-controller-overview\"\u003eConfig Controller\u003c/a\u003e, a hosted service to provision and orchestrate Google Cloud resources. This service offers an API endpoint that can provision, actuate, and orchestrate Google Cloud resources the same way it manages Kubernetes resources. You don’t have to install or manage the components—or be an expert in Kubernetes resource management or GitOps—because Google Cloud will manage them for you. \u003c/p\u003e\u003cp\u003eToday, we’re also announcing that, in addition to using it for hybrid and multicloud use cases, Anthos Config Management is now available for Google Kubernetes Engine (GKE) as a standalone service. GKE customers can now take advantage of config and policy automation in Google Cloud at a low incremental per-cluster cost.\u003c/p\u003e\u003cp\u003eThese announcements deliver a whole new approach to config and policy management—one that’s descriptive or \u003ci\u003edeclarative\u003c/i\u003e, rather than procedural or \u003ci\u003eimperative\u003c/i\u003e. Let’s take a closer look.  \u003c/p\u003e\u003ch3\u003eLet Kubernetes automate your configs and policies \u003c/h3\u003e\u003cp\u003eDevelopment teams need stable and secure environments to build apps quickly and deploy them easily. Today, platform teams often scramble to provision and configure the necessary infrastructure components, apps, and cloud services the same way—in many different places—and keep them all up-to-date, patched, and secure. \u003c/p\u003e\u003cp\u003eThe struggle is real, and it’s not new. Platform administrators have been hand-crafting and partially automating configuration with new infrastructure-as-code languages and tools for years. We can spin up new containerized dev environments in minutes in the cloud and on-prem. We can push code to production hundreds of times a day with automated CI/CD processes. So why do configurations drift and fall out of sync with production? \u003c/p\u003e\u003cp\u003eBecause it takes time and toil to develop a \u003cb\u003econsistent and automated way to \u003ci\u003edescribe\u003c/i\u003e what we want, \u003ci\u003ecreate\u003c/i\u003e what we need, and repair what we break.\u003c/b\u003e The declarative \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/understanding-configuration-as-data-in-kubernetes\"\u003eKubernetes Resource Model (KRM)\u003c/a\u003e reduces this toil with a consistent way to define and update resources: describe what you want and Kubernetes makes it happen. ACM makes it even easier by adding \u003cb\u003epre-built, opinionated config and policy automations\u003c/b\u003e, such as creating a \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/tutorials/landing-zone\"\u003esecure landing zone\u003c/a\u003e and provisioning a \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/tutorials/gke-cluster-blueprint\"\u003eGKE cluster from a blueprint\u003c/a\u003e. Blueprints help platform teams configure both Kubernetes and Google Cloud services the same way every time.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/GKE_cluster_from_a_blueprint.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"GKE cluster from a blueprint.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/GKE_cluster_from_a_blueprint.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eDescribe your intent with a single resource model\u003c/h3\u003e\u003cp\u003eThe Kubernetes API server includes controllers that make sure your container infrastructure state always matches the state you declare in YAML. For example, Kubernetes can ensure that a load balancer and service proxy are always created, connected to the right pods, and configured properly. But KRM can manage more than just container infrastructure. You can use KRM to deploy and manage resources such as cloud databases, storage, and networks. It can also manage your custom-developed apps and services using \u003ca href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/\" target=\"_blank\"\u003ecustom resource definitions\u003c/a\u003e. \u003c/p\u003e\u003ch3\u003eCreate what you need from a single source of truth\u003c/h3\u003e\u003cp\u003eWith Anthos Config Management, you declare and set configurations once and forget them. You don’t have to be an expert in KRM or GitOps-style configuration because the hosted Config Controller service takes care of it. Config Controller provisions infrastructure, apps, and cloud services; configures them to meet your desired intent; monitors them for configuration drift; and applies changes every time you push a new resource declaration to your Git repository. Config changes are as easy as a git push—and easily integrate with your development workflows. \u003c/p\u003e\u003cp\u003eAnthos Config Management uses \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/config-sync-overview\"\u003eConfig Sync\u003c/a\u003e to continuously reconcile the state of your registered clusters and resources—that means any GKE, Anthos, or \u003ca href=\"https://cloud.google.com/anthos/multicluster-management/connect/registering-a-cluster\"\u003eother registered\u003c/a\u003e cluster—and makes sure unvetted changes are never pushed to live clusters. Anthos Config Management reduces the risk of dev or ops teams making any changes outside the Git source of truth by requiring code reviews and rolling back any breaking changes to a good working state. In short, using Anthos Config Management both encourages and enforces best practices.\u003c/p\u003e\u003ch3\u003eRepair what breaks for automated compliance\u003c/h3\u003e\u003cp\u003eAnthos Config Management’s \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/concepts/policy-controller\"\u003ePolicy Controller\u003c/a\u003e makes it easier to create and enforce fully programmable policies across all connected clusters. Policies act as guardrails to prevent any changes to configuration from violating your custom security, operational, or compliance controls. For example, you can set policies to actively block any non-compliant API requests, require every namespace to have a label, prevent pods from running privileged containers, restrict the types of storage volumes a container can mount, and more.\u003c/p\u003e\u003cp\u003ePolicy Controller is based on the open source \u003ca href=\"https://open-policy-agent.github.io/gatekeeper/website/docs/\" target=\"_blank\"\u003eOpen Policy Agent Gatekeeper\u003c/a\u003e project, augmented by Google Cloud with a ready-to-use \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/reference/constraint-template-library\"\u003elibrary of pre-built policies\u003c/a\u003e for the most common security and compliance controls. Customers can establish a secure baseline easily without deep expertise and ACM applies policies to a single cluster (e.g. GKE) or to a distributed set of Anthos clusters on-prem or in other cloud platforms. You can audit and add your own custom policies by allowing your security-savvy experts to \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/how-to/write-a-constraint-template\"\u003ecreate constraint templates\u003c/a\u003e which anyone \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/how-to/creating-constraints\"\u003ecan invoke\u003c/a\u003e in different dev or production environments without learning how to write or manage policy code. The \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/how-to/auditing-constraints\"\u003eaudit functionality\u003c/a\u003e included allows platform admins to audit all violations, simplifying compliance reviews.\u003c/p\u003e\u003ch3\u003eConfigure and control every cluster consistently\u003c/h3\u003e\u003cp\u003eThe hosted service, \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/concepts/config-controller-overview\"\u003eConfig Controller\u003c/a\u003e, which runs Config Connector, Config Sync, and Policy Controller for you, is available in Preview. Config Controller leverages \u003ca href=\"https://cloud.google.com/config-connector/docs/overview\"\u003eConfig Connector,\u003c/a\u003e which lets you manage \u003ca href=\"https://cloud.google.com/config-connector/docs/reference/overview\"\u003eGoogle Cloud resources\u003c/a\u003e the same way you manage other Kubernetes resources, with continuous monitoring and self-healing. For example, you can ask Config Connector to create a Cloud SQL instance and a database. Config Connector can manage more than 60 Google Cloud resources, including Bigtable, BigQuery, Pub/Sub, Spanner, Cloud Storage, and Cloud Load Balancer.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/anthos_config_manager.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"anthos config manager.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/anthos_config_manager.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eOnce you’ve embraced a consistent resource model, using ACM to enforce configuration and policy automatically for individual resources, take the next step with blueprints. A \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/concepts/blueprints\"\u003eblueprint\u003c/a\u003e is a package of config and policy that documents an opinionated solution to deploy and manage \u003cb\u003emultiple\u003c/b\u003e resources at once. Blueprints capture best practices and policy guardrails, package them together, and let you deploy them as a complete solution to any Kubernetes clusters using Config Controller. Use Blueprints to manage multiple resources at once, or to create customized \u003ca href=\"https://cloud.google.com/anthos-config-management/docs/tutorials/landing-zone\"\u003elanding zones\u003c/a\u003e—compliant, properly configured, and easily duplicated environments that meet your own best practice guidelines and that are properly networked and secured. \u003c/p\u003e\u003cp\u003eThe Vienna Insurance Group uses Anthos Config Management in its Viesure Innovation Center, which it credits with improving its compliance posture.\u003c/p\u003e\u003cp\u003e\u003ci\u003e\"Google's Landing Zones and Config Controller equipped us with an extensive set of tools to set up our Google Cloud infrastructure quickly and securely. Their policy controllers are a powerful instrument for ensuring compliance for all our Google Cloud resources.\"\u003c/i\u003e —Rene Schakmann, Head of Technology at viesure innovation center GmbH\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eGet started today\u003c/h3\u003e\u003cp\u003eAnthos Config Management on GKE is generally available today. If you’re a GKE customer, you can also now use Anthos Config Management at a low incremental cost. By making it available to GKE customers, and offering it as a hosted, managed service for everyone, we’re making it easier than ever for you to leverage “KRM as a service” to simplify and secure Kubernetes resource management from the data center to the cloud.\u003c/p\u003e\u003cp\u003eTo learn more about the technical details behind ACM, check out \u003ca href=\"https://kubernetespodcast.com/episode/154-gatekeeper-and-policy-controller/\" target=\"_blank\"\u003ethis recent episode\u003c/a\u003e of the \u003ca href=\"https://kubernetespodcast.com/\" target=\"_blank\"\u003eKubernetes Podcast from Google\u003c/a\u003e with the TL for Policy Controller, Max Smythe.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/containers-kubernetes/understanding-configuration-as-data-in-kubernetes/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud-01_xyGPYQS.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eI do declare! Infrastructure automation with Configuration as Data\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eConfiguration as Data enables operational consistency, security, and velocity on Google Cloud with products like Config Connector.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/GCP_Kubernetes_A.max-2200x2200.jpg",
      "date_published": "2021-08-03T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eJeff Reed\u003c/name\u003e\u003ctitle\u003eVP of Product, GKE and Anthos\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/application-development/google-introduces-slsa-framework/",
      "title": "Securing the software development lifecycle with Cloud Build and SLSA",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Each level of SLSA represents an incremental step towards a more secure software supply chain, adding additional security guidelines to address the most common threats to source and build integrity. Nor are these guidelines Google-specific: they are developed by the security extended community and established by consensus to be adopted amongst the wider industry.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Although SLSA is a new framework, many of the security guidelines it advocates for are already available for and adopted by consumers today.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Understanding SLSA\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;The SLSA framework introduces a number of new tools and concepts for securing the software development lifecycle:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Artifact - any file produced as the result of a build pipeline, such as container images, language packages, compiled binaries, etc.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Provenance - metadata about how an artifact was built, including the build process, top-level source, and dependencies\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Digest - the result of a cryptographic hash function which produces a fixed-size value uniquely identifying an artifact, such as a SHA-256 hash of a container image\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Attestation - a cryptographically signed file recording the provenance of the build pipeline at the time a specific artifact or set of artifacts was produced\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Attestor - any system or process that produces an attestation, often included as part of a build pipeline after artifact creation and prior to deployment\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Immutable references - an identifier, such as a URL, that is guaranteed to always point to the same, immutable artifact, such as a specific container image or language package\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Build integrity - the verification of the output of a build pipeline via attestations\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;When used in combination, these represent a build pipeline that adheres to the standards set by the SLSA framework.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Cloud Build supports SLSA 1\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;If you use \u0026lt;a href=\u0026#34;https://cloud.google.com/build\u0026#34;\u0026gt;Cloud Build\u0026lt;/a\u0026gt;, Google Cloud\u0026amp;#8217;s hosted CI/CD platform, you are likely already operating a software development lifecycle at SLSA 1, the first step in securing your software delivery pipeline. That\u0026amp;#8217;s because by default, Cloud Build allows you to create an automated build pipeline, and because any Cloud Build pipeline automatically generates provenance. While provenance for Cloud Build has been available for quite some time, it hasn\u0026amp;#8217;t been widely used to verify build pipelines.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Having a software supply chain at SLSA 1 does not entirely protect against tampering, but it does offer a basic level of code source identification and may aid in vulnerability management, protecting against software delivery that is not a product of the CI/CD system. At the same time, Cloud Build represents a foundation for a hosted software build system upon which you can reach higher SLSA levels, using techniques like verifiable source control, automatically verified provenance, and tools like \u0026lt;a href=\u0026#34;https://cloud.google.com/binary-authorization\u0026#34;\u0026gt;Binary Authorization\u0026lt;/a\u0026gt;.\u0026amp;#160;\u0026amp;#160;\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;You can start now\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;By creating a build process that\u0026amp;#8217;s fully automated, mandating the use of a build system for production workflows, and by building your software pipeline with Cloud Build, you can have a SLSA 1 supply chain right from the start.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;To get started today, you can follow the Cloud Build quickstart for \u0026lt;a href=\u0026#34;https://cloud.google.com/build/docs/quickstart-build\u0026#34;\u0026gt;building a Docker image and pushing the image to Artifact Registry\u0026lt;/a\u0026gt;, followed by the quickstart for \u0026lt;a href=\u0026#34;https://cloud.google.com/build/docs/quickstart-deploy\u0026#34;\u0026gt;deploying that containerized application to Cloud Run\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;For more details on SLSA, you can read more here:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;https://slsa.dev/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;SLSA: Supply-chain Levels for Software Artifacts\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;https://security.googleblog.com/2021/06/introducing-slsa-end-to-end-framework.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Introducing SLSA, an End-to-End Framework for Supply Chain Integrity\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;Want to learn more about how you as a developer can help improve the security of your software? Today, we\u0026amp;#8217;re hosting \u0026lt;a href=\u0026#34;https://cloudonair.withgoogle.com/events/container-security\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Building trust in your software supply chain\u0026lt;/a\u0026gt;, which explores this topic in depth. Click here to \u0026lt;a href=\u0026#34;https://cloudonair.withgoogle.com/events/container-security\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;register\u0026lt;/a\u0026gt; for the live event or to watch it on demand.\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eEach level of SLSA represents an incremental step towards a more secure software supply chain, adding additional security guidelines to address the most common threats to source and build integrity. Nor are these guidelines Google-specific: they are developed by the security extended community and established by consensus to be adopted amongst the wider industry.\u003c/p\u003e\u003cp\u003eAlthough SLSA is a new framework, many of the security guidelines it advocates for are already available for and adopted by consumers today.\u003c/p\u003e\u003ch3\u003eUnderstanding SLSA\u003c/h3\u003e\u003cp\u003eThe SLSA framework introduces a number of new tools and concepts for securing the software development lifecycle:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eArtifact - any file produced as the result of a build pipeline, such as container images, language packages, compiled binaries, etc.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eProvenance - metadata about how an artifact was built, including the build process, top-level source, and dependencies\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDigest - the result of a cryptographic hash function which produces a fixed-size value uniquely identifying an artifact, such as a SHA-256 hash of a container image\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eAttestation - a cryptographically signed file recording the provenance of the build pipeline at the time a specific artifact or set of artifacts was produced\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eAttestor - any system or process that produces an attestation, often included as part of a build pipeline after artifact creation and prior to deployment\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eImmutable references - an identifier, such as a URL, that is guaranteed to always point to the same, immutable artifact, such as a specific container image or language package\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eBuild integrity - the verification of the output of a build pipeline via attestations\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWhen used in combination, these represent a build pipeline that adheres to the standards set by the SLSA framework.\u003c/p\u003e\u003ch3\u003eCloud Build supports SLSA 1\u003c/h3\u003e\u003cp\u003eIf you use \u003ca href=\"https://cloud.google.com/build\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/build\" track-metadata-module=\"post\"\u003eCloud Build\u003c/a\u003e, Google Cloud’s hosted CI/CD platform, you are likely already operating a software development lifecycle at SLSA 1, the first step in securing your software delivery pipeline. That’s because by default, Cloud Build allows you to create an automated build pipeline, and because any Cloud Build pipeline automatically generates provenance. While provenance for Cloud Build has been available for quite some time, it hasn’t been widely used to verify build pipelines.\u003c/p\u003e\u003cp\u003eHaving a software supply chain at SLSA 1 does not entirely protect against tampering, but it does offer a basic level of code source identification and may aid in vulnerability management, protecting against software delivery that is not a product of the CI/CD system. At the same time, Cloud Build represents a foundation for a hosted software build system upon which you can reach higher SLSA levels, using techniques like verifiable source control, automatically verified provenance, and tools like \u003ca href=\"https://cloud.google.com/binary-authorization\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/binary-authorization\" track-metadata-module=\"post\"\u003eBinary Authorization\u003c/a\u003e.   \u003c/p\u003e\u003ch3\u003eYou can start now\u003c/h3\u003e\u003cp\u003eBy creating a build process that’s fully automated, mandating the use of a build system for production workflows, and by building your software pipeline with Cloud Build, you can have a SLSA 1 supply chain right from the start. \u003c/p\u003e\u003cp\u003eTo get started today, you can follow the Cloud Build quickstart for \u003ca href=\"https://cloud.google.com/build/docs/quickstart-build\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/build/docs/quickstart-build\" track-metadata-module=\"post\"\u003ebuilding a Docker image and pushing the image to Artifact Registry\u003c/a\u003e, followed by the quickstart for \u003ca href=\"https://cloud.google.com/build/docs/quickstart-deploy\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/build/docs/quickstart-deploy\" track-metadata-module=\"post\"\u003edeploying that containerized application to Cloud Run\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eFor more details on SLSA, you can read more here:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://slsa.dev/\" target=\"_blank\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://slsa.dev\" track-metadata-module=\"post\"\u003eSLSA: Supply-chain Levels for Software Artifacts\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://security.googleblog.com/2021/06/introducing-slsa-end-to-end-framework.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://security.googleblog.com\" track-metadata-module=\"post\"\u003eIntroducing SLSA, an End-to-End Framework for Supply Chain Integrity\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003ci\u003eWant to learn more about how you as a developer can help improve the security of your software? Today, we’re hosting \u003ca href=\"https://cloudonair.withgoogle.com/events/container-security\" target=\"_blank\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloudonair.withgoogle.com\" track-metadata-module=\"post\"\u003eBuilding trust in your software supply chain\u003c/a\u003e, which explores this topic in depth. Click here to \u003ca href=\"https://cloudonair.withgoogle.com/events/container-security\" target=\"_blank\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloudonair.withgoogle.com\" track-metadata-module=\"post\"\u003eregister\u003c/a\u003e for the live event or to watch it on demand.\u003c/i\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eOne of the biggest challenges for software developers is the need to make informed choices about the external software and products they use in their own software systems. Evaluating whether a given system is appropriately secured can be challenging, especially if it’s external or owned by a third party.\u003c/p\u003e\u003cp\u003eThis so-called software supply chain has been under increasing scrutiny in recent years, with attacks on software systems being responsible for damages to both public and private interests. In collaboration with the \u003ca href=\"https://openssf.org/\" target=\"_blank\"\u003eOpenSSF\u003c/a\u003e, Google has proposed Supply-chain Levels for Software Artifacts (SLSA). The new \u003ca href=\"https://slsa.dev/\" target=\"_blank\"\u003eSLSA\u003c/a\u003e framework formalizes criteria around software supply chain integrity, to help the industry and open-source ecosystem secure the software development lifecycle.\u003c/p\u003e\u003ch3\u003eSecure your own software development lifecycle\u003c/h3\u003e\u003cp\u003eSLSA is not just for the public software supply chain. You can also apply these same levels, originally inspired by Google’s internal framework for secure software delivery, to your own software development life cycle.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"software development lifecycle.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/software_development_life.0480027109600294.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eEach level of SLSA represents an incremental step towards a more secure software supply chain, adding additional security guidelines to address the most common threats to source and build integrity. Nor are these guidelines Google-specific: they are developed by the security extended community and established by consensus to be adopted amongst the wider industry.\u003c/p\u003e\u003cp\u003eAlthough SLSA is a new framework, many of the security guidelines it advocates for are already available for and adopted by consumers today.\u003c/p\u003e\u003ch3\u003eUnderstanding SLSA\u003c/h3\u003e\u003cp\u003eThe SLSA framework introduces a number of new tools and concepts for securing the software development lifecycle:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eArtifact - any file produced as the result of a build pipeline, such as container images, language packages, compiled binaries, etc.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eProvenance - metadata about how an artifact was built, including the build process, top-level source, and dependencies\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDigest - the result of a cryptographic hash function which produces a fixed-size value uniquely identifying an artifact, such as a SHA-256 hash of a container image\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eAttestation - a cryptographically signed file recording the provenance of the build pipeline at the time a specific artifact or set of artifacts was produced\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eAttestor - any system or process that produces an attestation, often included as part of a build pipeline after artifact creation and prior to deployment\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eImmutable references - an identifier, such as a URL, that is guaranteed to always point to the same, immutable artifact, such as a specific container image or language package\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eBuild integrity - the verification of the output of a build pipeline via attestations\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWhen used in combination, these represent a build pipeline that adheres to the standards set by the SLSA framework.\u003c/p\u003e\u003ch3\u003eCloud Build supports SLSA 1\u003c/h3\u003e\u003cp\u003eIf you use \u003ca href=\"https://cloud.google.com/build\"\u003eCloud Build\u003c/a\u003e, Google Cloud’s hosted CI/CD platform, you are likely already operating a software development lifecycle at SLSA 1, the first step in securing your software delivery pipeline. That’s because by default, Cloud Build allows you to create an automated build pipeline, and because any Cloud Build pipeline automatically generates provenance. While provenance for Cloud Build has been available for quite some time, it hasn’t been widely used to verify build pipelines.\u003c/p\u003e\u003cp\u003eHaving a software supply chain at SLSA 1 does not entirely protect against tampering, but it does offer a basic level of code source identification and may aid in vulnerability management, protecting against software delivery that is not a product of the CI/CD system. At the same time, Cloud Build represents a foundation for a hosted software build system upon which you can reach higher SLSA levels, using techniques like verifiable source control, automatically verified provenance, and tools like \u003ca href=\"https://cloud.google.com/binary-authorization\"\u003eBinary Authorization\u003c/a\u003e.   \u003c/p\u003e\u003ch3\u003eYou can start now\u003c/h3\u003e\u003cp\u003eBy creating a build process that’s fully automated, mandating the use of a build system for production workflows, and by building your software pipeline with Cloud Build, you can have a SLSA 1 supply chain right from the start. \u003c/p\u003e\u003cp\u003eTo get started today, you can follow the Cloud Build quickstart for \u003ca href=\"https://cloud.google.com/build/docs/quickstart-build\"\u003ebuilding a Docker image and pushing the image to Artifact Registry\u003c/a\u003e, followed by the quickstart for \u003ca href=\"https://cloud.google.com/build/docs/quickstart-deploy\"\u003edeploying that containerized application to Cloud Run\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eFor more details on SLSA, you can read more here:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003ca href=\"https://slsa.dev/\" target=\"_blank\"\u003eSLSA: Supply-chain Levels for Software Artifacts\u003c/a\u003e\u003c/li\u003e\u003cli\u003e\u003ca href=\"https://security.googleblog.com/2021/06/introducing-slsa-end-to-end-framework.html\" target=\"_blank\"\u003eIntroducing SLSA, an End-to-End Framework for Supply Chain Integrity\u003c/a\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003ci\u003eWant to learn more about how you as a developer can help improve the security of your software? Today, we’re hosting \u003ca href=\"https://cloudonair.withgoogle.com/events/container-security\" target=\"_blank\"\u003eBuilding trust in your software supply chain\u003c/a\u003e, which explores this topic in depth. Click here to \u003ca href=\"https://cloudonair.withgoogle.com/events/container-security\" target=\"_blank\"\u003eregister\u003c/a\u003e for the live event or to watch it on demand.\u003c/i\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/identity-security/cloud-ciso-perspectives-june-2021/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Datastorage_8NMQKRy.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eCloud CISO Perspectives: June 2021\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eGoogle Cloud CISO Phil Venables shares his thoughts on ransomware, software supply chains, and RSA retrospectives.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Security_BlogHeader_B_epmyJP1.max-2200x2200.jpg",
      "date_published": "2021-07-29T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eDustin Ingram\u003c/name\u003e\u003ctitle\u003eSenior Developer Advocate\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/cloud-build-private-pools-offers-cicd-for-private-networks/",
      "title": "Introducing Cloud Build private pools: Secure CI/CD for private networks",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;A recent \u0026lt;a href=\u0026#34;https://devops.com/survey-shows-mounting-devops-frustration-and-costs/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;survey\u0026lt;/a\u0026gt; found that developers spend 39% of their time managing the DevOps infrastructure that powers their continuous integration (CI) and continuous delivery (CD) pipelines. Unreliable availability, manual provisioning, limited scaling, breaking upgrades, long queue times, and high fixed costs all slow down development and take valuable time and focus away from DevOps teams. And while cloud-based CI/CD solutions can solve many of these friction points, they largely only work with cloud-hosted resources.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;That\u0026amp;#8217;s why we\u0026amp;#8217;re excited to announce that starting today, you can take advantage of serverless build environments within your own private network, with new \u0026lt;b\u0026gt;Cloud Build private pools\u0026lt;/b\u0026gt;. Launched in 2018, \u0026lt;a href=\u0026#34;https://cloud.google.com/build\u0026#34;\u0026gt;Cloud Build\u0026lt;/a\u0026gt;\u0026amp;#160;has helped thousands of customers modernize their CI/CD workloads to run on fully managed, secure, pay-as-you-go \u0026amp;#8216;workers\u0026amp;#8217; with no infrastructure to manage.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Cloud Build offers on-demand auto-scaling capabilities, active build minute billing, all with no infrastructure to manage. The new private pools feature augments Cloud Build with secure, fully managed CI/CD and DevOps workflow automation that uses network peering to connect into your private networks. Private pools also unlocks a host of new customization options such as new machine types, higher maximum concurrency, regional builds, and network configuration options.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;With Cloud Build private pools, you get the benefits of a cloud-hosted, fully managed CI/CD product while meeting enterprise security and compliance requirements\u0026amp;#8212;even for highly regulated industries like finance, healthcare, retail, and others. For instance, you can trigger fully managed DevOps workflows from source-code repositories hosted in private networks, including Github Enterprise.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;With private pools, Cloud Build now supports:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;VPC Peering\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;VPC-SC\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Static IP ranges\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;No public IPs\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Org policy enforcement\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Cross-project builds\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Build from private source repositories with first class integrations, including Github Enterprise\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Regionalization in 15 regions across the US, EU, Asia, Australia, and South America\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Hundreds of concurrent builds per pool\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;15 machine types\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;And while designed primarily for private networking use cases, private pools work just as well with resources in Google Cloud, if you\u0026amp;#8217;re interested in trying out new features like higher concurrency or additional machine types.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Same Cloud Build, new build environment\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Private pools introduces a new build environment for executing your builds with Cloud Build while maintaining a consistent product and API experience. All the same great features of Cloud Build are available with private pools, including fully managed workers, pay-as-you-go pricing, Cloud Console UI, source repo integrations, IAM permissions, Secret Manager and Pub/Sub integrations, and native support for Google Cloud runtimes like Google Kubernetes Engine (GKE), Cloud Run, Cloud Functions, App Engine, and Firebase.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Running builds on a private pool is as easy as creating the pool and setting it as your \u0026lt;a href=\u0026#34;https://cloud.google.com/build/docs/private-pools/run-builds-in-private-pool\u0026#34;\u0026gt;build environment in your cloudbuild.yaml config file\u0026lt;/a\u0026gt;. Private networking is optionally configured via Service Networking by \u0026lt;a href=\u0026#34;https://cloud.google.com/build/docs/private-pools/set-up-private-pool-environment#setup-private-connection\u0026#34;\u0026gt;peering your private pool to your customer-managed VPC\u0026lt;/a\u0026gt; and supports both peered and shared VPCs.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Running your first build is easy:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eA recent \u003ca href=\"https://devops.com/survey-shows-mounting-devops-frustration-and-costs/\" target=\"_blank\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://devops.com\" track-metadata-module=\"post\"\u003esurvey\u003c/a\u003e found that developers spend 39% of their time managing the DevOps infrastructure that powers their continuous integration (CI) and continuous delivery (CD) pipelines. Unreliable availability, manual provisioning, limited scaling, breaking upgrades, long queue times, and high fixed costs all slow down development and take valuable time and focus away from DevOps teams. And while cloud-based CI/CD solutions can solve many of these friction points, they largely only work with cloud-hosted resources. \u003c/p\u003e\u003cp\u003eThat’s why we’re excited to announce that starting today, you can take advantage of serverless build environments within your own private network, with new \u003cb\u003eCloud Build private pools\u003c/b\u003e. Launched in 2018, \u003ca href=\"https://cloud.google.com/build\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/build\" track-metadata-module=\"post\"\u003eCloud Build\u003c/a\u003e has helped thousands of customers modernize their CI/CD workloads to run on fully managed, secure, pay-as-you-go ‘workers’ with no infrastructure to manage. \u003c/p\u003e\u003cp\u003eCloud Build offers on-demand auto-scaling capabilities, active build minute billing, all with no infrastructure to manage. The new private pools feature augments Cloud Build with secure, fully managed CI/CD and DevOps workflow automation that uses network peering to connect into your private networks. Private pools also unlocks a host of new customization options such as new machine types, higher maximum concurrency, regional builds, and network configuration options.\u003c/p\u003e\u003cp\u003eWith Cloud Build private pools, you get the benefits of a cloud-hosted, fully managed CI/CD product while meeting enterprise security and compliance requirements—even for highly regulated industries like finance, healthcare, retail, and others. For instance, you can trigger fully managed DevOps workflows from source-code repositories hosted in private networks, including Github Enterprise.\u003c/p\u003e\u003cp\u003eWith private pools, Cloud Build now supports:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eVPC Peering\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eVPC-SC\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eStatic IP ranges\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eNo public IPs\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eOrg policy enforcement\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCross-project builds\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eBuild from private source repositories with first class integrations, including Github Enterprise\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eRegionalization in 15 regions across the US, EU, Asia, Australia, and South America\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eHundreds of concurrent builds per pool\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e15 machine types\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eAnd while designed primarily for private networking use cases, private pools work just as well with resources in Google Cloud, if you’re interested in trying out new features like higher concurrency or additional machine types.\u003c/p\u003e\u003ch3\u003eSame Cloud Build, new build environment\u003c/h3\u003e\u003cp\u003ePrivate pools introduces a new build environment for executing your builds with Cloud Build while maintaining a consistent product and API experience. All the same great features of Cloud Build are available with private pools, including fully managed workers, pay-as-you-go pricing, Cloud Console UI, source repo integrations, IAM permissions, Secret Manager and Pub/Sub integrations, and native support for Google Cloud runtimes like Google Kubernetes Engine (GKE), Cloud Run, Cloud Functions, App Engine, and Firebase.\u003c/p\u003e\u003cp\u003eRunning builds on a private pool is as easy as creating the pool and setting it as your \u003ca href=\"https://cloud.google.com/build/docs/private-pools/run-builds-in-private-pool\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/build/docs/private-pools/run-builds-in-private-pool\" track-metadata-module=\"post\"\u003ebuild environment in your cloudbuild.yaml config file\u003c/a\u003e. Private networking is optionally configured via Service Networking by \u003ca href=\"https://cloud.google.com/build/docs/private-pools/set-up-private-pool-environment#setup-private-connection\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/build/docs/private-pools/set-up-private-pool-environment#setup-private-connection\" track-metadata-module=\"post\"\u003epeering your private pool to your customer-managed VPC\u003c/a\u003e and supports both peered and shared VPCs.\u003c/p\u003e\u003cp\u003eRunning your first build is easy:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eA recent \u003ca href=\"https://devops.com/survey-shows-mounting-devops-frustration-and-costs/\" target=\"_blank\"\u003esurvey\u003c/a\u003e found that developers spend 39% of their time managing the DevOps infrastructure that powers their continuous integration (CI) and continuous delivery (CD) pipelines. Unreliable availability, manual provisioning, limited scaling, breaking upgrades, long queue times, and high fixed costs all slow down development and take valuable time and focus away from DevOps teams. And while cloud-based CI/CD solutions can solve many of these friction points, they largely only work with cloud-hosted resources. \u003c/p\u003e\u003cp\u003eThat’s why we’re excited to announce that starting today, you can take advantage of serverless build environments within your own private network, with new \u003cb\u003eCloud Build private pools\u003c/b\u003e. Launched in 2018, \u003ca href=\"https://cloud.google.com/build\"\u003eCloud Build\u003c/a\u003e has helped thousands of customers modernize their CI/CD workloads to run on fully managed, secure, pay-as-you-go ‘workers’ with no infrastructure to manage. \u003c/p\u003e\u003cp\u003eCloud Build offers on-demand auto-scaling capabilities, active build minute billing, all with no infrastructure to manage. The new private pools feature augments Cloud Build with secure, fully managed CI/CD and DevOps workflow automation that uses network peering to connect into your private networks. Private pools also unlocks a host of new customization options such as new machine types, higher maximum concurrency, regional builds, and network configuration options.\u003c/p\u003e\u003cp\u003eWith Cloud Build private pools, you get the benefits of a cloud-hosted, fully managed CI/CD product while meeting enterprise security and compliance requirements—even for highly regulated industries like finance, healthcare, retail, and others. For instance, you can trigger fully managed DevOps workflows from source-code repositories hosted in private networks, including Github Enterprise.\u003c/p\u003e\u003cp\u003eWith private pools, Cloud Build now supports:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eVPC Peering\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eVPC-SC\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eStatic IP ranges\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eNo public IPs\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eOrg policy enforcement\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCross-project builds\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eBuild from private source repositories with first class integrations, including Github Enterprise\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eRegionalization in 15 regions across the US, EU, Asia, Australia, and South America\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eHundreds of concurrent builds per pool\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e15 machine types\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eAnd while designed primarily for private networking use cases, private pools work just as well with resources in Google Cloud, if you’re interested in trying out new features like higher concurrency or additional machine types.\u003c/p\u003e\u003ch3\u003eSame Cloud Build, new build environment\u003c/h3\u003e\u003cp\u003ePrivate pools introduces a new build environment for executing your builds with Cloud Build while maintaining a consistent product and API experience. All the same great features of Cloud Build are available with private pools, including fully managed workers, pay-as-you-go pricing, Cloud Console UI, source repo integrations, IAM permissions, Secret Manager and Pub/Sub integrations, and native support for Google Cloud runtimes like Google Kubernetes Engine (GKE), Cloud Run, Cloud Functions, App Engine, and Firebase.\u003c/p\u003e\u003cp\u003eRunning builds on a private pool is as easy as creating the pool and setting it as your \u003ca href=\"https://cloud.google.com/build/docs/private-pools/run-builds-in-private-pool\"\u003ebuild environment in your cloudbuild.yaml config file\u003c/a\u003e. Private networking is optionally configured via Service Networking by \u003ca href=\"https://cloud.google.com/build/docs/private-pools/set-up-private-pool-environment#setup-private-connection\"\u003epeering your private pool to your customer-managed VPC\u003c/a\u003e and supports both peered and shared VPCs.\u003c/p\u003e\u003cp\u003eRunning your first build is easy:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWe’re excited to share private pools with you, so you can enjoy the secure, fully managed Cloud Build developer automation platform from your private network. The private pools feature is generally available today, and we look forward to introducing per-trigger service accounts and approval gates soon. To get started, try the \u003ca href=\"https://cloud.google.com/build/docs/private-pools/quickstart-private-pools\"\u003equickstart\u003c/a\u003e or read the \u003ca href=\"https://cloud.google.com/build/docs/private-pools/private-pools-overview\"\u003eoverview documentation\u003c/a\u003e for more details.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003ci\u003eWant to learn more about Cloud Build, and how to use it to improve the security of your software supply chain? On July 29 event \u003ca href=\"https://cloudonair.withgoogle.com/events/container-security\" target=\"_blank\"\u003eBuilding trust in your software supply chain\u003c/a\u003e explores this topic in depth. Click here to \u003ca href=\"https://cloudonair.withgoogle.com/events/container-security\" target=\"_blank\"\u003eregister\u003c/a\u003e for the live event or to watch it on demand.\u003c/i\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/application-development/forgerock-developers-stay-productive-with-google-cloud/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/appdev.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eDevOps on Google Cloud: tools to speed up software development velocity\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eGoogle Cloud’s application development and continuous integration/continuous delivery (CI/CD) tools help ForgeRock developers stay produc...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/devops.max-2200x2200.jpg",
      "date_published": "2021-07-29T15:00:00Z",
      "author": {
        "name": "\u003cname\u003eChristopher Sanson\u003c/name\u003e\u003ctitle\u003eProduct Manager, Google Cloud\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/announcing-2021-state-devops-report-sponsors/",
      "title": "Announcing the 2021 State of DevOps Report Sponsors",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle-page\u003e\u003cmain id=\"jump-content\"\u003e\u003carticle\u003e\u003carticle-header-block\u003e\u003c/article-header-block\u003e\u003carticle-aspect-image-block\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003esodr\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/article-aspect-image-block\u003e\u003cdiv\u003e\u003carticle-cta _nghost-c17=\"\"\u003e\u003cdiv _ngcontent-c17=\"\"\u003e\u003ch4 _ngcontent-c17=\"\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eAccelerate State of DevOps Report\u003c/span\u003e\u003c/h4\u003e\u003cp _ngcontent-c17=\"\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eGet a comprehensive view of the DevOps industry, providing actionable guidance for organizations of all sizes.\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003ca _ngcontent-c17=\"\" clicktracker=\"\" rel=\"external\" track-metadata-module=\"article cta\" track-type=\"button\" track-name=\"DORA_2019\" track-metadata-eventdetail=\"https://cloud.google.com/devops/state-of-devops?utm_source=google\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY19-Q3-global-demandgen-website-wd-gcp_gtm_stateofdevops\" href=\"https://cloud.google.com/devops/state-of-devops?utm_source=google\u0026amp;utm_medium=blog\u0026amp;utm_campaign=FY19-Q3-global-demandgen-website-wd-gcp_gtm_stateofdevops\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eDownload\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-cta\u003e\u003c/div\u003e\u003carticle-share-block\u003e\u003c/article-share-block\u003e\u003carticle-sticky-share-block\u003e\u003c/article-sticky-share-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-content-stream-block\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Google Cloud and the \u0026lt;a href=\u0026#34;https://www.devops-research.com/research.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;DORA\u0026lt;/a\u0026gt; research team are excited to announce our eight sponsors for the 2021 State of DevOps report. We recently launched the \u0026lt;a href=\u0026#34;https://google.qualtrics.com/jfe/form/SV_cIb0SmhJPfm8H7n\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;2021 State of DevOps survey\u0026lt;/a\u0026gt;, a 25-min survey for the DevOps community to share how they are using DevOps to improve software delivery performance. So if you haven\u0026amp;#8217;t taken the survey yet, this is your chance!\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;For those unfamiliar with the State Of DevOps report, it is the largest and longest running research of its kind. It provides an independent view into how teams and companies can drive powerful business outcomes, no matter what stage of the DevOps journey.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;With the \u0026lt;a href=\u0026#34;https://cloud.google.com/devops\u0026#34;\u0026gt;State of DevOps\u0026lt;/a\u0026gt; reports we aim to capture how teams and companies are driving excellence in technology delivery through the implementation of DevOps practices, no matter what stage of the DevOps journey your team is in. If you\u0026amp;#8217;re wondering how your team measures up in your industry take our \u0026lt;a href=\u0026#34;https://www.devops-research.com/quickcheck.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;DevOps Quick Check\u0026lt;/a\u0026gt; and discover which capabilities you should focus on to improve your performance.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;To capture a diverse array of information on how those in the DevOps community are performing, our eight sponsors of the 2021 State of DevOps survey are focussed on helping organizations of all sizes and industries to develop and deliver software faster across the whole DevOps lifecycle. Captured below, you\u0026amp;#8217;ll find more information on our sponsors for this year and why they chose to sponsor the State Of the DevOps 2021 Report.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://www.armory.io/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Armory\u0026lt;/a\u0026gt; \u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eGoogle Cloud and the \u003ca href=\"https://www.devops-research.com/research.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://www.devops-research.com\" track-metadata-module=\"post\"\u003eDORA\u003c/a\u003e research team are excited to announce our eight sponsors for the 2021 State of DevOps report. We recently launched the \u003ca href=\"https://google.qualtrics.com/jfe/form/SV_cIb0SmhJPfm8H7n\" target=\"_blank\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://google.qualtrics.com\" track-metadata-module=\"post\"\u003e2021 State of DevOps survey\u003c/a\u003e, a 25-min survey for the DevOps community to share how they are using DevOps to improve software delivery performance. So if you haven’t taken the survey yet, this is your chance! \u003c/p\u003e\u003cp\u003eFor those unfamiliar with the State Of DevOps report, it is the largest and longest running research of its kind. It provides an independent view into how teams and companies can drive powerful business outcomes, no matter what stage of the DevOps journey.\u003c/p\u003e\u003cp\u003eWith the \u003ca href=\"https://cloud.google.com/devops\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/devops\" track-metadata-module=\"post\"\u003eState of DevOps\u003c/a\u003e reports we aim to capture how teams and companies are driving excellence in technology delivery through the implementation of DevOps practices, no matter what stage of the DevOps journey your team is in. If you’re wondering how your team measures up in your industry take our \u003ca href=\"https://www.devops-research.com/quickcheck.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://www.devops-research.com\" track-metadata-module=\"post\"\u003eDevOps Quick Check\u003c/a\u003e and discover which capabilities you should focus on to improve your performance.\u003c/p\u003e\u003cp\u003eTo capture a diverse array of information on how those in the DevOps community are performing, our eight sponsors of the 2021 State of DevOps survey are focussed on helping organizations of all sizes and industries to develop and deliver software faster across the whole DevOps lifecycle. Captured below, you’ll find more information on our sponsors for this year and why they chose to sponsor the State Of the DevOps 2021 Report.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.armory.io/\" target=\"_blank\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://www.armory.io\" track-metadata-module=\"post\"\u003eArmory\u003c/a\u003e \u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Armory enables enterprise companies to ship better software, faster through trusted, reliable, safe, and secure deployments -- at its core, Armory is powered by Spinnaker OSS.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026amp;#8220;Armory exists to unlock innovation through software. To achieve this, we help enterprises reliably deploy software at scale, naturally aligning with DevOps practices to improve software delivery performance. Given this, we applaud efforts like the State of DevOps Report that provides an independent view into the practices and capabilities that organizations can employ to drive better performance.\u0026amp;#34;\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Carl Timm, Senior Director of Product Marketing at Armory\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://circleci.com/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;CircleCI\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eArmory enables enterprise companies to ship better software, faster through trusted, reliable, safe, and secure deployments -- at its core, Armory is powered by Spinnaker OSS.\u003c/p\u003e\u003cp\u003e“Armory exists to unlock innovation through software. To achieve this, we help enterprises reliably deploy software at scale, naturally aligning with DevOps practices to improve software delivery performance. Given this, we applaud efforts like the State of DevOps Report that provides an independent view into the practices and capabilities that organizations can employ to drive better performance.\u0026#34; \u003c/p\u003e\u003cp\u003eCarl Timm, Senior Director of Product Marketing at Armory\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://circleci.com/\" target=\"_blank\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://circleci.com\" track-metadata-module=\"post\"\u003eCircleCI\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;The world\u0026amp;#8217;s best software teams deliver quality code, confidently, with CircleCI. The world\u0026amp;#8217;s best software teams use CircleCI to go from next-up to feature shipped, at the speed ambitious businesses require.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026amp;#8220;Though the DevOps space is only over a decade old, it moves incredibly quickly. Google\u0026amp;#8217;s State of DevOps report is both a reflection and projection of the industry, capturing how DevOps culture drives business results and where DevOps practitioners can look to improve. At CircleCI, we rely heavily on this survey data to glean valuable insights into our market and our customers overall. We also build upon these insights to guide our own research into how engineering teams move code through pipelines in our annual \u0026lt;a href=\u0026#34;https://circleci.com/resources/2020-state-of-software-delivery/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;State of Software Delivery report\u0026lt;/a\u0026gt;. Taken together, this research highlights teams\u0026amp;#8217; reported and actual behavior and paints a vibrant picture of how technology-driven organizations drive for success.\u0026amp;#8221;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Emma Webb, VP, Corporate Communications, CircleCI\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cd.foundation/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Continuous Delivery Foundation\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eThe world’s best software teams deliver quality code, confidently, with CircleCI. The world’s best software teams use CircleCI to go from next-up to feature shipped, at the speed ambitious businesses require. \u003c/p\u003e\u003cp\u003e“Though the DevOps space is only over a decade old, it moves incredibly quickly. Google’s State of DevOps report is both a reflection and projection of the industry, capturing how DevOps culture drives business results and where DevOps practitioners can look to improve. At CircleCI, we rely heavily on this survey data to glean valuable insights into our market and our customers overall. We also build upon these insights to guide our own research into how engineering teams move code through pipelines in our annual \u003ca href=\"https://circleci.com/resources/2020-state-of-software-delivery/\" target=\"_blank\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://circleci.com\" track-metadata-module=\"post\"\u003eState of Software Delivery report\u003c/a\u003e. Taken together, this research highlights teams’ reported and actual behavior and paints a vibrant picture of how technology-driven organizations drive for success.”\u003c/p\u003e\u003cp\u003eEmma Webb, VP, Corporate Communications, CircleCI \u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cd.foundation/\" target=\"_blank\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cd.foundation\" track-metadata-module=\"post\"\u003eContinuous Delivery Foundation\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;CD Foundation is an open-source community improving the world\u0026#39;s ability to deliver software with security and speed.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026amp;#34;Good decision-making is based on good data. Open source is a critical piece of the technology roadmap for DevOps, and the 2021 State of DevOps Report will provide actionable information for high performing teams in organizations of all types and sizes. The report will show where open source and DevOps intersect, and in a space that is changing so quickly, new relevant data is critical,\u0026amp;#34; said Tracy Miranda, Continuous Delivery Foundation Executive Director. \u0026amp;#34;CD Foundation members are deeply involved with producing this annual report, with over 10 years of historic research. Thank you to Google and our other members who have worked so hard on it. This report is a tangible result of working together.\u0026amp;#34;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Tracy Miranda, Continuous Delivery Foundation Executive Director\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://www2.deloitte.com/us/en.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Deloitte\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eCD Foundation is an open-source community improving the world\u0026#39;s ability to deliver software with security and speed.\u003c/p\u003e\u003cp\u003e\u0026#34;Good decision-making is based on good data. Open source is a critical piece of the technology roadmap for DevOps, and the 2021 State of DevOps Report will provide actionable information for high performing teams in organizations of all types and sizes. The report will show where open source and DevOps intersect, and in a space that is changing so quickly, new relevant data is critical,\u0026#34; said Tracy Miranda, Continuous Delivery Foundation Executive Director. \u0026#34;CD Foundation members are deeply involved with producing this annual report, with over 10 years of historic research. Thank you to Google and our other members who have worked so hard on it. This report is a tangible result of working together.\u0026#34;\u003c/p\u003e\u003cp\u003eTracy Miranda, Continuous Delivery Foundation Executive Director\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www2.deloitte.com/us/en.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://www2.deloitte.com\" track-metadata-module=\"post\"\u003eDeloitte\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Deloitte provides audit and assurance, tax, consulting, and risk and financial advisory services to a broad cross-section of the largest corporations and governmental agencies. At Deloitte, they are continuously evolving how they work and how they look at marketplace challenges so they can continually deliver measurable, sustainable results for their clients and communities.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026amp;#8220;Software delivery is evolving rapidly and we know our customers need unique and compelling insights to make the right decisions. State of DevOps is a widely used report and considered as an Industry standard to understand the drivers for excellence in Software Development and Delivery. Deloitte is excited to help the team at DORA and Google Cloud in publishing this report through our sponsoring since we believe the insights from this report will help make software delivery better.\u0026amp;#8221;\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Manoj Mishra, Consulting Managing Director, Deloitte Consulting LLP\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://about.gitlab.com/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;GitLab\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eDeloitte provides audit and assurance, tax, consulting, and risk and financial advisory services to a broad cross-section of the largest corporations and governmental agencies. At Deloitte, they are continuously evolving how they work and how they look at marketplace challenges so they can continually deliver measurable, sustainable results for their clients and communities.\u003c/p\u003e\u003cp\u003e“Software delivery is evolving rapidly and we know our customers need unique and compelling insights to make the right decisions. State of DevOps is a widely used report and considered as an Industry standard to understand the drivers for excellence in Software Development and Delivery. Deloitte is excited to help the team at DORA and Google Cloud in publishing this report through our sponsoring since we believe the insights from this report will help make software delivery better.” \u003c/p\u003e\u003cp\u003eManoj Mishra, Consulting Managing Director, Deloitte Consulting LLP\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://about.gitlab.com/\" target=\"_blank\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://about.gitlab.com\" track-metadata-module=\"post\"\u003eGitLab\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;GitLab is the open DevOps platform built from the ground up as a single application for all stages of the DevOps lifecycle enabling Product, Development, QA, Security, and Operations teams to work concurrently on the same project.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026amp;#8220;We\u0026#39;re happy to sponsor the DORA Report and the vital work behind it. The more we understand the DevOps journey, the better we and our GitLab community can contribute to its future. We\u0026#39;re particularly interested to see this year\u0026#39;s results and the impact COVID-19 and remote work have had on DevOps. We appreciate the chance to be part of this exciting, informative process.\u0026amp;#8221;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Brendon O\u0026amp;#8217;Leary, Senior Developer Evangelist\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://www.liquibase.com/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Liquibase\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eGitLab is the open DevOps platform built from the ground up as a single application for all stages of the DevOps lifecycle enabling Product, Development, QA, Security, and Operations teams to work concurrently on the same project.\u003c/p\u003e\u003cp\u003e“We\u0026#39;re happy to sponsor the DORA Report and the vital work behind it. The more we understand the DevOps journey, the better we and our GitLab community can contribute to its future. We\u0026#39;re particularly interested to see this year\u0026#39;s results and the impact COVID-19 and remote work have had on DevOps. We appreciate the chance to be part of this exciting, informative process.”\u003c/p\u003e\u003cp\u003eBrendon O’Leary, Senior Developer Evangelist\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.liquibase.com/\" target=\"_blank\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://www.liquibase.com\" track-metadata-module=\"post\"\u003eLiquibase\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Liquibase helps millions of developers easily manage database schema changes by enabling teams to track, version, and deploy database changes by delivering on the promise of CI/CD for the database.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026amp;#8220;With their rigorous methodology, the DORA research team delivers actionable information with the simple goal of helping organizations of any size accelerate the development and delivery of software. Liquibase is honored to sponsor the 2021 State of DevOps Report and its role in helping so many organizations build value for their customers and shareholders\u0026amp;#8221;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Matt Geise, VP of Marketing at Liquibase\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://www.pagerduty.com/platform/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;PagerDuty\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eLiquibase helps millions of developers easily manage database schema changes by enabling teams to track, version, and deploy database changes by delivering on the promise of CI/CD for the database.\u003c/p\u003e\u003cp\u003e“With their rigorous methodology, the DORA research team delivers actionable information with the simple goal of helping organizations of any size accelerate the development and delivery of software. Liquibase is honored to sponsor the 2021 State of DevOps Report and its role in helping so many organizations build value for their customers and shareholders”\u003c/p\u003e\u003cp\u003eMatt Geise, VP of Marketing at Liquibase\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.pagerduty.com/platform/\" target=\"_blank\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://www.pagerduty.com\" track-metadata-module=\"post\"\u003ePagerDuty\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;PagerDuty is a digital operations management platform that empowers the right action, when seconds matter.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026amp;#8220;As a leader in digital operations management, PagerDuty is proud to sponsor this year\u0026amp;#8217;s report as it aligns with our dedication to helping DevOps professionals make better decisions. This report will inform tech and business leaders about the trends/challenges developers are facing and the opportunities there are to accelerate their own DevOps transformation.\u0026amp;#8221;\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Carolyn Guss, VP of Corporate Marketing\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://sysdig.com/resources/whitepapers/5-keys-to-a-secure-devops-workflow/?utm_source=google\u0026amp;amp;utm_medium=cpc\u0026amp;amp;utm_campaign=10874493567\u0026amp;amp;adgroupid=106662582683\u0026amp;amp;utm_content=471144145325\u0026amp;amp;utm_term=sysdig\u0026amp;amp;utm_position=\u0026amp;amp;utm_device=c\u0026amp;amp;utm_type=e\u0026amp;amp;utm_geo=9033320\u0026amp;amp;gclid=CjwKCAjw_JuGBhBkEiwA1xmbRSyNOvpZ_6_BMU7Cd_NqwtoumsXkkVHoHcEHLNTQmh2sAWTCOP3WiRoC8ycQAvD_BwE\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;SysDig\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003ePagerDuty is a digital operations management platform that empowers the right action, when seconds matter.\u003c/p\u003e\u003cp\u003e“As a leader in digital operations management, PagerDuty is proud to sponsor this year’s report as it aligns with our dedication to helping DevOps professionals make better decisions. This report will inform tech and business leaders about the trends/challenges developers are facing and the opportunities there are to accelerate their own DevOps transformation.” \u003c/p\u003e\u003cp\u003eCarolyn Guss, VP of Corporate Marketing\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://sysdig.com/resources/whitepapers/5-keys-to-a-secure-devops-workflow/?utm_source=google\u0026amp;utm_medium=cpc\u0026amp;utm_campaign=10874493567\u0026amp;adgroupid=106662582683\u0026amp;utm_content=471144145325\u0026amp;utm_term=sysdig\u0026amp;utm_position=\u0026amp;utm_device=c\u0026amp;utm_type=e\u0026amp;utm_geo=9033320\u0026amp;gclid=CjwKCAjw_JuGBhBkEiwA1xmbRSyNOvpZ_6_BMU7Cd_NqwtoumsXkkVHoHcEHLNTQmh2sAWTCOP3WiRoC8ycQAvD_BwE\" target=\"_blank\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://sysdig.com\" track-metadata-module=\"post\"\u003eSysDig\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Sysdig is driving the secure DevOps movement, empowering organizations to confidently secure containers, Kubernetes and cloud.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026amp;#8220;There is a learning curve with all new technology, cloud is no exception. Learning from mistakes and sharing best practices is how we will ultimately ship secure applications, faster. For seven years, DORA and Google have partnered to understand the State of DevOps to help vendors and cloud practitioners to learn from each other and implement standards for best practices,\u0026amp;#8221;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Loris Degioanni, CTO and founder of Sysdig\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud, the DORA team, and our sponsors are very excited about this year\u0026amp;#8217;s report. We look forward to hearing from you, your colleagues, and networks about how DevOps is integrated into your workflow and ways we can help to further improve your performance. Please share your experience with software delivery by \u0026lt;a href=\u0026#34;https://google.qualtrics.com/jfe/form/SV_cIb0SmhJPfm8H7n\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;completing our survey\u0026lt;/a\u0026gt; that will be used to foster the next generation of DevOps best practices. To provide ample time for the DevOps community to contribute to this industry wide report we have extended the deadline for the survey until July 2nd.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Thank you to everyone who has participated so far, and the Google Cloud DORA team looks forward to hearing from even more of you soon!\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eSysdig is driving the secure DevOps movement, empowering organizations to confidently secure containers, Kubernetes and cloud.\u003c/p\u003e\u003cp\u003e“There is a learning curve with all new technology, cloud is no exception. Learning from mistakes and sharing best practices is how we will ultimately ship secure applications, faster. For seven years, DORA and Google have partnered to understand the State of DevOps to help vendors and cloud practitioners to learn from each other and implement standards for best practices,”\u003c/p\u003e\u003cp\u003eLoris Degioanni, CTO and founder of Sysdig\u003c/p\u003e\u003cp\u003eGoogle Cloud, the DORA team, and our sponsors are very excited about this year’s report. We look forward to hearing from you, your colleagues, and networks about how DevOps is integrated into your workflow and ways we can help to further improve your performance. Please share your experience with software delivery by \u003ca href=\"https://google.qualtrics.com/jfe/form/SV_cIb0SmhJPfm8H7n\" target=\"_blank\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://google.qualtrics.com\" track-metadata-module=\"post\"\u003ecompleting our survey\u003c/a\u003e that will be used to foster the next generation of DevOps best practices. To provide ample time for the DevOps community to contribute to this industry wide report we have extended the deadline for the survey until July 2nd.\u003c/p\u003e\u003cp\u003eThank you to everyone who has participated so far, and the Google Cloud DORA team looks forward to hearing from even more of you soon!\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/article-content-stream-block\u003e\u003carticle-tag-list-block\u003e\u003c/article-tag-list-block\u003e\u003c/div\u003e\u003csection\u003e\u003carticle-up-1to3-block _nghost-c18=\"\"\u003e\u003c/article-up-1to3-block\u003e\u003c/section\u003e\u003c/div\u003e\u003c/article\u003e\u003c/main\u003e\u003c/article-page\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eGoogle Cloud and the \u003ca href=\"https://www.devops-research.com/research.html\" target=\"_blank\"\u003eDORA\u003c/a\u003e research team are excited to announce our eight sponsors for the 2021 State of DevOps report. We recently launched the \u003ca href=\"https://google.qualtrics.com/jfe/form/SV_cIb0SmhJPfm8H7n\" target=\"_blank\"\u003e2021 State of DevOps survey\u003c/a\u003e, a 25-min survey for the DevOps community to share how they are using DevOps to improve software delivery performance. So if you haven’t taken the survey yet, this is your chance! \u003c/p\u003e\u003cp\u003eFor those unfamiliar with the State Of DevOps report, it is the largest and longest running research of its kind. It provides an independent view into how teams and companies can drive powerful business outcomes, no matter what stage of the DevOps journey.\u003c/p\u003e\u003cp\u003eWith the \u003ca href=\"https://cloud.google.com/devops\"\u003eState of DevOps\u003c/a\u003e reports we aim to capture how teams and companies are driving excellence in technology delivery through the implementation of DevOps practices, no matter what stage of the DevOps journey your team is in. If you’re wondering how your team measures up in your industry take our \u003ca href=\"https://www.devops-research.com/quickcheck.html\" target=\"_blank\"\u003eDevOps Quick Check\u003c/a\u003e and discover which capabilities you should focus on to improve your performance.\u003c/p\u003e\u003cp\u003eTo capture a diverse array of information on how those in the DevOps community are performing, our eight sponsors of the 2021 State of DevOps survey are focussed on helping organizations of all sizes and industries to develop and deliver software faster across the whole DevOps lifecycle. Captured below, you’ll find more information on our sponsors for this year and why they chose to sponsor the State Of the DevOps 2021 Report.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.armory.io/\" target=\"_blank\"\u003eArmory\u003c/a\u003e \u003cbr/\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--medium h-c-grid__col h-c-grid__col--4 h-c-grid__col--offset-4 \"\u003e\u003cimg alt=\"armory\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/armory.max-1000x1000.png\"/\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cbr/\u003e\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eArmory enables enterprise companies to ship better software, faster through trusted, reliable, safe, and secure deployments -- at its core, Armory is powered by Spinnaker OSS.\u003c/p\u003e\u003cp\u003e“Armory exists to unlock innovation through software. To achieve this, we help enterprises reliably deploy software at scale, naturally aligning with DevOps practices to improve software delivery performance. Given this, we applaud efforts like the State of DevOps Report that provides an independent view into the practices and capabilities that organizations can employ to drive better performance.\" \u003c/p\u003e\u003cp\u003eCarl Timm, Senior Director of Product Marketing at Armory\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://circleci.com/\" target=\"_blank\"\u003eCircleCI\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--medium h-c-grid__col h-c-grid__col--4 h-c-grid__col--offset-4 \"\u003e\u003cimg alt=\"circleci\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/circelci.max-1000x1000.png\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eThe world’s best software teams deliver quality code, confidently, with CircleCI. The world’s best software teams use CircleCI to go from next-up to feature shipped, at the speed ambitious businesses require. \u003c/p\u003e\u003cp\u003e“Though the DevOps space is only over a decade old, it moves incredibly quickly. Google’s State of DevOps report is both a reflection and projection of the industry, capturing how DevOps culture drives business results and where DevOps practitioners can look to improve. At CircleCI, we rely heavily on this survey data to glean valuable insights into our market and our customers overall. We also build upon these insights to guide our own research into how engineering teams move code through pipelines in our annual \u003ca href=\"https://circleci.com/resources/2020-state-of-software-delivery/\" target=\"_blank\"\u003eState of Software Delivery report\u003c/a\u003e. Taken together, this research highlights teams’ reported and actual behavior and paints a vibrant picture of how technology-driven organizations drive for success.”\u003c/p\u003e\u003cp\u003eEmma Webb, VP, Corporate Communications, CircleCI \u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cd.foundation/\" target=\"_blank\"\u003eContinuous Delivery Foundation\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--medium h-c-grid__col h-c-grid__col--4 h-c-grid__col--offset-4 \"\u003e\u003cimg alt=\"cdf\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/cdf.max-1000x1000.png\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eCD Foundation is an open-source community improving the world's ability to deliver software with security and speed.\u003c/p\u003e\u003cp\u003e\"Good decision-making is based on good data. Open source is a critical piece of the technology roadmap for DevOps, and the 2021 State of DevOps Report will provide actionable information for high performing teams in organizations of all types and sizes. The report will show where open source and DevOps intersect, and in a space that is changing so quickly, new relevant data is critical,\" said Tracy Miranda, Continuous Delivery Foundation Executive Director. \"CD Foundation members are deeply involved with producing this annual report, with over 10 years of historic research. Thank you to Google and our other members who have worked so hard on it. This report is a tangible result of working together.\"\u003c/p\u003e\u003cp\u003eTracy Miranda, Continuous Delivery Foundation Executive Director\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www2.deloitte.com/us/en.html\" target=\"_blank\"\u003eDeloitte\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--medium h-c-grid__col h-c-grid__col--4 h-c-grid__col--offset-4 \"\u003e\u003cimg alt=\"deloitte\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/deloitte.max-1000x1000.png\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eDeloitte provides audit and assurance, tax, consulting, and risk and financial advisory services to a broad cross-section of the largest corporations and governmental agencies. At Deloitte, they are continuously evolving how they work and how they look at marketplace challenges so they can continually deliver measurable, sustainable results for their clients and communities.\u003c/p\u003e\u003cp\u003e“Software delivery is evolving rapidly and we know our customers need unique and compelling insights to make the right decisions. State of DevOps is a widely used report and considered as an Industry standard to understand the drivers for excellence in Software Development and Delivery. Deloitte is excited to help the team at DORA and Google Cloud in publishing this report through our sponsoring since we believe the insights from this report will help make software delivery better.” \u003c/p\u003e\u003cp\u003eManoj Mishra, Consulting Managing Director, Deloitte Consulting LLP\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://about.gitlab.com/\" target=\"_blank\"\u003eGitLab\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--medium h-c-grid__col h-c-grid__col--4 h-c-grid__col--offset-4 \"\u003e\u003cimg alt=\"gitlab\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/gitlab.max-1000x1000.jpeg\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eGitLab is the open DevOps platform built from the ground up as a single application for all stages of the DevOps lifecycle enabling Product, Development, QA, Security, and Operations teams to work concurrently on the same project.\u003c/p\u003e\u003cp\u003e“We're happy to sponsor the DORA Report and the vital work behind it. The more we understand the DevOps journey, the better we and our GitLab community can contribute to its future. We're particularly interested to see this year's results and the impact COVID-19 and remote work have had on DevOps. We appreciate the chance to be part of this exciting, informative process.”\u003c/p\u003e\u003cp\u003eBrendon O’Leary, Senior Developer Evangelist\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.liquibase.com/\" target=\"_blank\"\u003eLiquibase\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--medium h-c-grid__col h-c-grid__col--4 h-c-grid__col--offset-4 \"\u003e\u003cimg alt=\"liquibase\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/liquibase.max-1000x1000.png\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eLiquibase helps millions of developers easily manage database schema changes by enabling teams to track, version, and deploy database changes by delivering on the promise of CI/CD for the database.\u003c/p\u003e\u003cp\u003e“With their rigorous methodology, the DORA research team delivers actionable information with the simple goal of helping organizations of any size accelerate the development and delivery of software. Liquibase is honored to sponsor the 2021 State of DevOps Report and its role in helping so many organizations build value for their customers and shareholders”\u003c/p\u003e\u003cp\u003eMatt Geise, VP of Marketing at Liquibase\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://www.pagerduty.com/platform/\" target=\"_blank\"\u003ePagerDuty\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--medium h-c-grid__col h-c-grid__col--4 h-c-grid__col--offset-4 \"\u003e\u003cimg alt=\"pagerduty\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/pagerduty.max-1000x1000.png\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003ePagerDuty is a digital operations management platform that empowers the right action, when seconds matter.\u003c/p\u003e\u003cp\u003e“As a leader in digital operations management, PagerDuty is proud to sponsor this year’s report as it aligns with our dedication to helping DevOps professionals make better decisions. This report will inform tech and business leaders about the trends/challenges developers are facing and the opportunities there are to accelerate their own DevOps transformation.” \u003c/p\u003e\u003cp\u003eCarolyn Guss, VP of Corporate Marketing\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://sysdig.com/resources/whitepapers/5-keys-to-a-secure-devops-workflow/?utm_source=google\u0026amp;utm_medium=cpc\u0026amp;utm_campaign=10874493567\u0026amp;adgroupid=106662582683\u0026amp;utm_content=471144145325\u0026amp;utm_term=sysdig\u0026amp;utm_position=\u0026amp;utm_device=c\u0026amp;utm_type=e\u0026amp;utm_geo=9033320\u0026amp;gclid=CjwKCAjw_JuGBhBkEiwA1xmbRSyNOvpZ_6_BMU7Cd_NqwtoumsXkkVHoHcEHLNTQmh2sAWTCOP3WiRoC8ycQAvD_BwE\" target=\"_blank\"\u003eSysDig\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--medium h-c-grid__col h-c-grid__col--4 h-c-grid__col--offset-4 \"\u003e\u003cimg alt=\"sysdig\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/sysdig.max-1000x1000.png\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eSysdig is driving the secure DevOps movement, empowering organizations to confidently secure containers, Kubernetes and cloud.\u003c/p\u003e\u003cp\u003e“There is a learning curve with all new technology, cloud is no exception. Learning from mistakes and sharing best practices is how we will ultimately ship secure applications, faster. For seven years, DORA and Google have partnered to understand the State of DevOps to help vendors and cloud practitioners to learn from each other and implement standards for best practices,”\u003c/p\u003e\u003cp\u003eLoris Degioanni, CTO and founder of Sysdig\u003c/p\u003e\u003cp\u003eGoogle Cloud, the DORA team, and our sponsors are very excited about this year’s report. We look forward to hearing from you, your colleagues, and networks about how DevOps is integrated into your workflow and ways we can help to further improve your performance. Please share your experience with software delivery by \u003ca href=\"https://google.qualtrics.com/jfe/form/SV_cIb0SmhJPfm8H7n\" target=\"_blank\"\u003ecompleting our survey\u003c/a\u003e that will be used to foster the next generation of DevOps best practices. To provide ample time for the DevOps community to contribute to this industry wide report we have extended the deadline for the survey until July 2nd.\u003c/p\u003e\u003cp\u003eThank you to everyone who has participated so far, and the Google Cloud DORA team looks forward to hearing from even more of you soon!\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/sodr.max-1600x1600.png",
      "date_published": "2021-06-30T11:28:00Z",
      "author": {
        "name": "\u003cname\u003eBrenna Washington\u003c/name\u003e\u003ctitle\u003eProduct Marketing Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/topics/developers-practitioners/blueprint-secure-infrastructure-google-cloud/",
      "title": "A blueprint for secure infrastructure on Google Cloud",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;When it comes to infrastructure security, every stakeholder has the same goal: maintain the confidentiality and integrity of their company\u0026amp;#8217;s data and systems. Period.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Developing and operating in the Cloud provides the opportunity to achieve these goals by being more secure and having greater visibility and governance over your resources and data. This is due to the relatively uniform environment of cloud infrastructure (as compared with on-prem) and inherent service-centric architecture. In addition, cloud providers take on some of the key responsibilities for security doing their part in a shared responsibility model.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;However, translating this shared goal into reality can be a complex endeavor for a few reasons. Firstly, administering security in public clouds is unlike what you may be used to as the infrastructure primitives (the building blocks available to you) and control abstractions (how you administer security policy) differ from on premise environments. Additionally, ensuring you make the right policy decisions in an area as high-stakes and ever-evolving as security means that you\u0026amp;#8217;ll likely spend hours researching and reading through documentation, perhaps even hiring experts.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;To \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/identity-security/delivering-the-industrys-most-trusted-cloud\u0026#34;\u0026gt;partner with you\u0026lt;/a\u0026gt; and help address these challenges, Google Cloud built the security foundations blueprint to identify core security decisions and guide you with opinionated best practices for deploying a secured GCP environment.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;What is the security foundations blueprint?\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;The security foundations blueprint is made up of two resources: the \u0026lt;a href=\u0026#34;https://services.google.com/fh/files/misc/google-cloud-security-foundations-guide.pdf\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;security foundations guide\u0026lt;/a\u0026gt;, and the \u0026lt;a href=\u0026#34;https://github.com/terraform-google-modules/terraform-example-foundation\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Terraform automation repository\u0026lt;/a\u0026gt;. For each security decision, the security foundations guide provides opinionated best practices in order to help you build a secure starting point for your Google Cloud deployment, and can be read and used as a reference guide. The recommended policies and architecture outlined in the document can then be deployed through automation using the \u0026lt;a href=\u0026#34;https://github.com/terraform-google-modules/terraform-example-foundation\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Terraform repository\u0026lt;/a\u0026gt; available on GitHub.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Who is it for?\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;The security foundations blueprint was designed with the enterprise in mind, including those with the strongest security requirements. However, the best practices are applicable to any size cloud customer, and can be adapted or adopted in pieces as needed for your organization. As far as who in an organization is going to find it most useful, it is beneficial for many roles:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;b\u0026gt;CISOs and compliance officers\u0026lt;/b\u0026gt; will use the \u0026lt;a href=\u0026#34;https://services.google.com/fh/files/misc/google-cloud-security-foundations-guide.pdf\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;security foundations guide\u0026lt;/a\u0026gt; as a reference to understand Google\u0026amp;#8217;s key principles for Cloud Security and how they can be applied and implemented to their deployments.\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;b\u0026gt;Security practitioners\u0026lt;/b\u0026gt; and\u0026lt;b\u0026gt; platform teams\u0026lt;/b\u0026gt; will follow the guide\u0026amp;#8217;s detailed instructions and accompanying Terraform templates for applying best practices so that they can actively set-up, configure, deploy, and operate their own security-centric infrastructure.\u0026amp;#160;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;b\u0026gt;Application developers\u0026lt;/b\u0026gt; will deploy their workloads and applications on this foundational infrastructure through an automated application deployment pipeline provided in the blueprint.\u0026amp;#160;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;h3\u0026gt;What topics does it cover?\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;This security foundations blueprint continues to expand the topics it covers, with its most recent release in April 2021 including the following areas:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;Google Cloud organization structure and policy\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Authentication and authorization\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Resource hierarchy and deployment\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Networking (segmentation and security)\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Key and secret management\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Logging\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Detective controls\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Billing setup\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;Application security\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;Each of the security decisions addressed in these topics come with background and discussion to support your own understanding of the concepts, which in turn enables you to customize the deployment to your own specific use case (if needed).\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The topics are useful separately, which makes it possible to pick-and-choose areas where you need recommendations, but they also work together. For example, by following the best practices for project and resource naming conventions, you will be set up for advanced monitoring capabilities, such as real-time notifications for compliance to custom policies.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;How can I use it?\u0026lt;/h3\u0026gt;While the \u0026lt;a href=\u0026#34;https://services.google.com/fh/files/misc/google-cloud-security-foundations-guide.pdf\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;security foundations guide\u0026lt;/a\u0026gt; is incredibly valuable on its own, the real magic for a security practitioner or application developer comes from the ability to adopt, adapt, and deploy the best practices using templates in \u0026lt;a href=\u0026#34;https://www.terraform.io/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Terraform\u0026lt;/a\u0026gt;, a tool for managing Infrastructure as Code (IaC). For anyone new to IaC, simply put, it allows you to automate your infrastructure through writing code that configures and provisions your infrastructure. By using IaC to minimize the amount of manual configuration, you also benefit through limiting the possibility of human error in enforcing these components of your security policy.\"\u003e\u003cp\u003eWhen it comes to infrastructure security, every stakeholder has the same goal: maintain the confidentiality and integrity of their company’s data and systems. Period.\u003c/p\u003e\u003cp\u003eDeveloping and operating in the Cloud provides the opportunity to achieve these goals by being more secure and having greater visibility and governance over your resources and data. This is due to the relatively uniform environment of cloud infrastructure (as compared with on-prem) and inherent service-centric architecture. In addition, cloud providers take on some of the key responsibilities for security doing their part in a shared responsibility model. \u003c/p\u003e\u003cp\u003eHowever, translating this shared goal into reality can be a complex endeavor for a few reasons. Firstly, administering security in public clouds is unlike what you may be used to as the infrastructure primitives (the building blocks available to you) and control abstractions (how you administer security policy) differ from on premise environments. Additionally, ensuring you make the right policy decisions in an area as high-stakes and ever-evolving as security means that you’ll likely spend hours researching and reading through documentation, perhaps even hiring experts. \u003c/p\u003e\u003cp\u003eTo \u003ca href=\"https://cloud.google.com/blog/products/identity-security/delivering-the-industrys-most-trusted-cloud\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/identity-security/delivering-the-industrys-most-trusted-cloud\" track-metadata-module=\"post\"\u003epartner with you\u003c/a\u003e and help address these challenges, Google Cloud built the security foundations blueprint to identify core security decisions and guide you with opinionated best practices for deploying a secured GCP environment. \u003c/p\u003e\u003ch3\u003eWhat is the security foundations blueprint?\u003c/h3\u003e\u003cp\u003eThe security foundations blueprint is made up of two resources: the \u003ca href=\"https://services.google.com/fh/files/misc/google-cloud-security-foundations-guide.pdf\" target=\"_blank\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://services.google.com\" track-metadata-module=\"post\"\u003esecurity foundations guide\u003c/a\u003e, and the \u003ca href=\"https://github.com/terraform-google-modules/terraform-example-foundation\" target=\"_blank\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eTerraform automation repository\u003c/a\u003e. For each security decision, the security foundations guide provides opinionated best practices in order to help you build a secure starting point for your Google Cloud deployment, and can be read and used as a reference guide. The recommended policies and architecture outlined in the document can then be deployed through automation using the \u003ca href=\"https://github.com/terraform-google-modules/terraform-example-foundation\" target=\"_blank\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eTerraform repository\u003c/a\u003e available on GitHub. \u003c/p\u003e\u003ch3\u003eWho is it for?\u003c/h3\u003e\u003cp\u003eThe security foundations blueprint was designed with the enterprise in mind, including those with the strongest security requirements. However, the best practices are applicable to any size cloud customer, and can be adapted or adopted in pieces as needed for your organization. As far as who in an organization is going to find it most useful, it is beneficial for many roles:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cb\u003eCISOs and compliance officers\u003c/b\u003e will use the \u003ca href=\"https://services.google.com/fh/files/misc/google-cloud-security-foundations-guide.pdf\" target=\"_blank\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://services.google.com\" track-metadata-module=\"post\"\u003esecurity foundations guide\u003c/a\u003e as a reference to understand Google’s key principles for Cloud Security and how they can be applied and implemented to their deployments.\u003c/li\u003e\u003cli\u003e\u003cb\u003eSecurity practitioners\u003c/b\u003e and\u003cb\u003e platform teams\u003c/b\u003e will follow the guide’s detailed instructions and accompanying Terraform templates for applying best practices so that they can actively set-up, configure, deploy, and operate their own security-centric infrastructure. \u003c/li\u003e\u003cli\u003e\u003cb\u003eApplication developers\u003c/b\u003e will deploy their workloads and applications on this foundational infrastructure through an automated application deployment pipeline provided in the blueprint. \u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eWhat topics does it cover?\u003c/h3\u003e\u003cp\u003eThis security foundations blueprint continues to expand the topics it covers, with its most recent release in April 2021 including the following areas:\u003c/p\u003e\u003cul\u003e\u003cli\u003eGoogle Cloud organization structure and policy\u003c/li\u003e\u003cli\u003eAuthentication and authorization\u003c/li\u003e\u003cli\u003eResource hierarchy and deployment\u003c/li\u003e\u003cli\u003eNetworking (segmentation and security)\u003c/li\u003e\u003cli\u003eKey and secret management\u003c/li\u003e\u003cli\u003eLogging\u003c/li\u003e\u003cli\u003eDetective controls\u003c/li\u003e\u003cli\u003eBilling setup\u003c/li\u003e\u003cli\u003eApplication security\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eEach of the security decisions addressed in these topics come with background and discussion to support your own understanding of the concepts, which in turn enables you to customize the deployment to your own specific use case (if needed).\u003c/p\u003e\u003cp\u003eThe topics are useful separately, which makes it possible to pick-and-choose areas where you need recommendations, but they also work together. For example, by following the best practices for project and resource naming conventions, you will be set up for advanced monitoring capabilities, such as real-time notifications for compliance to custom policies.\u003c/p\u003e\u003ch3\u003eHow can I use it?\u003c/h3\u003e\u003cp\u003eWhile the \u003ca href=\"https://services.google.com/fh/files/misc/google-cloud-security-foundations-guide.pdf\" target=\"_blank\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://services.google.com\" track-metadata-module=\"post\"\u003esecurity foundations guide\u003c/a\u003e is incredibly valuable on its own, the real magic for a security practitioner or application developer comes from the ability to adopt, adapt, and deploy the best practices using templates in \u003ca href=\"https://www.terraform.io/\" target=\"_blank\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://www.terraform.io\" track-metadata-module=\"post\"\u003eTerraform\u003c/a\u003e, a tool for managing Infrastructure as Code (IaC). For anyone new to IaC, simply put, it allows you to automate your infrastructure through writing code that configures and provisions your infrastructure. By using IaC to minimize the amount of manual configuration, you also benefit through limiting the possibility of human error in enforcing these components of your security policy.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eWhen it comes to infrastructure security, every stakeholder has the same goal: maintain the confidentiality and integrity of their company’s data and systems. Period.\u003c/p\u003e\u003cp\u003eDeveloping and operating in the Cloud provides the opportunity to achieve these goals by being more secure and having greater visibility and governance over your resources and data. This is due to the relatively uniform environment of cloud infrastructure (as compared with on-prem) and inherent service-centric architecture. In addition, cloud providers take on some of the key responsibilities for security doing their part in a shared responsibility model. \u003c/p\u003e\u003cp\u003eHowever, translating this shared goal into reality can be a complex endeavor for a few reasons. Firstly, administering security in public clouds is unlike what you may be used to as the infrastructure primitives (the building blocks available to you) and control abstractions (how you administer security policy) differ from on premise environments. Additionally, ensuring you make the right policy decisions in an area as high-stakes and ever-evolving as security means that you’ll likely spend hours researching and reading through documentation, perhaps even hiring experts. \u003c/p\u003e\u003cp\u003eTo \u003ca href=\"https://cloud.google.com/blog/products/identity-security/delivering-the-industrys-most-trusted-cloud\"\u003epartner with you\u003c/a\u003e and help address these challenges, Google Cloud built the security foundations blueprint to identify core security decisions and guide you with opinionated best practices for deploying a secured GCP environment. \u003c/p\u003e\u003ch3\u003eWhat is the security foundations blueprint?\u003c/h3\u003e\u003cp\u003eThe security foundations blueprint is made up of two resources: the \u003ca href=\"https://services.google.com/fh/files/misc/google-cloud-security-foundations-guide.pdf\" target=\"_blank\"\u003esecurity foundations guide\u003c/a\u003e, and the \u003ca href=\"https://github.com/terraform-google-modules/terraform-example-foundation\" target=\"_blank\"\u003eTerraform automation repository\u003c/a\u003e. For each security decision, the security foundations guide provides opinionated best practices in order to help you build a secure starting point for your Google Cloud deployment, and can be read and used as a reference guide. The recommended policies and architecture outlined in the document can then be deployed through automation using the \u003ca href=\"https://github.com/terraform-google-modules/terraform-example-foundation\" target=\"_blank\"\u003eTerraform repository\u003c/a\u003e available on GitHub. \u003c/p\u003e\u003ch3\u003eWho is it for?\u003c/h3\u003e\u003cp\u003eThe security foundations blueprint was designed with the enterprise in mind, including those with the strongest security requirements. However, the best practices are applicable to any size cloud customer, and can be adapted or adopted in pieces as needed for your organization. As far as who in an organization is going to find it most useful, it is beneficial for many roles:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cb\u003eCISOs and compliance officers\u003c/b\u003e will use the \u003ca href=\"https://services.google.com/fh/files/misc/google-cloud-security-foundations-guide.pdf\" target=\"_blank\"\u003esecurity foundations guide\u003c/a\u003e as a reference to understand Google’s key principles for Cloud Security and how they can be applied and implemented to their deployments.\u003c/li\u003e\u003cli\u003e\u003cb\u003eSecurity practitioners\u003c/b\u003e and\u003cb\u003eplatform teams\u003c/b\u003e will follow the guide’s detailed instructions and accompanying Terraform templates for applying best practices so that they can actively set-up, configure, deploy, and operate their own security-centric infrastructure. \u003c/li\u003e\u003cli\u003e\u003cb\u003eApplication developers\u003c/b\u003e will deploy their workloads and applications on this foundational infrastructure through an automated application deployment pipeline provided in the blueprint. \u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eWhat topics does it cover?\u003c/h3\u003e\u003cp\u003eThis security foundations blueprint continues to expand the topics it covers, with its most recent release in April 2021 including the following areas:\u003c/p\u003e\u003cul\u003e\u003cli\u003eGoogle Cloud organization structure and policy\u003c/li\u003e\u003cli\u003eAuthentication and authorization\u003c/li\u003e\u003cli\u003eResource hierarchy and deployment\u003c/li\u003e\u003cli\u003eNetworking (segmentation and security)\u003c/li\u003e\u003cli\u003eKey and secret management\u003c/li\u003e\u003cli\u003eLogging\u003c/li\u003e\u003cli\u003eDetective controls\u003c/li\u003e\u003cli\u003eBilling setup\u003c/li\u003e\u003cli\u003eApplication security\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eEach of the security decisions addressed in these topics come with background and discussion to support your own understanding of the concepts, which in turn enables you to customize the deployment to your own specific use case (if needed).\u003c/p\u003e\u003cp\u003eThe topics are useful separately, which makes it possible to pick-and-choose areas where you need recommendations, but they also work together. For example, by following the best practices for project and resource naming conventions, you will be set up for advanced monitoring capabilities, such as real-time notifications for compliance to custom policies.\u003c/p\u003e\u003ch3\u003eHow can I use it?\u003c/h3\u003eWhile the \u003ca href=\"https://services.google.com/fh/files/misc/google-cloud-security-foundations-guide.pdf\" target=\"_blank\"\u003esecurity foundations guide\u003c/a\u003e is incredibly valuable on its own, the real magic for a security practitioner or application developer comes from the ability to adopt, adapt, and deploy the best practices using templates in \u003ca href=\"https://www.terraform.io/\" target=\"_blank\"\u003eTerraform\u003c/a\u003e, a tool for managing Infrastructure as Code (IaC). For anyone new to IaC, simply put, it allows you to automate your infrastructure through writing code that configures and provisions your infrastructure. By using IaC to minimize the amount of manual configuration, you also benefit through limiting the possibility of human error in enforcing these components of your security policy.\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Untitled_2.max-1000x1000.png\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"The Security Foundations Blueprint\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Untitled_2.max-1000x1000.png\"/\u003e\u003c/a\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eThe Security Foundations Blueprint as an automated deployment pipeline\u003c/p\u003e\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eThe \u003ca href=\"https://github.com/terraform-google-modules/terraform-example-foundation\" target=\"_blank\"\u003eTerraform automation repo\u003c/a\u003e includes configuration that defines the environment outlined in the \u003ca href=\"https://services.google.com/fh/files/misc/google-cloud-security-foundations-guide.pdf\" target=\"_blank\"\u003eguide\u003c/a\u003e. You can apply the repo end-to-end to deploy the full security foundations blueprint, or use the included modules individually and modify them so that you can adopt just portions of the blueprint. It’s important to note that there are a few differences between the policies for the sample organization outlined in the guide and what is deployed using the Terraform templates. Luckily, those few differences are outlined in the \u003ca href=\"https://github.com/terraform-google-modules/terraform-example-foundation/blob/master/ERRATA.md\" target=\"_blank\"\u003eerrata pages\u003c/a\u003e that are part of the \u003ca href=\"https://github.com/terraform-google-modules/terraform-example-foundation\" target=\"_blank\"\u003eTerraform automation repo\u003c/a\u003e.\u003cbr/\u003e\u003c/p\u003e\u003ch3\u003eSo what should I do next? \u003c/h3\u003e\u003cp\u003eWe hope you’ll continue following the journey of this blog series where we’ll dive deeper into the best practices provided throughout the topical sections of the \u003ca href=\"https://services.google.com/fh/files/misc/google-cloud-security-foundations-guide.pdf\" target=\"_blank\"\u003eguide\u003c/a\u003e, discuss the different ways in which the blueprints have helped enterprises secure their own Cloud deployment, and take a look inside the \u003ca href=\"https://github.com/terraform-google-modules/terraform-example-foundation\" target=\"_blank\"\u003eTerraform templates\u003c/a\u003e to see how they can be adopted, adapted, and deployed. In the meantime, take a look at \u003ca href=\"https://cloud.google.com/blog/products/identity-security/google-cloud-security-foundations-guide\"\u003ethis recent Cloud blog post\u003c/a\u003e which announces the launch of the blueprint’s latest version and discusses the key security principles that steer the best practices.\u003c/p\u003e\u003cp\u003e If you’re ready to dive straight into the \u003ca href=\"https://services.google.com/fh/files/misc/google-cloud-security-foundations-guide.pdf\" target=\"_blank\"\u003esecurity foundations guide\u003c/a\u003e, you can start at the beginning, or head to a topic in which you’re particularly interested. Reviewing the guide in this way, you will be able to see for yourself the level of detail and discussion, and most importantly, the direct path it provides to move beyond recommendations and into implementation. We don’t expect you to try and apply the blueprint to your security posture right away, but a great first step would be to fork the repo and deploy it in a new folder or organization. Go forth, deploy and stay safe out there.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/identity-security/google-cloud-security-foundations-guide/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_security.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eBuild security into Google Cloud deployments with our updated security foundations blueprint\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eGet step by step guidance for creating a secured environment with Google Cloud with the security foundations guide and Terraform blueprin...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://cloud.google.com/blog/static/assets/GCP_Twitter_Card-2000×1000.png",
      "date_published": "2021-06-24T19:00:00Z",
      "author": {
        "name": "\u003cname\u003eAlicia Williams\u003c/name\u003e\u003ctitle\u003eDeveloper Advocate\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/evaluating-where-your-team-lies-on-the-sre-spectrum/",
      "title": "Are we there yet? Thoughts on assessing an SRE team’s maturity",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;One facet of our work as \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/introducing-a-new-era-of-customer-support-google-customer-reliability-engineering\u0026#34;\u0026gt;Customer Reliability Engineers\u0026lt;/a\u0026gt;\u0026amp;#8212;Google Site Reliability Engineers (SREs) tapped to help Google Cloud customers develop that practice in their own organizations\u0026amp;#8212;is advising operations or SRE teams to improve their operational maturity. We\u0026#39;ve noticed a recurring question cropping up across many of these discussions, usually phrased along the lines of \u0026amp;#34;is what we\u0026#39;re currently doing \u0026lt;i\u0026gt;\u0026#39;SRE work\u0026#39;?\u0026amp;#34;\u0026lt;/i\u0026gt; or, with a little more existential dread, \u0026amp;#34;can we call ourselves SREs yet?\u0026amp;#34;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;We\u0026#39;ve answered this question before with a \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/how-to-start-and-assess-your-sre-journey\u0026#34;\u0026gt;list of practices\u0026lt;/a\u0026gt; from the \u0026lt;a href=\u0026#34;https://sre.google/workbook/table-of-contents/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;SRE workbook\u0026lt;/a\u0026gt;. But the list is long on the \u0026lt;i\u0026gt;what\u0026lt;/i\u0026gt; and short on the \u0026lt;i\u0026gt;why\u0026lt;/i\u0026gt;, which can make it hard to digest for folks already suffering an identity crisis. Instead, we hope to help answer this question by discussing some principles we consider fundamental to how an SRE team operates. We\u0026#39;ll examine why they\u0026#39;re important and suggest questions that characterize a team\u0026#39;s progress towards embodying them.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h2\u0026gt;Are we there yet?\u0026lt;/h2\u0026gt;\u0026lt;p\u0026gt;This question is asked in different ways, for a myriad of different reasons, and it can be quite hard to answer due to the wide range of \u0026lt;a href=\u0026#34;https://web.devopstopologies.com/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;different circumstances\u0026lt;/a\u0026gt; that our customers operate in. Moreover, CRE, and Google in general, is not the final arbiter of what is and isn\u0026#39;t \u0026amp;#34;SRE\u0026amp;#34; for your organization, so we can\u0026#39;t provide an authoritative answer, if one even exists. We can only influence you and the community at large by expressing our opinions and experiences, in person or via our \u0026lt;a href=\u0026#34;https://sre.google/books/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;books\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/topics/cre-life-lessons\u0026#34;\u0026gt;blog posts\u0026lt;/a\u0026gt;.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Further, discussions of this topic tend to be complicated by the fact that the term \u0026amp;#34;SRE\u0026amp;#34; is used interchangeably to mean three things:\u0026lt;/p\u0026gt;\u0026lt;ol\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;A \u0026lt;b\u0026gt;job role\u0026lt;/b\u0026gt; primarily focused on maintaining the reliability of a service or product.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;A \u0026lt;b\u0026gt;group of people \u0026lt;/b\u0026gt;working within an organization, usually in the above job role.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;A \u0026lt;b\u0026gt;set of principles and practices\u0026lt;/b\u0026gt; that the above people can utilize to improve service reliability.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ol\u0026gt;\u0026lt;p\u0026gt;When people ask \u0026amp;#34;can we call ourselves SREs yet?\u0026amp;#34; we could interpret it as a desire to link these three definitions together. A clearer restatement of this interpretation might be: \u0026amp;#34;Is our \u0026lt;b\u0026gt;group\u0026lt;/b\u0026gt; sufficiently advanced in our application of the \u0026lt;b\u0026gt;principles and practices\u0026lt;/b\u0026gt; that we can justifiably term our \u0026lt;b\u0026gt;job role\u0026lt;/b\u0026gt; SRE?\u0026amp;#34;\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;We should stress that we\u0026#39;re not saying that you need a clearly defined \u0026lt;b\u0026gt;job role\u0026lt;/b\u0026gt;\u0026amp;#8212;or even a \u0026lt;b\u0026gt;team\u0026lt;/b\u0026gt;\u0026amp;#8212;before you can start utilizing the \u0026lt;b\u0026gt;principles and practices\u0026lt;/b\u0026gt; to do things that are recognizably SRE-like. Job roles and teams crystallize from a more fluid set of responsibilities as organizations grow larger. But as this process plays out, the people involved may feel less certain of the scope of their responsibilities, precipitating the \u0026amp;#8216;are we there yet?\u0026amp;#8217; question. We suspect that\u0026#39;s where the tone of existential dread comes from...\u0026lt;/p\u0026gt;\u0026lt;h2\u0026gt;Key SRE indicators\u0026lt;/h2\u0026gt;\u0026lt;p\u0026gt;Within the CRE team here at Google Cloud, the \u0026amp;#8216;are we there yet?\u0026amp;#8217; question surfaced a wide variety of opinions about the core principles that should guide an SRE team. We did manage to reach a rough consensus, with one proviso\u0026amp;#8212;the answer is partially dependent on how a team engages with the services it supports.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;We\u0026#39;ve chosen to structure this post around a set of principles that we would broadly expect groups of people working as SREs that \u0026lt;i\u0026gt;directly support services in production\u0026lt;/i\u0026gt; to adhere to. As in a \u0026lt;a href=\u0026#34;https://en.wikipedia.org/wiki/Litmus#Uses\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;litmus test\u0026lt;/a\u0026gt;, this won\u0026#39;t provide pin-point accuracy; but in our collective opinion at least, alignment with most of the principles laid out below is a good signal that a team is practicing something that can recognizably be termed \u0026lt;i\u0026gt;Site Reliability Engineering.\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Directly engaged SRE teams are usually considered \u0026lt;i\u0026gt;Accountable\u0026lt;/i\u0026gt; (in \u0026lt;a href=\u0026#34;https://en.wikipedia.org/wiki/Responsibility_assignment_matrix\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;RACI terms\u0026lt;/a\u0026gt;) for the service\u0026amp;#8217;s reliability, with \u0026lt;i\u0026gt;Responsibility\u0026lt;/i\u0026gt; shared between the SRE and development teams. As a team provides less direct support these indicators may be less applicable. We hope those teams can still adapt the principles to their own circumstances.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;To illustrate how you might do this, for each principle we\u0026#39;ve given a counter-example of a team of SREs operating in an advisory capacity. They\u0026#39;re subject-matter experts who are \u0026lt;i\u0026gt;Consulted\u0026lt;/i\u0026gt; by development teams who are themselves \u0026lt;i\u0026gt;Responsible\u0026lt;/i\u0026gt; and \u0026lt;i\u0026gt;Accountable\u0026lt;/i\u0026gt; for service reliability.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Wherever your engagement model lies on the spectrum, being perceived by the rest of the organization as jointly responsible for a service\u0026#39;s reliability, or as reliability subject-matter experts, is a key indicator of SRE-hood.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Principle #1: SREs mitigate present and \u0026lt;i\u0026gt;future\u0026lt;/i\u0026gt; incidents\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;This principle is the one that usually underlies the perception of \u0026lt;b\u0026gt;responsibility and accountability\u0026lt;/b\u0026gt; for a service\u0026#39;s reliability. All the careful engineering and active regulation in the world can\u0026#39;t guarantee reliability, especially in complex distributed systems\u0026amp;#8212;sometimes, things go wrong unexpectedly and the only thing left to do is react, mitigate, and fix. SREs have both the authority and the technical capability to act fast to restore service in these situations.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;But mitigating the immediate problem isn\u0026#39;t enough. If it can happen again tomorrow, then tomorrow isn\u0026#39;t better than today, so SREs should work to understand the precipitating factors of incidents and propose changes that remediate the entire class of problem in the infrastructure they are responsible for. Don\u0026#39;t have the same outage again next month!\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;How unique are your outages? Ask yourself these questions:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Can you mitigate the majority of the incidents without needing specialist knowledge from the development team?\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Do you maintain training materials and practice incident response scenarios?\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;After a major outage happens to your service, are you a key participant in blamelessly figuring out what \u0026lt;b\u0026gt;really\u0026lt;/b\u0026gt; went wrong, and how to prevent future outages?\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;Now, for a counter example. In many organizations, SREs are a scarce resource and may add more value by developing platforms and best practices to uplift large swathes of the company, rather than being primarily focused on incident response. Thus, a consulting SRE team would probably not be directly involved in mitigating most incidents, though they may be called on to coordinate incident response for a widespread outage. Rather than authoring training materials and postmortems, they would be responsible for reviewing those created by the teams they advise.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Principle #2: SREs actively regulate service reliability\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Reliability goals and feedback signals are fundamental for both motivating SRE work and influencing the prioritization of development work.\u0026lt;/b\u0026gt; At Google, we call our reliability goals \u0026lt;a href=\u0026#34;https://sre.google/sre-book/service-level-objectives/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;\u0026lt;i\u0026gt;Service Level Objectives\u0026lt;/i\u0026gt;\u0026lt;/a\u0026gt; and our feedback signals \u0026lt;i\u0026gt;Error Budgets\u0026lt;/i\u0026gt;, and you can read more about how we use them in the \u0026lt;a href=\u0026#34;https://sre.google/workbook/implementing-slos/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Site Reliability Workbook\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Do your reliability signals affect your organization\u0026#39;s priorities? Ask yourself these questions:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Do you agree on goals for the reliability of the services you support with your organization, and track performance against those goals in real time?\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Do you have an established feedback loop that moderates the behaviour of the organization based on recent service reliability?\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Do you have the influence to effect change within the organization in pursuit of the reliability goals?\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Do you have the \u0026lt;a href=\u0026#34;https://en.wikipedia.org/wiki/Agency_(sociology)\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;agency\u0026lt;/a\u0026gt; to refuse, or negotiate looser goals, when asked to make changes that may cause a service to miss its current reliability goals?\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;Each question builds on the last. It is almost impossible to establish a data-driven feedback loop without a well-defined and measured reliability goal. For those goals to be meaningful, SREs must have the capability to defend them. Periods of lower service reliability should result in consequences that temporarily reduce the aggregate risk of future production changes and shift engineering priorities towards reliability.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;When it comes down to a choice between service reliability and the rollout of new but unreliable features, SREs need to be able to say \u0026amp;#34;no\u0026amp;#34;. This should be a data driven decision\u0026amp;#8212;when there\u0026#39;s not enough spare error budget, there needs to be a valid business reason for making users unhappy. Sometimes, of course, there will be, and this can be accommodated with new, lower SLO targets that reflect the relaxed reliability requirements.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Consultant SREs, in contrast, help teams draft their reliability goals and may develop shared monitoring infrastructure for measuring them across the organization. They are the de-facto regulators of the reliability feedback loop and maintain the policy documents that underpin it. Their connection to many teams and services gives them broader insights that can spark cross-functional reliability improvements.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Principle #3: SREs engage early and comprehensively\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;As we said earlier, \u0026lt;b\u0026gt;SREs should be empowered to make tomorrow better than today.\u0026lt;/b\u0026gt; Without the ability to change the code and configuration of the services they support, they cannot fix problems as they encounter them. Involving SREs earlier in the design process can head off common reliability anti-patterns that are costly to correct \u0026lt;i\u0026gt;post-facto\u0026lt;/i\u0026gt;. And, with the ability to influence architectural decision making, SREs can drive convergence across an organization so that work to increase the reliability of one service can benefit the entire company.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Is your team actively working to make tomorrow better than today? Ask yourself these questions, which go from fine detail to a broad, high-level scope:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Do you engineer your service \u0026lt;b\u0026gt;now\u0026lt;/b\u0026gt; to improve its reliability, e.g. by viewing and modifying the source code and/or configuration?\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Are you involved in analysis and design of \u0026lt;b\u0026gt;future\u0026lt;/b\u0026gt; iterations of your service, providing a lens on reliability/operability/maintainability?\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Can you influence your \u0026lt;b\u0026gt;organization\u0026amp;#8217;s\u0026lt;/b\u0026gt; wider architectural decision making?\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;Advising other teams naturally shifts priorities away from directly modifying the configuration or code of individual services. But consultant SREs may still maintain frameworks or shared libraries providing core reliability features, like exporting common metrics or graceful service degradation. Their breadth of engagements across many teams makes them naturally suited for providing high-level architectural advice to improve reliability across an entire organization.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Principle #4: SREs automate anything repetitive\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Finally, SREs believe that computers are fundamentally better suited to doing repetitive work than humans are. People often underestimate the \u0026lt;a href=\u0026#34;https://xkcd.com/1205/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;returns on investment\u0026lt;/a\u0026gt; when considering whether to automate a routine task, and that\u0026#39;s before factoring in the exponential growth curve that comes with running a large, successful service. Moreover, computers never become inattentive and make mistakes when doing the same task for the hundredth time, or become demoralized and quit. Hiring or \u0026lt;a href=\u0026#34;https://sre.google/resources/practices-and-processes/training-site-reliability-engineers/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;training SREs\u0026lt;/a\u0026gt; is expensive and time-consuming, so a successful SRE organization depends heavily on making computers do the grunt work.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Are you sufficiently automating your work? Ask yourself these questions:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Do you use\u0026amp;#8212;or create\u0026amp;#8212;automation and other tools to ensure that operational load won\u0026#39;t scale linearly with organic growth or the number of services you support?\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Do you try to measure repetitive work on your team, and reduce it over time?\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;h2\u0026gt;A call for reflection\u0026lt;/h2\u0026gt;\u0026lt;p\u0026gt;Most blog posts end with a call for action. We\u0026#39;d rather you took time to reflect, instead of jumping up to make changes straight after reading. \u0026lt;b\u0026gt;There\u0026#39;s a risk, when writing an opinionated piece like this, that the lines drawn in the sand are used to divide, not to grow and improve.\u0026lt;/b\u0026gt; We promise this isn\u0026#39;t a deliberate effort to gatekeep SRE and exclude those who don\u0026#39;t tick the boxes; we see no value in that. But in some ways gatekeeping is what job roles are \u0026lt;i\u0026gt;designed\u0026lt;/i\u0026gt; to do, because specialization and the division of labour is critical to the success of any organization, and this makes it hard to avoid drawing those lines.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;For those who aspire to call themselves SREs, or are concerned that others may disagree with their characterization of themselves as SREs, perhaps these opinions can assuage some of that existential dread.\u0026lt;/p\u0026gt;\" _nghost-c19=\"\"\u003e\u003cp\u003eOne facet of our work as \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/introducing-a-new-era-of-customer-support-google-customer-reliability-engineering\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/introducing-a-new-era-of-customer-support-google-customer-reliability-engineering\" track-metadata-module=\"post\"\u003eCustomer Reliability Engineers\u003c/a\u003e—Google Site Reliability Engineers (SREs) tapped to help Google Cloud customers develop that practice in their own organizations—is advising operations or SRE teams to improve their operational maturity. We\u0026#39;ve noticed a recurring question cropping up across many of these discussions, usually phrased along the lines of \u0026#34;is what we\u0026#39;re currently doing \u003ci\u003e\u0026#39;SRE work\u0026#39;?\u0026#34;\u003c/i\u003e or, with a little more existential dread, \u0026#34;can we call ourselves SREs yet?\u0026#34;\u003c/p\u003e\u003cp\u003eWe\u0026#39;ve answered this question before with a \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/how-to-start-and-assess-your-sre-journey\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/how-to-start-and-assess-your-sre-journey\" track-metadata-module=\"post\"\u003elist of practices\u003c/a\u003e from the \u003ca href=\"https://sre.google/workbook/table-of-contents/\" target=\"_blank\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003eSRE workbook\u003c/a\u003e. But the list is long on the \u003ci\u003ewhat\u003c/i\u003e and short on the \u003ci\u003ewhy\u003c/i\u003e, which can make it hard to digest for folks already suffering an identity crisis. Instead, we hope to help answer this question by discussing some principles we consider fundamental to how an SRE team operates. We\u0026#39;ll examine why they\u0026#39;re important and suggest questions that characterize a team\u0026#39;s progress towards embodying them. \u003c/p\u003e\u003ch2\u003eAre we there yet?\u003c/h2\u003e\u003cp\u003eThis question is asked in different ways, for a myriad of different reasons, and it can be quite hard to answer due to the wide range of \u003ca href=\"https://web.devopstopologies.com/\" target=\"_blank\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://web.devopstopologies.com\" track-metadata-module=\"post\"\u003edifferent circumstances\u003c/a\u003e that our customers operate in. Moreover, CRE, and Google in general, is not the final arbiter of what is and isn\u0026#39;t \u0026#34;SRE\u0026#34; for your organization, so we can\u0026#39;t provide an authoritative answer, if one even exists. We can only influence you and the community at large by expressing our opinions and experiences, in person or via our \u003ca href=\"https://sre.google/books/\" target=\"_blank\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003ebooks\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/blog/topics/cre-life-lessons\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/blog/topics/cre-life-lessons\" track-metadata-module=\"post\"\u003eblog posts\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eFurther, discussions of this topic tend to be complicated by the fact that the term \u0026#34;SRE\u0026#34; is used interchangeably to mean three things:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cp\u003eA \u003cb\u003ejob role\u003c/b\u003e primarily focused on maintaining the reliability of a service or product.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eA \u003cb\u003egroup of people \u003c/b\u003eworking within an organization, usually in the above job role.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eA \u003cb\u003eset of principles and practices\u003c/b\u003e that the above people can utilize to improve service reliability.\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eWhen people ask \u0026#34;can we call ourselves SREs yet?\u0026#34; we could interpret it as a desire to link these three definitions together. A clearer restatement of this interpretation might be: \u0026#34;Is our \u003cb\u003egroup\u003c/b\u003e sufficiently advanced in our application of the \u003cb\u003eprinciples and practices\u003c/b\u003e that we can justifiably term our \u003cb\u003ejob role\u003c/b\u003e SRE?\u0026#34; \u003c/p\u003e\u003cp\u003eWe should stress that we\u0026#39;re not saying that you need a clearly defined \u003cb\u003ejob role\u003c/b\u003e—or even a \u003cb\u003eteam\u003c/b\u003e—before you can start utilizing the \u003cb\u003eprinciples and practices\u003c/b\u003e to do things that are recognizably SRE-like. Job roles and teams crystallize from a more fluid set of responsibilities as organizations grow larger. But as this process plays out, the people involved may feel less certain of the scope of their responsibilities, precipitating the ‘are we there yet?’ question. We suspect that\u0026#39;s where the tone of existential dread comes from...\u003c/p\u003e\u003ch2\u003eKey SRE indicators\u003c/h2\u003e\u003cp\u003eWithin the CRE team here at Google Cloud, the ‘are we there yet?’ question surfaced a wide variety of opinions about the core principles that should guide an SRE team. We did manage to reach a rough consensus, with one proviso—the answer is partially dependent on how a team engages with the services it supports.\u003c/p\u003e\u003cp\u003eWe\u0026#39;ve chosen to structure this post around a set of principles that we would broadly expect groups of people working as SREs that \u003ci\u003edirectly support services in production\u003c/i\u003e to adhere to. As in a \u003ca href=\"https://en.wikipedia.org/wiki/Litmus#Uses\" target=\"_blank\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://en.wikipedia.org\" track-metadata-module=\"post\"\u003elitmus test\u003c/a\u003e, this won\u0026#39;t provide pin-point accuracy; but in our collective opinion at least, alignment with most of the principles laid out below is a good signal that a team is practicing something that can recognizably be termed \u003ci\u003eSite Reliability Engineering.\u003c/i\u003e\u003c/p\u003e\u003cp\u003eDirectly engaged SRE teams are usually considered \u003ci\u003eAccountable\u003c/i\u003e (in \u003ca href=\"https://en.wikipedia.org/wiki/Responsibility_assignment_matrix\" target=\"_blank\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://en.wikipedia.org\" track-metadata-module=\"post\"\u003eRACI terms\u003c/a\u003e) for the service’s reliability, with \u003ci\u003eResponsibility\u003c/i\u003e shared between the SRE and development teams. As a team provides less direct support these indicators may be less applicable. We hope those teams can still adapt the principles to their own circumstances. \u003c/p\u003e\u003cp\u003eTo illustrate how you might do this, for each principle we\u0026#39;ve given a counter-example of a team of SREs operating in an advisory capacity. They\u0026#39;re subject-matter experts who are \u003ci\u003eConsulted\u003c/i\u003e by development teams who are themselves \u003ci\u003eResponsible\u003c/i\u003e and \u003ci\u003eAccountable\u003c/i\u003e for service reliability.\u003c/p\u003e\u003cp\u003eWherever your engagement model lies on the spectrum, being perceived by the rest of the organization as jointly responsible for a service\u0026#39;s reliability, or as reliability subject-matter experts, is a key indicator of SRE-hood.\u003c/p\u003e\u003ch3\u003ePrinciple #1: SREs mitigate present and \u003ci\u003efuture\u003c/i\u003e incidents\u003c/h3\u003e\u003cp\u003eThis principle is the one that usually underlies the perception of \u003cb\u003eresponsibility and accountability\u003c/b\u003e for a service\u0026#39;s reliability. All the careful engineering and active regulation in the world can\u0026#39;t guarantee reliability, especially in complex distributed systems—sometimes, things go wrong unexpectedly and the only thing left to do is react, mitigate, and fix. SREs have both the authority and the technical capability to act fast to restore service in these situations.\u003c/p\u003e\u003cp\u003eBut mitigating the immediate problem isn\u0026#39;t enough. If it can happen again tomorrow, then tomorrow isn\u0026#39;t better than today, so SREs should work to understand the precipitating factors of incidents and propose changes that remediate the entire class of problem in the infrastructure they are responsible for. Don\u0026#39;t have the same outage again next month!\u003c/p\u003e\u003cp\u003eHow unique are your outages? Ask yourself these questions:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eCan you mitigate the majority of the incidents without needing specialist knowledge from the development team?\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDo you maintain training materials and practice incident response scenarios?\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eAfter a major outage happens to your service, are you a key participant in blamelessly figuring out what \u003cb\u003ereally\u003c/b\u003e went wrong, and how to prevent future outages?\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eNow, for a counter example. In many organizations, SREs are a scarce resource and may add more value by developing platforms and best practices to uplift large swathes of the company, rather than being primarily focused on incident response. Thus, a consulting SRE team would probably not be directly involved in mitigating most incidents, though they may be called on to coordinate incident response for a widespread outage. Rather than authoring training materials and postmortems, they would be responsible for reviewing those created by the teams they advise.\u003c/p\u003e\u003ch3\u003ePrinciple #2: SREs actively regulate service reliability\u003c/h3\u003e\u003cp\u003e\u003cb\u003eReliability goals and feedback signals are fundamental for both motivating SRE work and influencing the prioritization of development work.\u003c/b\u003e At Google, we call our reliability goals \u003ca href=\"https://sre.google/sre-book/service-level-objectives/\" target=\"_blank\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003e\u003ci\u003eService Level Objectives\u003c/i\u003e\u003c/a\u003e and our feedback signals \u003ci\u003eError Budgets\u003c/i\u003e, and you can read more about how we use them in the \u003ca href=\"https://sre.google/workbook/implementing-slos/\" target=\"_blank\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003eSite Reliability Workbook\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eDo your reliability signals affect your organization\u0026#39;s priorities? Ask yourself these questions:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eDo you agree on goals for the reliability of the services you support with your organization, and track performance against those goals in real time?\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDo you have an established feedback loop that moderates the behaviour of the organization based on recent service reliability?\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDo you have the influence to effect change within the organization in pursuit of the reliability goals?\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDo you have the \u003ca href=\"https://en.wikipedia.org/wiki/Agency_(sociology)\" target=\"_blank\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://en.wikipedia.org\" track-metadata-module=\"post\"\u003eagency\u003c/a\u003e to refuse, or negotiate looser goals, when asked to make changes that may cause a service to miss its current reliability goals?\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eEach question builds on the last. It is almost impossible to establish a data-driven feedback loop without a well-defined and measured reliability goal. For those goals to be meaningful, SREs must have the capability to defend them. Periods of lower service reliability should result in consequences that temporarily reduce the aggregate risk of future production changes and shift engineering priorities towards reliability. \u003c/p\u003e\u003cp\u003eWhen it comes down to a choice between service reliability and the rollout of new but unreliable features, SREs need to be able to say \u0026#34;no\u0026#34;. This should be a data driven decision—when there\u0026#39;s not enough spare error budget, there needs to be a valid business reason for making users unhappy. Sometimes, of course, there will be, and this can be accommodated with new, lower SLO targets that reflect the relaxed reliability requirements.\u003c/p\u003e\u003cp\u003eConsultant SREs, in contrast, help teams draft their reliability goals and may develop shared monitoring infrastructure for measuring them across the organization. They are the de-facto regulators of the reliability feedback loop and maintain the policy documents that underpin it. Their connection to many teams and services gives them broader insights that can spark cross-functional reliability improvements. \u003c/p\u003e\u003ch3\u003ePrinciple #3: SREs engage early and comprehensively\u003c/h3\u003e\u003cp\u003eAs we said earlier, \u003cb\u003eSREs should be empowered to make tomorrow better than today.\u003c/b\u003e Without the ability to change the code and configuration of the services they support, they cannot fix problems as they encounter them. Involving SREs earlier in the design process can head off common reliability anti-patterns that are costly to correct \u003ci\u003epost-facto\u003c/i\u003e. And, with the ability to influence architectural decision making, SREs can drive convergence across an organization so that work to increase the reliability of one service can benefit the entire company.\u003c/p\u003e\u003cp\u003eIs your team actively working to make tomorrow better than today? Ask yourself these questions, which go from fine detail to a broad, high-level scope:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eDo you engineer your service \u003cb\u003enow\u003c/b\u003e to improve its reliability, e.g. by viewing and modifying the source code and/or configuration?\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eAre you involved in analysis and design of \u003cb\u003efuture\u003c/b\u003e iterations of your service, providing a lens on reliability/operability/maintainability?\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCan you influence your \u003cb\u003eorganization’s\u003c/b\u003e wider architectural decision making?\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eAdvising other teams naturally shifts priorities away from directly modifying the configuration or code of individual services. But consultant SREs may still maintain frameworks or shared libraries providing core reliability features, like exporting common metrics or graceful service degradation. Their breadth of engagements across many teams makes them naturally suited for providing high-level architectural advice to improve reliability across an entire organization.\u003c/p\u003e\u003ch3\u003ePrinciple #4: SREs automate anything repetitive\u003c/h3\u003e\u003cp\u003eFinally, SREs believe that computers are fundamentally better suited to doing repetitive work than humans are. People often underestimate the \u003ca href=\"https://xkcd.com/1205/\" target=\"_blank\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://xkcd.com\" track-metadata-module=\"post\"\u003ereturns on investment\u003c/a\u003e when considering whether to automate a routine task, and that\u0026#39;s before factoring in the exponential growth curve that comes with running a large, successful service. Moreover, computers never become inattentive and make mistakes when doing the same task for the hundredth time, or become demoralized and quit. Hiring or \u003ca href=\"https://sre.google/resources/practices-and-processes/training-site-reliability-engineers/\" target=\"_blank\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003etraining SREs\u003c/a\u003e is expensive and time-consuming, so a successful SRE organization depends heavily on making computers do the grunt work.\u003c/p\u003e\u003cp\u003eAre you sufficiently automating your work? Ask yourself these questions:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eDo you use—or create—automation and other tools to ensure that operational load won\u0026#39;t scale linearly with organic growth or the number of services you support?\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDo you try to measure repetitive work on your team, and reduce it over time?\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2\u003eA call for reflection\u003c/h2\u003e\u003cp\u003eMost blog posts end with a call for action. We\u0026#39;d rather you took time to reflect, instead of jumping up to make changes straight after reading. \u003cb\u003eThere\u0026#39;s a risk, when writing an opinionated piece like this, that the lines drawn in the sand are used to divide, not to grow and improve.\u003c/b\u003e We promise this isn\u0026#39;t a deliberate effort to gatekeep SRE and exclude those who don\u0026#39;t tick the boxes; we see no value in that. But in some ways gatekeeping is what job roles are \u003ci\u003edesigned\u003c/i\u003e to do, because specialization and the division of labour is critical to the success of any organization, and this makes it hard to avoid drawing those lines.\u003c/p\u003e\u003cp\u003eFor those who aspire to call themselves SREs, or are concerned that others may disagree with their characterization of themselves as SREs, perhaps these opinions can assuage some of that existential dread.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eOne facet of our work as \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/introducing-a-new-era-of-customer-support-google-customer-reliability-engineering\"\u003eCustomer Reliability Engineers\u003c/a\u003e—Google Site Reliability Engineers (SREs) tapped to help Google Cloud customers develop that practice in their own organizations—is advising operations or SRE teams to improve their operational maturity. We've noticed a recurring question cropping up across many of these discussions, usually phrased along the lines of \"is what we're currently doing \u003ci\u003e'SRE work'?\"\u003c/i\u003e or, with a little more existential dread, \"can we call ourselves SREs yet?\"\u003c/p\u003e\u003cp\u003eWe've answered this question before with a \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/how-to-start-and-assess-your-sre-journey\"\u003elist of practices\u003c/a\u003e from the \u003ca href=\"https://sre.google/workbook/table-of-contents/\" target=\"_blank\"\u003eSRE workbook\u003c/a\u003e. But the list is long on the \u003ci\u003ewhat\u003c/i\u003e and short on the \u003ci\u003ewhy\u003c/i\u003e, which can make it hard to digest for folks already suffering an identity crisis. Instead, we hope to help answer this question by discussing some principles we consider fundamental to how an SRE team operates. We'll examine why they're important and suggest questions that characterize a team's progress towards embodying them. \u003c/p\u003e\u003ch2\u003eAre we there yet?\u003c/h2\u003e\u003cp\u003eThis question is asked in different ways, for a myriad of different reasons, and it can be quite hard to answer due to the wide range of \u003ca href=\"https://web.devopstopologies.com/\" target=\"_blank\"\u003edifferent circumstances\u003c/a\u003e that our customers operate in. Moreover, CRE, and Google in general, is not the final arbiter of what is and isn't \"SRE\" for your organization, so we can't provide an authoritative answer, if one even exists. We can only influence you and the community at large by expressing our opinions and experiences, in person or via our \u003ca href=\"https://sre.google/books/\" target=\"_blank\"\u003ebooks\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/blog/topics/cre-life-lessons\"\u003eblog posts\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eFurther, discussions of this topic tend to be complicated by the fact that the term \"SRE\" is used interchangeably to mean three things:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cp\u003eA \u003cb\u003ejob role\u003c/b\u003e primarily focused on maintaining the reliability of a service or product.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eA \u003cb\u003egroup of people\u003c/b\u003eworking within an organization, usually in the above job role.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eA \u003cb\u003eset of principles and practices\u003c/b\u003e that the above people can utilize to improve service reliability.\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eWhen people ask \"can we call ourselves SREs yet?\" we could interpret it as a desire to link these three definitions together. A clearer restatement of this interpretation might be: \"Is our \u003cb\u003egroup\u003c/b\u003e sufficiently advanced in our application of the \u003cb\u003eprinciples and practices\u003c/b\u003e that we can justifiably term our \u003cb\u003ejob role\u003c/b\u003e SRE?\" \u003c/p\u003e\u003cp\u003eWe should stress that we're not saying that you need a clearly defined \u003cb\u003ejob role\u003c/b\u003e—or even a \u003cb\u003eteam\u003c/b\u003e—before you can start utilizing the \u003cb\u003eprinciples and practices\u003c/b\u003e to do things that are recognizably SRE-like. Job roles and teams crystallize from a more fluid set of responsibilities as organizations grow larger. But as this process plays out, the people involved may feel less certain of the scope of their responsibilities, precipitating the ‘are we there yet?’ question. We suspect that's where the tone of existential dread comes from...\u003c/p\u003e\u003ch2\u003eKey SRE indicators\u003c/h2\u003e\u003cp\u003eWithin the CRE team here at Google Cloud, the ‘are we there yet?’ question surfaced a wide variety of opinions about the core principles that should guide an SRE team. We did manage to reach a rough consensus, with one proviso—the answer is partially dependent on how a team engages with the services it supports.\u003c/p\u003e\u003cp\u003eWe've chosen to structure this post around a set of principles that we would broadly expect groups of people working as SREs that \u003ci\u003edirectly support services in production\u003c/i\u003e to adhere to. As in a \u003ca href=\"https://en.wikipedia.org/wiki/Litmus#Uses\" target=\"_blank\"\u003elitmus test\u003c/a\u003e, this won't provide pin-point accuracy; but in our collective opinion at least, alignment with most of the principles laid out below is a good signal that a team is practicing something that can recognizably be termed \u003ci\u003eSite Reliability Engineering.\u003c/i\u003e\u003c/p\u003e\u003cp\u003eDirectly engaged SRE teams are usually considered \u003ci\u003eAccountable\u003c/i\u003e (in \u003ca href=\"https://en.wikipedia.org/wiki/Responsibility_assignment_matrix\" target=\"_blank\"\u003eRACI terms\u003c/a\u003e) for the service’s reliability, with \u003ci\u003eResponsibility\u003c/i\u003e shared between the SRE and development teams. As a team provides less direct support these indicators may be less applicable. We hope those teams can still adapt the principles to their own circumstances. \u003c/p\u003e\u003cp\u003eTo illustrate how you might do this, for each principle we've given a counter-example of a team of SREs operating in an advisory capacity. They're subject-matter experts who are \u003ci\u003eConsulted\u003c/i\u003e by development teams who are themselves \u003ci\u003eResponsible\u003c/i\u003e and \u003ci\u003eAccountable\u003c/i\u003e for service reliability.\u003c/p\u003e\u003cp\u003eWherever your engagement model lies on the spectrum, being perceived by the rest of the organization as jointly responsible for a service's reliability, or as reliability subject-matter experts, is a key indicator of SRE-hood.\u003c/p\u003e\u003ch3\u003ePrinciple #1: SREs mitigate present and \u003ci\u003efuture\u003c/i\u003e incidents\u003c/h3\u003e\u003cp\u003eThis principle is the one that usually underlies the perception of \u003cb\u003eresponsibility and accountability\u003c/b\u003e for a service's reliability. All the careful engineering and active regulation in the world can't guarantee reliability, especially in complex distributed systems—sometimes, things go wrong unexpectedly and the only thing left to do is react, mitigate, and fix. SREs have both the authority and the technical capability to act fast to restore service in these situations.\u003c/p\u003e\u003cp\u003eBut mitigating the immediate problem isn't enough. If it can happen again tomorrow, then tomorrow isn't better than today, so SREs should work to understand the precipitating factors of incidents and propose changes that remediate the entire class of problem in the infrastructure they are responsible for. Don't have the same outage again next month!\u003c/p\u003e\u003cp\u003eHow unique are your outages? Ask yourself these questions:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eCan you mitigate the majority of the incidents without needing specialist knowledge from the development team?\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDo you maintain training materials and practice incident response scenarios?\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eAfter a major outage happens to your service, are you a key participant in blamelessly figuring out what \u003cb\u003ereally\u003c/b\u003e went wrong, and how to prevent future outages?\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eNow, for a counter example. In many organizations, SREs are a scarce resource and may add more value by developing platforms and best practices to uplift large swathes of the company, rather than being primarily focused on incident response. Thus, a consulting SRE team would probably not be directly involved in mitigating most incidents, though they may be called on to coordinate incident response for a widespread outage. Rather than authoring training materials and postmortems, they would be responsible for reviewing those created by the teams they advise.\u003c/p\u003e\u003ch3\u003ePrinciple #2: SREs actively regulate service reliability\u003c/h3\u003e\u003cp\u003e\u003cb\u003eReliability goals and feedback signals are fundamental for both motivating SRE work and influencing the prioritization of development work.\u003c/b\u003e At Google, we call our reliability goals \u003ca href=\"https://sre.google/sre-book/service-level-objectives/\" target=\"_blank\"\u003e\u003ci\u003eService Level Objectives\u003c/i\u003e\u003c/a\u003e and our feedback signals \u003ci\u003eError Budgets\u003c/i\u003e, and you can read more about how we use them in the \u003ca href=\"https://sre.google/workbook/implementing-slos/\" target=\"_blank\"\u003eSite Reliability Workbook\u003c/a\u003e.\u003c/p\u003e\u003cp\u003eDo your reliability signals affect your organization's priorities? Ask yourself these questions:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eDo you agree on goals for the reliability of the services you support with your organization, and track performance against those goals in real time?\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDo you have an established feedback loop that moderates the behaviour of the organization based on recent service reliability?\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDo you have the influence to effect change within the organization in pursuit of the reliability goals?\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDo you have the \u003ca href=\"https://en.wikipedia.org/wiki/Agency_(sociology)\" target=\"_blank\"\u003eagency\u003c/a\u003e to refuse, or negotiate looser goals, when asked to make changes that may cause a service to miss its current reliability goals?\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eEach question builds on the last. It is almost impossible to establish a data-driven feedback loop without a well-defined and measured reliability goal. For those goals to be meaningful, SREs must have the capability to defend them. Periods of lower service reliability should result in consequences that temporarily reduce the aggregate risk of future production changes and shift engineering priorities towards reliability. \u003c/p\u003e\u003cp\u003eWhen it comes down to a choice between service reliability and the rollout of new but unreliable features, SREs need to be able to say \"no\". This should be a data driven decision—when there's not enough spare error budget, there needs to be a valid business reason for making users unhappy. Sometimes, of course, there will be, and this can be accommodated with new, lower SLO targets that reflect the relaxed reliability requirements.\u003c/p\u003e\u003cp\u003eConsultant SREs, in contrast, help teams draft their reliability goals and may develop shared monitoring infrastructure for measuring them across the organization. They are the de-facto regulators of the reliability feedback loop and maintain the policy documents that underpin it. Their connection to many teams and services gives them broader insights that can spark cross-functional reliability improvements. \u003c/p\u003e\u003ch3\u003ePrinciple #3: SREs engage early and comprehensively\u003c/h3\u003e\u003cp\u003eAs we said earlier, \u003cb\u003eSREs should be empowered to make tomorrow better than today.\u003c/b\u003e Without the ability to change the code and configuration of the services they support, they cannot fix problems as they encounter them. Involving SREs earlier in the design process can head off common reliability anti-patterns that are costly to correct \u003ci\u003epost-facto\u003c/i\u003e. And, with the ability to influence architectural decision making, SREs can drive convergence across an organization so that work to increase the reliability of one service can benefit the entire company.\u003c/p\u003e\u003cp\u003eIs your team actively working to make tomorrow better than today? Ask yourself these questions, which go from fine detail to a broad, high-level scope:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eDo you engineer your service \u003cb\u003enow\u003c/b\u003e to improve its reliability, e.g. by viewing and modifying the source code and/or configuration?\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eAre you involved in analysis and design of \u003cb\u003efuture\u003c/b\u003e iterations of your service, providing a lens on reliability/operability/maintainability?\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCan you influence your \u003cb\u003eorganization’s\u003c/b\u003e wider architectural decision making?\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eAdvising other teams naturally shifts priorities away from directly modifying the configuration or code of individual services. But consultant SREs may still maintain frameworks or shared libraries providing core reliability features, like exporting common metrics or graceful service degradation. Their breadth of engagements across many teams makes them naturally suited for providing high-level architectural advice to improve reliability across an entire organization.\u003c/p\u003e\u003ch3\u003ePrinciple #4: SREs automate anything repetitive\u003c/h3\u003e\u003cp\u003eFinally, SREs believe that computers are fundamentally better suited to doing repetitive work than humans are. People often underestimate the \u003ca href=\"https://xkcd.com/1205/\" target=\"_blank\"\u003ereturns on investment\u003c/a\u003e when considering whether to automate a routine task, and that's before factoring in the exponential growth curve that comes with running a large, successful service. Moreover, computers never become inattentive and make mistakes when doing the same task for the hundredth time, or become demoralized and quit. Hiring or \u003ca href=\"https://sre.google/resources/practices-and-processes/training-site-reliability-engineers/\" target=\"_blank\"\u003etraining SREs\u003c/a\u003e is expensive and time-consuming, so a successful SRE organization depends heavily on making computers do the grunt work.\u003c/p\u003e\u003cp\u003eAre you sufficiently automating your work? Ask yourself these questions:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eDo you use—or create—automation and other tools to ensure that operational load won't scale linearly with organic growth or the number of services you support?\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDo you try to measure repetitive work on your team, and reduce it over time?\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch2\u003eA call for reflection\u003c/h2\u003e\u003cp\u003eMost blog posts end with a call for action. We'd rather you took time to reflect, instead of jumping up to make changes straight after reading. \u003cb\u003eThere's a risk, when writing an opinionated piece like this, that the lines drawn in the sand are used to divide, not to grow and improve.\u003c/b\u003e We promise this isn't a deliberate effort to gatekeep SRE and exclude those who don't tick the boxes; we see no value in that. But in some ways gatekeeping is what job roles are \u003ci\u003edesigned\u003c/i\u003e to do, because specialization and the division of labour is critical to the success of any organization, and this makes it hard to avoid drawing those lines.\u003c/p\u003e\u003cp\u003eFor those who aspire to call themselves SREs, or are concerned that others may disagree with their characterization of themselves as SREs, perhaps these opinions can assuage some of that existential dread.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps.max-2200x2200.jpg",
      "date_published": "2021-06-18T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eAlex Bramley\u003c/name\u003e\u003ctitle\u003eCustomer Reliability Engineer\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/application-development/artifact-registry-adds-node-python-and-java-repositories/",
      "title": "Node, Python and Java repositories now available in Artifact Registry",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;As a developer, you need a secure place to store all your stuff: container images of course, but also language packages that can enable code reuse across multiple applications. Today, we\u0026amp;#8217;re pleased to announce support for Node.js, Python and Java repositories for \u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry\u0026#34;\u0026gt;Artifact Registry\u0026lt;/a\u0026gt; in Preview. With today\u0026amp;#8217;s announcement, you can not only use Artifact Registry to secure and distribute container images, but also manage and secure your other software artifacts.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;At the same time, the Artifact Registry managed service provides advantages over on-premises registries. As a fully serverless platform, it scales based on demand, so you only pay for what you actually use. Enterprise security features such as VPC-SC, CMEK, and granular IAM ensure you get greater control and security features for both container and non-container artifacts. You can also connect to tools you are already using as a part of a CI/CD workflow.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Let\u0026amp;#8217;s take a closer look at the features you\u0026amp;#8217;ll find in Artifact Registry, giving you a fully-managed tool to store, manage, and secure all your artifacts.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Expanded repository formats\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;With support for new repository formats, you can streamline and get a consistent view across all your artifacts. Now, supported artifacts include:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/java\u0026#34;\u0026gt;Java\u0026lt;/a\u0026gt; packages\u0026amp;#160; (using the Maven repository format)\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/nodejs\u0026#34;\u0026gt;Node.js\u0026lt;/a\u0026gt; packages (using the npm repository format)\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/python\u0026#34;\u0026gt;Python\u0026lt;/a\u0026gt; packages (using the PyPI repository format)\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;In addition to existing container images and Helm charts (using the Docker repository format).\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Easy integration with your CI/CD toolchain\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;You can also integrate Artifact Registry, including the new repository formats, with Google Cloud\u0026amp;#8217;s build and runtime services or your existing build system. The following are just some of the use cases that are made possible by this integration:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Deployment to Google Kubernetes Engine (GKE), Cloud Run, Compute Engine and other runtime services\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;CI/CD with Cloud Build, with automatic vulnerability scanning for OCI images\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Compatibility with Jenkins, Circle CI, TeamCity and other CI tools\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Native support for \u0026lt;a href=\u0026#34;https://cloud.google.com/binary-authorization\u0026#34;\u0026gt;Binary Authorization\u0026lt;/a\u0026gt; to ensure only approved artifact images are deployed\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Storage and management of artifacts in a variety of formats\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Streamlined authentication and access control across repositories using Google Cloud IAM\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;h3\u0026gt;A more secure software supply chain\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Storing trusted artifacts in private repositories is a key part of a secure software supply chain and helps mitigate the risks associated with using artifacts directly from public repositories. With Artifact Registry, you can:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Scan container images for vulnerabilities\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Protect repositories via a security perimeter (VPC-SC support)\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Configure access control at the repository level using Cloud IAM\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Use customer managed encryption keys (CMEK) instead of the default Google-managed encryption\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Use Cloud Audit Logging to track and review repository usage\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;h3\u0026gt;Optimize your infrastructure and maintain data compliance\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Artifact Registry provides regional support, enabling you to manage and host artifacts in the regions where your deployments occur, reducing latency and cost. By implementing regional repositories, you can also comply with your local data sovereignty and security requirements.\u0026lt;/p\u0026gt;\u0026lt;h2\u0026gt;Get started today\u0026lt;/h2\u0026gt;\u0026lt;p\u0026gt;These new features are available to all Artifact Registry customers. Pricing for language packages is the same as container pricing; see the \u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/pricing\u0026#34;\u0026gt;pricing documentation\u0026lt;/a\u0026gt; for details.To get started using Node.js, Python and Java repositories, try the quickstarts in the Artifact Registry documentation.\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/nodejs\u0026#34;\u0026gt;Node.js\u0026lt;/a\u0026gt; Quickstart Guide\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/python\u0026#34;\u0026gt;Python\u0026lt;/a\u0026gt; Quickstart Guide\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/artifact-registry/docs/java\u0026#34;\u0026gt;Java\u0026lt;/a\u0026gt; Quickstart Guide\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://youtu.be/2-P4cSCk1VM\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Video Overview: using Maven in Artifact Registry\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\"\u003e\u003cp\u003eAs a developer, you need a secure place to store all your stuff: container images of course, but also language packages that can enable code reuse across multiple applications. Today, we’re pleased to announce support for Node.js, Python and Java repositories for \u003ca href=\"https://cloud.google.com/artifact-registry\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry\" track-metadata-module=\"post\"\u003eArtifact Registry\u003c/a\u003e in Preview. With today’s announcement, you can not only use Artifact Registry to secure and distribute container images, but also manage and secure your other software artifacts. \u003c/p\u003e\u003cp\u003eAt the same time, the Artifact Registry managed service provides advantages over on-premises registries. As a fully serverless platform, it scales based on demand, so you only pay for what you actually use. Enterprise security features such as VPC-SC, CMEK, and granular IAM ensure you get greater control and security features for both container and non-container artifacts. You can also connect to tools you are already using as a part of a CI/CD workflow. \u003c/p\u003e\u003cp\u003eLet’s take a closer look at the features you’ll find in Artifact Registry, giving you a fully-managed tool to store, manage, and secure all your artifacts. \u003c/p\u003e\u003ch3\u003eExpanded repository formats\u003c/h3\u003e\u003cp\u003eWith support for new repository formats, you can streamline and get a consistent view across all your artifacts. Now, supported artifacts include:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/java\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/java\" track-metadata-module=\"post\"\u003eJava\u003c/a\u003e packages  (using the Maven repository format)\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/nodejs\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/nodejs\" track-metadata-module=\"post\"\u003eNode.js\u003c/a\u003e packages (using the npm repository format)\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/python\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/python\" track-metadata-module=\"post\"\u003ePython\u003c/a\u003e packages (using the PyPI repository format)\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eIn addition to existing container images and Helm charts (using the Docker repository format). \u003c/p\u003e\u003ch3\u003eEasy integration with your CI/CD toolchain\u003c/h3\u003e\u003cp\u003eYou can also integrate Artifact Registry, including the new repository formats, with Google Cloud’s build and runtime services or your existing build system. The following are just some of the use cases that are made possible by this integration:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eDeployment to Google Kubernetes Engine (GKE), Cloud Run, Compute Engine and other runtime services \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCI/CD with Cloud Build, with automatic vulnerability scanning for OCI images \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCompatibility with Jenkins, Circle CI, TeamCity and other CI tools \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eNative support for \u003ca href=\"https://cloud.google.com/binary-authorization\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/binary-authorization\" track-metadata-module=\"post\"\u003eBinary Authorization\u003c/a\u003e to ensure only approved artifact images are deployed\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eStorage and management of artifacts in a variety of formats\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eStreamlined authentication and access control across repositories using Google Cloud IAM\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eA more secure software supply chain\u003c/h3\u003e\u003cp\u003eStoring trusted artifacts in private repositories is a key part of a secure software supply chain and helps mitigate the risks associated with using artifacts directly from public repositories. With Artifact Registry, you can:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eScan container images for vulnerabilities\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eProtect repositories via a security perimeter (VPC-SC support)\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eConfigure access control at the repository level using Cloud IAM\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eUse customer managed encryption keys (CMEK) instead of the default Google-managed encryption\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eUse Cloud Audit Logging to track and review repository usage\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eOptimize your infrastructure and maintain data compliance\u003c/h3\u003e\u003cp\u003eArtifact Registry provides regional support, enabling you to manage and host artifacts in the regions where your deployments occur, reducing latency and cost. By implementing regional repositories, you can also comply with your local data sovereignty and security requirements.\u003c/p\u003e\u003ch2\u003eGet started today\u003c/h2\u003e\u003cp\u003eThese new features are available to all Artifact Registry customers. Pricing for language packages is the same as container pricing; see the \u003ca href=\"https://cloud.google.com/artifact-registry/pricing\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/pricing\" track-metadata-module=\"post\"\u003epricing documentation\u003c/a\u003e for details.To get started using Node.js, Python and Java repositories, try the quickstarts in the Artifact Registry documentation.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/nodejs\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/nodejs\" track-metadata-module=\"post\"\u003eNode.js\u003c/a\u003e Quickstart Guide\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/python\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/python\" track-metadata-module=\"post\"\u003ePython\u003c/a\u003e Quickstart Guide\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/java\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/artifact-registry/docs/java\" track-metadata-module=\"post\"\u003eJava\u003c/a\u003e Quickstart Guide\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://youtu.be/2-P4cSCk1VM\" target=\"_blank\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://youtu.be\" track-metadata-module=\"post\"\u003eVideo Overview: using Maven in Artifact Registry\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eAs a developer, you need a secure place to store all your stuff: container images of course, but also language packages that can enable code reuse across multiple applications. Today, we’re pleased to announce support for Node.js, Python and Java repositories for \u003ca href=\"https://cloud.google.com/artifact-registry\"\u003eArtifact Registry\u003c/a\u003e in Preview. With today’s announcement, you can not only use Artifact Registry to secure and distribute container images, but also manage and secure your other software artifacts. \u003c/p\u003e\u003cp\u003eAt the same time, the Artifact Registry managed service provides advantages over on-premises registries. As a fully serverless platform, it scales based on demand, so you only pay for what you actually use. Enterprise security features such as VPC-SC, CMEK, and granular IAM ensure you get greater control and security features for both container and non-container artifacts. You can also connect to tools you are already using as a part of a CI/CD workflow. \u003c/p\u003e\u003cp\u003eLet’s take a closer look at the features you’ll find in Artifact Registry, giving you a fully-managed tool to store, manage, and secure all your artifacts. \u003c/p\u003e\u003ch3\u003eExpanded repository formats\u003c/h3\u003e\u003cp\u003eWith support for new repository formats, you can streamline and get a consistent view across all your artifacts. Now, supported artifacts include:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/java\"\u003eJava\u003c/a\u003e packages  (using the Maven repository format)\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/nodejs\"\u003eNode.js\u003c/a\u003e packages (using the npm repository format)\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/python\"\u003ePython\u003c/a\u003e packages (using the PyPI repository format)\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eIn addition to existing container images and Helm charts (using the Docker repository format). \u003c/p\u003e\u003ch3\u003eEasy integration with your CI/CD toolchain\u003c/h3\u003e\u003cp\u003eYou can also integrate Artifact Registry, including the new repository formats, with Google Cloud’s build and runtime services or your existing build system. The following are just some of the use cases that are made possible by this integration:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eDeployment to Google Kubernetes Engine (GKE), Cloud Run, Compute Engine and other runtime services \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCI/CD with Cloud Build, with automatic vulnerability scanning for OCI images \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCompatibility with Jenkins, Circle CI, TeamCity and other CI tools \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eNative support for \u003ca href=\"https://cloud.google.com/binary-authorization\"\u003eBinary Authorization\u003c/a\u003e to ensure only approved artifact images are deployed\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eStorage and management of artifacts in a variety of formats\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eStreamlined authentication and access control across repositories using Google Cloud IAM\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eA more secure software supply chain\u003c/h3\u003e\u003cp\u003eStoring trusted artifacts in private repositories is a key part of a secure software supply chain and helps mitigate the risks associated with using artifacts directly from public repositories. With Artifact Registry, you can:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eScan container images for vulnerabilities\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eProtect repositories via a security perimeter (VPC-SC support)\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eConfigure access control at the repository level using Cloud IAM\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eUse customer managed encryption keys (CMEK) instead of the default Google-managed encryption\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eUse Cloud Audit Logging to track and review repository usage\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eOptimize your infrastructure and maintain data compliance\u003c/h3\u003e\u003cp\u003eArtifact Registry provides regional support, enabling you to manage and host artifacts in the regions where your deployments occur, reducing latency and cost. By implementing regional repositories, you can also comply with your local data sovereignty and security requirements.\u003c/p\u003e\u003ch2\u003eGet started today\u003c/h2\u003e\u003cp\u003eThese new features are available to all Artifact Registry customers. Pricing for language packages is the same as container pricing; see the \u003ca href=\"https://cloud.google.com/artifact-registry/pricing\"\u003epricing documentation\u003c/a\u003e for details.To get started using Node.js, Python and Java repositories, try the quickstarts in the Artifact Registry documentation.\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/nodejs\"\u003eNode.js\u003c/a\u003e Quickstart Guide\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/python\"\u003ePython\u003c/a\u003e Quickstart Guide\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/artifact-registry/docs/java\"\u003eJava\u003c/a\u003e Quickstart Guide\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://youtu.be/2-P4cSCk1VM\" target=\"_blank\"\u003eVideo Overview: using Maven in Artifact Registry\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/identity-security/how-were-helping-reshape-software-supply-chain-ecosystem-securely/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Security_BlogHeader_B_epmyJP1.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eHow we’re helping to reshape the software supply chain ecosystem securely\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eWe’re sharing some of the security best practices we employ and investments we make in secure software development and supply chain risk ...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Artifact_Registry_ubFsgrO.max-2200x2200.jpg",
      "date_published": "2021-06-07T16:30:00Z",
      "author": {
        "name": "\u003cname\u003ePatrick Faucher\u003c/name\u003e\u003ctitle\u003eSenior Product Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/how-lowes-leverages-google-sre-practices/",
      "title": "How Lowe’s meets customer demand with Google SRE practices",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;\u0026lt;b\u0026gt;Editor\u0026amp;#8217;s note:\u0026lt;/b\u0026gt; Today we hear from the Lowe\u0026amp;#8217;s SRE team. They share about how they have been able to increase the number of releases they can support by adopting Google\u0026amp;#8217;s \u0026lt;a href=\u0026#34;https://sre.google/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Site Reliability Engineering\u0026lt;/a\u0026gt; (SRE) framework and leveraging their partnership with Google Cloud.\u0026amp;#160;\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;hr\u0026gt;\u0026lt;p\u0026gt;At Lowe\u0026amp;#8217;s, we\u0026amp;#8217;ve made significant progress in our multiyear technology transformation. To modernize our systems and build new capabilities for our customers and associates, we leverage Google\u0026amp;#8217;s SRE framework and Google Cloud, which helps us meet their needs faster and more effectively. With these efforts, we\u0026amp;#8217;ve been able to go from one release every two weeks to 20+ releases daily\u0026amp;#8212;a 300x increase.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Our SRE transformation didn\u0026amp;#8217;t happen overnight, though. Every step along the way brought some challenges. But looking back, we are excited to see how much we have accomplished for our customers as a result.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Back in 2018, before adopting SRE practices, we were more reactive than proactive, following an \u0026amp;#8220;eyes on glass\u0026amp;#8221; approach. On-call structures and incident management efficiency were not at optimal levels with too many repetitive and manual tasks, resulting in operational toil. Production concerns were not surfaced into the product roadmap, which resulted in delays in making fixes.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Bootstrapping SRE at Lowe\u0026amp;#8217;s\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;As we moved from on-prem to \u0026lt;a href=\u0026#34;https://cloud.google.com/\u0026#34;\u0026gt;Google Cloud\u0026lt;/a\u0026gt;, we decided to move from a monolithic- to microservices-based architecture. And to better manage this new architecture, we embarked on an SRE journey.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Then as COVID-19 hit, we really had to accelerate this journey as customers increasingly moved to online ordering and delivery to meet their Total Home Improvement needs. To do so, we followed four key principles that allowed us to meet changing customer needs quickly and release fast and reliably.\u0026lt;/p\u0026gt;\u0026lt;ol\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Automate away toil\u0026amp;#160;\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;As we moved from traditional Ops to an SRE ecosystem, our biggest opportunity was \u0026lt;a href=\u0026#34;https://sre.google/sre-book/eliminating-toil/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;reducing toil\u0026lt;/a\u0026gt;, so that engineers can spend time on activities that drive business impact and customer outcomes. We think of toil as work that is manual, repetitive,\u0026amp;#160; tactical, devoid of enduring value\u0026amp;#8212;but automatable. So, to tackle toil, we focused on automating away the need for manual intervention. As an example, we made sure engineers were not the first point of contact for any alert. Any triage or resolution that an engineer can perform, a machine can be trained to do the same. We used supervised and unsupervised learning techniques to automate our toil. With a long-term goal of \u0026amp;#8220;no toil,\u0026amp;#8221; our SREs work on identifying and reducing toil to a manageable level across the organization.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Engineer alignment through roadmaps\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;Our goal is to maximize the engineering velocity of developer teams while keeping products reliable. We want an engagement model where product, SRE and development teams are closely aligned. A key way we\u0026amp;#8217;ve been able to create this alignment is by having our SREs embedded into domain and product teams. Each domain has an SRE, who is\u0026amp;#160; involved at the beginning stages of product development to ensure that the domain stakeholders are in alignment with the SRE initiatives. As such, SREs are able to improve the reliability, performance, scalability and launch velocity of the services throughout all phases of the service lifecycle.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Adopt one-touch releases\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;Our path to production used to contain many manual steps and validations, slowing the rate at which we released features. Additionally, we used to bulk all our releases together to deploy at once, which increased the risk of failure and created a longer feedback loop from production. To tackle this with an SRE mindset, we created a one-touch release process in which SREs review the product team\u0026amp;#8217;s pull requests. When approved, this triggers a DevSecOps pipeline that deploys the approved changes to production securely. This process created a safe, reliable and sustainable continuous delivery pipeline with quick feedback loops. Striking the right balance between speed, innovation and stability, we were able to increase our releases exponentially for the year, taking less than 30 minutes per release to deliver quality code, including various automated quality checks and processes, all in just one click.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Embrace capacity planning\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;To ensure our services have enough spare capacity to handle any surge in traffic patterns, our SREs emphasize capacity planning, making recommended capacity changes in the continuous delivery (CD) pipeline. They constantly \u0026lt;a href=\u0026#34;https://cloud.google.com/monitoring\u0026#34;\u0026gt;monitor performance\u0026lt;/a\u0026gt; to make sure the service is robust, stable and available. And when there\u0026amp;#8217;s a sudden surge beyond the forecasted volume, SREs change the capacity on demand and document changes for the performance and domain teams.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ol\u0026gt;\u0026lt;p\u0026gt;Capacity planning is especially important for us during peak holiday times such as Black Friday and Cyber Monday (BFCM). We lay out our SRE stability plan three months in advance and surface into the domain team\u0026amp;#8217;s product roadmap. This way development teams are able to allocate sufficient engineering time to reliability. We do performance testing to ensure the environment is able to sustain increased load over long periods of time and also handle sudden surges in traffic. We also do region failover testing at a global scale to validate the automatic failover duration of service level agreements\u0026amp;#160; (SLAs), SRE and domain readiness. Additionally, we conduct Black Friday and Cyber Monday-specific destructive testing to validate customer experience, reliability and more.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Google Cloud\u0026amp;#8217;s Black Friday and Cyber Monday \u0026lt;a href=\u0026#34;https://cloud.google.com/solutions/retail\u0026#34;\u0026gt;white-glove service\u0026lt;/a\u0026gt; played a key role in ensuring our success in both BFCM 2019 and BFCM 2020. This service included on-site visits from Google\u0026amp;#8217;s Customer Reliability Engineering (CRE) team who reviewed Lowe\u0026amp;#8217;s web architecture, capacity planning, operations practices for event risks, and presented workshops on topics such as incident response best practices.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Looking ahead\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;There is always room for improvement, and at Lowe\u0026amp;#8217;s we aim to continuously improve our SRE practices. One thing that has worked well for us, which we plan to continue, has been our road shows, where senior SRE leads present to other SREs and application domain teams on the latest SRE principles and best practices, and to get input in real-time from them.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/products/operations\u0026#34;\u0026gt;Google\u0026amp;#8217;s tools\u0026lt;/a\u0026gt; and methodology have played an instrumental role in helping reshape our SRE practices and better serve our customers. We look forward to building on the momentum and partnership as we continue our SRE journey at Lowe\u0026amp;#8217;s.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;If you want to learn more about how to adopt SRE best practices on Google Cloud, \u0026lt;a href=\u0026#34;https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring\u0026#34;\u0026gt;check out our documentation\u0026lt;/a\u0026gt;. If you want to learn more about Google SRE, \u0026lt;a href=\u0026#34;https://sre.google/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;visit our website\u0026lt;/a\u0026gt;. Stay tuned for the next blogs with Lowe\u0026amp;#8217;s discussing how they trained their engineering talent to adopt SRE practices and tooling, and how they improved MTTR using SRE principles.\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e\u003ci\u003e\u003cb\u003eEditor’s note:\u003c/b\u003e Today we hear from the Lowe’s SRE team. They share about how they have been able to increase the number of releases they can support by adopting Google’s \u003ca href=\"https://sre.google/\" target=\"_blank\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003eSite Reliability Engineering\u003c/a\u003e (SRE) framework and leveraging their partnership with Google Cloud. \u003c/i\u003e\u003c/p\u003e\u003chr/\u003e\u003cp\u003eAt Lowe’s, we’ve made significant progress in our multiyear technology transformation. To modernize our systems and build new capabilities for our customers and associates, we leverage Google’s SRE framework and Google Cloud, which helps us meet their needs faster and more effectively. With these efforts, we’ve been able to go from one release every two weeks to 20+ releases daily—a 300x increase. \u003c/p\u003e\u003cp\u003eOur SRE transformation didn’t happen overnight, though. Every step along the way brought some challenges. But looking back, we are excited to see how much we have accomplished for our customers as a result. \u003c/p\u003e\u003cp\u003eBack in 2018, before adopting SRE practices, we were more reactive than proactive, following an “eyes on glass” approach. On-call structures and incident management efficiency were not at optimal levels with too many repetitive and manual tasks, resulting in operational toil. Production concerns were not surfaced into the product roadmap, which resulted in delays in making fixes.\u003c/p\u003e\u003ch3\u003eBootstrapping SRE at Lowe’s\u003c/h3\u003e\u003cp\u003eAs we moved from on-prem to \u003ca href=\"https://cloud.google.com/\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/\" track-metadata-module=\"post\"\u003eGoogle Cloud\u003c/a\u003e, we decided to move from a monolithic- to microservices-based architecture. And to better manage this new architecture, we embarked on an SRE journey. \u003c/p\u003e\u003cp\u003eThen as COVID-19 hit, we really had to accelerate this journey as customers increasingly moved to online ordering and delivery to meet their Total Home Improvement needs. To do so, we followed four key principles that allowed us to meet changing customer needs quickly and release fast and reliably.\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eAutomate away toil \u003cbr/\u003e\u003c/b\u003eAs we moved from traditional Ops to an SRE ecosystem, our biggest opportunity was \u003ca href=\"https://sre.google/sre-book/eliminating-toil/\" target=\"_blank\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003ereducing toil\u003c/a\u003e, so that engineers can spend time on activities that drive business impact and customer outcomes. We think of toil as work that is manual, repetitive,  tactical, devoid of enduring value—but automatable. So, to tackle toil, we focused on automating away the need for manual intervention. As an example, we made sure engineers were not the first point of contact for any alert. Any triage or resolution that an engineer can perform, a machine can be trained to do the same. We used supervised and unsupervised learning techniques to automate our toil. With a long-term goal of “no toil,” our SREs work on identifying and reducing toil to a manageable level across the organization.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eEngineer alignment through roadmaps\u003cbr/\u003e\u003c/b\u003eOur goal is to maximize the engineering velocity of developer teams while keeping products reliable. We want an engagement model where product, SRE and development teams are closely aligned. A key way we’ve been able to create this alignment is by having our SREs embedded into domain and product teams. Each domain has an SRE, who is  involved at the beginning stages of product development to ensure that the domain stakeholders are in alignment with the SRE initiatives. As such, SREs are able to improve the reliability, performance, scalability and launch velocity of the services throughout all phases of the service lifecycle. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eAdopt one-touch releases\u003cbr/\u003e\u003c/b\u003eOur path to production used to contain many manual steps and validations, slowing the rate at which we released features. Additionally, we used to bulk all our releases together to deploy at once, which increased the risk of failure and created a longer feedback loop from production. To tackle this with an SRE mindset, we created a one-touch release process in which SREs review the product team’s pull requests. When approved, this triggers a DevSecOps pipeline that deploys the approved changes to production securely. This process created a safe, reliable and sustainable continuous delivery pipeline with quick feedback loops. Striking the right balance between speed, innovation and stability, we were able to increase our releases exponentially for the year, taking less than 30 minutes per release to deliver quality code, including various automated quality checks and processes, all in just one click. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eEmbrace capacity planning\u003cbr/\u003e\u003c/b\u003eTo ensure our services have enough spare capacity to handle any surge in traffic patterns, our SREs emphasize capacity planning, making recommended capacity changes in the continuous delivery (CD) pipeline. They constantly \u003ca href=\"https://cloud.google.com/monitoring\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/monitoring\" track-metadata-module=\"post\"\u003emonitor performance\u003c/a\u003e to make sure the service is robust, stable and available. And when there’s a sudden surge beyond the forecasted volume, SREs change the capacity on demand and document changes for the performance and domain teams. \u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eCapacity planning is especially important for us during peak holiday times such as Black Friday and Cyber Monday (BFCM). We lay out our SRE stability plan three months in advance and surface into the domain team’s product roadmap. This way development teams are able to allocate sufficient engineering time to reliability. We do performance testing to ensure the environment is able to sustain increased load over long periods of time and also handle sudden surges in traffic. We also do region failover testing at a global scale to validate the automatic failover duration of service level agreements  (SLAs), SRE and domain readiness. Additionally, we conduct Black Friday and Cyber Monday-specific destructive testing to validate customer experience, reliability and more.\u003c/p\u003e\u003cp\u003eGoogle Cloud’s Black Friday and Cyber Monday \u003ca href=\"https://cloud.google.com/solutions/retail\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/solutions/retail\" track-metadata-module=\"post\"\u003ewhite-glove service\u003c/a\u003e played a key role in ensuring our success in both BFCM 2019 and BFCM 2020. This service included on-site visits from Google’s Customer Reliability Engineering (CRE) team who reviewed Lowe’s web architecture, capacity planning, operations practices for event risks, and presented workshops on topics such as incident response best practices. \u003c/p\u003e\u003ch3\u003eLooking ahead\u003c/h3\u003e\u003cp\u003eThere is always room for improvement, and at Lowe’s we aim to continuously improve our SRE practices. One thing that has worked well for us, which we plan to continue, has been our road shows, where senior SRE leads present to other SREs and application domain teams on the latest SRE principles and best practices, and to get input in real-time from them. \u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/products/operations\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/products/operations\" track-metadata-module=\"post\"\u003eGoogle’s tools\u003c/a\u003e and methodology have played an instrumental role in helping reshape our SRE practices and better serve our customers. We look forward to building on the momentum and partnership as we continue our SRE journey at Lowe’s. \u003c/p\u003e\u003cp\u003e\u003ci\u003eIf you want to learn more about how to adopt SRE best practices on Google Cloud, \u003ca href=\"https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring\" track-metadata-module=\"post\"\u003echeck out our documentation\u003c/a\u003e. If you want to learn more about Google SRE, \u003ca href=\"https://sre.google/\" target=\"_blank\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003evisit our website\u003c/a\u003e. Stay tuned for the next blogs with Lowe’s discussing how they trained their engineering talent to adopt SRE practices and tooling, and how they improved MTTR using SRE principles.\u003c/i\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003ci\u003e\u003cb\u003eEditor’s note:\u003c/b\u003e Today we hear from the Lowe’s SRE team. They share about how they have been able to increase the number of releases they can support by adopting Google’s \u003ca href=\"https://sre.google/\" target=\"_blank\"\u003eSite Reliability Engineering\u003c/a\u003e (SRE) framework and leveraging their partnership with Google Cloud. \u003c/i\u003e\u003c/p\u003e\u003chr/\u003e\u003cp\u003eAt Lowe’s, we’ve made significant progress in our multiyear technology transformation. To modernize our systems and build new capabilities for our customers and associates, we leverage Google’s SRE framework and Google Cloud, which helps us meet their needs faster and more effectively. With these efforts, we’ve been able to go from one release every two weeks to 20+ releases daily—a 300x increase. \u003c/p\u003e\u003cp\u003eOur SRE transformation didn’t happen overnight, though. Every step along the way brought some challenges. But looking back, we are excited to see how much we have accomplished for our customers as a result. \u003c/p\u003e\u003cp\u003eBack in 2018, before adopting SRE practices, we were more reactive than proactive, following an “eyes on glass” approach. On-call structures and incident management efficiency were not at optimal levels with too many repetitive and manual tasks, resulting in operational toil. Production concerns were not surfaced into the product roadmap, which resulted in delays in making fixes.\u003c/p\u003e\u003ch3\u003eBootstrapping SRE at Lowe’s\u003c/h3\u003e\u003cp\u003eAs we moved from on-prem to \u003ca href=\"https://cloud.google.com/\"\u003eGoogle Cloud\u003c/a\u003e, we decided to move from a monolithic- to microservices-based architecture. And to better manage this new architecture, we embarked on an SRE journey. \u003c/p\u003e\u003cp\u003eThen as COVID-19 hit, we really had to accelerate this journey as customers increasingly moved to online ordering and delivery to meet their Total Home Improvement needs. To do so, we followed four key principles that allowed us to meet changing customer needs quickly and release fast and reliably.\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eAutomate away toil \u003cbr/\u003e\u003c/b\u003eAs we moved from traditional Ops to an SRE ecosystem, our biggest opportunity was \u003ca href=\"https://sre.google/sre-book/eliminating-toil/\" target=\"_blank\"\u003ereducing toil\u003c/a\u003e, so that engineers can spend time on activities that drive business impact and customer outcomes. We think of toil as work that is manual, repetitive,  tactical, devoid of enduring value—but automatable. So, to tackle toil, we focused on automating away the need for manual intervention. As an example, we made sure engineers were not the first point of contact for any alert. Any triage or resolution that an engineer can perform, a machine can be trained to do the same. We used supervised and unsupervised learning techniques to automate our toil. With a long-term goal of “no toil,” our SREs work on identifying and reducing toil to a manageable level across the organization.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eEngineer alignment through roadmaps\u003cbr/\u003e\u003c/b\u003eOur goal is to maximize the engineering velocity of developer teams while keeping products reliable. We want an engagement model where product, SRE and development teams are closely aligned. A key way we’ve been able to create this alignment is by having our SREs embedded into domain and product teams. Each domain has an SRE, who is  involved at the beginning stages of product development to ensure that the domain stakeholders are in alignment with the SRE initiatives. As such, SREs are able to improve the reliability, performance, scalability and launch velocity of the services throughout all phases of the service lifecycle. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eAdopt one-touch releases\u003cbr/\u003e\u003c/b\u003eOur path to production used to contain many manual steps and validations, slowing the rate at which we released features. Additionally, we used to bulk all our releases together to deploy at once, which increased the risk of failure and created a longer feedback loop from production. To tackle this with an SRE mindset, we created a one-touch release process in which SREs review the product team’s pull requests. When approved, this triggers a DevSecOps pipeline that deploys the approved changes to production securely. This process created a safe, reliable and sustainable continuous delivery pipeline with quick feedback loops. Striking the right balance between speed, innovation and stability, we were able to increase our releases exponentially for the year, taking less than 30 minutes per release to deliver quality code, including various automated quality checks and processes, all in just one click. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eEmbrace capacity planning\u003cbr/\u003e\u003c/b\u003eTo ensure our services have enough spare capacity to handle any surge in traffic patterns, our SREs emphasize capacity planning, making recommended capacity changes in the continuous delivery (CD) pipeline. They constantly \u003ca href=\"https://cloud.google.com/monitoring\"\u003emonitor performance\u003c/a\u003e to make sure the service is robust, stable and available. And when there’s a sudden surge beyond the forecasted volume, SREs change the capacity on demand and document changes for the performance and domain teams. \u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eCapacity planning is especially important for us during peak holiday times such as Black Friday and Cyber Monday (BFCM). We lay out our SRE stability plan three months in advance and surface into the domain team’s product roadmap. This way development teams are able to allocate sufficient engineering time to reliability. We do performance testing to ensure the environment is able to sustain increased load over long periods of time and also handle sudden surges in traffic. We also do region failover testing at a global scale to validate the automatic failover duration of service level agreements  (SLAs), SRE and domain readiness. Additionally, we conduct Black Friday and Cyber Monday-specific destructive testing to validate customer experience, reliability and more.\u003c/p\u003e\u003cp\u003eGoogle Cloud’s Black Friday and Cyber Monday \u003ca href=\"https://cloud.google.com/solutions/retail\"\u003ewhite-glove service\u003c/a\u003e played a key role in ensuring our success in both BFCM 2019 and BFCM 2020. This service included on-site visits from Google’s Customer Reliability Engineering (CRE) team who reviewed Lowe’s web architecture, capacity planning, operations practices for event risks, and presented workshops on topics such as incident response best practices. \u003c/p\u003e\u003ch3\u003eLooking ahead\u003c/h3\u003e\u003cp\u003eThere is always room for improvement, and at Lowe’s we aim to continuously improve our SRE practices. One thing that has worked well for us, which we plan to continue, has been our road shows, where senior SRE leads present to other SREs and application domain teams on the latest SRE principles and best practices, and to get input in real-time from them. \u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/products/operations\"\u003eGoogle’s tools\u003c/a\u003e and methodology have played an instrumental role in helping reshape our SRE practices and better serve our customers. We look forward to building on the momentum and partnership as we continue our SRE journey at Lowe’s. \u003c/p\u003e\u003cp\u003e\u003ci\u003eIf you want to learn more about how to adopt SRE best practices on Google Cloud, \u003ca href=\"https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring\"\u003echeck out our documentation\u003c/a\u003e. If you want to learn more about Google SRE, \u003ca href=\"https://sre.google/\" target=\"_blank\"\u003evisit our website\u003c/a\u003e. Stay tuned for the next blogs with Lowe’s discussing how they trained their engineering talent to adopt SRE practices and tooling, and how they improved MTTR using SRE principles.\u003c/i\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/four-steps-to-jumpstarting-your-sre-practice/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_B_Rnd3.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eFour steps to jumpstarting your SRE practice\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eOnce you have leadership buy-in, there are some things you can do to get the SRE ball rolling, fast.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/devops.max-2200x2200.jpg",
      "date_published": "2021-06-07T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eRahul Mohan Kola Kandy\u003c/name\u003e\u003ctitle\u003eSr. Manager, Digital SRE, Lowe’s Companies, Inc.\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/application-development/forgerock-developers-stay-productive-with-google-cloud/",
      "title": "DevOps on Google Cloud: tools to speed up software development velocity",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;\u0026lt;b\u0026gt;Editor\u0026amp;#8217;s note\u0026lt;/b\u0026gt;: Today we hear from \u0026lt;a href=\u0026#34;https://www.forgerock.com/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;ForgeRock\u0026lt;/a\u0026gt;, a multinational \u0026lt;a href=\u0026#34;https://en.wikipedia.org/wiki/Identity_and_access_management\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;identity and access management\u0026lt;/a\u0026gt; software company with more than 1,100 enterprise customers, including a major public broadcaster. In total, customers use the ForgeRock Identity Platform to authenticate and log in over 45 million users daily, helping them manage identity, governance, and access management across all platforms, including on-premises and multicloud environments.\u0026amp;#160;\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;Operating at that kind of scale isn\u0026amp;#8217;t easy. In this blog post, ForgeRock Engineering Director, Warren Strange discusses the three things that help make their developers efficient and productive, and the Google Cloud tools they use along the way.\u0026amp;#160;\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;hr\u0026gt;\u0026lt;p\u0026gt;At ForgeRock, we\u0026amp;#8217;ve been an early adopter of Kubernetes, viewing it as a strategic platform. Running on Kubernetes allows us to drive multicloud support across \u0026lt;a href=\u0026#34;https://cloud.google.com/kubernetes-engine\u0026#34;\u0026gt;Google Kubernetes Engine\u0026lt;/a\u0026gt; (GKE), Amazon (EKS), and Azure (AKS). So no matter which cloud our customers are running on, we are able to seamlessly integrate our products into customers\u0026#39; environments.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Making it easier for ForgeRock\u0026#39;s developers and operators to build, deploy and manage applications has been crucial in our ability to continually provide high quality solutions for our customers. We\u0026amp;#8217;re always looking for tools to improve productivity and keep our developers focused on coding instead of configuration. Google Cloud\u0026amp;#8217;s suite of DevOps tools have streamlined three specific practices to help keep our developers productive:\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;1. Make developers productive within IDEs\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Developer productivity is core to the success of any organization, including ForgeRock. Since developers spend most of their time within their IDE of choice, our goal at ForgeRock has been to make it easier for our developers to write Kubernetes applications within the IDEs they know and love. \u0026lt;a href=\u0026#34;https://cloud.google.com/code\u0026#34;\u0026gt;Cloud Code\u0026lt;/a\u0026gt; helps us precisely with that: it makes the process of building, deploying, scaling, and managing Kubernetes infrastructure and applications a breeze.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In particular, working with the Kubernetes YAML syntax and schema takes time, and a lot of trial and error to master. Thanks to \u0026lt;a href=\u0026#34;https://cloud.google.com/code/docs/vscode/yaml-editing\u0026#34;\u0026gt;YAML authoring support\u0026lt;/a\u0026gt; within Cloud Code, we can easily avoid the complicated and time consuming task of writing YAML files at ForgeRock. With YAML authoring support, developers save time on every bug. Cloud Code\u0026amp;#8217;s inline\u0026amp;#160; snippets, completions, and schema validation, a.k.a. \u0026amp;#8220;linting,\u0026amp;#8221; further streamline working with YAML files.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The benefits of Cloud Code extend to local development as well. Iterating locally on Kubernetes applications often requires multiple manual steps, including building container images, updating Kubernetes manifests, and redeploying applications. Doing these steps over and over again can be a chore. Cloud Code \u0026lt;a href=\u0026#34;https://cloud.google.com/code/docs/intellij/deploying-a-k8-app\u0026#34;\u0026gt;supports Skaffold under the hood,\u0026lt;/a\u0026gt; which tracks changes as they come and automatically rebuilds and redeploys\u0026amp;#8212;reducing repetitive development tasks.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Finally, developing for Kubernetes usually involves jumping between the IDE, documentation, samples etc. Cloud Code reduces this context switching with Kubernetes \u0026lt;a href=\u0026#34;https://github.com/GoogleCloudPlatform/cloud-code-samples\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;code samples\u0026lt;/a\u0026gt;. With samples, we can get new developers up and running quickly. They spend less time learning about configuration and management of the application\u0026amp;#8212;and spend more time on writing and evolving the code.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;2. Drive end-to-end automation\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;To further improve developer productivity, we\u0026amp;#8217;ve focused on end-to-end automation: from writing code within IDEs, to automatically triggering CI/CD pipelines and running the code in production. In particular, \u0026lt;a href=\u0026#34;https://cloud.google.com/tekton\u0026#34;\u0026gt;Tekton\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/cloud-build\u0026#34;\u0026gt;Cloud Build\u0026lt;/a\u0026gt;, \u0026lt;a href=\u0026#34;https://cloud.google.com/container-registry\u0026#34;\u0026gt;Container Registry,\u0026lt;/a\u0026gt; and GKE have been critical to Forgerock as we streamline the flow of code, feedback and remediation through the build and deployment processes. The process looks something like this:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e\u003ci\u003e\u003cb\u003eEditor’s note\u003c/b\u003e: Today we hear from \u003ca href=\"https://www.forgerock.com/\" target=\"_blank\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://www.forgerock.com\" track-metadata-module=\"post\"\u003eForgeRock\u003c/a\u003e, a multinational \u003ca href=\"https://en.wikipedia.org/wiki/Identity_and_access_management\" target=\"_blank\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://en.wikipedia.org\" track-metadata-module=\"post\"\u003eidentity and access management\u003c/a\u003e software company with more than 1,100 enterprise customers, including a major public broadcaster. In total, customers use the ForgeRock Identity Platform to authenticate and log in over 45 million users daily, helping them manage identity, governance, and access management across all platforms, including on-premises and multicloud environments. \u003c/i\u003e\u003c/p\u003e\u003cp\u003e\u003ci\u003eOperating at that kind of scale isn’t easy. In this blog post, ForgeRock Engineering Director, Warren Strange discusses the three things that help make their developers efficient and productive, and the Google Cloud tools they use along the way. \u003c/i\u003e\u003c/p\u003e\u003chr/\u003e\u003cp\u003eAt ForgeRock, we’ve been an early adopter of Kubernetes, viewing it as a strategic platform. Running on Kubernetes allows us to drive multicloud support across \u003ca href=\"https://cloud.google.com/kubernetes-engine\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/kubernetes-engine\" track-metadata-module=\"post\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE), Amazon (EKS), and Azure (AKS). So no matter which cloud our customers are running on, we are able to seamlessly integrate our products into customers\u0026#39; environments. \u003c/p\u003e\u003cp\u003eMaking it easier for ForgeRock\u0026#39;s developers and operators to build, deploy and manage applications has been crucial in our ability to continually provide high quality solutions for our customers. We’re always looking for tools to improve productivity and keep our developers focused on coding instead of configuration. Google Cloud’s suite of DevOps tools have streamlined three specific practices to help keep our developers productive: \u003c/p\u003e\u003ch3\u003e1. Make developers productive within IDEs\u003c/h3\u003e\u003cp\u003eDeveloper productivity is core to the success of any organization, including ForgeRock. Since developers spend most of their time within their IDE of choice, our goal at ForgeRock has been to make it easier for our developers to write Kubernetes applications within the IDEs they know and love. \u003ca href=\"https://cloud.google.com/code\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/code\" track-metadata-module=\"post\"\u003eCloud Code\u003c/a\u003e helps us precisely with that: it makes the process of building, deploying, scaling, and managing Kubernetes infrastructure and applications a breeze. \u003c/p\u003e\u003cp\u003eIn particular, working with the Kubernetes YAML syntax and schema takes time, and a lot of trial and error to master. Thanks to \u003ca href=\"https://cloud.google.com/code/docs/vscode/yaml-editing\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/code/docs/vscode/yaml-editing\" track-metadata-module=\"post\"\u003eYAML authoring support\u003c/a\u003e within Cloud Code, we can easily avoid the complicated and time consuming task of writing YAML files at ForgeRock. With YAML authoring support, developers save time on every bug. Cloud Code’s inline  snippets, completions, and schema validation, a.k.a. “linting,” further streamline working with YAML files. \u003c/p\u003e\u003cp\u003eThe benefits of Cloud Code extend to local development as well. Iterating locally on Kubernetes applications often requires multiple manual steps, including building container images, updating Kubernetes manifests, and redeploying applications. Doing these steps over and over again can be a chore. Cloud Code \u003ca href=\"https://cloud.google.com/code/docs/intellij/deploying-a-k8-app\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/code/docs/intellij/deploying-a-k8-app\" track-metadata-module=\"post\"\u003esupports Skaffold under the hood,\u003c/a\u003e which tracks changes as they come and automatically rebuilds and redeploys—reducing repetitive development tasks. \u003c/p\u003e\u003cp\u003eFinally, developing for Kubernetes usually involves jumping between the IDE, documentation, samples etc. Cloud Code reduces this context switching with Kubernetes \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-code-samples\" target=\"_blank\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003ecode samples\u003c/a\u003e. With samples, we can get new developers up and running quickly. They spend less time learning about configuration and management of the application—and spend more time on writing and evolving the code.\u003c/p\u003e\u003ch3\u003e2. Drive end-to-end automation\u003c/h3\u003e\u003cp\u003eTo further improve developer productivity, we’ve focused on end-to-end automation: from writing code within IDEs, to automatically triggering CI/CD pipelines and running the code in production. In particular, \u003ca href=\"https://cloud.google.com/tekton\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/tekton\" track-metadata-module=\"post\"\u003eTekton\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/cloud-build\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/cloud-build\" track-metadata-module=\"post\"\u003eCloud Build\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/container-registry\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloud.google.com/container-registry\" track-metadata-module=\"post\"\u003eContainer Registry,\u003c/a\u003e and GKE have been critical to Forgerock as we streamline the flow of code, feedback and remediation through the build and deployment processes. The process looks something like this:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003ci\u003e\u003cb\u003eEditor’s note\u003c/b\u003e: Today we hear from \u003ca href=\"https://www.forgerock.com/\" target=\"_blank\"\u003eForgeRock\u003c/a\u003e, a multinational \u003ca href=\"https://en.wikipedia.org/wiki/Identity_and_access_management\" target=\"_blank\"\u003eidentity and access management\u003c/a\u003e software company with more than 1,100 enterprise customers, including a major public broadcaster. In total, customers use the ForgeRock Identity Platform to authenticate and log in over 45 million users daily, helping them manage identity, governance, and access management across all platforms, including on-premises and multicloud environments. \u003c/i\u003e\u003c/p\u003e\u003cp\u003e\u003ci\u003eOperating at that kind of scale isn’t easy. In this blog post, ForgeRock Engineering Director, Warren Strange discusses the three things that help make their developers efficient and productive, and the Google Cloud tools they use along the way. \u003c/i\u003e\u003c/p\u003e\u003chr/\u003e\u003cp\u003eAt ForgeRock, we’ve been an early adopter of Kubernetes, viewing it as a strategic platform. Running on Kubernetes allows us to drive multicloud support across \u003ca href=\"https://cloud.google.com/kubernetes-engine\"\u003eGoogle Kubernetes Engine\u003c/a\u003e (GKE), Amazon (EKS), and Azure (AKS). So no matter which cloud our customers are running on, we are able to seamlessly integrate our products into customers' environments. \u003c/p\u003e\u003cp\u003eMaking it easier for ForgeRock's developers and operators to build, deploy and manage applications has been crucial in our ability to continually provide high quality solutions for our customers. We’re always looking for tools to improve productivity and keep our developers focused on coding instead of configuration. Google Cloud’s suite of DevOps tools have streamlined three specific practices to help keep our developers productive: \u003c/p\u003e\u003ch3\u003e1. Make developers productive within IDEs\u003c/h3\u003e\u003cp\u003eDeveloper productivity is core to the success of any organization, including ForgeRock. Since developers spend most of their time within their IDE of choice, our goal at ForgeRock has been to make it easier for our developers to write Kubernetes applications within the IDEs they know and love. \u003ca href=\"https://cloud.google.com/code\"\u003eCloud Code\u003c/a\u003e helps us precisely with that: it makes the process of building, deploying, scaling, and managing Kubernetes infrastructure and applications a breeze. \u003c/p\u003e\u003cp\u003eIn particular, working with the Kubernetes YAML syntax and schema takes time, and a lot of trial and error to master. Thanks to \u003ca href=\"https://cloud.google.com/code/docs/vscode/yaml-editing\"\u003eYAML authoring support\u003c/a\u003e within Cloud Code, we can easily avoid the complicated and time consuming task of writing YAML files at ForgeRock. With YAML authoring support, developers save time on every bug. Cloud Code’s inline  snippets, completions, and schema validation, a.k.a. “linting,” further streamline working with YAML files. \u003c/p\u003e\u003cp\u003eThe benefits of Cloud Code extend to local development as well. Iterating locally on Kubernetes applications often requires multiple manual steps, including building container images, updating Kubernetes manifests, and redeploying applications. Doing these steps over and over again can be a chore. Cloud Code \u003ca href=\"https://cloud.google.com/code/docs/intellij/deploying-a-k8-app\"\u003esupports Skaffold under the hood,\u003c/a\u003e which tracks changes as they come and automatically rebuilds and redeploys—reducing repetitive development tasks. \u003c/p\u003e\u003cp\u003eFinally, developing for Kubernetes usually involves jumping between the IDE, documentation, samples etc. Cloud Code reduces this context switching with Kubernetes \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-code-samples\" target=\"_blank\"\u003ecode samples\u003c/a\u003e. With samples, we can get new developers up and running quickly. They spend less time learning about configuration and management of the application—and spend more time on writing and evolving the code.\u003c/p\u003e\u003ch3\u003e2. Drive end-to-end automation\u003c/h3\u003e\u003cp\u003eTo further improve developer productivity, we’ve focused on end-to-end automation: from writing code within IDEs, to automatically triggering CI/CD pipelines and running the code in production. In particular, \u003ca href=\"https://cloud.google.com/tekton\"\u003eTekton\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/cloud-build\"\u003eCloud Build\u003c/a\u003e, \u003ca href=\"https://cloud.google.com/container-registry\"\u003eContainer Registry,\u003c/a\u003e and GKE have been critical to Forgerock as we streamline the flow of code, feedback and remediation through the build and deployment processes. The process looks something like this:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/ForgeRock__Google.0997050516950896.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"ForgeRock + Google.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/ForgeRock__Google.0997050516950896.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWe begin by developing Kubernetes manifests and dockerfiles using Cloud Code. Then we use \u003ca href=\"https://cloud.google.com/blog/products/application-development/kubernetes-development-simplified-skaffold-is-now-ga\"\u003eSkaffold\u003c/a\u003e to build containers locally, while Cloud Build helps with continuous integration (CI). The \u003ca href=\"https://github.com/marketplace/google-cloud-build\" target=\"_blank\"\u003eCloud Build GitHub app\u003c/a\u003e allows us to automate builds and tests as part of our GitHub workflow. Cloud Build is differentiated from other continuous integration tools since it is fully serverless. It scales up and scales down in response to load, with no need for us to pre-provision servers or pay in advance for additional capacity. We pay for the exact resources we use. \u003c/p\u003e\u003cp\u003eOnce the image is built by Cloud Build, it is stored, managed, and secured in Google’s \u003ca href=\"https://cloud.google.com/container-registry\"\u003eContainer Registry\u003c/a\u003e. Just like Cloud Build, Container Registry is serverless, so we only pay for what we  use. Additionally, since Container Registry comes with automatic vulnerability scanning, every time we upload a new image to Container Registry, we can also scan it for vulnerabilities. \u003c/p\u003e\u003cp\u003eNext, a Tekton pipeline is triggered, which deploys the docker images stored in Container Registry and Kubernetes manifests to a running GKE cluster. Along with Cloud Build, Tekton is a critical part of our CI/CD process at ForgeRock. Most importantly, since Tekton comes with standardized Kubernetes-native primitives, we can create continuous delivery workflows very quickly.\u003c/p\u003e\u003cp\u003eAfter deployment, Tekton triggers a functional test suite to ensure that the applications we deploy perform as expected. The test results are posted to our team Slack channel so all developers have instant access and insights about each cluster. From there, we are able to provide our customers with their finished product request.\u003c/p\u003e\u003ch3\u003e3.  Leverage multicloud patterns and practices\u003c/h3\u003e\u003cp\u003eThe industry has seen a shift towards \u003ca href=\"https://cloud.google.com/multicloud\"\u003emulticloud\u003c/a\u003e. Organizations have adopted multicloud strategies to minimize vendor lock-in, take advantage of best-in-class solutions, improve cost-efficiencies, and increase flexibility through choice. \u003c/p\u003e\u003cp\u003eAt ForgeRock, we’re big proponents of multicloud. Part of that comes from the fact that our identity and access management product works across Google Cloud, AWS, and Azure. Developing products using open-source technologies such as Kubernetes has been particularly helpful in driving this interoperability. \u003c/p\u003e\u003cp\u003eTekton has been another critical project that has allowed us to prevent vendor lock-in. Thanks to Tekton, our continuous delivery pipelines can deploy across any Kubernetes cluster. Most importantly, since Tekton pipelines run on Kubernetes, these pipelines can be decoupled from the runtime. Like Tekton and Kubernetes, both Cloud Build and Container Registry are based on open technologies. \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-builders-community\" target=\"_blank\"\u003eCommunity-contributed builders\u003c/a\u003eand \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-builders\" target=\"_blank\"\u003eofficial builder images\u003c/a\u003e allow us to connect to a variety of tools as a part of the build process. And finally, with support for open technologies like \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/google-cloud-now-supports-buildpacks\"\u003eGoogle Cloud buildpacks\u003c/a\u003e within Cloud Build, we can build containers without even knowing Docker. \u003c/p\u003e\u003cp\u003eMaking it easier for developers and operators to build, deploy and manage applications is critical for the success of any organization. Driving developer productivity within IDEs, leveraging end-to-end automation, and support for multi-cloud patterns and practices are just some of the ways we are trying to achieve this at ForgeRock. To learn more about ForgeRock, and to deploy the ForgeRock Identity Platform into your Kubernetes cluster, check out our open-source \u003ca href=\"https://github.com/ForgeRock/forgeops\" target=\"_blank\"\u003eForgeOps\u003c/a\u003e repository on GitHub.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/appdev.max-2200x2200.jpg",
      "date_published": "2021-06-01T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eWarren Strange\u003c/name\u003e\u003ctitle\u003eEngineering Director, ForgeRock\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/four-steps-to-jumpstarting-your-sre-practice/",
      "title": "Four steps to jumpstarting your SRE practice",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle-page\u003e\u003cmain id=\"jump-content\"\u003e\u003carticle\u003e\u003carticle-header-block\u003e\u003c/article-header-block\u003e\u003carticle-aspect-image-block\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003e#DevOps\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/article-aspect-image-block\u003e\u003cdiv\u003e\u003carticle-cta _nghost-c17=\"\"\u003e\u003cdiv _ngcontent-c17=\"\"\u003e\u003ch4 _ngcontent-c17=\"\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eTry GCP\u003c/span\u003e\u003c/h4\u003e\u003cp _ngcontent-c17=\"\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eStart building on Google Cloud with $300 in free credits and 20+ always free products.\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003ca _ngcontent-c17=\"\" clicktracker=\"\" rel=\"external\" track-metadata-module=\"article cta\" track-type=\"button\" track-name=\"free trial\" track-metadata-eventdetail=\"https://cloud.google.com/free/\" href=\"https://cloud.google.com/free/\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eFree Trial\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-cta\u003e\u003c/div\u003e\u003carticle-share-block\u003e\u003c/article-share-block\u003e\u003carticle-sticky-share-block\u003e\u003c/article-sticky-share-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-content-stream-block\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;A few months ago, we wrote about how the first step to implementing Site Reliability Engineering (SRE) in an organization is \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/sre-success-starts-with-getting-leadership-on-board\u0026#34;\u0026gt;getting leadership on board\u0026lt;/a\u0026gt;. So, let\u0026amp;#8217;s assume that you\u0026amp;#8217;ve gone ahead and done that. Now what? What are some concrete steps you can take to get the SRE ball rolling? In this blog post, we\u0026amp;#8217;ll take a look at what you as an IT leader can do to fast-track SRE within your team.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h2\u0026gt;Step 1: Start small and iterate\u0026amp;#160;\u0026lt;/h2\u0026gt;\u0026lt;p\u0026gt;\u0026amp;#34;Rome wasn\u0026#39;t built in a day,\u0026amp;#34; the saying goes, but you do need to start somewhere. When it comes to implementing SRE principles, the approach that I (and my team) found to be the most effective is to start with a proof of concept, learn from our mistakes, and iterate!\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Start by identifying a relevant application and/or team\u0026amp;#160;\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;There are many factors that go into choosing a specific team or application for your SRE proof of concept. Most of the time, though, this is a strategic decision for the organization, which is outside the scope of this article. Possible candidates can be a team shifting from traditional operations or DevOps to SRE, or a need to increase reliability to a business-critical product. No matter the reason, it\u0026amp;#8217;s crucial to select an application that is:\u0026lt;/p\u0026gt;\u0026lt;ol\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Critical to the business. Your customers should care deeply about its uptime and reliability.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Currently in development. Pick an application in which the business is actively investing resources.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;In a perfect world, the application provides data and metrics regarding its behaviour.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ol\u0026gt;\u0026lt;p\u0026gt;Conversely, stay away from proprietary software. If the application wasn\u0026amp;#8217;t built by you, it\u0026#39;s not a good candidate for SRE! You need the ability to make strategic decisions about\u0026amp;#8212;and engineering changes to\u0026amp;#8212;the application as needed.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Pro tip\u0026lt;/b\u0026gt;: In general, if you have workloads both on-premises and in the cloud, try to start with the cloud-based app. If your engineers come from a traditional operations environment, changing their thinking away from \u0026#39;bare metal\u0026#39; and infrastructure metrics will be easier for a cloud-based app, as managed infrastructure turns practitioners into users and forces them to consume it like developers (APIs, infrastructure as code, etc.)\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Remember\u0026lt;/b\u0026gt;: Set realistic goals. Discouraging your team with unrealistic expectations early on will have a negative effect on the initiative.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h2\u0026gt;Step 2: Empower your teams\u0026lt;/h2\u0026gt;\u0026lt;p\u0026gt;Implementing SRE principles requires fostering a learning culture, and in that regard, \u0026lt;b\u0026gt;team enablement\u0026lt;/b\u0026gt; means both training them, i.e., in regards to knowledge, as well as \u0026lt;i\u0026gt;empowering\u0026lt;/i\u0026gt; them.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Building a training program is a topic in and of itself, but it\u0026amp;#8217;s important to think about an \u0026lt;b\u0026gt;enablement strategy\u0026lt;/b\u0026gt; at an early stage. Especially in large organizations, you need to address topics like internal upskilling, hiring and scaling the team as well as onboarding and creating a learning community.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Your enablement strategy should also accommodate employees at different levels and in different functions. For example, higher leadership\u0026#39;s training will look very different from practitioners\u0026amp;#8217; training. Leadership\u0026#39;s education should be sufficient to get buy-in and to be able to make organizational decisions. To drive change in the entire organization, additional training to leadership on cultural concepts and practices might be required.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eA few months ago, we wrote about how the first step to implementing Site Reliability Engineering (SRE) in an organization is \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/sre-success-starts-with-getting-leadership-on-board\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/sre-success-starts-with-getting-leadership-on-board\" track-metadata-module=\"post\"\u003egetting leadership on board\u003c/a\u003e. So, let’s assume that you’ve gone ahead and done that. Now what? What are some concrete steps you can take to get the SRE ball rolling? In this blog post, we’ll take a look at what you as an IT leader can do to fast-track SRE within your team. \u003c/p\u003e\u003ch2\u003eStep 1: Start small and iterate \u003c/h2\u003e\u003cp\u003e\u0026#34;Rome wasn\u0026#39;t built in a day,\u0026#34; the saying goes, but you do need to start somewhere. When it comes to implementing SRE principles, the approach that I (and my team) found to be the most effective is to start with a proof of concept, learn from our mistakes, and iterate!\u003c/p\u003e\u003ch3\u003eStart by identifying a relevant application and/or team \u003c/h3\u003e\u003cp\u003eThere are many factors that go into choosing a specific team or application for your SRE proof of concept. Most of the time, though, this is a strategic decision for the organization, which is outside the scope of this article. Possible candidates can be a team shifting from traditional operations or DevOps to SRE, or a need to increase reliability to a business-critical product. No matter the reason, it’s crucial to select an application that is:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cp\u003eCritical to the business. Your customers should care deeply about its uptime and reliability. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCurrently in development. Pick an application in which the business is actively investing resources. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eIn a perfect world, the application provides data and metrics regarding its behaviour. \u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eConversely, stay away from proprietary software. If the application wasn’t built by you, it\u0026#39;s not a good candidate for SRE! You need the ability to make strategic decisions about—and engineering changes to—the application as needed. \u003c/p\u003e\u003cp\u003e\u003cb\u003ePro tip\u003c/b\u003e: In general, if you have workloads both on-premises and in the cloud, try to start with the cloud-based app. If your engineers come from a traditional operations environment, changing their thinking away from \u0026#39;bare metal\u0026#39; and infrastructure metrics will be easier for a cloud-based app, as managed infrastructure turns practitioners into users and forces them to consume it like developers (APIs, infrastructure as code, etc.)\u003c/p\u003e\u003cp\u003e\u003cb\u003eRemember\u003c/b\u003e: Set realistic goals. Discouraging your team with unrealistic expectations early on will have a negative effect on the initiative. \u003c/p\u003e\u003ch2\u003eStep 2: Empower your teams\u003c/h2\u003e\u003cp\u003eImplementing SRE principles requires fostering a learning culture, and in that regard, \u003cb\u003eteam enablement\u003c/b\u003e means both training them, i.e., in regards to knowledge, as well as \u003ci\u003eempowering\u003c/i\u003e them.\u003c/p\u003e\u003cp\u003eBuilding a training program is a topic in and of itself, but it’s important to think about an \u003cb\u003eenablement strategy\u003c/b\u003e at an early stage. Especially in large organizations, you need to address topics like internal upskilling, hiring and scaling the team as well as onboarding and creating a learning community. \u003c/p\u003e\u003cp\u003eYour enablement strategy should also accommodate employees at different levels and in different functions. For example, higher leadership\u0026#39;s training will look very different from practitioners’ training. Leadership\u0026#39;s education should be sufficient to get buy-in and to be able to make organizational decisions. To drive change in the entire organization, additional training to leadership on cultural concepts and practices might be required.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;When it comes to engineering leadership and/or middle management (managers that manage managers), training should be a combination of\u0026amp;#160; high-level cultural concepts to help foster the required culture, and technical SRE practices that are deep enough to understand prioritization, resource allocation, process creation, and future needs.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;When it comes to practitioners, ideally you want the entire organization to be aligned both from a knowledge perspective as well as culturally. But as we\u0026amp;#8217;ve mentioned earlier, it\u0026amp;#8217;s best to start simple, with just one team.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The starting point for those teams should be to understand reliability and key concepts like \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/sre-fundamentals-slis-slas-and-slos\u0026#34;\u0026gt;SLAs, SLOs, SLIs\u0026lt;/a\u0026gt; and \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/management-tools/sre-error-budgets-and-maintenance-windows\u0026#34;\u0026gt;error budgets\u0026lt;/a\u0026gt;. These are important because SRE is focused on the customer experience. Measuring whether systems meet customer expectations requires a shift in mindset and can take time.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eWhen it comes to engineering leadership and/or middle management (managers that manage managers), training should be a combination of  high-level cultural concepts to help foster the required culture, and technical SRE practices that are deep enough to understand prioritization, resource allocation, process creation, and future needs.\u003c/p\u003e\u003cp\u003eWhen it comes to practitioners, ideally you want the entire organization to be aligned both from a knowledge perspective as well as culturally. But as we’ve mentioned earlier, it’s best to start simple, with just one team.\u003c/p\u003e\u003cp\u003eThe starting point for those teams should be to understand reliability and key concepts like \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/sre-fundamentals-slis-slas-and-slos\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/sre-fundamentals-slis-slas-and-slos\" track-metadata-module=\"post\"\u003eSLAs, SLOs, SLIs\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/blog/products/management-tools/sre-error-budgets-and-maintenance-windows\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/management-tools/sre-error-budgets-and-maintenance-windows\" track-metadata-module=\"post\"\u003eerror budgets\u003c/a\u003e. These are important because SRE is focused on the customer experience. Measuring whether systems meet customer expectations requires a shift in mindset and can take time.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cp\u003eAfter identifying your first application and/or the team responsible for it, it\u0026#39;s time to identify the app’s user journeys, the set of interactions a user has with a service to achieve a single goal—for example, a single click or a multi-step pipeline, and rank them according to business impact. The most critical ones are called Critical User Journeys (CUJ), and these are where you should start  drafting SLO/SLIs.\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Pro tip\u0026lt;/b\u0026gt;: There are some general technical practices that can help you embrace SRE faster. For example, using less repos rather than more can help you reduce silos within the organization and better utilize resources.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Likewise, prioritizing automatic processes and self-healing systems can benefit reliability, but also team satisfaction, helping the organization retain talent.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e\u003cb\u003ePro tip\u003c/b\u003e: There are some general technical practices that can help you embrace SRE faster. For example, using less repos rather than more can help you reduce silos within the organization and better utilize resources. \u003c/p\u003e\u003cp\u003eLikewise, prioritizing automatic processes and self-healing systems can benefit reliability, but also team satisfaction, helping the organization retain talent.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Final note\u0026lt;/b\u0026gt;: Similar to the way that you make architecture decisions, your chosen technology, solutions and implementation tools should enable you to do what you are trying to do and not vice versa.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h2\u0026gt;Step 3: Scale those learnings\u0026amp;#160;\u0026lt;/h2\u0026gt;\u0026lt;p\u0026gt;After you establish these SRE practices with one or a few teams, the next step is to think about building an SRE community and formalized processes across the organization. In some organizations, you can do this in parallel to the end of step 2, and in some organizations, only after you have a few successful implementations under your belt.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In this phase, you\u0026amp;#8217;ll probably want to address \u0026lt;b\u0026gt;community, culture, enablement and processes.\u0026lt;/b\u0026gt; You will need to address them all, especially as they are intertwined, but which one you prioritize will depend on your organization.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Creating an SRE \u0026lt;b\u0026gt;community\u0026lt;/b\u0026gt; in the organization is important both from a learning perspective, but also to establish a knowledge base of best practices, train subject-matter experts, help create needed guardrails, and align processes.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Building a community goes hand in hand with fostering an \u0026lt;b\u0026gt;empowered culture and training teams\u0026lt;/b\u0026gt;. The idea is that early adopters are ambassadors for SRE who share their learnings and train other teams in the organization.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;It is also useful to identify potential ambassadors or champions in individual development teams who are passionate about SRE and will help with the adoption of those practices.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;It is also crucial to create repeatable trainings for each functional role, including onboarding sessions. Onboarding new team members is a critical aspect of training and fostering an empowered SRE culture. Therefore it is vital to be mindful about your onboarding process and make sure that the knowledge is not lost when team members change roles.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e\u003cb\u003eFinal note\u003c/b\u003e: Similar to the way that you make architecture decisions, your chosen technology, solutions and implementation tools should enable you to do what you are trying to do and not vice versa. \u003c/p\u003e\u003ch2\u003eStep 3: Scale those learnings \u003c/h2\u003e\u003cp\u003eAfter you establish these SRE practices with one or a few teams, the next step is to think about building an SRE community and formalized processes across the organization. In some organizations, you can do this in parallel to the end of step 2, and in some organizations, only after you have a few successful implementations under your belt.\u003c/p\u003e\u003cp\u003eIn this phase, you’ll probably want to address \u003cb\u003ecommunity, culture, enablement and processes.\u003c/b\u003e You will need to address them all, especially as they are intertwined, but which one you prioritize will depend on your organization.\u003c/p\u003e\u003cp\u003eCreating an SRE \u003cb\u003ecommunity\u003c/b\u003e in the organization is important both from a learning perspective, but also to establish a knowledge base of best practices, train subject-matter experts, help create needed guardrails, and align processes. \u003c/p\u003e\u003cp\u003eBuilding a community goes hand in hand with fostering an \u003cb\u003eempowered culture and training teams\u003c/b\u003e. The idea is that early adopters are ambassadors for SRE who share their learnings and train other teams in the organization. \u003c/p\u003e\u003cp\u003eIt is also useful to identify potential ambassadors or champions in individual development teams who are passionate about SRE and will help with the adoption of those practices.\u003c/p\u003e\u003cp\u003eIt is also crucial to create repeatable trainings for each functional role, including onboarding sessions. Onboarding new team members is a critical aspect of training and fostering an empowered SRE culture. Therefore it is vital to be mindful about your onboarding process and make sure that the knowledge is not lost when team members change roles.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;During this phase, you also want to foster an org-wide culture that promotes psychological safety, accepts failure as normal and enables the team to learn from mistakes. For that, leadership must model the desired culture and promote transparency.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Finally, having structured and formalized processes can help reduce the stress around emergency response\u0026amp;#8212;especially being on-call. Processes can also provide clarity and make teams more collaborative and effective.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In order to have the most impact, start by prioritizing the most painful areas under your team\u0026amp;#8217;s remit\u0026amp;#8212;for example, clean up noisy alerts to avoid (or address) alert fatigue, automate your change management processes and involve only the necessary people to save team bandwidth. Team members shouldn\u0026#39;t work on software engineering projects while doing on-call incident management, and vice-versa. Make sure they have enough bandwidth to do both, separately.\u0026amp;#160; Similar to other areas, you want to use data to drive your decisions.\u0026amp;#160; As such, identify where your teams spend the most time, and for how long.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;If you find that it is challenging to collect this kind of data, be it quantitative or qualitative, a good starting point is often your emergency response processes, as those have a direct impact on the business, especially around the escalation process, incident management and related policies.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Pro tip\u0026lt;/b\u0026gt;: All the above practices contribute to reducing silos and align goals across the organization; those should include also your vendors and engineering partners. To that end, make sure your contracts with them capture those goals as well.\u0026lt;/p\u0026gt;\u0026lt;h2\u0026gt;Step 4: Embody a data-driven mindset\u0026lt;/h2\u0026gt;\u0026lt;p\u0026gt;Starting the SRE journey can take time, even if you\u0026#39;re just implementing it for one team. Two quick wins that you can start with that will make a positive impact are collecting data and doing blameless postmortems.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In SRE we try to be as \u0026lt;b\u0026gt;data-driven\u0026lt;/b\u0026gt; as possible, so creating a measurement culture in your organization is crucial. When prioritizing data collection, ideally look for data that represents the customer experience. Collecting that data will help you identify your gaps and help you prioritize according to business needs and by extension your customer expectations.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eDuring this phase, you also want to foster an org-wide culture that promotes psychological safety, accepts failure as normal and enables the team to learn from mistakes. For that, leadership must model the desired culture and promote transparency. \u003c/p\u003e\u003cp\u003eFinally, having structured and formalized processes can help reduce the stress around emergency response—especially being on-call. Processes can also provide clarity and make teams more collaborative and effective. \u003c/p\u003e\u003cp\u003eIn order to have the most impact, start by prioritizing the most painful areas under your team’s remit—for example, clean up noisy alerts to avoid (or address) alert fatigue, automate your change management processes and involve only the necessary people to save team bandwidth. Team members shouldn\u0026#39;t work on software engineering projects while doing on-call incident management, and vice-versa. Make sure they have enough bandwidth to do both, separately.  Similar to other areas, you want to use data to drive your decisions.  As such, identify where your teams spend the most time, and for how long. \u003c/p\u003e\u003cp\u003eIf you find that it is challenging to collect this kind of data, be it quantitative or qualitative, a good starting point is often your emergency response processes, as those have a direct impact on the business, especially around the escalation process, incident management and related policies. \u003c/p\u003e\u003cp\u003e\u003cb\u003ePro tip\u003c/b\u003e: All the above practices contribute to reducing silos and align goals across the organization; those should include also your vendors and engineering partners. To that end, make sure your contracts with them capture those goals as well.\u003c/p\u003e\u003ch2\u003eStep 4: Embody a data-driven mindset\u003c/h2\u003e\u003cp\u003eStarting the SRE journey can take time, even if you\u0026#39;re just implementing it for one team. Two quick wins that you can start with that will make a positive impact are collecting data and doing blameless postmortems.\u003c/p\u003e\u003cp\u003eIn SRE we try to be as \u003cb\u003edata-driven\u003c/b\u003e as possible, so creating a measurement culture in your organization is crucial. When prioritizing data collection, ideally look for data that represents the customer experience. Collecting that data will help you identify your gaps and help you prioritize according to business needs and by extension your customer expectations.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Another thing that you can do is run or improve \u0026lt;a href=\u0026#34;https://sre.google/sre-book/postmortem-culture/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;postmortems\u0026lt;/a\u0026gt;, which are an essential way of learning from failure and fostering a strong SRE culture. From our experience, even organizations that do run postmortems can benefit from them much more with a few minor improvements. It is important to remember that postmortems should be blameless in order to make the team feel safe to share and learn from failures. And to make tomorrow better than today, i.e., not repeat the same problems, it\u0026amp;#8217;s important that postmortems include action items and are assigned to an owner.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/fearless-shared-postmortems-cre-life-lessons\u0026#34;\u0026gt;Creating a shared repository\u0026lt;/a\u0026gt; for postmortems can have a tremendous impact on the team: it increases transparency, reduces silos, and contributes to the \u0026lt;a href=\u0026#34;https://cloud.google.com/solutions/devops/devops-culture-learning-culture\u0026#34;\u0026gt;learning culture\u0026lt;/a\u0026gt;. It also shows the team that the organization \u0026amp;#8220;practices what it preaches.\u0026amp;#8221; Implementing a repository can be as easy as creating a shared drive.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Pro ti\u0026lt;/b\u0026gt;p: Postmortems should be blameless and actionable.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eAnother thing that you can do is run or improve \u003ca href=\"https://sre.google/sre-book/postmortem-culture/\" target=\"_blank\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003epostmortems\u003c/a\u003e, which are an essential way of learning from failure and fostering a strong SRE culture. From our experience, even organizations that do run postmortems can benefit from them much more with a few minor improvements. It is important to remember that postmortems should be blameless in order to make the team feel safe to share and learn from failures. And to make tomorrow better than today, i.e., not repeat the same problems, it’s important that postmortems include action items and are assigned to an owner. \u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/fearless-shared-postmortems-cre-life-lessons\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/fearless-shared-postmortems-cre-life-lessons\" track-metadata-module=\"post\"\u003eCreating a shared repository\u003c/a\u003e for postmortems can have a tremendous impact on the team: it increases transparency, reduces silos, and contributes to the \u003ca href=\"https://cloud.google.com/solutions/devops/devops-culture-learning-culture\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/solutions/devops/devops-culture-learning-culture\" track-metadata-module=\"post\"\u003elearning culture\u003c/a\u003e. It also shows the team that the organization “practices what it preaches.” Implementing a repository can be as easy as creating a shared drive.\u003c/p\u003e\u003cp\u003e\u003cb\u003ePro ti\u003c/b\u003ep: Postmortems should be blameless and actionable.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/article-content-stream-block\u003e\u003carticle-tag-list-block\u003e\u003c/article-tag-list-block\u003e\u003c/div\u003e\u003csection\u003e\u003carticle-up-1to3-block _nghost-c18=\"\"\u003e\u003c/article-up-1to3-block\u003e\u003c/section\u003e\u003c/div\u003e\u003c/article\u003e\u003c/main\u003e\u003c/article-page\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eA few months ago, we wrote about how the first step to implementing Site Reliability Engineering (SRE) in an organization is \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/sre-success-starts-with-getting-leadership-on-board\"\u003egetting leadership on board\u003c/a\u003e. So, let’s assume that you’ve gone ahead and done that. Now what? What are some concrete steps you can take to get the SRE ball rolling? In this blog post, we’ll take a look at what you as an IT leader can do to fast-track SRE within your team. \u003c/p\u003e\u003ch2\u003eStep 1: Start small and iterate \u003c/h2\u003e\u003cp\u003e\"Rome wasn't built in a day,\" the saying goes, but you do need to start somewhere. When it comes to implementing SRE principles, the approach that I (and my team) found to be the most effective is to start with a proof of concept, learn from our mistakes, and iterate!\u003c/p\u003e\u003ch3\u003eStart by identifying a relevant application and/or team \u003c/h3\u003e\u003cp\u003eThere are many factors that go into choosing a specific team or application for your SRE proof of concept. Most of the time, though, this is a strategic decision for the organization, which is outside the scope of this article. Possible candidates can be a team shifting from traditional operations or DevOps to SRE, or a need to increase reliability to a business-critical product. No matter the reason, it’s crucial to select an application that is:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cp\u003eCritical to the business. Your customers should care deeply about its uptime and reliability. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCurrently in development. Pick an application in which the business is actively investing resources. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eIn a perfect world, the application provides data and metrics regarding its behaviour. \u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eConversely, stay away from proprietary software. If the application wasn’t built by you, it's not a good candidate for SRE! You need the ability to make strategic decisions about—and engineering changes to—the application as needed. \u003c/p\u003e\u003cp\u003e\u003cb\u003ePro tip\u003c/b\u003e: In general, if you have workloads both on-premises and in the cloud, try to start with the cloud-based app. If your engineers come from a traditional operations environment, changing their thinking away from 'bare metal' and infrastructure metrics will be easier for a cloud-based app, as managed infrastructure turns practitioners into users and forces them to consume it like developers (APIs, infrastructure as code, etc.)\u003c/p\u003e\u003cp\u003e\u003cb\u003eRemember\u003c/b\u003e: Set realistic goals. Discouraging your team with unrealistic expectations early on will have a negative effect on the initiative. \u003c/p\u003e\u003ch2\u003eStep 2: Empower your teams\u003c/h2\u003e\u003cp\u003eImplementing SRE principles requires fostering a learning culture, and in that regard, \u003cb\u003eteam enablement\u003c/b\u003e means both training them, i.e., in regards to knowledge, as well as \u003ci\u003eempowering\u003c/i\u003e them.\u003c/p\u003e\u003cp\u003eBuilding a training program is a topic in and of itself, but it’s important to think about an \u003cb\u003eenablement strategy\u003c/b\u003e at an early stage. Especially in large organizations, you need to address topics like internal upskilling, hiring and scaling the team as well as onboarding and creating a learning community. \u003c/p\u003e\u003cp\u003eYour enablement strategy should also accommodate employees at different levels and in different functions. For example, higher leadership's training will look very different from practitioners’ training. Leadership's education should be sufficient to get buy-in and to be able to make organizational decisions. To drive change in the entire organization, additional training to leadership on cultural concepts and practices might be required.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout_external\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003e\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWhen it comes to engineering leadership and/or middle management (managers that manage managers), training should be a combination of  high-level cultural concepts to help foster the required culture, and technical SRE practices that are deep enough to understand prioritization, resource allocation, process creation, and future needs.\u003c/p\u003e\u003cp\u003eWhen it comes to practitioners, ideally you want the entire organization to be aligned both from a knowledge perspective as well as culturally. But as we’ve mentioned earlier, it’s best to start simple, with just one team.\u003c/p\u003e\u003cp\u003eThe starting point for those teams should be to understand reliability and key concepts like \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/sre-fundamentals-slis-slas-and-slos\"\u003eSLAs, SLOs, SLIs\u003c/a\u003e and \u003ca href=\"https://cloud.google.com/blog/products/management-tools/sre-error-budgets-and-maintenance-windows\"\u003eerror budgets\u003c/a\u003e. These are important because SRE is focused on the customer experience. Measuring whether systems meet customer expectations requires a shift in mindset and can take time.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout_external\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003e\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eAfter identifying your first application and/or the team responsible for it, it's time to identify the app’s user journeys, the set of interactions a user has with a service to achieve a single goal—for example, a single click or a multi-step pipeline, and rank them according to business impact. The most critical ones are called Critical User Journeys (CUJ), and these are where you should start  drafting SLO/SLIs.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_kqBt6Vr.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"image1.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/image1_kqBt6Vr.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003cb\u003ePro tip\u003c/b\u003e: There are some general technical practices that can help you embrace SRE faster. For example, using less repos rather than more can help you reduce silos within the organization and better utilize resources. \u003c/p\u003e\u003cp\u003eLikewise, prioritizing automatic processes and self-healing systems can benefit reliability, but also team satisfaction, helping the organization retain talent.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout_external\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003e\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003cb\u003eFinal note\u003c/b\u003e: Similar to the way that you make architecture decisions, your chosen technology, solutions and implementation tools should enable you to do what you are trying to do and not vice versa. \u003c/p\u003e\u003ch2\u003eStep 3: Scale those learnings \u003c/h2\u003e\u003cp\u003eAfter you establish these SRE practices with one or a few teams, the next step is to think about building an SRE community and formalized processes across the organization. In some organizations, you can do this in parallel to the end of step 2, and in some organizations, only after you have a few successful implementations under your belt.\u003c/p\u003e\u003cp\u003eIn this phase, you’ll probably want to address \u003cb\u003ecommunity, culture, enablement and processes.\u003c/b\u003e You will need to address them all, especially as they are intertwined, but which one you prioritize will depend on your organization.\u003c/p\u003e\u003cp\u003eCreating an SRE \u003cb\u003ecommunity\u003c/b\u003e in the organization is important both from a learning perspective, but also to establish a knowledge base of best practices, train subject-matter experts, help create needed guardrails, and align processes. \u003c/p\u003e\u003cp\u003eBuilding a community goes hand in hand with fostering an \u003cb\u003eempowered culture and training teams\u003c/b\u003e. The idea is that early adopters are ambassadors for SRE who share their learnings and train other teams in the organization. \u003c/p\u003e\u003cp\u003eIt is also useful to identify potential ambassadors or champions in individual development teams who are passionate about SRE and will help with the adoption of those practices.\u003c/p\u003e\u003cp\u003eIt is also crucial to create repeatable trainings for each functional role, including onboarding sessions. Onboarding new team members is a critical aspect of training and fostering an empowered SRE culture. Therefore it is vital to be mindful about your onboarding process and make sure that the knowledge is not lost when team members change roles.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout_external\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003e\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eDuring this phase, you also want to foster an org-wide culture that promotes psychological safety, accepts failure as normal and enables the team to learn from mistakes. For that, leadership must model the desired culture and promote transparency. \u003c/p\u003e\u003cp\u003eFinally, having structured and formalized processes can help reduce the stress around emergency response—especially being on-call. Processes can also provide clarity and make teams more collaborative and effective. \u003c/p\u003e\u003cp\u003eIn order to have the most impact, start by prioritizing the most painful areas under your team’s remit—for example, clean up noisy alerts to avoid (or address) alert fatigue, automate your change management processes and involve only the necessary people to save team bandwidth. Team members shouldn't work on software engineering projects while doing on-call incident management, and vice-versa. Make sure they have enough bandwidth to do both, separately.  Similar to other areas, you want to use data to drive your decisions.  As such, identify where your teams spend the most time, and for how long. \u003c/p\u003e\u003cp\u003eIf you find that it is challenging to collect this kind of data, be it quantitative or qualitative, a good starting point is often your emergency response processes, as those have a direct impact on the business, especially around the escalation process, incident management and related policies. \u003c/p\u003e\u003cp\u003e\u003cb\u003ePro tip\u003c/b\u003e: All the above practices contribute to reducing silos and align goals across the organization; those should include also your vendors and engineering partners. To that end, make sure your contracts with them capture those goals as well.\u003c/p\u003e\u003ch2\u003eStep 4: Embody a data-driven mindset\u003c/h2\u003e\u003cp\u003eStarting the SRE journey can take time, even if you're just implementing it for one team. Two quick wins that you can start with that will make a positive impact are collecting data and doing blameless postmortems.\u003c/p\u003e\u003cp\u003eIn SRE we try to be as \u003cb\u003edata-driven\u003c/b\u003e as possible, so creating a measurement culture in your organization is crucial. When prioritizing data collection, ideally look for data that represents the customer experience. Collecting that data will help you identify your gaps and help you prioritize according to business needs and by extension your customer expectations.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout_external\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003e\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eAnother thing that you can do is run or improve \u003ca href=\"https://sre.google/sre-book/postmortem-culture/\" target=\"_blank\"\u003epostmortems\u003c/a\u003e, which are an essential way of learning from failure and fostering a strong SRE culture. From our experience, even organizations that do run postmortems can benefit from them much more with a few minor improvements. It is important to remember that postmortems should be blameless in order to make the team feel safe to share and learn from failures. And to make tomorrow better than today, i.e., not repeat the same problems, it’s important that postmortems include action items and are assigned to an owner. \u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/fearless-shared-postmortems-cre-life-lessons\"\u003eCreating a shared repository\u003c/a\u003e for postmortems can have a tremendous impact on the team: it increases transparency, reduces silos, and contributes to the \u003ca href=\"https://cloud.google.com/solutions/devops/devops-culture-learning-culture\"\u003elearning culture\u003c/a\u003e. It also shows the team that the organization “practices what it preaches.” Implementing a repository can be as easy as creating a shared drive.\u003c/p\u003e\u003cp\u003e\u003cb\u003ePro ti\u003c/b\u003ep: Postmortems should be blameless and actionable.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout_external\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003e\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch2\u003eOn the SRE fast track\u003c/h2\u003e\u003cp\u003eOf course, no two organizations are alike, and no two SRE teams are either. But by following these steps, you can help get your team on the path to SRE success faster. To learn more about developing an effective SRE practice, check out the following resources. \u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://medium.com/@ayeletsachti/sre-public-resources-for-gcp-customers-bab039444ad3\" target=\"_blank\"\u003eCollection of SRE Public resources\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/consulting\"\u003eGoogle Professional Services SRE packages\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/sre-success-starts-with-getting-leadership-on-board/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_D_Rnd3.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eWith SRE, failing to plan is planning to fail\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eThe process of becoming a successful Site Reliability Engineering shop starts well before you take your first class or read your first ma...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_B_Rnd3.max-2200x2200.jpg",
      "date_published": "2021-05-25T18:30:00Z",
      "author": {
        "name": "\u003cname\u003eAyelet Sachto\u003c/name\u003e\u003ctitle\u003eStrategic Cloud Engineer, Infra, AppMod, SRE\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/sre-fundamentals-sli-vs-slo-vs-sla/",
      "title": "SRE fundamentals 2021: SLIs vs SLAs vs SLOs",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;A big part of \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/available-or-not-that-is-the-question-cre-life-lessons\u0026#34;\u0026gt;ensuring the availability of your applications\u0026lt;/a\u0026gt; is establishing and monitoring service-level metrics\u0026amp;#8212;something that our \u0026lt;a href=\u0026#34;https://sre.google/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Site Reliability Engineering\u0026lt;/a\u0026gt; (SRE) team does every day here at Google Cloud. The end goal of our SRE principles is to improve services and in turn the user experience.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The concept of SRE starts with the idea that metrics should be closely tied to business objectives. In addition to business-level SLAs, we also use \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/availability-part-deux-cre-life-lessons\u0026#34;\u0026gt;SLOs and SLIs\u0026lt;/a\u0026gt; in SRE planning and practice.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h2\u0026gt;Defining the terms of site reliability engineering\u0026lt;/h2\u0026gt;\u0026lt;p\u0026gt;These tools aren\u0026amp;#8217;t just useful abstractions. Without them, you won\u0026amp;#8217;t know if your system is reliable, available, or even useful. If the tools don\u0026amp;#8217;t tie back to your business objectives, then you\u0026amp;#8217;ll be missing data on whether your choices are helping or hurting your business.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;As a refresher, here\u0026amp;#8217;s a look at SLOs, SLAs, and SLIS, as discussed by our Customer Reliability Engineering team in their blog post, \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/availability-part-deux-cre-life-lessons\u0026#34;\u0026gt;SLOs, SLIs, SLAs, oh my - CRE life lessons\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;1. Service-Level Objective (SLO)\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;SRE begins with the idea that \u0026lt;a href=\u0026#34;https://sre.google/sre-book/embracing-risk/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;availability is a prerequisite for success\u0026lt;/a\u0026gt;. An unavailable system can\u0026amp;#8217;t perform its function and will fail by default. Availability, in SRE terms, defines whether a system is able to fulfill its intended function at a point in time. In addition to its use as a reporting tool, the historical availability measurement can also describe the probability that your system will perform as expected in the future.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;When we set out to define the terms of SRE, we wanted to set a precise numerical target for system availability. We term this target the availability \u0026lt;a href=\u0026#34;https://sre.google/sre-book/service-level-objectives/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Service-Level Objective\u0026lt;/a\u0026gt; (SLO) of our system. Any future discussion about whether the system is running reliably and if any design or architectural changes to it are needed must be framed in terms of our system continuing to meet this SLO.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Keep in mind that the more reliable the service, the more it costs to operate. Define the lowest level of reliability that is acceptable for users of each service, then state that as your SLO. Every service should have an availability SLO\u0026amp;#8212;without it, your team and your stakeholders can\u0026amp;#8217;t make principled judgments about whether your service needs to be made more reliable (increasing cost and slowing development) or less reliable (allowing greater velocity of development). Excessive availability has become the expectation, which can lead to problems. Don\u0026amp;#8217;t make your system overly reliable if the user experience doesn\u0026amp;#8217;t necessitate it, and especially if you don\u0026amp;#8217;t intend to commit to always reaching that level. You can learn more about this by participating in \u0026lt;a href=\u0026#34;https://sre.google/resources/practices-and-processes/art-of-slos/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;The Art of SLOs\u0026lt;/a\u0026gt; training.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026amp;#160;Within Google Cloud, we implement periodic downtime in some services to prevent a service from being overly available. You could also try experimenting with occasional planned-downtime exercises with front-end servers, as we did with one of our internal systems. We found that these exercises can uncover services that are using those servers inappropriately. With that information, you can then move workloads to a more suitable place and keep servers at the right availability level.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;2. Service-Level Agreement (SLA)\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;At Google Cloud, \u0026lt;a href=\u0026#34;https://sre.google/sre-book/service-level-objectives/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;we distinguish between an SLO and a Service-Level Agreement (SLA)\u0026lt;/a\u0026gt;. An SLA normally involves a promise to a service user that the service availability SLO should meet a certain level over a certain period. Failing to do so then results in some kind of penalty. This might be a partial refund of the service subscription fee paid by customers for that period, or additional subscription time added for free. Going out of SLO will hurt the service team, so they will push hard to stay within SLO. If you\u0026amp;#8217;re charging your customers money, you\u0026amp;#8217;ll probably need an SLA.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Because of this, and because of the principle that availability shouldn\u0026amp;#8217;t be much better than the SLO, the availability SLO in the SLA is normally a looser objective than the internal availability SLO. This might be expressed in availability numbers: for instance, an availability SLO of 99.9% over one month, with an internal availability SLO of 99.95%. Alternatively, the SLA might only specify a subset of the metrics that make up the internal SLO.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;If you have an SLO in your SLA that is different from your internal SLO (as it almost always is), it\u0026amp;#8217;s important for your monitoring to explicitly measure SLO compliance. You want to be able to view your system\u0026amp;#8217;s availability over the SLA calendar period, and quickly see if it appears to be in danger of going out of SLO.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;You\u0026amp;#8217;ll also need a precise measurement of compliance, usually from logs analysis. Since we have an extra set of obligations (described in the SLA) to paying customers, we need to measure queries received from them separately from other queries. This is another benefit of establishing an SLA\u0026amp;#8212;it\u0026amp;#8217;s an unambiguous way to prioritize traffic.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;When you define your SLA\u0026amp;#8217;s availability SLO, be careful about which queries you count as legitimate. For example, if a customer goes over quota because they released a buggy version of their mobile client, you may consider excluding all \u0026amp;#8220;out of quota\u0026amp;#8221; response codes from your SLA accounting.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;3. Service-Level Indicator (SLI)\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Our Service-Level Indicator (SLI) is a direct measurement of a service\u0026amp;#8217;s behavior, defined as the frequency of successful probes of our system. When we evaluate whether our system has been running within SLO for the past week, \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/management-tools/tune-up-your-sli-metrics-cre-life-lessons\u0026#34;\u0026gt;we look at the SLI\u0026lt;/a\u0026gt; to get the service availability percentage. If it goes below the specified SLO, we have a problem and may need to make the system more available in some way, such as by running a second instance of the service in a different city and load-balancing between the two. If you want to know how reliable your service is, you must be able to measure the rates of successful and unsuccessful queries as your SLIs.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;If you\u0026amp;#8217;re building a system from scratch, make sure that SLIs and SLOs are part of your system requirements. If you already have a production system but don\u0026amp;#8217;t have them clearly defined, then that\u0026amp;#8217;s your highest priority work.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eA big part of \u003ca href=\"https://cloud.google.com/blog/products/gcp/available-or-not-that-is-the-question-cre-life-lessons\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/available-or-not-that-is-the-question-cre-life-lessons\" track-metadata-module=\"post\"\u003eensuring the availability of your applications\u003c/a\u003e is establishing and monitoring service-level metrics—something that our \u003ca href=\"https://sre.google/\" target=\"_blank\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003eSite Reliability Engineering\u003c/a\u003e (SRE) team does every day here at Google Cloud. The end goal of our SRE principles is to improve services and in turn the user experience.\u003c/p\u003e\u003cp\u003eThe concept of SRE starts with the idea that metrics should be closely tied to business objectives. In addition to business-level SLAs, we also use \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/availability-part-deux-cre-life-lessons\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/availability-part-deux-cre-life-lessons\" track-metadata-module=\"post\"\u003eSLOs and SLIs\u003c/a\u003e in SRE planning and practice. \u003c/p\u003e\u003ch2\u003eDefining the terms of site reliability engineering\u003c/h2\u003e\u003cp\u003eThese tools aren’t just useful abstractions. Without them, you won’t know if your system is reliable, available, or even useful. If the tools don’t tie back to your business objectives, then you’ll be missing data on whether your choices are helping or hurting your business.\u003c/p\u003e\u003cp\u003eAs a refresher, here’s a look at SLOs, SLAs, and SLIS, as discussed by our Customer Reliability Engineering team in their blog post, \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/availability-part-deux-cre-life-lessons\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/availability-part-deux-cre-life-lessons\" track-metadata-module=\"post\"\u003eSLOs, SLIs, SLAs, oh my - CRE life lessons\u003c/a\u003e.\u003c/p\u003e\u003ch3\u003e1. Service-Level Objective (SLO)\u003c/h3\u003e\u003cp\u003eSRE begins with the idea that \u003ca href=\"https://sre.google/sre-book/embracing-risk/\" target=\"_blank\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003eavailability is a prerequisite for success\u003c/a\u003e. An unavailable system can’t perform its function and will fail by default. Availability, in SRE terms, defines whether a system is able to fulfill its intended function at a point in time. In addition to its use as a reporting tool, the historical availability measurement can also describe the probability that your system will perform as expected in the future.\u003c/p\u003e\u003cp\u003eWhen we set out to define the terms of SRE, we wanted to set a precise numerical target for system availability. We term this target the availability \u003ca href=\"https://sre.google/sre-book/service-level-objectives/\" target=\"_blank\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003eService-Level Objective\u003c/a\u003e (SLO) of our system. Any future discussion about whether the system is running reliably and if any design or architectural changes to it are needed must be framed in terms of our system continuing to meet this SLO.\u003c/p\u003e\u003cp\u003eKeep in mind that the more reliable the service, the more it costs to operate. Define the lowest level of reliability that is acceptable for users of each service, then state that as your SLO. Every service should have an availability SLO—without it, your team and your stakeholders can’t make principled judgments about whether your service needs to be made more reliable (increasing cost and slowing development) or less reliable (allowing greater velocity of development). Excessive availability has become the expectation, which can lead to problems. Don’t make your system overly reliable if the user experience doesn’t necessitate it, and especially if you don’t intend to commit to always reaching that level. You can learn more about this by participating in \u003ca href=\"https://sre.google/resources/practices-and-processes/art-of-slos/\" target=\"_blank\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003eThe Art of SLOs\u003c/a\u003e training.\u003c/p\u003e\u003cp\u003e Within Google Cloud, we implement periodic downtime in some services to prevent a service from being overly available. You could also try experimenting with occasional planned-downtime exercises with front-end servers, as we did with one of our internal systems. We found that these exercises can uncover services that are using those servers inappropriately. With that information, you can then move workloads to a more suitable place and keep servers at the right availability level.\u003c/p\u003e\u003ch3\u003e2. Service-Level Agreement (SLA)\u003c/h3\u003e\u003cp\u003eAt Google Cloud, \u003ca href=\"https://sre.google/sre-book/service-level-objectives/\" target=\"_blank\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003ewe distinguish between an SLO and a Service-Level Agreement (SLA)\u003c/a\u003e. An SLA normally involves a promise to a service user that the service availability SLO should meet a certain level over a certain period. Failing to do so then results in some kind of penalty. This might be a partial refund of the service subscription fee paid by customers for that period, or additional subscription time added for free. Going out of SLO will hurt the service team, so they will push hard to stay within SLO. If you’re charging your customers money, you’ll probably need an SLA.\u003c/p\u003e\u003cp\u003eBecause of this, and because of the principle that availability shouldn’t be much better than the SLO, the availability SLO in the SLA is normally a looser objective than the internal availability SLO. This might be expressed in availability numbers: for instance, an availability SLO of 99.9% over one month, with an internal availability SLO of 99.95%. Alternatively, the SLA might only specify a subset of the metrics that make up the internal SLO.\u003c/p\u003e\u003cp\u003eIf you have an SLO in your SLA that is different from your internal SLO (as it almost always is), it’s important for your monitoring to explicitly measure SLO compliance. You want to be able to view your system’s availability over the SLA calendar period, and quickly see if it appears to be in danger of going out of SLO. \u003c/p\u003e\u003cp\u003eYou’ll also need a precise measurement of compliance, usually from logs analysis. Since we have an extra set of obligations (described in the SLA) to paying customers, we need to measure queries received from them separately from other queries. This is another benefit of establishing an SLA—it’s an unambiguous way to prioritize traffic.\u003c/p\u003e\u003cp\u003eWhen you define your SLA’s availability SLO, be careful about which queries you count as legitimate. For example, if a customer goes over quota because they released a buggy version of their mobile client, you may consider excluding all “out of quota” response codes from your SLA accounting.\u003c/p\u003e\u003ch3\u003e3. Service-Level Indicator (SLI)\u003c/h3\u003e\u003cp\u003eOur Service-Level Indicator (SLI) is a direct measurement of a service’s behavior, defined as the frequency of successful probes of our system. When we evaluate whether our system has been running within SLO for the past week, \u003ca href=\"https://cloud.google.com/blog/products/management-tools/tune-up-your-sli-metrics-cre-life-lessons\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/management-tools/tune-up-your-sli-metrics-cre-life-lessons\" track-metadata-module=\"post\"\u003ewe look at the SLI\u003c/a\u003e to get the service availability percentage. If it goes below the specified SLO, we have a problem and may need to make the system more available in some way, such as by running a second instance of the service in a different city and load-balancing between the two. If you want to know how reliable your service is, you must be able to measure the rates of successful and unsuccessful queries as your SLIs.\u003c/p\u003e\u003cp\u003eIf you’re building a system from scratch, make sure that SLIs and SLOs are part of your system requirements. If you already have a production system but don’t have them clearly defined, then that’s your highest priority work.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eA big part of \u003ca href=\"https://cloud.google.com/blog/products/gcp/available-or-not-that-is-the-question-cre-life-lessons\"\u003eensuring the availability of your applications\u003c/a\u003e is establishing and monitoring service-level metrics—something that our \u003ca href=\"https://sre.google/\" target=\"_blank\"\u003eSite Reliability Engineering\u003c/a\u003e (SRE) team does every day here at Google Cloud. The end goal of our SRE principles is to improve services and in turn the user experience.\u003c/p\u003e\u003cp\u003eThe concept of SRE starts with the idea that metrics should be closely tied to business objectives. In addition to business-level SLAs, we also use \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/availability-part-deux-cre-life-lessons\"\u003eSLOs and SLIs\u003c/a\u003e in SRE planning and practice. \u003c/p\u003e\u003ch2\u003eDefining the terms of site reliability engineering\u003c/h2\u003e\u003cp\u003eThese tools aren’t just useful abstractions. Without them, you won’t know if your system is reliable, available, or even useful. If the tools don’t tie back to your business objectives, then you’ll be missing data on whether your choices are helping or hurting your business.\u003c/p\u003e\u003cp\u003eAs a refresher, here’s a look at SLOs, SLAs, and SLIS, as discussed by our Customer Reliability Engineering team in their blog post, \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/availability-part-deux-cre-life-lessons\"\u003eSLOs, SLIs, SLAs, oh my - CRE life lessons\u003c/a\u003e.\u003c/p\u003e\u003ch3\u003e1. Service-Level Objective (SLO)\u003c/h3\u003e\u003cp\u003eSRE begins with the idea that \u003ca href=\"https://sre.google/sre-book/embracing-risk/\" target=\"_blank\"\u003eavailability is a prerequisite for success\u003c/a\u003e. An unavailable system can’t perform its function and will fail by default. Availability, in SRE terms, defines whether a system is able to fulfill its intended function at a point in time. In addition to its use as a reporting tool, the historical availability measurement can also describe the probability that your system will perform as expected in the future.\u003c/p\u003e\u003cp\u003eWhen we set out to define the terms of SRE, we wanted to set a precise numerical target for system availability. We term this target the availability \u003ca href=\"https://sre.google/sre-book/service-level-objectives/\" target=\"_blank\"\u003eService-Level Objective\u003c/a\u003e (SLO) of our system. Any future discussion about whether the system is running reliably and if any design or architectural changes to it are needed must be framed in terms of our system continuing to meet this SLO.\u003c/p\u003e\u003cp\u003eKeep in mind that the more reliable the service, the more it costs to operate. Define the lowest level of reliability that is acceptable for users of each service, then state that as your SLO. Every service should have an availability SLO—without it, your team and your stakeholders can’t make principled judgments about whether your service needs to be made more reliable (increasing cost and slowing development) or less reliable (allowing greater velocity of development). Excessive availability has become the expectation, which can lead to problems. Don’t make your system overly reliable if the user experience doesn’t necessitate it, and especially if you don’t intend to commit to always reaching that level. You can learn more about this by participating in \u003ca href=\"https://sre.google/resources/practices-and-processes/art-of-slos/\" target=\"_blank\"\u003eThe Art of SLOs\u003c/a\u003e training.\u003c/p\u003e\u003cp\u003e Within Google Cloud, we implement periodic downtime in some services to prevent a service from being overly available. You could also try experimenting with occasional planned-downtime exercises with front-end servers, as we did with one of our internal systems. We found that these exercises can uncover services that are using those servers inappropriately. With that information, you can then move workloads to a more suitable place and keep servers at the right availability level.\u003c/p\u003e\u003ch3\u003e2. Service-Level Agreement (SLA)\u003c/h3\u003e\u003cp\u003eAt Google Cloud, \u003ca href=\"https://sre.google/sre-book/service-level-objectives/\" target=\"_blank\"\u003ewe distinguish between an SLO and a Service-Level Agreement (SLA)\u003c/a\u003e. An SLA normally involves a promise to a service user that the service availability SLO should meet a certain level over a certain period. Failing to do so then results in some kind of penalty. This might be a partial refund of the service subscription fee paid by customers for that period, or additional subscription time added for free. Going out of SLO will hurt the service team, so they will push hard to stay within SLO. If you’re charging your customers money, you’ll probably need an SLA.\u003c/p\u003e\u003cp\u003eBecause of this, and because of the principle that availability shouldn’t be much better than the SLO, the availability SLO in the SLA is normally a looser objective than the internal availability SLO. This might be expressed in availability numbers: for instance, an availability SLO of 99.9% over one month, with an internal availability SLO of 99.95%. Alternatively, the SLA might only specify a subset of the metrics that make up the internal SLO.\u003c/p\u003e\u003cp\u003eIf you have an SLO in your SLA that is different from your internal SLO (as it almost always is), it’s important for your monitoring to explicitly measure SLO compliance. You want to be able to view your system’s availability over the SLA calendar period, and quickly see if it appears to be in danger of going out of SLO. \u003c/p\u003e\u003cp\u003eYou’ll also need a precise measurement of compliance, usually from logs analysis. Since we have an extra set of obligations (described in the SLA) to paying customers, we need to measure queries received from them separately from other queries. This is another benefit of establishing an SLA—it’s an unambiguous way to prioritize traffic.\u003c/p\u003e\u003cp\u003eWhen you define your SLA’s availability SLO, be careful about which queries you count as legitimate. For example, if a customer goes over quota because they released a buggy version of their mobile client, you may consider excluding all “out of quota” response codes from your SLA accounting.\u003c/p\u003e\u003ch3\u003e3. Service-Level Indicator (SLI)\u003c/h3\u003e\u003cp\u003eOur Service-Level Indicator (SLI) is a direct measurement of a service’s behavior, defined as the frequency of successful probes of our system. When we evaluate whether our system has been running within SLO for the past week, \u003ca href=\"https://cloud.google.com/blog/products/management-tools/tune-up-your-sli-metrics-cre-life-lessons\"\u003ewe look at the SLI\u003c/a\u003e to get the service availability percentage. If it goes below the specified SLO, we have a problem and may need to make the system more available in some way, such as by running a second instance of the service in a different city and load-balancing between the two. If you want to know how reliable your service is, you must be able to measure the rates of successful and unsuccessful queries as your SLIs.\u003c/p\u003e\u003cp\u003eIf you’re building a system from scratch, make sure that SLIs and SLOs are part of your system requirements. If you already have a production system but don’t have them clearly defined, then that’s your highest priority work.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Monitoring_sZG2gQO.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Cloud Monitoring.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Cloud_Monitoring_sZG2gQO.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003cfigcaption class=\"article-image__caption \"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ci\u003e\u003ca href=\"https://cloud.google.com/monitoring\"\u003eCloud Monitoring\u003c/a\u003e provides predefined dashboards for the Google Cloud services that you use. These dashboards require no setup or configuration effort. Learn how to set SLOs in Cloud Monitoring \u003ca href=\"https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring/ui/create-slo\"\u003ehere\u003c/a\u003e.\u003c/i\u003e\u003c/div\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eLearn more about these concepts in our \u003ca href=\"https://cloud.google.com/blog/products/management-tools/practical-guide-to-setting-slos\"\u003epractical guide to setting SLOs\u003c/a\u003e, and make use of our \u003ca href=\"https://sre.google/resources/practices-and-processes/art-of-slos/\" target=\"_blank\"\u003eshared training materials\u003c/a\u003e to teach others in your organization.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/sre-at-google-our-complete-list-of-cre-life-lessons/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_D_Rnd3.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eSRE at Google: Our complete list of CRE life lessons\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eFind links to blog posts that share Google’s SRE best practices in one handy location.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_B_Rnd3.max-2200x2200.jpg",
      "date_published": "2021-05-07T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eAdrian Hilton\u003c/name\u003e\u003ctitle\u003eCustomer Reliability Engineer, SRE\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/take-2021-state-devops-survey-shape-future-devops/",
      "title": "Take the 2021 State of DevOps survey: Shape the future of DevOps",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Today, Google Cloud and the \u0026lt;a href=\u0026#34;https://www.devops-research.com/research.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;DORA\u0026lt;/a\u0026gt; research team are excited to announce the launch of the \u0026lt;a href=\u0026#34;https://google.qualtrics.com/jfe/form/SV_cIb0SmhJPfm8H7n\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;2021 State of DevOps survey\u0026lt;/a\u0026gt;. The \u0026lt;a href=\u0026#34;https://google.qualtrics.com/jfe/form/SV_cIb0SmhJPfm8H7n\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;survey\u0026lt;/a\u0026gt; takes approximately 25 minutes to complete and we\u0026amp;#8217;d love to hear from you. Your answers will allow us to better understand the practices that teams are employing to improve software delivery performance and inturn generate powerful business outcomes.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The \u0026lt;a href=\u0026#34;https://cloud.google.com/devops#read-dora%E2%80%99s-state-of-devops-reports-and-devops-roi-whitepaper\u0026#34;\u0026gt;State of DevOps report\u0026lt;/a\u0026gt; by Google Cloud and the DORA research team is the largest and longest running research of its kind. It provides an independent view into the practices and capabilities that organizations, irrespective of their size, industry, and region can employ to drive better performance.\u0026amp;#160;\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Like the past six research reports, our goal this year is to perform detailed analysis to help various teams benchmark their performance against the industry as elite, high, medium, or low performers. We also look to show specific strategies that teams can employ to improve their performance.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The table below highlights elite, high, medium, and low performers at a glance from the \u0026lt;a href=\u0026#34;https://cloud.google.com/devops/state-of-devops\u0026#34;\u0026gt;last report.\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eToday, Google Cloud and the \u003ca href=\"https://www.devops-research.com/research.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://www.devops-research.com\" track-metadata-module=\"post\"\u003eDORA\u003c/a\u003e research team are excited to announce the launch of the \u003ca href=\"https://google.qualtrics.com/jfe/form/SV_cIb0SmhJPfm8H7n\" target=\"_blank\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://google.qualtrics.com\" track-metadata-module=\"post\"\u003e2021 State of DevOps survey\u003c/a\u003e. The \u003ca href=\"https://google.qualtrics.com/jfe/form/SV_cIb0SmhJPfm8H7n\" target=\"_blank\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://google.qualtrics.com\" track-metadata-module=\"post\"\u003esurvey\u003c/a\u003e takes approximately 25 minutes to complete and we’d love to hear from you. Your answers will allow us to better understand the practices that teams are employing to improve software delivery performance and inturn generate powerful business outcomes.\u003c/p\u003e\u003cp\u003eThe \u003ca href=\"https://cloud.google.com/devops#read-dora%E2%80%99s-state-of-devops-reports-and-devops-roi-whitepaper\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/devops#read-dora%E2%80%99s-state-of-devops-reports-and-devops-roi-whitepaper\" track-metadata-module=\"post\"\u003eState of DevOps report\u003c/a\u003e by Google Cloud and the DORA research team is the largest and longest running research of its kind. It provides an independent view into the practices and capabilities that organizations, irrespective of their size, industry, and region can employ to drive better performance.  \u003c/p\u003e\u003cp\u003eLike the past six research reports, our goal this year is to perform detailed analysis to help various teams benchmark their performance against the industry as elite, high, medium, or low performers. We also look to show specific strategies that teams can employ to improve their performance. \u003c/p\u003e\u003cp\u003eThe table below highlights elite, high, medium, and low performers at a glance from the \u003ca href=\"https://cloud.google.com/devops/state-of-devops\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/devops/state-of-devops\" track-metadata-module=\"post\"\u003elast report.\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eToday, Google Cloud and the \u003ca href=\"https://www.devops-research.com/research.html\" target=\"_blank\"\u003eDORA\u003c/a\u003e research team are excited to announce the launch of the \u003ca href=\"https://google.qualtrics.com/jfe/form/SV_cIb0SmhJPfm8H7n\" target=\"_blank\"\u003e2021 State of DevOps survey\u003c/a\u003e. The \u003ca href=\"https://google.qualtrics.com/jfe/form/SV_cIb0SmhJPfm8H7n\" target=\"_blank\"\u003esurvey\u003c/a\u003e takes approximately 25 minutes to complete and we’d love to hear from you. Your answers will allow us to better understand the practices that teams are employing to improve software delivery performance and inturn generate powerful business outcomes.\u003c/p\u003e\u003cp\u003eThe \u003ca href=\"https://cloud.google.com/devops#read-dora%E2%80%99s-state-of-devops-reports-and-devops-roi-whitepaper\"\u003eState of DevOps report\u003c/a\u003e by Google Cloud and the DORA research team is the largest and longest running research of its kind. It provides an independent view into the practices and capabilities that organizations, irrespective of their size, industry, and region can employ to drive better performance.  \u003c/p\u003e\u003cp\u003eLike the past six research reports, our goal this year is to perform detailed analysis to help various teams benchmark their performance against the industry as elite, high, medium, or low performers. We also look to show specific strategies that teams can employ to improve their performance. \u003c/p\u003e\u003cp\u003eThe table below highlights elite, high, medium, and low performers at a glance from the \u003ca href=\"https://cloud.google.com/devops/state-of-devops\"\u003elast report.\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"dora2\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Screen_Shot_2021-05-03_at_12.43.32_AM.max-1000x1000.png\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eAchieving elite performance is a team endeavor and diverse, inclusive teams drive the best performance. The research program benefits from the participation of a diverse group of people. Please help us encourage more voices by sharing this survey with your network, especially with your colleagues from underrepresented parts of our industry. \u003c/p\u003e\u003cp\u003eThe \u003ca href=\"https://google.qualtrics.com/jfe/form/SV_cIb0SmhJPfm8H7n\" target=\"_blank\"\u003esurvey\u003c/a\u003e is for everyone, regardless of where you are on your DevOps journey, the size of your organization, or your organization's industry. There are no right or wrong answers, in fact we often hear feedback that questions in the survey prompt ideas for improvement. Many of these ideas can be put into practice immediately. \u003c/p\u003e\u003cp\u003eSome of the key topics we look to deep dive into this year include:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eMetrics and Measurement: Practices employed by high performing teams \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eSRE and DevOps: How do they fit together and how they impact performance\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eHow to best integrate security \u0026amp; compliance as a part of your app development \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eThe impact of cloud, monitoring \u0026amp; observability, open source, and documentation on performance\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDistributed teams: Practices to improve work/life balance and reduce burnout\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eThe state of multi-cloud computing \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eHelp us shape the future of DevOps and make your voice heard by completing the \u003ca href=\"https://google.qualtrics.com/jfe/form/SV_cIb0SmhJPfm8H7n\" target=\"_blank\"\u003esurvey now\u003c/a\u003e. \u003c/p\u003e\u003cp\u003e\u003ca href=\"https://google.qualtrics.com/jfe/form/SV_cIb0SmhJPfm8H7n\" target=\"_blank\"\u003eThe survey\u003c/a\u003e will remain open until midnight PST on July 2, 2021. We look forward to hearing from you. \u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/WorkplaceTransformation-01_TjiwJTd.max-1000x1000.png",
      "date_published": "2021-05-03T13:50:00Z",
      "author": {
        "name": "\u003cname\u003eDustin Smith\u003c/name\u003e\u003ctitle\u003eDORA Research Lead\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/sre-at-google-our-complete-list-of-cre-life-lessons/",
      "title": "SRE at Google: Our complete list of CRE life lessons",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;In 2016 we announced a new discipline at Google, \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/introducing-a-new-era-of-customer-support-google-customer-reliability-engineering\u0026#34;\u0026gt;Customer Reliability Engineering\u0026lt;/a\u0026gt;, an offshoot of \u0026lt;a href=\u0026#34;https://sre.google/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Site Reliability Engineering\u0026lt;/a\u0026gt; (SRE). Our goal with CRE was (and still is) to create a shared operational fate between Google and our Google Cloud customers, to give you more control over the critical applications you\u0026#39;re entrusting to us. Since then, here on the Google Cloud blog, we\u0026amp;#8217;ve published a wealth of resources to help you take the best practices we\u0026amp;#8217;ve learned from SRE teams at Google and apply them in your own environments.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Below is the complete list of CRE life lessons posts we\u0026amp;#8217;ve published \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/topics/cre-life-lessons\u0026#34;\u0026gt;in the past five years\u0026lt;/a\u0026gt; in one convenient location.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Common pitfalls\u0026lt;/h3\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/know-thy-enemy-how-to-prioritize-and-communicate-risks-cre-life-lessons\u0026#34;\u0026gt;Know thy enemy: How to prioritize and communicate risks\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/how-to-avoid-a-self-inflicted-ddos-attack-cre-life-lessons\u0026#34;\u0026gt;How to avoid a self-inflicted DDoS Attack\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/using-load-shedding-to-survive-a-success-disaster-cre-life-lessons\u0026#34;\u0026gt;Using load shedding to survive a success disaster\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;h3\u0026gt;Service-level metrics\u0026lt;/h3\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/available-or-not-that-is-the-question-cre-life-lessons\u0026#34;\u0026gt;Available . . . or not? That is the question\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/availability-part-deux-cre-life-lessons\u0026#34;\u0026gt;SLOs, SLIs, SLAs, oh my\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/building-good-slos-cre-life-lessons\u0026#34;\u0026gt;Building good SLOs\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/consequences-of-slo-violations-cre-life-lessons\u0026#34;\u0026gt;Consequences of SLO violations\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/an-example-escalation-policy-cre-life-lessons\u0026#34;\u0026gt;An example escalation policy\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/applying-the-escalation-policy-cre-life-lessons\u0026#34;\u0026gt;Applying the escalation policy\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/defining-slos-for-services-with-dependencies-cre-life-lessons\u0026#34;\u0026gt;Defining SLOs for services with dependencies\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/management-tools/tune-up-your-sli-metrics-cre-life-lessons\u0026#34;\u0026gt;Tune up your SLI metrics\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/management-tools/learn-how-to-set-slos-for-an-sre-or-cre-practice\u0026#34;\u0026gt;Learning\u0026amp;#8212;and teaching\u0026amp;#8212;the art of service-level objectives\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/management-tools/using-deemed-slis-to-measure-customer-reliability\u0026#34;\u0026gt;Using deemed SLIs to measure customer reliability\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;h3\u0026gt;Releases\u0026lt;/h3\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/reliable-releases-and-rollbacks-cre-life-lessons\u0026#34;\u0026gt;Reliable releases and rollbacks\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/how-release-canaries-can-save-your-bacon-cre-life-lessons\u0026#34;\u0026gt;How release canaries can save your bacon\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;h3\u0026gt;SRE support\u0026lt;/h3\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/why-should-your-app-get-sre-support-cre-life-lessons\u0026#34;\u0026gt;Why should your app get SRE support?\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/how-sres-find-the-landmines-in-a-service-cre-life-lessons\u0026#34;\u0026gt;How SREs find the landmines in a service\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/making-the-most-of-an-sre-service-takeover-cre-life-lessons\u0026#34;\u0026gt;Making the most of an SRE service takeover\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;h3\u0026gt;Dark launches\u0026lt;/h3\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/cre-life-lessons-what-is-a-dark-launch-and-what-does-it-do-for-me\u0026#34;\u0026gt;What is a dark launch, and what does it do for me?\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/cre-life-lessons-practicalities-of-dark-launches\u0026#34;\u0026gt;The practicalities of dark launching\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;h3\u0026gt;Postmortems\u0026lt;/h3\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/fearless-shared-postmortems-cre-life-lessons\u0026#34;\u0026gt;Fearless shared postmortems\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/getting-the-most-out-of-shared-postmortems-cre-life-lessons\u0026#34;\u0026gt;Getting the most out of shared postmortems\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;h3\u0026gt;Error budgets\u0026lt;/h3\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/good-housekeeping-error-budgetscre-life-lessons\u0026#34;\u0026gt;Good housekeeping for error budgets\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/gcp/understanding-error-budget-overspend-cre-life-lessons\u0026#34;\u0026gt;Understanding error budget overspend\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;h3\u0026gt;Production incidents\u0026lt;/h3\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/shrinking-the-impact-of-production-incidents-using-sre-principles-cre-life-lessons\u0026#34;\u0026gt;Shrinking the impact of production incidents using SRE principles\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/management-tools/shrinking-the-time-to-mitigate-production-incidents\u0026#34;\u0026gt;Shrinking the time to mitigate production incidents\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Becoming an SRE team\u0026lt;/h3\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/sre-success-starts-with-getting-leadership-on-board\u0026#34;\u0026gt;How to implement a successful SRE practice from the outset\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/four-steps-to-jumpstarting-your-sre-practice\u0026#34;\u0026gt;Jumpstarting your SRE practice\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/evaluating-where-your-team-lies-on-the-sre-spectrum\u0026#34;\u0026gt;Assessing an SRE team\u0026amp;#8217;s maturity\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;We still have plenty more articles to come, so keep your eye on our \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre\u0026#34;\u0026gt;DevOps \u0026amp;amp; SRE channel\u0026lt;/a\u0026gt;. You can also check out \u0026lt;a href=\u0026#34;http://sre.google\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;sre.google\u0026lt;/a\u0026gt; or \u0026lt;a href=\u0026#34;https://sre.google/books/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;read our SRE books online\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eIn 2016 we announced a new discipline at Google, \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/introducing-a-new-era-of-customer-support-google-customer-reliability-engineering\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/introducing-a-new-era-of-customer-support-google-customer-reliability-engineering\" track-metadata-module=\"post\"\u003eCustomer Reliability Engineering\u003c/a\u003e, an offshoot of \u003ca href=\"https://sre.google/\" target=\"_blank\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003eSite Reliability Engineering\u003c/a\u003e (SRE). Our goal with CRE was (and still is) to create a shared operational fate between Google and our Google Cloud customers, to give you more control over the critical applications you\u0026#39;re entrusting to us. Since then, here on the Google Cloud blog, we’ve published a wealth of resources to help you take the best practices we’ve learned from SRE teams at Google and apply them in your own environments. \u003c/p\u003e\u003cp\u003eBelow is the complete list of CRE life lessons posts we’ve published \u003ca href=\"https://cloud.google.com/blog/topics/cre-life-lessons\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/blog/topics/cre-life-lessons\" track-metadata-module=\"post\"\u003ein the past five years\u003c/a\u003e in one convenient location.\u003c/p\u003e\u003ch3\u003eCommon pitfalls\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/know-thy-enemy-how-to-prioritize-and-communicate-risks-cre-life-lessons\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/know-thy-enemy-how-to-prioritize-and-communicate-risks-cre-life-lessons\" track-metadata-module=\"post\"\u003eKnow thy enemy: How to prioritize and communicate risks\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/how-to-avoid-a-self-inflicted-ddos-attack-cre-life-lessons\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/how-to-avoid-a-self-inflicted-ddos-attack-cre-life-lessons\" track-metadata-module=\"post\"\u003eHow to avoid a self-inflicted DDoS Attack\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/using-load-shedding-to-survive-a-success-disaster-cre-life-lessons\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/using-load-shedding-to-survive-a-success-disaster-cre-life-lessons\" track-metadata-module=\"post\"\u003eUsing load shedding to survive a success disaster\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eService-level metrics\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/available-or-not-that-is-the-question-cre-life-lessons\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/available-or-not-that-is-the-question-cre-life-lessons\" track-metadata-module=\"post\"\u003eAvailable . . . or not? That is the question\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/devops-sre/availability-part-deux-cre-life-lessons\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/availability-part-deux-cre-life-lessons\" track-metadata-module=\"post\"\u003eSLOs, SLIs, SLAs, oh my\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/building-good-slos-cre-life-lessons\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/building-good-slos-cre-life-lessons\" track-metadata-module=\"post\"\u003eBuilding good SLOs\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/consequences-of-slo-violations-cre-life-lessons\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/consequences-of-slo-violations-cre-life-lessons\" track-metadata-module=\"post\"\u003eConsequences of SLO violations\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/an-example-escalation-policy-cre-life-lessons\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/an-example-escalation-policy-cre-life-lessons\" track-metadata-module=\"post\"\u003eAn example escalation policy\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/applying-the-escalation-policy-cre-life-lessons\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/applying-the-escalation-policy-cre-life-lessons\" track-metadata-module=\"post\"\u003eApplying the escalation policy\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/devops-sre/defining-slos-for-services-with-dependencies-cre-life-lessons\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/defining-slos-for-services-with-dependencies-cre-life-lessons\" track-metadata-module=\"post\"\u003eDefining SLOs for services with dependencies\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/management-tools/tune-up-your-sli-metrics-cre-life-lessons\" track-type=\"inline link\" track-name=\"14\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/management-tools/tune-up-your-sli-metrics-cre-life-lessons\" track-metadata-module=\"post\"\u003eTune up your SLI metrics\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/management-tools/learn-how-to-set-slos-for-an-sre-or-cre-practice\" track-type=\"inline link\" track-name=\"15\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/management-tools/learn-how-to-set-slos-for-an-sre-or-cre-practice\" track-metadata-module=\"post\"\u003eLearning—and teaching—the art of service-level objectives\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/management-tools/using-deemed-slis-to-measure-customer-reliability\" track-type=\"inline link\" track-name=\"16\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/management-tools/using-deemed-slis-to-measure-customer-reliability\" track-metadata-module=\"post\"\u003eUsing deemed SLIs to measure customer reliability\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eReleases\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/reliable-releases-and-rollbacks-cre-life-lessons\" track-type=\"inline link\" track-name=\"17\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/reliable-releases-and-rollbacks-cre-life-lessons\" track-metadata-module=\"post\"\u003eReliable releases and rollbacks\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/how-release-canaries-can-save-your-bacon-cre-life-lessons\" track-type=\"inline link\" track-name=\"18\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/how-release-canaries-can-save-your-bacon-cre-life-lessons\" track-metadata-module=\"post\"\u003eHow release canaries can save your bacon\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eSRE support\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/why-should-your-app-get-sre-support-cre-life-lessons\" track-type=\"inline link\" track-name=\"19\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/why-should-your-app-get-sre-support-cre-life-lessons\" track-metadata-module=\"post\"\u003eWhy should your app get SRE support?\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/how-sres-find-the-landmines-in-a-service-cre-life-lessons\" track-type=\"inline link\" track-name=\"20\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/how-sres-find-the-landmines-in-a-service-cre-life-lessons\" track-metadata-module=\"post\"\u003eHow SREs find the landmines in a service\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/making-the-most-of-an-sre-service-takeover-cre-life-lessons\" track-type=\"inline link\" track-name=\"21\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/making-the-most-of-an-sre-service-takeover-cre-life-lessons\" track-metadata-module=\"post\"\u003eMaking the most of an SRE service takeover\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eDark launches\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/cre-life-lessons-what-is-a-dark-launch-and-what-does-it-do-for-me\" track-type=\"inline link\" track-name=\"22\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/cre-life-lessons-what-is-a-dark-launch-and-what-does-it-do-for-me\" track-metadata-module=\"post\"\u003eWhat is a dark launch, and what does it do for me?\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/cre-life-lessons-practicalities-of-dark-launches\" track-type=\"inline link\" track-name=\"23\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/cre-life-lessons-practicalities-of-dark-launches\" track-metadata-module=\"post\"\u003eThe practicalities of dark launching\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003ePostmortems\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/fearless-shared-postmortems-cre-life-lessons\" track-type=\"inline link\" track-name=\"24\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/fearless-shared-postmortems-cre-life-lessons\" track-metadata-module=\"post\"\u003eFearless shared postmortems\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/getting-the-most-out-of-shared-postmortems-cre-life-lessons\" track-type=\"inline link\" track-name=\"25\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/getting-the-most-out-of-shared-postmortems-cre-life-lessons\" track-metadata-module=\"post\"\u003eGetting the most out of shared postmortems\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eError budgets\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/devops-sre/good-housekeeping-error-budgetscre-life-lessons\" track-type=\"inline link\" track-name=\"26\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/good-housekeeping-error-budgetscre-life-lessons\" track-metadata-module=\"post\"\u003eGood housekeeping for error budgets\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/understanding-error-budget-overspend-cre-life-lessons\" track-type=\"inline link\" track-name=\"27\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/gcp/understanding-error-budget-overspend-cre-life-lessons\" track-metadata-module=\"post\"\u003eUnderstanding error budget overspend\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eProduction incidents\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/devops-sre/shrinking-the-impact-of-production-incidents-using-sre-principles-cre-life-lessons\" track-type=\"inline link\" track-name=\"28\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/shrinking-the-impact-of-production-incidents-using-sre-principles-cre-life-lessons\" track-metadata-module=\"post\"\u003eShrinking the impact of production incidents using SRE principles\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/management-tools/shrinking-the-time-to-mitigate-production-incidents\" track-type=\"inline link\" track-name=\"29\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/management-tools/shrinking-the-time-to-mitigate-production-incidents\" track-metadata-module=\"post\"\u003eShrinking the time to mitigate production incidents\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eBecoming an SRE team\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/devops-sre/sre-success-starts-with-getting-leadership-on-board\" track-type=\"inline link\" track-name=\"30\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/sre-success-starts-with-getting-leadership-on-board\" track-metadata-module=\"post\"\u003eHow to implement a successful SRE practice from the outset\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/devops-sre/four-steps-to-jumpstarting-your-sre-practice\" track-type=\"inline link\" track-name=\"31\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/four-steps-to-jumpstarting-your-sre-practice\" track-metadata-module=\"post\"\u003eJumpstarting your SRE practice\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/devops-sre/evaluating-where-your-team-lies-on-the-sre-spectrum\" track-type=\"inline link\" track-name=\"32\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/evaluating-where-your-team-lies-on-the-sre-spectrum\" track-metadata-module=\"post\"\u003eAssessing an SRE team’s maturity\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eWe still have plenty more articles to come, so keep your eye on our \u003ca href=\"https://cloud.google.com/blog/products/devops-sre\" track-type=\"inline link\" track-name=\"33\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre\" track-metadata-module=\"post\"\u003eDevOps \u0026amp; SRE channel\u003c/a\u003e. You can also check out \u003ca href=\"http://sre.google\" target=\"_blank\" track-type=\"inline link\" track-name=\"34\" track-metadata-eventdetail=\"http://sre.google\" track-metadata-module=\"post\"\u003esre.google\u003c/a\u003e or \u003ca href=\"https://sre.google/books/\" target=\"_blank\" track-type=\"inline link\" track-name=\"35\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003eread our SRE books online\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIn 2016 we announced a new discipline at Google, \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/introducing-a-new-era-of-customer-support-google-customer-reliability-engineering\"\u003eCustomer Reliability Engineering\u003c/a\u003e, an offshoot of \u003ca href=\"https://sre.google/\" target=\"_blank\"\u003eSite Reliability Engineering\u003c/a\u003e (SRE). Our goal with CRE was (and still is) to create a shared operational fate between Google and our Google Cloud customers, to give you more control over the critical applications you're entrusting to us. Since then, here on the Google Cloud blog, we’ve published a wealth of resources to help you take the best practices we’ve learned from SRE teams at Google and apply them in your own environments. \u003c/p\u003e\u003cp\u003eBelow is the complete list of CRE life lessons posts we’ve published \u003ca href=\"https://cloud.google.com/blog/topics/cre-life-lessons\"\u003ein the past five years\u003c/a\u003e in one convenient location.\u003c/p\u003e\u003ch3\u003eCommon pitfalls\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/know-thy-enemy-how-to-prioritize-and-communicate-risks-cre-life-lessons\"\u003eKnow thy enemy: How to prioritize and communicate risks\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/how-to-avoid-a-self-inflicted-ddos-attack-cre-life-lessons\"\u003eHow to avoid a self-inflicted DDoS Attack\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/using-load-shedding-to-survive-a-success-disaster-cre-life-lessons\"\u003eUsing load shedding to survive a success disaster\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eService-level metrics\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/available-or-not-that-is-the-question-cre-life-lessons\"\u003eAvailable . . . or not? That is the question\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/devops-sre/availability-part-deux-cre-life-lessons\"\u003eSLOs, SLIs, SLAs, oh my\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/building-good-slos-cre-life-lessons\"\u003eBuilding good SLOs\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/consequences-of-slo-violations-cre-life-lessons\"\u003eConsequences of SLO violations\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/an-example-escalation-policy-cre-life-lessons\"\u003eAn example escalation policy\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/applying-the-escalation-policy-cre-life-lessons\"\u003eApplying the escalation policy\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/devops-sre/defining-slos-for-services-with-dependencies-cre-life-lessons\"\u003eDefining SLOs for services with dependencies\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/management-tools/tune-up-your-sli-metrics-cre-life-lessons\"\u003eTune up your SLI metrics\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/management-tools/learn-how-to-set-slos-for-an-sre-or-cre-practice\"\u003eLearning—and teaching—the art of service-level objectives\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/management-tools/using-deemed-slis-to-measure-customer-reliability\"\u003eUsing deemed SLIs to measure customer reliability\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eReleases\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/reliable-releases-and-rollbacks-cre-life-lessons\"\u003eReliable releases and rollbacks\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/how-release-canaries-can-save-your-bacon-cre-life-lessons\"\u003eHow release canaries can save your bacon\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eSRE support\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/why-should-your-app-get-sre-support-cre-life-lessons\"\u003eWhy should your app get SRE support?\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/how-sres-find-the-landmines-in-a-service-cre-life-lessons\"\u003eHow SREs find the landmines in a service\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/making-the-most-of-an-sre-service-takeover-cre-life-lessons\"\u003eMaking the most of an SRE service takeover\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eDark launches\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/cre-life-lessons-what-is-a-dark-launch-and-what-does-it-do-for-me\"\u003eWhat is a dark launch, and what does it do for me?\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/cre-life-lessons-practicalities-of-dark-launches\"\u003eThe practicalities of dark launching\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003ePostmortems\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/fearless-shared-postmortems-cre-life-lessons\"\u003eFearless shared postmortems\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/getting-the-most-out-of-shared-postmortems-cre-life-lessons\"\u003eGetting the most out of shared postmortems\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eError budgets\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/devops-sre/good-housekeeping-error-budgetscre-life-lessons\"\u003eGood housekeeping for error budgets\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/gcp/understanding-error-budget-overspend-cre-life-lessons\"\u003eUnderstanding error budget overspend\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eProduction incidents\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/devops-sre/shrinking-the-impact-of-production-incidents-using-sre-principles-cre-life-lessons\"\u003eShrinking the impact of production incidents using SRE principles\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/management-tools/shrinking-the-time-to-mitigate-production-incidents\"\u003eShrinking the time to mitigate production incidents\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003c/p\u003e\u003ch3\u003eBecoming an SRE team\u003c/h3\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/devops-sre/sre-success-starts-with-getting-leadership-on-board\"\u003eHow to implement a successful SRE practice from the outset\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/devops-sre/four-steps-to-jumpstarting-your-sre-practice\"\u003eJumpstarting your SRE practice\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/blog/products/devops-sre/evaluating-where-your-team-lies-on-the-sre-spectrum\"\u003eAssessing an SRE team’s maturity\u003c/a\u003e\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003e\u003c/p\u003e\u003cp\u003eWe still have plenty more articles to come, so keep your eye on our \u003ca href=\"https://cloud.google.com/blog/products/devops-sre\"\u003eDevOps \u0026amp; SRE channel\u003c/a\u003e. You can also check out \u003ca href=\"http://sre.google\" target=\"_blank\"\u003esre.google\u003c/a\u003e or \u003ca href=\"https://sre.google/books/\" target=\"_blank\"\u003eread our SRE books online\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/sre-fundamentals-sli-vs-slo-vs-sla/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_D_Rnd3.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eSRE fundamentals 2021: SLIs vs SLAs vs SLOs\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eWhat’s the difference between an SLI, an SLO and an SLA? Google Site Reliability Engineers (SRE) explain.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_D_Rnd3.max-2200x2200.jpg",
      "date_published": "2021-04-27T20:00:00Z",
      "author": {
        "name": "\u003cname\u003eThe Google Cloud content marketing team \u003c/name\u003e\u003ctitle\u003e\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/containers-kubernetes/how-configuration-as-data-impacts-policy/",
      "title": "Sign here! Creating a policy contract with Configuration as Data",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003crouter-outlet\u003e\u003c/router-outlet\u003e\u003cdynamic-page\u003e\u003carticle-page\u003e\u003cmain id=\"jump-content\"\u003e\u003carticle\u003e\u003carticle-header-block\u003e\u003c/article-header-block\u003e\u003carticle-aspect-image-block\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003e#containers\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/article-aspect-image-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-author-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003cp\u003e Mark Balch \u003c/p\u003e\u003cp\u003e Senior Product Manager, Google Cloud \u003c/p\u003e\u003c/div\u003e\u003cp\u003e\u003cspan\u003e April 26, 2021 \u003c/span\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-author-block\u003e\u003c/div\u003e\u003carticle-cta _nghost-c17=\"\"\u003e\u003cdiv _ngcontent-c17=\"\"\u003e\u003ch4 _ngcontent-c17=\"\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eTry GCP\u003c/span\u003e\u003c/h4\u003e\u003cp _ngcontent-c17=\"\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eStart building on Google Cloud with $300 in free credits and 20+ always free products.\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003ca _ngcontent-c17=\"\" clicktracker=\"\" rel=\"external\" track-metadata-module=\"article cta\" track-type=\"button\" track-name=\"free trial\" track-metadata-eventdetail=\"https://cloud.google.com/free/\" href=\"https://cloud.google.com/free/\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eFree Trial\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-cta\u003e\u003c/div\u003e\u003carticle-share-block\u003e\u003c/article-share-block\u003e\u003carticle-sticky-share-block\u003e\u003c/article-sticky-share-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-content-stream-block\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Configuration as Data is an emerging cloud infrastructure management paradigm that allows developers to \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/containers-kubernetes/understanding-configuration-as-data-in-kubernetes\u0026#34;\u0026gt;declare the desired state\u0026lt;/a\u0026gt; of their applications and infrastructure, without specifying the precise actions or steps for how to achieve it. However, declaring a configuration is only half the battle: you also want policy that defines how a configuration is to be used.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Configuration as Data enables a normalized policy contract across all your cloud resources. That contract, knowing how your deployment will operate, can be inspected and enforced throughout a CI/CD pipeline, from upstream in your development environment to deployment time, and ongoing in the live runtime environment. This consistency is possible by expressing configuration as data throughout the development and operations lifecycle.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://cloud.google.com/config-connector/docs/overview\u0026#34;\u0026gt;Config Connector\u0026lt;/a\u0026gt; is the tool that allows you to express configuration as data in Google Cloud. In this model, configuration is what you want to deploy, such as \u0026amp;#8220;a storage bucket named \u0026lt;code\u0026gt;my-bucket\u0026lt;/code\u0026gt; with a standard storage class and uniform access control.\u0026amp;#8221;\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Policy, meanwhile, typically specifies what you\u0026amp;#8217;re allowed to deploy, usually in conformance with your organization\u0026amp;#8217;s compliance needs. For example, \u0026amp;#8220;all resources must be deployed in Google Cloud\u0026amp;#8217;s \u0026lt;code\u0026gt;LONDON\u0026lt;/code\u0026gt; region.\u0026amp;#8221;\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;When each stage in your pipeline treats configuration as data, you can use any tool or language to manipulate configuration as data, knowing they will interoperate and that policy can be consistently enforced at any or all stages. And while a policy engine won\u0026amp;#8217;t be able to understand every tool, it can validate the data generated by each tool. It\u0026amp;#8217;s just like data in a database can be inspected by anyone who knows the schema regardless of the tool that wrote into the database.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Contrast that with pipelines today, where policy is manually validated, hard coded in scripts within the pipeline logic itself, or post-processed on raw deployment artifacts after rendering configuration templates into specific instances. In each case, policy is siloed\u0026amp;#8212;you can\u0026amp;#8217;t take the same policy and apply it anywhere in your pipeline because formats differ from tool to tool.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Helm, for example, contains code \u0026lt;a href=\u0026#34;https://helm.sh/docs/chart_template_guide/control_structures/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;specific to its own format\u0026lt;/a\u0026gt;.\u0026lt;sup\u0026gt;1\u0026lt;/sup\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eConfiguration as Data is an emerging cloud infrastructure management paradigm that allows developers to \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/understanding-configuration-as-data-in-kubernetes\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/containers-kubernetes/understanding-configuration-as-data-in-kubernetes\" track-metadata-module=\"post\"\u003edeclare the desired state\u003c/a\u003e of their applications and infrastructure, without specifying the precise actions or steps for how to achieve it. However, declaring a configuration is only half the battle: you also want policy that defines how a configuration is to be used. \u003c/p\u003e\u003cp\u003eConfiguration as Data enables a normalized policy contract across all your cloud resources. That contract, knowing how your deployment will operate, can be inspected and enforced throughout a CI/CD pipeline, from upstream in your development environment to deployment time, and ongoing in the live runtime environment. This consistency is possible by expressing configuration as data throughout the development and operations lifecycle.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/config-connector/docs/overview\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/config-connector/docs/overview\" track-metadata-module=\"post\"\u003eConfig Connector\u003c/a\u003e is the tool that allows you to express configuration as data in Google Cloud. In this model, configuration is what you want to deploy, such as “a storage bucket named \u003ccode\u003emy-bucket\u003c/code\u003e with a standard storage class and uniform access control.” \u003c/p\u003e\u003cp\u003ePolicy, meanwhile, typically specifies what you’re allowed to deploy, usually in conformance with your organization’s compliance needs. For example, “all resources must be deployed in Google Cloud’s \u003ccode\u003eLONDON\u003c/code\u003e region.” \u003c/p\u003e\u003cp\u003eWhen each stage in your pipeline treats configuration as data, you can use any tool or language to manipulate configuration as data, knowing they will interoperate and that policy can be consistently enforced at any or all stages. And while a policy engine won’t be able to understand every tool, it can validate the data generated by each tool. It’s just like data in a database can be inspected by anyone who knows the schema regardless of the tool that wrote into the database.\u003c/p\u003e\u003cp\u003eContrast that with pipelines today, where policy is manually validated, hard coded in scripts within the pipeline logic itself, or post-processed on raw deployment artifacts after rendering configuration templates into specific instances. In each case, policy is siloed—you can’t take the same policy and apply it anywhere in your pipeline because formats differ from tool to tool. \u003c/p\u003e\u003cp\u003eHelm, for example, contains code \u003ca href=\"https://helm.sh/docs/chart_template_guide/control_structures/\" target=\"_blank\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://helm.sh\" track-metadata-module=\"post\"\u003especific to its own format\u003c/a\u003e.\u003csup\u003e1\u003c/sup\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c20=\"\"\u003e\u003cpre _ngcontent-c20=\"\"\u003e  \u003ccode _ngcontent-c20=\"\"\u003e{{- if .Values.master.usePodSecurityContext }}\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e      securityContext:\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e        runAsUser: {{ default 0 .Values.master.runAsUser }}\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e{{- if and (.Values.master.runAsUser) (.Values.master.fsGroup) }}\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e{{- if not (eq (int .Values.master.runAsUser) 0) }}\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e        fsGroup: {{ .Values.master.fsGroup }}\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e{{- end }}\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e{{- end }}\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e{{- end }}\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c20=\"\"\u003e\u003cpre _ngcontent-c20=\"\"\u003e  \u003ccode _ngcontent-c20=\"\"\u003edata \u0026#34;helm_repository\u0026#34; \u0026#34;stable\u0026#34; {\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e  name = \u0026#34;stable\u0026#34;\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e  url  = \u0026#34;https://kubernetes-charts.storage.googleapis.com/\u0026#34;\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e}\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003eresource \u0026#34;helm_release\u0026#34; \u0026#34;default\u0026#34; {\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e  name  = \u0026#34;spin\u0026#34;\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e  chart = \u0026#34;stable/spinnaker\u0026#34;\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e  values = [local.helm_chart_values]\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e  timeout = 1200\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e}\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cp\u003eThe HCL becomes a \u003ca href=\"https://www.terraform.io/docs/internals/json-format.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://www.terraform.io\" track-metadata-module=\"post\"\u003eJSON plan\u003c/a\u003e, where the deployment-ready configuration may be validated before being applied to the live environment.\u003csup\u003e3\u003c/sup\u003e\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c20=\"\"\u003e\u003cpre _ngcontent-c20=\"\"\u003e  \u003ccode _ngcontent-c20=\"\"\u003e# google_compute_instance.vm_instance will be created\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e  + resource \u0026#34;google_compute_instance\u0026#34; \u0026#34;vm_instance\u0026#34; {\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e      + can_ip_forward       = false\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e      + cpu_platform         = (known after apply)\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e      + deletion_protection  = false\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e      + guest_accelerator    = (known after apply)\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e      + id                   = (known after apply)\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e      + instance_id          = (known after apply)\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e      + label_fingerprint    = (known after apply)\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e      + machine_type         = \u0026#34;f1-micro\u0026#34;\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e...\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e        }\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;These examples show three disparate data formats across two different tools representing different portions of a desired end state. Add in Python scripting, gcloud CLI, or \u0026lt;code\u0026gt;kubectl\u0026lt;/code\u0026gt; commands and you start approaching ten different formats\u0026amp;#8212;all for the same deployment!\u0026amp;#160; Reliably enforcing a policy contract requires you to inject tool- and format-specific validation logic on case-by-case basis. If you decide to move a config step from Python to Terraform or from Terraform to \u0026lt;code\u0026gt;kubectl\u0026lt;/code\u0026gt;, you\u0026amp;#8217;ll need to re-evaluate your contract and probably re-implement some of that policy validation.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Why don\u0026amp;#8217;t these tools work together cleanly? Why does policy validation change depending on the development tools you\u0026amp;#8217;re using? Each tool can do a good job enforcing policy within itself. As long as you use that tool everywhere, things will probably work ok. But we all know that\u0026amp;#8217;s not how development works. People tend to choose tools that fit their needs and figure out integration later on.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;A Rosetta Stone for policy contracts\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Imagine that everyone is defining their configuration as data, while using tools and formats of their choice. Terraform or Python for orchestration. Helm for application packaging. Java or Go for data transformation and validation. Once the data format is understood (because it is open source and extensible), your pipeline becomes a bus that anyone can push configuration onto and pull configuration from.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eThese examples show three disparate data formats across two different tools representing different portions of a desired end state. Add in Python scripting, gcloud CLI, or \u003ccode\u003ekubectl\u003c/code\u003e commands and you start approaching ten different formats—all for the same deployment!  Reliably enforcing a policy contract requires you to inject tool- and format-specific validation logic on case-by-case basis. If you decide to move a config step from Python to Terraform or from Terraform to \u003ccode\u003ekubectl\u003c/code\u003e, you’ll need to re-evaluate your contract and probably re-implement some of that policy validation. \u003c/p\u003e\u003cp\u003eWhy don’t these tools work together cleanly? Why does policy validation change depending on the development tools you’re using? Each tool can do a good job enforcing policy within itself. As long as you use that tool everywhere, things will probably work ok. But we all know that’s not how development works. People tend to choose tools that fit their needs and figure out integration later on.\u003c/p\u003e\u003ch3\u003eA Rosetta Stone for policy contracts\u003c/h3\u003e\u003cp\u003eImagine that everyone is defining their configuration as data, while using tools and formats of their choice. Terraform or Python for orchestration. Helm for application packaging. Java or Go for data transformation and validation. Once the data format is understood (because it is open source and extensible), your pipeline becomes a bus that anyone can push configuration onto and pull configuration from.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Policies can be automatically validated at commit or build time using custom and \u0026lt;a href=\u0026#34;https://googlecontainertools.github.io/kpt/guides/consumer/function/catalog/validators/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;off-the-shelf functions\u0026lt;/a\u0026gt; that operate on YAML. You can manage commit and merge permissions separately for config and policy to separate these distinct concerns. You can have folders and unique permissions for org-wide policy, team-wide policy, or app-specific policy. Therein lies the dream.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;The most common way to generate configuration is to simply write a YAML file describing how Kubernetes should create a resource for you. The resulting YAML file is then stored in a git repository where it can be versioned and picked up by another tool and applied to a Kubernetes cluster. Policies can be enforced on the git repo side to limit who can push changes to the repository and ultimately reference them at deploy time.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;For most users this is not where policy enforcement ends. While code reviews can catch a lot of things, it\u0026amp;#8217;s considered best practice to \u0026amp;#8220;trust but verify\u0026amp;#8221; at all layers in the stack. That\u0026amp;#8217;s where admission controllers come in, which can be considered to be the last mile of policy enforcement. \u0026lt;a href=\u0026#34;https://www.openpolicyagent.org/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Gatekeeper\u0026lt;/a\u0026gt; serves as an admission controller inside of a Kubernetes cluster. Only configurations that meet defined constraints will be admitted to the live cloud environment.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Let\u0026amp;#8217;s tie these concepts together \u0026lt;a href=\u0026#34;https://github.com/kelseyhightower/config-connector-policy-demo\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;with an example\u0026lt;/a\u0026gt;. Imagine you want to enable users to create Cloud Storage buckets, but you don\u0026amp;#8217;t want them doing so using the Google Cloud Console or the gcloud command line tool. You want all users to declare what they want and push those changes to a git repository for review before the underlying Cloud Storage buckets are created with \u0026lt;a href=\u0026#34;https://cloud.google.com/config-connector/docs/overview\u0026#34;\u0026gt;Config Connector\u0026lt;/a\u0026gt;. Essentially you want users to be able to submit a YAML file that looks like this:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003ePolicies can be automatically validated at commit or build time using custom and \u003ca href=\"https://googlecontainertools.github.io/kpt/guides/consumer/function/catalog/validators/\" target=\"_blank\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://googlecontainertools.github.io\" track-metadata-module=\"post\"\u003eoff-the-shelf functions\u003c/a\u003e that operate on YAML. You can manage commit and merge permissions separately for config and policy to separate these distinct concerns. You can have folders and unique permissions for org-wide policy, team-wide policy, or app-specific policy. Therein lies the dream. \u003c/p\u003e\u003cp\u003eThe most common way to generate configuration is to simply write a YAML file describing how Kubernetes should create a resource for you. The resulting YAML file is then stored in a git repository where it can be versioned and picked up by another tool and applied to a Kubernetes cluster. Policies can be enforced on the git repo side to limit who can push changes to the repository and ultimately reference them at deploy time.\u003c/p\u003e\u003cp\u003eFor most users this is not where policy enforcement ends. While code reviews can catch a lot of things, it’s considered best practice to “trust but verify” at all layers in the stack. That’s where admission controllers come in, which can be considered to be the last mile of policy enforcement. \u003ca href=\"https://www.openpolicyagent.org/\" target=\"_blank\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://www.openpolicyagent.org\" track-metadata-module=\"post\"\u003eGatekeeper\u003c/a\u003e serves as an admission controller inside of a Kubernetes cluster. Only configurations that meet defined constraints will be admitted to the live cloud environment.\u003c/p\u003e\u003cp\u003eLet’s tie these concepts together \u003ca href=\"https://github.com/kelseyhightower/config-connector-policy-demo\" target=\"_blank\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003ewith an example\u003c/a\u003e. Imagine you want to enable users to create Cloud Storage buckets, but you don’t want them doing so using the Google Cloud Console or the gcloud command line tool. You want all users to declare what they want and push those changes to a git repository for review before the underlying Cloud Storage buckets are created with \u003ca href=\"https://cloud.google.com/config-connector/docs/overview\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/config-connector/docs/overview\" track-metadata-module=\"post\"\u003eConfig Connector\u003c/a\u003e. Essentially you want users to be able to submit a YAML file that looks like this:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c20=\"\"\u003e\u003cpre _ngcontent-c20=\"\"\u003e  \u003ccode _ngcontent-c20=\"\"\u003eapiVersion: storage.cnrm.cloud.google.com/v1beta1\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003ekind: StorageBucket\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003emetadata:\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e  name: ${BUCKET_NAME}\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;This creates a storage bucket in a default location. There is one problem with this: users can create buckets in any location even if company policy dictates otherwise. Sure, you can catch people using forbidden bucket locations during code review, but that\u0026amp;#8217;s prone to human error.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;This is where Gatekeeper comes in. You want the ability to limit which Cloud Storage bucket location can be used. Ideally you can write policies that look like this:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eThis creates a storage bucket in a default location. There is one problem with this: users can create buckets in any location even if company policy dictates otherwise. Sure, you can catch people using forbidden bucket locations during code review, but that’s prone to human error.\u003c/p\u003e\u003cp\u003eThis is where Gatekeeper comes in. You want the ability to limit which Cloud Storage bucket location can be used. Ideally you can write policies that look like this:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c20=\"\"\u003e\u003cpre _ngcontent-c20=\"\"\u003e  \u003ccode _ngcontent-c20=\"\"\u003eapiVersion: constraints.gatekeeper.sh/v1beta1\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003ekind: StorageBucketAllowedLocations\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003emetadata:\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e  name: allowmultiregions\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003espec:\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e  match:\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e    kinds:\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e      - apiGroups: [\u0026#34;storage.cnrm.cloud.google.com\u0026#34;]\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e        kinds: [\u0026#34;StorageBucket\u0026#34;]\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e  parameters:\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e    locations:\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e      - \u0026#34;ASIA\u0026#34;\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e      - \u0026#34;EU\u0026#34;\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e      - \u0026#34;US\u0026#34;\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;The above \u0026lt;code\u0026gt;StorageBucketAllowedLocation\u0026lt;/code\u0026gt; policy rejects \u0026lt;code\u0026gt;StorageBucket\u0026lt;/code\u0026gt; objects with the \u0026lt;code\u0026gt;spec.location\u0026lt;/code\u0026gt; field set to any value other than one of the Cloud Storage multi-region locations: ASIA, EU, US. You decide where to validate policy without being limited by your tool of choice and anywhere in your pipeline.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Now you have the last stage of your configuration pipeline.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Testing the contract\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;How does this work in practice? Let\u0026amp;#8217;s say someone managed to check in \u0026lt;code\u0026gt;StorageBucket\u0026lt;/code\u0026gt; resource with the following config:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eThe above \u003ccode\u003eStorageBucketAllowedLocation\u003c/code\u003e policy rejects \u003ccode\u003eStorageBucket\u003c/code\u003e objects with the \u003ccode\u003espec.location\u003c/code\u003e field set to any value other than one of the Cloud Storage multi-region locations: ASIA, EU, US. You decide where to validate policy without being limited by your tool of choice and anywhere in your pipeline.\u003c/p\u003e\u003cp\u003eNow you have the last stage of your configuration pipeline. \u003c/p\u003e\u003ch3\u003eTesting the contract\u003c/h3\u003e\u003cp\u003eHow does this work in practice? Let’s say someone managed to check in \u003ccode\u003eStorageBucket\u003c/code\u003e resource with the following config:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c20=\"\"\u003e\u003cpre _ngcontent-c20=\"\"\u003e  \u003ccode _ngcontent-c20=\"\"\u003eapiVersion: storage.cnrm.cloud.google.com/v1beta1\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003ekind: StorageBucket\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003emetadata:\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e  annotations:\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e    cnrm.cloud.google.com/force-destroy: \u0026#34;false\u0026#34;\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e  name: ${BUCKET_NAME}\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003espec:\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cp\u003eOur policy would reject the bucket because an empty location is not allowed. What happens if configuration was set to a Cloud Storage location not allowed by the policy, \u003ccode\u003eUS-WEST1\u003c/code\u003e for example?\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c20=\"\"\u003e\u003cpre _ngcontent-c20=\"\"\u003e  \u003ccode _ngcontent-c20=\"\"\u003eapiVersion: storage.cnrm.cloud.google.com/v1beta1\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003ekind: StorageBucket\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003emetadata:\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e  annotations:\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e    cnrm.cloud.google.com/force-destroy: \u0026#34;false\u0026#34;\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e  name: ${BUCKET_NAME}\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003espec:\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003e  location: \u0026#34;US-WEST1\u0026#34;\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Ideally you would catch this during the code review process before the config is committed to a git repo, but as mentioned above, that\u0026amp;#8217;s error prone.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Luckily, the configuration will fail because the \u0026lt;code\u0026gt;allowmultiregions\u0026lt;/code\u0026gt; policy constraint only allows multi-region bucket locations including ASIA, EU, and US, and will reject the configuration. So, now, if you set location to \u0026amp;#8220;US\u0026amp;#8221; you can deploy the Cloud Storage bucket. You can also apply this type of location policy or any other like it to all of your resource types\u0026amp;#8212;Redis instances, Compute Engine virtual machines, even Google Kubernetes Engine (GKE) clusters. Beyond admission control, you can apply the same constraint anywhere in your pipeline, by \u0026amp;#8221;shifting left\u0026amp;#8221; policy validation at any stage.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;One contract to rule them all\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;When config is managed in silos\u0026amp;#8212;whether across many tools, pipelines, graphical interfaces, and command lines\u0026amp;#8212;you can\u0026amp;#8217;t inject logic without building bespoke tools for every interface. You may be able to define policies built for your front-end tools and hope nothing changes on the backend. Or you can wait until deployment time to scan for deviations and hope nothing appears during crunch time.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Compare that with configuration as data contracts, which are transparent and normalized across resource types, which has facilitated a rich ecosystem of tooling built around Kubernetes with varied syntax (YAML, JSON) and languages including Ruby, Typescript, Go, Jinja, Mustache, Jsonnet, Starlark, and many others. This isn\u0026amp;#8217;t possible without a data model.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Configuration-as-Data-inspired tools such as \u0026lt;a href=\u0026#34;https://cloud.google.com/config-connector/docs/overview\u0026#34;\u0026gt;Config Connector\u0026lt;/a\u0026gt; and Gatekeeper let you enforce policy and governance as natural parts of your existing git-based workflow rather than creating manual processes and approvals. Configuration as data normalizes your contract across resource types and even cloud providers. You don\u0026amp;#8217;t need to reverse engineer scripts and code paths to know if your contract is being met\u0026amp;#8212;just look at the data.\u0026lt;/p\u0026gt;\u0026lt;hr\u0026gt;\u0026lt;sup\u0026gt;\u0026lt;i\u0026gt;1.\u0026amp;#160;\u0026lt;a href=\u0026#34;https://github.com/helm/charts/blob/master/stable/jenkins/templates/jenkins-master-deployment.yaml\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;https://github.com/helm/charts/blob/master/stable/jenkins/templates/jenkins-master-deployment.yaml\u0026lt;/a\u0026gt;\u0026lt;/i\u0026gt;\u0026lt;/sup\u0026gt;\u0026lt;p\u0026gt;\u0026lt;sup\u0026gt;\u0026lt;i\u0026gt;2.\u0026amp;#160;\u0026lt;a href=\u0026#34;https://medium.com/swlh/deploying-helm-charts-w-terraform-58bd3a690e55\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;https://medium.com/swlh/deploying-helm-charts-w-terraform-58bd3a690e55\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt;\u0026lt;/i\u0026gt;\u0026lt;/sup\u0026gt;\u0026lt;sup\u0026gt;\u0026lt;i\u0026gt;3.\u0026amp;#160;\u0026lt;/i\u0026gt;\u0026lt;/sup\u0026gt;\u0026lt;a href=\u0026#34;https://github.com/hashicorp/terraform-getting-started-gcp-cloud-shell/blob/master/tutorial/cloudshell_tutorial.md\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;\u0026lt;sup\u0026gt;\u0026lt;i\u0026gt;https://github.com/hashicorp/terraform-getting-started-gcp-cloud-shell/blob/master/tutorial/cloudshell_tutorial.md\u0026lt;/i\u0026gt;\u0026lt;/sup\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eIdeally you would catch this during the code review process before the config is committed to a git repo, but as mentioned above, that’s error prone. \u003c/p\u003e\u003cp\u003eLuckily, the configuration will fail because the \u003ccode\u003eallowmultiregions\u003c/code\u003e policy constraint only allows multi-region bucket locations including ASIA, EU, and US, and will reject the configuration. So, now, if you set location to “US” you can deploy the Cloud Storage bucket. You can also apply this type of location policy or any other like it to all of your resource types—Redis instances, Compute Engine virtual machines, even Google Kubernetes Engine (GKE) clusters. Beyond admission control, you can apply the same constraint anywhere in your pipeline, by ”shifting left” policy validation at any stage. \u003c/p\u003e\u003ch3\u003eOne contract to rule them all\u003c/h3\u003e\u003cp\u003eWhen config is managed in silos—whether across many tools, pipelines, graphical interfaces, and command lines—you can’t inject logic without building bespoke tools for every interface. You may be able to define policies built for your front-end tools and hope nothing changes on the backend. Or you can wait until deployment time to scan for deviations and hope nothing appears during crunch time. \u003c/p\u003e\u003cp\u003eCompare that with configuration as data contracts, which are transparent and normalized across resource types, which has facilitated a rich ecosystem of tooling built around Kubernetes with varied syntax (YAML, JSON) and languages including Ruby, Typescript, Go, Jinja, Mustache, Jsonnet, Starlark, and many others. This isn’t possible without a data model. \u003c/p\u003e\u003cp\u003eConfiguration-as-Data-inspired tools such as \u003ca href=\"https://cloud.google.com/config-connector/docs/overview\" track-type=\"inline link\" track-name=\"10\" track-metadata-eventdetail=\"https://cloud.google.com/config-connector/docs/overview\" track-metadata-module=\"post\"\u003eConfig Connector\u003c/a\u003e and Gatekeeper let you enforce policy and governance as natural parts of your existing git-based workflow rather than creating manual processes and approvals. Configuration as data normalizes your contract across resource types and even cloud providers. You don’t need to reverse engineer scripts and code paths to know if your contract is being met—just look at the data.\u003c/p\u003e\u003chr/\u003e\u003cp\u003e\u003csup\u003e\u003ci\u003e1. \u003ca href=\"https://github.com/helm/charts/blob/master/stable/jenkins/templates/jenkins-master-deployment.yaml\" target=\"_blank\" track-type=\"inline link\" track-name=\"11\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003ehttps://github.com/helm/charts/blob/master/stable/jenkins/templates/jenkins-master-deployment.yaml\u003c/a\u003e\u003c/i\u003e\u003c/sup\u003e\u003c/p\u003e\u003cp\u003e\u003csup\u003e\u003ci\u003e2. \u003ca href=\"https://medium.com/swlh/deploying-helm-charts-w-terraform-58bd3a690e55\" target=\"_blank\" track-type=\"inline link\" track-name=\"12\" track-metadata-eventdetail=\"https://medium.com\" track-metadata-module=\"post\"\u003ehttps://medium.com/swlh/deploying-helm-charts-w-terraform-58bd3a690e55\u003c/a\u003e\u003cbr/\u003e\u003c/i\u003e\u003c/sup\u003e\u003csup\u003e\u003ci\u003e3. \u003c/i\u003e\u003c/sup\u003e\u003ca href=\"https://github.com/hashicorp/terraform-getting-started-gcp-cloud-shell/blob/master/tutorial/cloudshell_tutorial.md\" target=\"_blank\" track-type=\"inline link\" track-name=\"13\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003e\u003csup\u003e\u003ci\u003ehttps://github.com/hashicorp/terraform-getting-started-gcp-cloud-shell/blob/master/tutorial/cloudshell_tutorial.md\u003c/i\u003e\u003c/sup\u003e\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/article-content-stream-block\u003e\u003carticle-tag-list-block\u003e\u003c/article-tag-list-block\u003e\u003c/div\u003e\u003csection\u003e\u003carticle-up-1to3-block _nghost-c18=\"\"\u003e\u003c/article-up-1to3-block\u003e\u003c/section\u003e\u003c/div\u003e\u003c/article\u003e\u003c/main\u003e\u003c/article-page\u003e\u003c/dynamic-page\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eConfiguration as Data is an emerging cloud infrastructure management paradigm that allows developers to \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/understanding-configuration-as-data-in-kubernetes\"\u003edeclare the desired state\u003c/a\u003e of their applications and infrastructure, without specifying the precise actions or steps for how to achieve it. However, declaring a configuration is only half the battle: you also want policy that defines how a configuration is to be used. \u003c/p\u003e\u003cp\u003eConfiguration as Data enables a normalized policy contract across all your cloud resources. That contract, knowing how your deployment will operate, can be inspected and enforced throughout a CI/CD pipeline, from upstream in your development environment to deployment time, and ongoing in the live runtime environment. This consistency is possible by expressing configuration as data throughout the development and operations lifecycle.\u003c/p\u003e\u003cp\u003e\u003ca href=\"https://cloud.google.com/config-connector/docs/overview\"\u003eConfig Connector\u003c/a\u003e is the tool that allows you to express configuration as data in Google Cloud. In this model, configuration is what you want to deploy, such as “a storage bucket named \u003ccode\u003emy-bucket\u003c/code\u003e with a standard storage class and uniform access control.” \u003c/p\u003e\u003cp\u003ePolicy, meanwhile, typically specifies what you’re allowed to deploy, usually in conformance with your organization’s compliance needs. For example, “all resources must be deployed in Google Cloud’s \u003ccode\u003eLONDON\u003c/code\u003e region.” \u003c/p\u003e\u003cp\u003eWhen each stage in your pipeline treats configuration as data, you can use any tool or language to manipulate configuration as data, knowing they will interoperate and that policy can be consistently enforced at any or all stages. And while a policy engine won’t be able to understand every tool, it can validate the data generated by each tool. It’s just like data in a database can be inspected by anyone who knows the schema regardless of the tool that wrote into the database.\u003c/p\u003e\u003cp\u003eContrast that with pipelines today, where policy is manually validated, hard coded in scripts within the pipeline logic itself, or post-processed on raw deployment artifacts after rendering configuration templates into specific instances. In each case, policy is siloed—you can’t take the same policy and apply it anywhere in your pipeline because formats differ from tool to tool. \u003c/p\u003e\u003cp\u003eHelm, for example, contains code \u003ca href=\"https://helm.sh/docs/chart_template_guide/control_structures/\" target=\"_blank\"\u003especific to its own format\u003c/a\u003e.\u003csup\u003e1\u003c/sup\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003ca href=\"https://www.terraform.io/docs/language/syntax/configuration.html\" target=\"_blank\"\u003eTerraform HCL\u003c/a\u003e may then deploy the Helm chart.\u003csup\u003e2\u003c/sup\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eThe HCL becomes a \u003ca href=\"https://www.terraform.io/docs/internals/json-format.html\" target=\"_blank\"\u003eJSON plan\u003c/a\u003e, where the deployment-ready configuration may be validated before being applied to the live environment.\u003csup\u003e3\u003c/sup\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eThese examples show three disparate data formats across two different tools representing different portions of a desired end state. Add in Python scripting, gcloud CLI, or \u003ccode\u003ekubectl\u003c/code\u003e commands and you start approaching ten different formats—all for the same deployment!  Reliably enforcing a policy contract requires you to inject tool- and format-specific validation logic on case-by-case basis. If you decide to move a config step from Python to Terraform or from Terraform to \u003ccode\u003ekubectl\u003c/code\u003e, you’ll need to re-evaluate your contract and probably re-implement some of that policy validation. \u003c/p\u003e\u003cp\u003eWhy don’t these tools work together cleanly? Why does policy validation change depending on the development tools you’re using? Each tool can do a good job enforcing policy within itself. As long as you use that tool everywhere, things will probably work ok. But we all know that’s not how development works. People tend to choose tools that fit their needs and figure out integration later on.\u003c/p\u003e\u003ch3\u003eA Rosetta Stone for policy contracts\u003c/h3\u003e\u003cp\u003eImagine that everyone is defining their configuration as data, while using tools and formats of their choice. Terraform or Python for orchestration. Helm for application packaging. Java or Go for data transformation and validation. Once the data format is understood (because it is open source and extensible), your pipeline becomes a bus that anyone can push configuration onto and pull configuration from.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/policy_contracts.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"policy contracts.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/policy_contracts.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003ePolicies can be automatically validated at commit or build time using custom and \u003ca href=\"https://googlecontainertools.github.io/kpt/guides/consumer/function/catalog/validators/\" target=\"_blank\"\u003eoff-the-shelf functions\u003c/a\u003e that operate on YAML. You can manage commit and merge permissions separately for config and policy to separate these distinct concerns. You can have folders and unique permissions for org-wide policy, team-wide policy, or app-specific policy. Therein lies the dream. \u003c/p\u003e\u003cp\u003eThe most common way to generate configuration is to simply write a YAML file describing how Kubernetes should create a resource for you. The resulting YAML file is then stored in a git repository where it can be versioned and picked up by another tool and applied to a Kubernetes cluster. Policies can be enforced on the git repo side to limit who can push changes to the repository and ultimately reference them at deploy time.\u003c/p\u003e\u003cp\u003eFor most users this is not where policy enforcement ends. While code reviews can catch a lot of things, it’s considered best practice to “trust but verify” at all layers in the stack. That’s where admission controllers come in, which can be considered to be the last mile of policy enforcement. \u003ca href=\"https://www.openpolicyagent.org/\" target=\"_blank\"\u003eGatekeeper\u003c/a\u003e serves as an admission controller inside of a Kubernetes cluster. Only configurations that meet defined constraints will be admitted to the live cloud environment.\u003c/p\u003e\u003cp\u003eLet’s tie these concepts together \u003ca href=\"https://github.com/kelseyhightower/config-connector-policy-demo\" target=\"_blank\"\u003ewith an example\u003c/a\u003e. Imagine you want to enable users to create Cloud Storage buckets, but you don’t want them doing so using the Google Cloud Console or the gcloud command line tool. You want all users to declare what they want and push those changes to a git repository for review before the underlying Cloud Storage buckets are created with \u003ca href=\"https://cloud.google.com/config-connector/docs/overview\"\u003eConfig Connector\u003c/a\u003e. Essentially you want users to be able to submit a YAML file that looks like this:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eThis creates a storage bucket in a default location. There is one problem with this: users can create buckets in any location even if company policy dictates otherwise. Sure, you can catch people using forbidden bucket locations during code review, but that’s prone to human error.\u003c/p\u003e\u003cp\u003eThis is where Gatekeeper comes in. You want the ability to limit which Cloud Storage bucket location can be used. Ideally you can write policies that look like this:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eThe above \u003ccode\u003eStorageBucketAllowedLocation\u003c/code\u003e policy rejects \u003ccode\u003eStorageBucket\u003c/code\u003e objects with the \u003ccode\u003espec.location\u003c/code\u003e field set to any value other than one of the Cloud Storage multi-region locations: ASIA, EU, US. You decide where to validate policy without being limited by your tool of choice and anywhere in your pipeline.\u003c/p\u003e\u003cp\u003eNow you have the last stage of your configuration pipeline. \u003c/p\u003e\u003ch3\u003eTesting the contract\u003c/h3\u003e\u003cp\u003eHow does this work in practice? Let’s say someone managed to check in \u003ccode\u003eStorageBucket\u003c/code\u003e resource with the following config:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eOur policy would reject the bucket because an empty location is not allowed. What happens if configuration was set to a Cloud Storage location not allowed by the policy, \u003ccode\u003eUS-WEST1\u003c/code\u003e for example?\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIdeally you would catch this during the code review process before the config is committed to a git repo, but as mentioned above, that’s error prone. \u003c/p\u003e\u003cp\u003eLuckily, the configuration will fail because the \u003ccode\u003eallowmultiregions\u003c/code\u003e policy constraint only allows multi-region bucket locations including ASIA, EU, and US, and will reject the configuration. So, now, if you set location to “US” you can deploy the Cloud Storage bucket. You can also apply this type of location policy or any other like it to all of your resource types—Redis instances, Compute Engine virtual machines, even Google Kubernetes Engine (GKE) clusters. Beyond admission control, you can apply the same constraint anywhere in your pipeline, by ”shifting left” policy validation at any stage. \u003c/p\u003e\u003ch3\u003eOne contract to rule them all\u003c/h3\u003e\u003cp\u003eWhen config is managed in silos—whether across many tools, pipelines, graphical interfaces, and command lines—you can’t inject logic without building bespoke tools for every interface. You may be able to define policies built for your front-end tools and hope nothing changes on the backend. Or you can wait until deployment time to scan for deviations and hope nothing appears during crunch time. \u003c/p\u003e\u003cp\u003eCompare that with configuration as data contracts, which are transparent and normalized across resource types, which has facilitated a rich ecosystem of tooling built around Kubernetes with varied syntax (YAML, JSON) and languages including Ruby, Typescript, Go, Jinja, Mustache, Jsonnet, Starlark, and many others. This isn’t possible without a data model. \u003c/p\u003e\u003cp\u003eConfiguration-as-Data-inspired tools such as \u003ca href=\"https://cloud.google.com/config-connector/docs/overview\"\u003eConfig Connector\u003c/a\u003e and Gatekeeper let you enforce policy and governance as natural parts of your existing git-based workflow rather than creating manual processes and approvals. Configuration as data normalizes your contract across resource types and even cloud providers. You don’t need to reverse engineer scripts and code paths to know if your contract is being met—just look at the data.\u003c/p\u003e\u003chr/\u003e\u003csup\u003e\u003ci\u003e1. \u003ca href=\"https://github.com/helm/charts/blob/master/stable/jenkins/templates/jenkins-master-deployment.yaml\" target=\"_blank\"\u003ehttps://github.com/helm/charts/blob/master/stable/jenkins/templates/jenkins-master-deployment.yaml\u003c/a\u003e\u003c/i\u003e\u003c/sup\u003e\u003cp\u003e\u003csup\u003e\u003ci\u003e2. \u003ca href=\"https://medium.com/swlh/deploying-helm-charts-w-terraform-58bd3a690e55\" target=\"_blank\"\u003ehttps://medium.com/swlh/deploying-helm-charts-w-terraform-58bd3a690e55\u003c/a\u003e\u003cbr/\u003e\u003c/i\u003e\u003c/sup\u003e\u003csup\u003e\u003ci\u003e3. \u003c/i\u003e\u003c/sup\u003e\u003ca href=\"https://github.com/hashicorp/terraform-getting-started-gcp-cloud-shell/blob/master/tutorial/cloudshell_tutorial.md\" target=\"_blank\"\u003e\u003csup\u003e\u003ci\u003ehttps://github.com/hashicorp/terraform-getting-started-gcp-cloud-shell/blob/master/tutorial/cloudshell_tutorial.md\u003c/i\u003e\u003c/sup\u003e\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/containers-kubernetes/understanding-configuration-as-data-in-kubernetes/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Blog_header_opensource_2.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eI do declare! Infrastructure automation with Configuration as Data\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eConfiguration as Data enables operational consistency, security, and velocity on Google Cloud with products like Config Connector.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_x_GKE.max-2200x2200.jpg",
      "date_published": "2021-04-26T16:00:00Z",
      "author": {
        "name": "\u003cname\u003eMark Balch\u003c/name\u003e\u003ctitle\u003eSenior Product Manager, Google Cloud\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/5-google-sre-resources-to-get-started/",
      "title": "5 resources to help you get started with SRE",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle-content-stream-block\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;\u0026lt;a href=\u0026#34;https://sre.google/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Site reliability engineering\u0026lt;/a\u0026gt; (SRE) is an essential part of engineering at Google\u0026amp;#8212;it\u0026amp;#8217;s a mindset, and a set of practices, metrics, and prescriptive ways to ensure systems reliability. But not everyone knows the best places to start to implement SRE in their own organizations. Here are our top resources at Google Cloud for getting started.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;1. Do you have an SRE team yet? How to start and assess your journey\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;We\u0026amp;#8217;re often asked what implementing SRE means in practice, since our customers face challenges quantifying their success when setting up their own SRE practices. \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/how-to-start-and-assess-your-sre-journey\u0026#34;\u0026gt;In this post\u0026lt;/a\u0026gt;, we share a couple of checklists to be used by members of an organization responsible for any high-reliability services. These will be useful when you\u0026amp;#8217;re trying to move your team toward an SRE model. Implementing this model at your organization can benefit both your services and teams due to higher service reliability, lower operational cost, and higher-value work for everyone on the team.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e\u003ca href=\"https://sre.google/\" target=\"_blank\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003eSite reliability engineering\u003c/a\u003e (SRE) is an essential part of engineering at Google—it’s a mindset, and a set of practices, metrics, and prescriptive ways to ensure systems reliability. But not everyone knows the best places to start to implement SRE in their own organizations. Here are our top resources at Google Cloud for getting started.\u003c/p\u003e\u003ch3\u003e1. Do you have an SRE team yet? How to start and assess your journey\u003c/h3\u003e\u003cp\u003eWe’re often asked what implementing SRE means in practice, since our customers face challenges quantifying their success when setting up their own SRE practices. \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/how-to-start-and-assess-your-sre-journey\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/how-to-start-and-assess-your-sre-journey\" track-metadata-module=\"post\"\u003eIn this post\u003c/a\u003e, we share a couple of checklists to be used by members of an organization responsible for any high-reliability services. These will be useful when you’re trying to move your team toward an SRE model. Implementing this model at your organization can benefit both your services and teams due to higher service reliability, lower operational cost, and higher-value work for everyone on the team.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;h3\u0026gt;2. SRE fundamentals: SLIs, SLAs and SLOs\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Core to the definition of SRE is the idea that metrics should be closely tied to business objectives. Thus, a big part of the day-to-day of SREs is establishing and monitoring these service-level metrics. At Google, we use several essential measurements\u0026amp;#8212;SLO, SLA and SLI\u0026amp;#8212;in SRE planning and practice. \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/sre-fundamentals-slis-slas-and-slos\u0026#34;\u0026gt;This post\u0026lt;/a\u0026gt; gives you an overview of what each of these acronyms are, what they mean, and how to incorporate them.\u0026lt;/p\u0026gt;\"\u003e\u003ch3\u003e2. SRE fundamentals: SLIs, SLAs and SLOs\u003c/h3\u003e\u003cp\u003eCore to the definition of SRE is the idea that metrics should be closely tied to business objectives. Thus, a big part of the day-to-day of SREs is establishing and monitoring these service-level metrics. At Google, we use several essential measurements—SLO, SLA and SLI—in SRE planning and practice. \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/sre-fundamentals-slis-slas-and-slos\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/sre-fundamentals-slis-slas-and-slos\" track-metadata-module=\"post\"\u003eThis post\u003c/a\u003e gives you an overview of what each of these acronyms are, what they mean, and how to incorporate them.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;h3\u0026gt;3. How SRE teams are organized, and how to get started\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;You know what SREs do and understand which best practices should be implemented at various levels of SRE maturity. Now you\u0026amp;#8217;re ready to take the next step by setting up your own SRE team. \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/devops-sre/how-sre-teams-are-organized-and-how-to-get-started\u0026#34;\u0026gt;In this post\u0026lt;/a\u0026gt;, we\u0026amp;#8217;ll cover how different implementations of SRE teams establish boundaries to achieve their goals. We describe six different implementations that we\u0026amp;#8217;ve experienced, and what we have observed to be their most important pros and cons.\u0026lt;/p\u0026gt;\"\u003e\u003ch3\u003e3. How SRE teams are organized, and how to get started\u003c/h3\u003e\u003cp\u003eYou know what SREs do and understand which best practices should be implemented at various levels of SRE maturity. Now you’re ready to take the next step by setting up your own SRE team. \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/how-sre-teams-are-organized-and-how-to-get-started\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/devops-sre/how-sre-teams-are-organized-and-how-to-get-started\" track-metadata-module=\"post\"\u003eIn this post\u003c/a\u003e, we’ll cover how different implementations of SRE teams establish boundaries to achieve their goals. We describe six different implementations that we’ve experienced, and what we have observed to be their most important pros and cons.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;h3\u0026gt;4. Meeting reliability challenges with SRE principles\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Through years of work using SRE principles, we\u0026amp;#8217;ve found there are a few common challenges that teams face, and some important ways to meet or avoid those challenges. Learn what we at Google think are the \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/management-tools/meeting-reliability-challenges-with-sre-principles\u0026#34;\u0026gt;three top sources of production stress\u0026lt;/a\u0026gt; and how we recommend addressing them.\u0026lt;/p\u0026gt;\"\u003e\u003ch3\u003e4. Meeting reliability challenges with SRE principles\u003c/h3\u003e\u003cp\u003eThrough years of work using SRE principles, we’ve found there are a few common challenges that teams face, and some important ways to meet or avoid those challenges. Learn what we at Google think are the \u003ca href=\"https://cloud.google.com/blog/products/management-tools/meeting-reliability-challenges-with-sre-principles\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/management-tools/meeting-reliability-challenges-with-sre-principles\" track-metadata-module=\"post\"\u003ethree top sources of production stress\u003c/a\u003e and how we recommend addressing them.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;h3\u0026gt;5. Transitioning a typical engineering ops team into an SRE powerhouse\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Perpetually adding engineers to ops teams to meet customer growth doesn\u0026amp;#8217;t scale. Google\u0026amp;#8217;s SRE principles can help, bringing software engineering solutions to operational problems. \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/management-tools/transitioning-a-typical-engineering-ops-team-into-an-sre-powerhouse\u0026#34;\u0026gt;In this post\u0026lt;/a\u0026gt;, we\u0026amp;#8217;ll take a look at how we transformed our global network ops team by abandoning traditional network engineering orthodoxy and replacing it with SRE. You\u0026amp;#8217;ll learn how Google\u0026amp;#8217;s production networking team tackled this problem and consider how you might incorporate SRE principles in your own organization.\u0026lt;/p\u0026gt;\"\u003e\u003ch3\u003e5. Transitioning a typical engineering ops team into an SRE powerhouse\u003c/h3\u003e\u003cp\u003ePerpetually adding engineers to ops teams to meet customer growth doesn’t scale. Google’s SRE principles can help, bringing software engineering solutions to operational problems. \u003ca href=\"https://cloud.google.com/blog/products/management-tools/transitioning-a-typical-engineering-ops-team-into-an-sre-powerhouse\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/management-tools/transitioning-a-typical-engineering-ops-team-into-an-sre-powerhouse\" track-metadata-module=\"post\"\u003eIn this post\u003c/a\u003e, we’ll take a look at how we transformed our global network ops team by abandoning traditional network engineering orthodoxy and replacing it with SRE. You’ll learn how Google’s production networking team tackled this problem and consider how you might incorporate SRE principles in your own organization.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/article-content-stream-block\u003e\u003carticle-tag-list-block\u003e\u003c/article-tag-list-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003ca href=\"https://sre.google/\" target=\"_blank\"\u003eSite reliability engineering\u003c/a\u003e (SRE) is an essential part of engineering at Google—it’s a mindset, and a set of practices, metrics, and prescriptive ways to ensure systems reliability. But not everyone knows the best places to start to implement SRE in their own organizations. Here are our top resources at Google Cloud for getting started.\u003c/p\u003e\u003ch3\u003e1. Do you have an SRE team yet? How to start and assess your journey\u003c/h3\u003e\u003cp\u003eWe’re often asked what implementing SRE means in practice, since our customers face challenges quantifying their success when setting up their own SRE practices. \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/how-to-start-and-assess-your-sre-journey\"\u003eIn this post\u003c/a\u003e, we share a couple of checklists to be used by members of an organization responsible for any high-reliability services. These will be useful when you’re trying to move your team toward an SRE model. Implementing this model at your organization can benefit both your services and teams due to higher service reliability, lower operational cost, and higher-value work for everyone on the team.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/how-to-start-and-assess-your-sre-journey/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_D_Rnd3.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eDo you have an SRE team yet? How to start and assess your journey\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eThis post shares checklists you can use when you’re trying to move your team toward an SRE model. These checklists can be useful as a for...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003e2. SRE fundamentals: SLIs, SLAs and SLOs\u003c/h3\u003e\u003cp\u003eCore to the definition of SRE is the idea that metrics should be closely tied to business objectives. Thus, a big part of the day-to-day of SREs is establishing and monitoring these service-level metrics. At Google, we use several essential measurements—SLO, SLA and SLI—in SRE planning and practice. \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/sre-fundamentals-slis-slas-and-slos\"\u003eThis post\u003c/a\u003e gives you an overview of what each of these acronyms are, what they mean, and how to incorporate them.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/sre-fundamentals-slis-slas-and-slos/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud-01_xyGPYQS.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eSRE fundamentals: SLIs, SLAs and SLOs\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eA big part of SRE is establishing and monitoring service-level metrics like SLOs, SLAs and SLIs. This post gives you an overview of what ...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003e3. How SRE teams are organized, and how to get started\u003c/h3\u003e\u003cp\u003eYou know what SREs do and understand which best practices should be implemented at various levels of SRE maturity. Now you’re ready to take the next step by setting up your own SRE team. \u003ca href=\"https://cloud.google.com/blog/products/devops-sre/how-sre-teams-are-organized-and-how-to-get-started\"\u003eIn this post\u003c/a\u003e, we’ll cover how different implementations of SRE teams establish boundaries to achieve their goals. We describe six different implementations that we’ve experienced, and what we have observed to be their most important pros and cons.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/how-sre-teams-are-organized-and-how-to-get-started/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_A_Rnd3.max-2800x2800.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eHow SRE teams are organized, and how to get started\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eLearn six different implementations of SRE teams you can apply in your organization, as well as how to establish boundaries to achieve th...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003e4. Meeting reliability challenges with SRE principles\u003c/h3\u003e\u003cp\u003eThrough years of work using SRE principles, we’ve found there are a few common challenges that teams face, and some important ways to meet or avoid those challenges. Learn what we at Google think are the \u003ca href=\"https://cloud.google.com/blog/products/management-tools/meeting-reliability-challenges-with-sre-principles\"\u003ethree top sources of production stress\u003c/a\u003e and how we recommend addressing them.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/management-tools/meeting-reliability-challenges-with-sre-principles/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_GCP.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eMeeting reliability challenges with SRE principles\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eFollowing SRE principles can help you build reliable production systems. When getting started, you may encounter three common challenges....\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003e5. Transitioning a typical engineering ops team into an SRE powerhouse\u003c/h3\u003e\u003cp\u003ePerpetually adding engineers to ops teams to meet customer growth doesn’t scale. Google’s SRE principles can help, bringing software engineering solutions to operational problems. \u003ca href=\"https://cloud.google.com/blog/products/management-tools/transitioning-a-typical-engineering-ops-team-into-an-sre-powerhouse\"\u003eIn this post\u003c/a\u003e, we’ll take a look at how we transformed our global network ops team by abandoning traditional network engineering orthodoxy and replacing it with SRE. You’ll learn how Google’s production networking team tackled this problem and consider how you might incorporate SRE principles in your own organization.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/management-tools/transitioning-a-typical-engineering-ops-team-into-an-sre-powerhouse/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_B_Rnd3.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eTransitioning a typical engineering ops team into an SRE powerhouse\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eMoving a network operations team to an SRE-driven model took some time, but was well worth the effort, as teams can focus on reliability ...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eLots more to read\u003c/h3\u003e\u003cp\u003eCan’t wait to read more about SRE? We wrote \u003ca href=\"https://sre.google/sre-book/table-of-contents/\" target=\"_blank\"\u003ean entire book on SRE\u003c/a\u003e to help you get started (actually, we’ve written \u003ca href=\"https://sre.google/books/\" target=\"_blank\"\u003emore than one\u003c/a\u003e). You can also find all our \u003ca href=\"https://cloud.google.com/blog/products/devops-sre\"\u003eDevOps and SRE blog content\u003c/a\u003e or follow our columns on \u003ca href=\"https://cloud.google.com/blog/topics/cre-life-lessons\"\u003eCustomer Reliability Engineering\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/gcp/sre-vs-devops-competing-standards-or-close-friends/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/SREvsDevOps.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eSRE vs. DevOps: Competing standards or close friends?\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eWhat exactly is SRE and how does it relate to DevOps? This post helps answer questions and reduce friction between the communities.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_C_Rnd3_n7MW7mI.max-2200x2200.jpg",
      "date_published": "2021-04-23T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eThe Google Cloud content marketing team \u003c/name\u003e\u003ctitle\u003e\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/a-practical-guide-to-cloud-migration-from-google-cloud-sres/",
      "title": "How do you eat an elephant? Google SREs talk digital transformation",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Today, everything from payroll software to specialized machine-learning systems is available \u0026amp;#8220;as a service\u0026amp;#8221; in the cloud, addressing a vast range of needs across businesses, enabling rapid growth and scale while allowing a business to focus on its core competencies.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;But moving to the cloud can generate tension, which is inevitably challenging for everyone involved\u0026amp;#8212;especially if that transformation creates \u0026amp;#34;winners\u0026amp;#34; and \u0026amp;#34;losers\u0026amp;#34; or frames individuals as \u0026amp;#34;old\u0026amp;#34; or \u0026amp;#34;new.\u0026amp;#34; The good news; however, is that a cloud transformation doesn\u0026#39;t have to be this way.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;As Google Cloud has grown, so too has the team of Googlers who build and support the platform, and many of us have sat in the same seat as our customers. We\u0026#39;ve experienced firsthand how empowering it can be to shape the future of an organization, help one another grow, as well as unlock the business opportunities that a transformation provides. Our own personal experiences, and those of our peers, have led us to conclude one thing we know to be true for every company - the story of digital transformation is a human story\u0026amp;#8212;one that involves as much cultural transformation as technological transformation. It\u0026amp;#8217;s with this realization we have identified the deeper factors behind a successful transformation. That\u0026#39;s why we recently published a guide, reflecting on the nature of these changes and how you can take action in your own organization to drive a migration to the cloud.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Posing challenging questions helps you reflect on your own organization\u0026amp;#8217;s journey and the unique path you will need to take to lead to meaningful change. We wrote this guide to share key tenets that underpin the change philosophy you need to instill in your own organization. In \u0026lt;a href=\u0026#34;https://googlesre.page.link/cloud-migration-guide\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;A Practical Guide to Moving to Cloud\u0026lt;/a\u0026gt;, we present the following calls to action:\u0026lt;/p\u0026gt;\u0026lt;ol\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Understand who in the organization you need to enlist to move to cloud.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Create a psychologically safe culture in which you can grow together.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Define clear objectives for your organization. Document measurable steps towards these goals and understand that each step must, in and of itself, deliver value.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Review your existing organizational behaviors and set principles/policies which influence and direct every future decision related to your transformation.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Use your new culture to refine how decisions are made, and provide meaningful autonomy across the organization.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Build structures that empower practitioners to share best practices and solve common problems. Use these structures to empower your peers.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Build guardrails into your cloud platform that support transformation, at pace, without negatively impacting others. Support safe experimentation.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Understand what types of cloud platforms are the best fit for your business needs and determine your multi-cloud strategy in anticipation of your evolving business needs (e.g. acquisitions, new revenue streams, competitive responses).\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Recognize that everything is now software, and understand what this means for your existing IT infrastructure functions.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Don\u0026amp;#8217;t be afraid to revisit existing, hallowed, security policies. Making them fit-for-purpose is crucial.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Continuously measure and apply your new policies through software.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Be bold; build a new way of operating your business products with a customer-centric perspective.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Love your developers.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ol\u0026gt;\u0026lt;p\u0026gt;At Google Cloud, we\u0026amp;#8217;re here to help you craft the right migration for you and your business. \u0026lt;a href=\u0026#34;https://googlesre.page.link/cloud-migration-guide\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;A Practical Guide to Moving to Cloud\u0026lt;/a\u0026gt; is available as a free download. You can also learn more about our \u0026lt;a href=\u0026#34;https://cloud.google.com/solutions/migration-center\u0026#34;\u0026gt;data center migration solutions\u0026lt;/a\u0026gt; or \u0026lt;a href=\u0026#34;https://inthecloud.withgoogle.com/tco-assessment-19/form.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;sign up for a free migration cost assessment\u0026lt;/a\u0026gt;. Let\u0026amp;#8217;s get migrating!\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;Visit \u0026lt;a href=\u0026#34;https://sre.google\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;sre.google\u0026lt;/a\u0026gt; to learn more about SRE and industry-leading practices for service reliability.\u0026lt;/i\u0026gt;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eToday, everything from payroll software to specialized machine-learning systems is available “as a service” in the cloud, addressing a vast range of needs across businesses, enabling rapid growth and scale while allowing a business to focus on its core competencies.\u003c/p\u003e\u003cp\u003eBut moving to the cloud can generate tension, which is inevitably challenging for everyone involved—especially if that transformation creates \u0026#34;winners\u0026#34; and \u0026#34;losers\u0026#34; or frames individuals as \u0026#34;old\u0026#34; or \u0026#34;new.\u0026#34; The good news; however, is that a cloud transformation doesn\u0026#39;t have to be this way.\u003c/p\u003e\u003cp\u003eAs Google Cloud has grown, so too has the team of Googlers who build and support the platform, and many of us have sat in the same seat as our customers. We\u0026#39;ve experienced firsthand how empowering it can be to shape the future of an organization, help one another grow, as well as unlock the business opportunities that a transformation provides. Our own personal experiences, and those of our peers, have led us to conclude one thing we know to be true for every company - the story of digital transformation is a human story—one that involves as much cultural transformation as technological transformation. It’s with this realization we have identified the deeper factors behind a successful transformation. That\u0026#39;s why we recently published a guide, reflecting on the nature of these changes and how you can take action in your own organization to drive a migration to the cloud. \u003c/p\u003e\u003cp\u003ePosing challenging questions helps you reflect on your own organization’s journey and the unique path you will need to take to lead to meaningful change. We wrote this guide to share key tenets that underpin the change philosophy you need to instill in your own organization. In \u003ca href=\"https://googlesre.page.link/cloud-migration-guide\" target=\"_blank\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://googlesre.page.link\" track-metadata-module=\"post\"\u003eA Practical Guide to Moving to Cloud\u003c/a\u003e, we present the following calls to action:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cp\u003eUnderstand who in the organization you need to enlist to move to cloud.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCreate a psychologically safe culture in which you can grow together.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDefine clear objectives for your organization. Document measurable steps towards these goals and understand that each step must, in and of itself, deliver value.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eReview your existing organizational behaviors and set principles/policies which influence and direct every future decision related to your transformation.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eUse your new culture to refine how decisions are made, and provide meaningful autonomy across the organization.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eBuild structures that empower practitioners to share best practices and solve common problems. Use these structures to empower your peers.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eBuild guardrails into your cloud platform that support transformation, at pace, without negatively impacting others. Support safe experimentation.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eUnderstand what types of cloud platforms are the best fit for your business needs and determine your multi-cloud strategy in anticipation of your evolving business needs (e.g. acquisitions, new revenue streams, competitive responses).\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eRecognize that everything is now software, and understand what this means for your existing IT infrastructure functions.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDon’t be afraid to revisit existing, hallowed, security policies. Making them fit-for-purpose is crucial.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eContinuously measure and apply your new policies through software.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eBe bold; build a new way of operating your business products with a customer-centric perspective. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eLove your developers.\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eAt Google Cloud, we’re here to help you craft the right migration for you and your business. \u003ca href=\"https://googlesre.page.link/cloud-migration-guide\" target=\"_blank\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://googlesre.page.link\" track-metadata-module=\"post\"\u003eA Practical Guide to Moving to Cloud\u003c/a\u003e is available as a free download. You can also learn more about our \u003ca href=\"https://cloud.google.com/solutions/migration-center\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/solutions/migration-center\" track-metadata-module=\"post\"\u003edata center migration solutions\u003c/a\u003e or \u003ca href=\"https://inthecloud.withgoogle.com/tco-assessment-19/form.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://inthecloud.withgoogle.com\" track-metadata-module=\"post\"\u003esign up for a free migration cost assessment\u003c/a\u003e. Let’s get migrating! \u003c/p\u003e\u003cp\u003e\u003ci\u003eVisit \u003ca href=\"https://sre.google\" target=\"_blank\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://sre.google\" track-metadata-module=\"post\"\u003esre.google\u003c/a\u003e to learn more about SRE and industry-leading practices for service reliability.\u003c/i\u003e\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eToday, everything from payroll software to specialized machine-learning systems is available “as a service” in the cloud, addressing a vast range of needs across businesses, enabling rapid growth and scale while allowing a business to focus on its core competencies.\u003c/p\u003e\u003cp\u003eBut moving to the cloud can generate tension, which is inevitably challenging for everyone involved—especially if that transformation creates \"winners\" and \"losers\" or frames individuals as \"old\" or \"new.\" The good news; however, is that a cloud transformation doesn't have to be this way.\u003c/p\u003e\u003cp\u003eAs Google Cloud has grown, so too has the team of Googlers who build and support the platform, and many of us have sat in the same seat as our customers. We've experienced firsthand how empowering it can be to shape the future of an organization, help one another grow, as well as unlock the business opportunities that a transformation provides. Our own personal experiences, and those of our peers, have led us to conclude one thing we know to be true for every company - the story of digital transformation is a human story—one that involves as much cultural transformation as technological transformation. It’s with this realization we have identified the deeper factors behind a successful transformation. That's why we recently published a guide, reflecting on the nature of these changes and how you can take action in your own organization to drive a migration to the cloud. \u003c/p\u003e\u003cp\u003ePosing challenging questions helps you reflect on your own organization’s journey and the unique path you will need to take to lead to meaningful change. We wrote this guide to share key tenets that underpin the change philosophy you need to instill in your own organization. In \u003ca href=\"https://googlesre.page.link/cloud-migration-guide\" target=\"_blank\"\u003eA Practical Guide to Moving to Cloud\u003c/a\u003e, we present the following calls to action:\u003c/p\u003e\u003col\u003e\u003cli\u003e\u003cp\u003eUnderstand who in the organization you need to enlist to move to cloud.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCreate a psychologically safe culture in which you can grow together.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDefine clear objectives for your organization. Document measurable steps towards these goals and understand that each step must, in and of itself, deliver value.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eReview your existing organizational behaviors and set principles/policies which influence and direct every future decision related to your transformation.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eUse your new culture to refine how decisions are made, and provide meaningful autonomy across the organization.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eBuild structures that empower practitioners to share best practices and solve common problems. Use these structures to empower your peers.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eBuild guardrails into your cloud platform that support transformation, at pace, without negatively impacting others. Support safe experimentation.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eUnderstand what types of cloud platforms are the best fit for your business needs and determine your multi-cloud strategy in anticipation of your evolving business needs (e.g. acquisitions, new revenue streams, competitive responses).\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eRecognize that everything is now software, and understand what this means for your existing IT infrastructure functions.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eDon’t be afraid to revisit existing, hallowed, security policies. Making them fit-for-purpose is crucial.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eContinuously measure and apply your new policies through software.\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eBe bold; build a new way of operating your business products with a customer-centric perspective. \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eLove your developers.\u003c/p\u003e\u003c/li\u003e\u003c/ol\u003e\u003cp\u003eAt Google Cloud, we’re here to help you craft the right migration for you and your business. \u003ca href=\"https://googlesre.page.link/cloud-migration-guide\" target=\"_blank\"\u003eA Practical Guide to Moving to Cloud\u003c/a\u003e is available as a free download. You can also learn more about our \u003ca href=\"https://cloud.google.com/solutions/migration-center\"\u003edata center migration solutions\u003c/a\u003e or \u003ca href=\"https://inthecloud.withgoogle.com/tco-assessment-19/form.html\" target=\"_blank\"\u003esign up for a free migration cost assessment\u003c/a\u003e. Let’s get migrating! \u003c/p\u003e\u003cp\u003e\u003ci\u003eVisit \u003ca href=\"https://sre.google\" target=\"_blank\"\u003esre.google\u003c/a\u003e to learn more about SRE and industry-leading practices for service reliability.\u003c/i\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/how-sre-teams-are-organized-and-how-to-get-started/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_B_Rnd3.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eHow SRE teams are organized, and how to get started\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eLearn six different implementations of SRE teams you can apply in your organization, as well as how to establish boundaries to achieve th...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Blog_CloudMigration_D.max-2200x2200.jpg",
      "date_published": "2021-03-12T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eKieran Broadfoot\u003c/name\u003e\u003ctitle\u003eDirector, Site Reliability Engineering\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/devops-sre/sre-success-starts-with-getting-leadership-on-board/",
      "title": "With SRE, failing to plan is planning to fail",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;People sometimes think that implementing \u0026lt;a href=\u0026#34;http://sre.google\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Site Reliability Engineering\u0026lt;/a\u0026gt; (or DevOps for that matter) will magically make everything better. Just sprinkle a little bit of SRE fairy dust on your organization and your services will be more reliable, more profitable, and your IT, product and engineering teams will be happy.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;It\u0026amp;#8217;s easy to see why people think this way. Some of the world\u0026amp;#8217;s most reliable and scalable services run with the help of an SRE team, Google being the prime example.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;For almost two decades, I\u0026amp;#8217;ve lived and breathed running production systems at large scale. I had to think about tradeoffs, reliability, costs, implementing a variety of architectures with different constraints and requirements\u0026amp;#8212;all while getting paged in the middle of the night. More recently, I\u0026amp;#8217;ve had the privilege to leverage that experience and knowledge to help Google Cloud customers modernize their infrastructure and applications, including implementing an SRE practice. While these learnings look different from organization to organization, there are common lessons learned that will impact the success of your deployment.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;When problems do arise, it\u0026amp;#8217;s usually not because of technical challenges. A stalled SRE culture is usually a business process failure\u0026amp;#8212;goals weren\u0026amp;#8217;t properly defined up front and stakeholders weren\u0026amp;#8217;t properly engaged. After watching this play out repeatedly, I\u0026amp;#8217;ve developed some advice for technology leaders about how to implement a successful SRE practice.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Before you start\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Your SRE journey should start well before you read your first manual, or put in your first call to an SRE advisor. As a technology leader within your organization, your first job is to answer a few key questions and gather some basic facts.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;What problem are you trying to solve?\u0026amp;#160;\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Most organizations will readily admit they\u0026amp;#8217;re not perfect. Perhaps you need to \u0026lt;a href=\u0026#34;https://www.youtube.com/watch?v=IvQ-15-yE_c\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;reduce toil\u0026lt;/a\u0026gt;, be more innovative, or release software faster. SRE, as a framework for operating large scale systems reliably, can certainly help with those goals. To do that, it\u0026amp;#8217;s important to understand your motivations and what gaps or needs exist in your organization.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Ask yourself what the organization is trying to achieve from the transformation. What worries the organization about reliability? For SRE to be successful and efficient, it is crucial to \u0026lt;b\u0026gt;start with the pain\u0026lt;/b\u0026gt;. Starting by identifying what you are trying to solve will not just help you solve it; it will help your organization be more focused, align the relevant parties to a common goal, and make it easier to gain decision-makers\u0026amp;#8217; buy-in (and much more).\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Once you understand the problem you are trying to solve, you need to know when you have \u0026amp;#8220;solved\u0026amp;#8221; it (e.g. how you will define success). Setting goals is critical\u0026amp;#8212;otherwise, how will you know if you have improved? We\u0026amp;#8217;ll discuss how to set up metrics to help in this self-evaluation in a later post.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Who are the key decision-makers in the organization?\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Even though implementing SRE principles involves engineering at its core, it\u0026amp;#8217;s actually more of a transformation process than a technological challenge. As such, it will likely require procedural and cultural changes.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;As with any business transformation, you need to identify the relevant decision-makers up front. Who those people are depends on the organization, but it usually includes stakeholders from product, operations, and engineering leadership, though these can be named differently in various organizations and can even be separated under multiple organizations. Identifying those decision makers can be especially difficult in a siloed organization. It is important to take the time and reach out to different groups to identify the key stakeholders and influencers (it will save you a lot of time later on). Make sure that you are throwing a wide enough net. It is important to get input from different groups with different requirements (e.g., security).\u0026amp;#160;\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;At the same time, try to be \u0026lt;b\u0026gt;flexible\u0026lt;/b\u0026gt;. It\u0026amp;#8217;s okay if your list of decision makers gets updated and fine-tuned during the process. Like in other engineering domains, the goal is to start simple and iterate.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Get buy-in and build trust\u0026lt;/b\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Once you\u0026amp;#8217;ve identified the relevant decision makers, make sure you have support from your colleagues, and the rest of the organization\u0026amp;#8217;s leaders. \u0026lt;b\u0026gt;Creating an empowered culture\u0026lt;/b\u0026gt; is critical for implementing the core principles of SRE: a \u0026lt;a href=\u0026#34;https://cloud.google.com/solutions/devops/devops-culture-learning-culture\u0026#34;\u0026gt;learning culture\u0026lt;/a\u0026gt; that accepts failures, that facilitates blamelessness and creates psychological safety, all while prioritizing gradual changes and automation.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;From my experience, you cannot drive real change in an organization without widespread support and buy-in from leadership and decision-makers\u0026amp;#8212;and that\u0026amp;#8217;s especially true for SRE.\u0026amp;#160; Implementing SRE, similar to DevOps, requires collaboration between different functions in the organization (product, operations and development). In most organizations, those functions fall under separate leadership chains, each with its own processes. If you\u0026amp;#8217;re going to align those goals and procedures, leadership needs to prioritize the change. At the same time, driving cultural change from the bottom up can be more challenging and take longer than top-down mandates, and in some cultures will be impossible. In short, leading by example and enabling the people in the organization are critical for driving change and fostering the \u0026#39;right\u0026#39; culture.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Remember: it\u0026#39;s a marathon, not a sprint\u0026amp;#160;\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;The journey to SRE combines several challenges, both from technical and human (culture, process, extra) perspectives, and those are intertwined. To be successful, leadership needs to prioritize organizational changes, allocating resources for \u0026lt;b\u0026gt;engineering excellence\u0026lt;/b\u0026gt; (quality and reliability) and \u0026lt;a href=\u0026#34;https://cloud.google.com/solutions/devops/devops-culture-westrum-organizational-culture#how_to_implement_organizational_culture\u0026#34;\u0026gt;\u0026lt;b\u0026gt;fostering cultural principles\u0026lt;/b\u0026gt;\u0026lt;/a\u0026gt; like reducing silos, blamelessness and accepting failure as normal.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Align expectations! All parties involved in an SRE implementation\u0026amp;#8212;from product and engineering to leadership\u0026amp;#8212;will need to recognize that change takes time and effort, and in the short term\u0026amp;#8212;resources. Daunting as it may be, SRE\u0026amp;#8217;s goal is to solve hard problems and build for a better tomorrow.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;i\u0026gt;Interested in getting deeper with SRE principles? Check out this Coursera course for leaders, \u0026lt;a href=\u0026#34;https://www.coursera.org/learn/developing-a-google-sre-culture\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Developing a Google SRE Culture\u0026lt;/a\u0026gt;.\u0026lt;/i\u0026gt; And stay tuned for my next post, where I outline some tactical considerations for teams that are early on their SRE journey, from identifying the right teams to start with, enablement and building community.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003ePeople sometimes think that implementing \u003ca href=\"http://sre.google\" target=\"_blank\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"http://sre.google\" track-metadata-module=\"post\"\u003eSite Reliability Engineering\u003c/a\u003e (or DevOps for that matter) will magically make everything better. Just sprinkle a little bit of SRE fairy dust on your organization and your services will be more reliable, more profitable, and your IT, product and engineering teams will be happy.\u003c/p\u003e\u003cp\u003eIt’s easy to see why people think this way. Some of the world’s most reliable and scalable services run with the help of an SRE team, Google being the prime example. \u003c/p\u003e\u003cp\u003eFor almost two decades, I’ve lived and breathed running production systems at large scale. I had to think about tradeoffs, reliability, costs, implementing a variety of architectures with different constraints and requirements—all while getting paged in the middle of the night. More recently, I’ve had the privilege to leverage that experience and knowledge to help Google Cloud customers modernize their infrastructure and applications, including implementing an SRE practice. While these learnings look different from organization to organization, there are common lessons learned that will impact the success of your deployment.\u003c/p\u003e\u003cp\u003eWhen problems do arise, it’s usually not because of technical challenges. A stalled SRE culture is usually a business process failure—goals weren’t properly defined up front and stakeholders weren’t properly engaged. After watching this play out repeatedly, I’ve developed some advice for technology leaders about how to implement a successful SRE practice. \u003c/p\u003e\u003ch3\u003eBefore you start\u003c/h3\u003e\u003cp\u003eYour SRE journey should start well before you read your first manual, or put in your first call to an SRE advisor. As a technology leader within your organization, your first job is to answer a few key questions and gather some basic facts. \u003c/p\u003e\u003cp\u003e\u003cb\u003eWhat problem are you trying to solve? \u003c/b\u003e\u003c/p\u003e\u003cp\u003eMost organizations will readily admit they’re not perfect. Perhaps you need to \u003ca href=\"https://www.youtube.com/watch?v=IvQ-15-yE_c\" target=\"_blank\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://www.youtube.com\" track-metadata-module=\"post\"\u003ereduce toil\u003c/a\u003e, be more innovative, or release software faster. SRE, as a framework for operating large scale systems reliably, can certainly help with those goals. To do that, it’s important to understand your motivations and what gaps or needs exist in your organization.\u003c/p\u003e\u003cp\u003eAsk yourself what the organization is trying to achieve from the transformation. What worries the organization about reliability? For SRE to be successful and efficient, it is crucial to \u003cb\u003estart with the pain\u003c/b\u003e. Starting by identifying what you are trying to solve will not just help you solve it; it will help your organization be more focused, align the relevant parties to a common goal, and make it easier to gain decision-makers’ buy-in (and much more).\u003c/p\u003e\u003cp\u003eOnce you understand the problem you are trying to solve, you need to know when you have “solved” it (e.g. how you will define success). Setting goals is critical—otherwise, how will you know if you have improved? We’ll discuss how to set up metrics to help in this self-evaluation in a later post.\u003c/p\u003e\u003cp\u003e\u003cb\u003eWho are the key decision-makers in the organization?\u003c/b\u003e\u003c/p\u003e\u003cp\u003eEven though implementing SRE principles involves engineering at its core, it’s actually more of a transformation process than a technological challenge. As such, it will likely require procedural and cultural changes.\u003c/p\u003e\u003cp\u003eAs with any business transformation, you need to identify the relevant decision-makers up front. Who those people are depends on the organization, but it usually includes stakeholders from product, operations, and engineering leadership, though these can be named differently in various organizations and can even be separated under multiple organizations. Identifying those decision makers can be especially difficult in a siloed organization. It is important to take the time and reach out to different groups to identify the key stakeholders and influencers (it will save you a lot of time later on). Make sure that you are throwing a wide enough net. It is important to get input from different groups with different requirements (e.g., security).  \u003c/p\u003e\u003cp\u003eAt the same time, try to be \u003cb\u003eflexible\u003c/b\u003e. It’s okay if your list of decision makers gets updated and fine-tuned during the process. Like in other engineering domains, the goal is to start simple and iterate. \u003c/p\u003e\u003cp\u003e\u003cb\u003eGet buy-in and build trust\u003c/b\u003e\u003c/p\u003e\u003cp\u003eOnce you’ve identified the relevant decision makers, make sure you have support from your colleagues, and the rest of the organization’s leaders. \u003cb\u003eCreating an empowered culture\u003c/b\u003e is critical for implementing the core principles of SRE: a \u003ca href=\"https://cloud.google.com/solutions/devops/devops-culture-learning-culture\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/solutions/devops/devops-culture-learning-culture\" track-metadata-module=\"post\"\u003elearning culture\u003c/a\u003e that accepts failures, that facilitates blamelessness and creates psychological safety, all while prioritizing gradual changes and automation.\u003c/p\u003e\u003cp\u003eFrom my experience, you cannot drive real change in an organization without widespread support and buy-in from leadership and decision-makers—and that’s especially true for SRE.  Implementing SRE, similar to DevOps, requires collaboration between different functions in the organization (product, operations and development). In most organizations, those functions fall under separate leadership chains, each with its own processes. If you’re going to align those goals and procedures, leadership needs to prioritize the change. At the same time, driving cultural change from the bottom up can be more challenging and take longer than top-down mandates, and in some cultures will be impossible. In short, leading by example and enabling the people in the organization are critical for driving change and fostering the \u0026#39;right\u0026#39; culture.\u003c/p\u003e\u003ch3\u003eRemember: it\u0026#39;s a marathon, not a sprint \u003c/h3\u003e\u003cp\u003eThe journey to SRE combines several challenges, both from technical and human (culture, process, extra) perspectives, and those are intertwined. To be successful, leadership needs to prioritize organizational changes, allocating resources for \u003cb\u003eengineering excellence\u003c/b\u003e (quality and reliability) and \u003ca href=\"https://cloud.google.com/solutions/devops/devops-culture-westrum-organizational-culture#how_to_implement_organizational_culture\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://cloud.google.com/solutions/devops/devops-culture-westrum-organizational-culture#how_to_implement_organizational_culture\" track-metadata-module=\"post\"\u003e\u003cb\u003efostering cultural principles\u003c/b\u003e\u003c/a\u003e like reducing silos, blamelessness and accepting failure as normal.\u003c/p\u003e\u003cp\u003eAlign expectations! All parties involved in an SRE implementation—from product and engineering to leadership—will need to recognize that change takes time and effort, and in the short term—resources. Daunting as it may be, SRE’s goal is to solve hard problems and build for a better tomorrow. \u003c/p\u003e\u003cp\u003e\u003ci\u003eInterested in getting deeper with SRE principles? Check out this Coursera course for leaders, \u003ca href=\"https://www.coursera.org/learn/developing-a-google-sre-culture\" target=\"_blank\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://www.coursera.org\" track-metadata-module=\"post\"\u003eDeveloping a Google SRE Culture\u003c/a\u003e.\u003c/i\u003e And stay tuned for my next post, where I outline some tactical considerations for teams that are early on their SRE journey, from identifying the right teams to start with, enablement and building community.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003ePeople sometimes think that implementing \u003ca href=\"http://sre.google\" target=\"_blank\"\u003eSite Reliability Engineering\u003c/a\u003e (or DevOps for that matter) will magically make everything better. Just sprinkle a little bit of SRE fairy dust on your organization and your services will be more reliable, more profitable, and your IT, product and engineering teams will be happy.\u003c/p\u003e\u003cp\u003eIt’s easy to see why people think this way. Some of the world’s most reliable and scalable services run with the help of an SRE team, Google being the prime example. \u003c/p\u003e\u003cp\u003eFor almost two decades, I’ve lived and breathed running production systems at large scale. I had to think about tradeoffs, reliability, costs, implementing a variety of architectures with different constraints and requirements—all while getting paged in the middle of the night. More recently, I’ve had the privilege to leverage that experience and knowledge to help Google Cloud customers modernize their infrastructure and applications, including implementing an SRE practice. While these learnings look different from organization to organization, there are common lessons learned that will impact the success of your deployment.\u003c/p\u003e\u003cp\u003eWhen problems do arise, it’s usually not because of technical challenges. A stalled SRE culture is usually a business process failure—goals weren’t properly defined up front and stakeholders weren’t properly engaged. After watching this play out repeatedly, I’ve developed some advice for technology leaders about how to implement a successful SRE practice. \u003c/p\u003e\u003ch3\u003eBefore you start\u003c/h3\u003e\u003cp\u003eYour SRE journey should start well before you read your first manual, or put in your first call to an SRE advisor. As a technology leader within your organization, your first job is to answer a few key questions and gather some basic facts. \u003c/p\u003e\u003cp\u003e\u003cb\u003eWhat problem are you trying to solve? \u003c/b\u003e\u003c/p\u003e\u003cp\u003eMost organizations will readily admit they’re not perfect. Perhaps you need to \u003ca href=\"https://www.youtube.com/watch?v=IvQ-15-yE_c\" target=\"_blank\"\u003ereduce toil\u003c/a\u003e, be more innovative, or release software faster. SRE, as a framework for operating large scale systems reliably, can certainly help with those goals. To do that, it’s important to understand your motivations and what gaps or needs exist in your organization.\u003c/p\u003e\u003cp\u003eAsk yourself what the organization is trying to achieve from the transformation. What worries the organization about reliability? For SRE to be successful and efficient, it is crucial to \u003cb\u003estart with the pain\u003c/b\u003e. Starting by identifying what you are trying to solve will not just help you solve it; it will help your organization be more focused, align the relevant parties to a common goal, and make it easier to gain decision-makers’ buy-in (and much more).\u003c/p\u003e\u003cp\u003eOnce you understand the problem you are trying to solve, you need to know when you have “solved” it (e.g. how you will define success). Setting goals is critical—otherwise, how will you know if you have improved? We’ll discuss how to set up metrics to help in this self-evaluation in a later post.\u003c/p\u003e\u003cp\u003e\u003cb\u003eWho are the key decision-makers in the organization?\u003c/b\u003e\u003c/p\u003e\u003cp\u003eEven though implementing SRE principles involves engineering at its core, it’s actually more of a transformation process than a technological challenge. As such, it will likely require procedural and cultural changes.\u003c/p\u003e\u003cp\u003eAs with any business transformation, you need to identify the relevant decision-makers up front. Who those people are depends on the organization, but it usually includes stakeholders from product, operations, and engineering leadership, though these can be named differently in various organizations and can even be separated under multiple organizations. Identifying those decision makers can be especially difficult in a siloed organization. It is important to take the time and reach out to different groups to identify the key stakeholders and influencers (it will save you a lot of time later on). Make sure that you are throwing a wide enough net. It is important to get input from different groups with different requirements (e.g., security).  \u003c/p\u003e\u003cp\u003eAt the same time, try to be \u003cb\u003eflexible\u003c/b\u003e. It’s okay if your list of decision makers gets updated and fine-tuned during the process. Like in other engineering domains, the goal is to start simple and iterate. \u003c/p\u003e\u003cp\u003e\u003cb\u003eGet buy-in and build trust\u003c/b\u003e\u003c/p\u003e\u003cp\u003eOnce you’ve identified the relevant decision makers, make sure you have support from your colleagues, and the rest of the organization’s leaders. \u003cb\u003eCreating an empowered culture\u003c/b\u003e is critical for implementing the core principles of SRE: a \u003ca href=\"https://cloud.google.com/solutions/devops/devops-culture-learning-culture\"\u003elearning culture\u003c/a\u003e that accepts failures, that facilitates blamelessness and creates psychological safety, all while prioritizing gradual changes and automation.\u003c/p\u003e\u003cp\u003eFrom my experience, you cannot drive real change in an organization without widespread support and buy-in from leadership and decision-makers—and that’s especially true for SRE.  Implementing SRE, similar to DevOps, requires collaboration between different functions in the organization (product, operations and development). In most organizations, those functions fall under separate leadership chains, each with its own processes. If you’re going to align those goals and procedures, leadership needs to prioritize the change. At the same time, driving cultural change from the bottom up can be more challenging and take longer than top-down mandates, and in some cultures will be impossible. In short, leading by example and enabling the people in the organization are critical for driving change and fostering the 'right' culture.\u003c/p\u003e\u003ch3\u003eRemember: it's a marathon, not a sprint \u003c/h3\u003e\u003cp\u003eThe journey to SRE combines several challenges, both from technical and human (culture, process, extra) perspectives, and those are intertwined. To be successful, leadership needs to prioritize organizational changes, allocating resources for \u003cb\u003eengineering excellence\u003c/b\u003e (quality and reliability) and \u003ca href=\"https://cloud.google.com/solutions/devops/devops-culture-westrum-organizational-culture#how_to_implement_organizational_culture\"\u003e\u003cb\u003efostering cultural principles\u003c/b\u003e\u003c/a\u003e like reducing silos, blamelessness and accepting failure as normal.\u003c/p\u003e\u003cp\u003eAlign expectations! All parties involved in an SRE implementation—from product and engineering to leadership—will need to recognize that change takes time and effort, and in the short term—resources. Daunting as it may be, SRE’s goal is to solve hard problems and build for a better tomorrow. \u003c/p\u003e\u003cp\u003e\u003ci\u003eInterested in getting deeper with SRE principles? Check out this Coursera course for leaders, \u003ca href=\"https://www.coursera.org/learn/developing-a-google-sre-culture\" target=\"_blank\"\u003eDeveloping a Google SRE Culture\u003c/a\u003e.\u003c/i\u003e And stay tuned for my next post, where I outline some tactical considerations for teams that are early on their SRE journey, from identifying the right teams to start with, enablement and building community.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/devops-sre/four-steps-to-jumpstarting-your-sre-practice/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_A_Rnd3.max-2800x2800.max-500x500.jpg')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eFour steps to jumpstarting your SRE practice\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eOnce you have leadership buy-in, there are some things you can do to get the SRE ball rolling, fast.\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/DevOps_BlogHeader_D_Rnd3.max-2200x2200.jpg",
      "date_published": "2021-02-26T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eAyelet Sachto\u003c/name\u003e\u003ctitle\u003eStrategic Cloud Engineer, Infra, AppMod, SRE\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/operations/troubleshooting-services-on-google-kubernetes-engine/",
      "title": "Troubleshooting services on Google Kubernetes Engine by example",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003carticle-page\u003e\u003cmain id=\"jump-content\"\u003e\u003carticle\u003e\u003carticle-header-block\u003e\u003c/article-header-block\u003e\u003carticle-aspect-image-block\u003e\u003cfigure\u003e\u003cp\u003e\u003cspan\u003e#containers\u003c/span\u003e\u003c/p\u003e\u003c/figure\u003e\u003c/article-aspect-image-block\u003e\u003cdiv\u003e\u003carticle-cta _nghost-c17=\"\"\u003e\u003cdiv _ngcontent-c17=\"\"\u003e\u003ch4 _ngcontent-c17=\"\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eTry GCP\u003c/span\u003e\u003c/h4\u003e\u003cp _ngcontent-c17=\"\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eStart building on Google Cloud with $300 in free credits and 20+ always free products.\u003c/span\u003e\u003c/p\u003e\u003cp\u003e\u003ca _ngcontent-c17=\"\" clicktracker=\"\" rel=\"external\" track-metadata-module=\"article cta\" track-type=\"button\" track-name=\"free trial\" track-metadata-eventdetail=\"https://cloud.google.com/free/\" href=\"https://cloud.google.com/free/\"\u003e\u003cspan _ngcontent-c17=\"\"\u003eFree Trial\u003c/span\u003e\u003c/a\u003e\u003c/p\u003e\u003c/div\u003e\u003c/article-cta\u003e\u003c/div\u003e\u003carticle-share-block\u003e\u003c/article-share-block\u003e\u003carticle-sticky-share-block\u003e\u003c/article-sticky-share-block\u003e\u003cdiv\u003e\u003cdiv\u003e\u003carticle-content-stream-block\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;Applications fail. Containers crash. It\u0026amp;#8217;s a fact of life that SRE and DevOps teams know all too well. To help navigate life\u0026amp;#8217;s hiccups, we\u0026amp;#8217;ve previously shared \u0026lt;a href=\u0026#34;https://cloud.google.com/blog/products/containers-kubernetes/tools-for-debugging-apps-on-google-kubernetes-engine\u0026#34;\u0026gt;how to debug applications running on Google Kubernetes Engine (GKE)\u0026lt;/a\u0026gt;. We\u0026amp;#8217;ve also updated the GKE \u0026lt;a href=\u0026#34;https://cloud.google.com/stackdriver/docs/solutions/gke/observing\u0026#34;\u0026gt;dashboard\u0026lt;/a\u0026gt; with new easier-to-use troubleshooting flows. Today, we go one step further and show you how you can use these flows to quickly find and resolve issues in your applications and infrastructure.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In this blog, we\u0026#39;ll walk through deploying a sample app to your cluster and configuring an alerting policy that will notify you if there are any container restarts observed. From there, we\u0026#39;ll trigger the alert and explore how the new GKE dashboard makes it easy to identify the issue and determine exactly what\u0026#39;s going on with your workload or infrastructure that may be causing it.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Setting up\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Deploy the app\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;This example uses a \u0026lt;a href=\u0026#34;https://github.com/yuriatgoogle/stack-doctor/blob/master/crashing-pod-demo/main.go\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;demo app\u0026lt;/a\u0026gt; that exposes two endpoints: an endpoint at /, which is just a \u0026amp;#34;hello world\u0026amp;#34;, and a /crashme endpoint, which uses Go\u0026#39;s \u0026lt;code\u0026gt;os.Exit(1)\u0026lt;/code\u0026gt; to terminate the process. To deploy the app in your own cluster, create a container image using Cloud Build and \u0026lt;a href=\u0026#34;https://github.com/yuriatgoogle/stack-doctor/blob/master/crashing-pod-demo/deployment.yaml\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;deploy\u0026lt;/a\u0026gt; it to GKE. Then, expose the service with a load balancer.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Once the service is deployed, check the running pods:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eApplications fail. Containers crash. It’s a fact of life that SRE and DevOps teams know all too well. To help navigate life’s hiccups, we’ve previously shared \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/tools-for-debugging-apps-on-google-kubernetes-engine\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/blog/products/containers-kubernetes/tools-for-debugging-apps-on-google-kubernetes-engine\" track-metadata-module=\"post\"\u003ehow to debug applications running on Google Kubernetes Engine (GKE)\u003c/a\u003e. We’ve also updated the GKE \u003ca href=\"https://cloud.google.com/stackdriver/docs/solutions/gke/observing\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://cloud.google.com/stackdriver/docs/solutions/gke/observing\" track-metadata-module=\"post\"\u003edashboard\u003c/a\u003e with new easier-to-use troubleshooting flows. Today, we go one step further and show you how you can use these flows to quickly find and resolve issues in your applications and infrastructure. \u003c/p\u003e\u003cp\u003eIn this blog, we\u0026#39;ll walk through deploying a sample app to your cluster and configuring an alerting policy that will notify you if there are any container restarts observed. From there, we\u0026#39;ll trigger the alert and explore how the new GKE dashboard makes it easy to identify the issue and determine exactly what\u0026#39;s going on with your workload or infrastructure that may be causing it.\u003c/p\u003e\u003ch3\u003eSetting up\u003c/h3\u003e\u003cp\u003e\u003cb\u003eDeploy the app\u003cbr/\u003e\u003c/b\u003eThis example uses a \u003ca href=\"https://github.com/yuriatgoogle/stack-doctor/blob/master/crashing-pod-demo/main.go\" target=\"_blank\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003edemo app\u003c/a\u003e that exposes two endpoints: an endpoint at /, which is just a \u0026#34;hello world\u0026#34;, and a /crashme endpoint, which uses Go\u0026#39;s \u003ccode\u003eos.Exit(1)\u003c/code\u003e to terminate the process. To deploy the app in your own cluster, create a container image using Cloud Build and \u003ca href=\"https://github.com/yuriatgoogle/stack-doctor/blob/master/crashing-pod-demo/deployment.yaml\" target=\"_blank\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003edeploy\u003c/a\u003e it to GKE. Then, expose the service with a load balancer. \u003c/p\u003e\u003cp\u003eOnce the service is deployed, check the running pods:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c20=\"\"\u003e\u003cpre _ngcontent-c20=\"\"\u003e  \u003ccode _ngcontent-c20=\"\"\u003e✗ kubectl get pods\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003eNAME                                     READY   STATUS    RESTARTS   AGE\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003erestarting-deployment-54c8678f79-gjh2v   1/1     Running   0          6m38s\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003erestarting-deployment-54c8678f79-l8tsm   1/1     Running   0          6m38s\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003erestarting-deployment-54c8678f79-qjrcb   1/1     Running   0          6m38s\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cp\u003eNotice that RESTARTS is initially at zero for each pod. Use a browser or a command line tool like curl to access the /crashme endpoint. At this point, you should see a restart:\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c20=\"\"\u003e\u003cpre _ngcontent-c20=\"\"\u003e  \u003ccode _ngcontent-c20=\"\"\u003e✗ kubectl get pods\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003eNAME                                     READY   STATUS    RESTARTS   AGE\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003erestarting-deployment-54c8678f79-gjh2v   1/1     Running   1          9m28s\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003erestarting-deployment-54c8678f79-l8tsm   1/1     Running   0          9m28s\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003erestarting-deployment-54c8678f79-qjrcb   1/1     Running   0          9m28s\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cp\u003eEach request to that endpoint will result in a restart. However, be careful to not do this more often than every 30 seconds or so, otherwise, the containers will go into CrashLoopBackOff, and it will take time for the service to be available again. You can use this simple shell script to trigger restarts when as needed:\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-code-block _nghost-c20=\"\"\u003e\u003cpre _ngcontent-c20=\"\"\u003e  \u003ccode _ngcontent-c20=\"\"\u003ewhile true;\n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003edo \n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003ecurl http://$IP_ADDRESS:8080/crashme; \n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003esleep 45; \n\u003c/code\u003e\u003ccode _ngcontent-c20=\"\"\u003edone\u003c/code\u003e\n\u003c/pre\u003e\u003c/article-code-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;where $IP_ADDRESS is the IP address of the load balancer you\u0026#39;ve already created.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Why do container restarts matter? Well, restarts, to a certain degree, are an expected part of a container\u0026amp;#8217;s typical lifecycle in Kubernetes. Too many container restarts, however, could affect the availability of your service, especially when expanded over a larger number of replicas for a given Pod. Not only do excessive restarts degrade the service in question, but they also risks affecting other services downstream that use it as a dependency.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;In real life,the culprit for a large number of restarts could be a poorly designed liveness probe, issues like \u0026lt;a href=\u0026#34;https://en.wikipedia.org/wiki/Deadlock\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;deadlocks\u0026lt;/a\u0026gt; in the application itself, or misconfigured memory requests that result in \u0026lt;a href=\u0026#34;https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;\u0026lt;code\u0026gt;OOMkilled\u0026lt;/code\u0026gt;\u0026lt;/a\u0026gt; errors. So, it is important for you to proactively alert on container restarts to preempt potential degradation that can cascade across multiple services.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Configure the alert\u0026lt;br\u0026gt;\u0026lt;/b\u0026gt;Now, you\u0026#39;re ready to configure the alert that will notify you when restarts are detected. Here\u0026#39;s how to set up your \u0026lt;a href=\u0026#34;https://cloud.google.com/monitoring/alerts\u0026#34;\u0026gt;alerting policy\u0026lt;/a\u0026gt;:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003ewhere $IP_ADDRESS is the IP address of the load balancer you\u0026#39;ve already created. \u003c/p\u003e\u003cp\u003eWhy do container restarts matter? Well, restarts, to a certain degree, are an expected part of a container’s typical lifecycle in Kubernetes. Too many container restarts, however, could affect the availability of your service, especially when expanded over a larger number of replicas for a given Pod. Not only do excessive restarts degrade the service in question, but they also risks affecting other services downstream that use it as a dependency.\u003c/p\u003e\u003cp\u003eIn real life,the culprit for a large number of restarts could be a poorly designed liveness probe, issues like \u003ca href=\"https://en.wikipedia.org/wiki/Deadlock\" target=\"_blank\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"https://en.wikipedia.org\" track-metadata-module=\"post\"\u003edeadlocks\u003c/a\u003e in the application itself, or misconfigured memory requests that result in \u003ca href=\"https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/\" target=\"_blank\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://kubernetes.io\" track-metadata-module=\"post\"\u003e\u003ccode\u003eOOMkilled\u003c/code\u003e\u003c/a\u003e errors. So, it is important for you to proactively alert on container restarts to preempt potential degradation that can cascade across multiple services. \u003c/p\u003e\u003cp\u003e\u003cb\u003eConfigure the alert\u003cbr/\u003e\u003c/b\u003eNow, you\u0026#39;re ready to configure the alert that will notify you when restarts are detected. Here\u0026#39;s how to set up your \u003ca href=\"https://cloud.google.com/monitoring/alerts\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://cloud.google.com/monitoring/alerts\" track-metadata-module=\"post\"\u003ealerting policy\u003c/a\u003e:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;You can use the \u0026lt;code\u0026gt;kubernetes.io/container/restart_count\u0026lt;/code\u0026gt; metric, filtered to the specific container name (as specified in the deployment yaml \u0026lt;a href=\u0026#34;https://github.com/yuriatgoogle/stack-doctor/blob/master/crashing-pod-demo/deployment.yaml\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;file\u0026lt;/a\u0026gt;). Configure the alert to trigger if any timeseries exceeded zero\u0026amp;#8212;meaning if any container restarts are observed.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;With the setup done, you are ready to test and see what happens!\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Testing the alert\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;When you\u0026amp;#8217;re ready, start the looped script to hit the /crashme endpoint every 45 seconds. The restart_count metric is sampled every 60 seconds, so it shouldn\u0026#39;t take very long for an alert to show up on the dashboard:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eYou can use the \u003ccode\u003ekubernetes.io/container/restart_count\u003c/code\u003e metric, filtered to the specific container name (as specified in the deployment yaml \u003ca href=\"https://github.com/yuriatgoogle/stack-doctor/blob/master/crashing-pod-demo/deployment.yaml\" target=\"_blank\" track-type=\"inline link\" track-name=\"8\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003efile\u003c/a\u003e). Configure the alert to trigger if any timeseries exceeded zero—meaning if any container restarts are observed. \u003c/p\u003e\u003cp\u003eWith the setup done, you are ready to test and see what happens!\u003c/p\u003e\u003ch3\u003eTesting the alert\u003c/h3\u003e\u003cp\u003eWhen you’re ready, start the looped script to hit the /crashme endpoint every 45 seconds. The restart_count metric is sampled every 60 seconds, so it shouldn\u0026#39;t take very long for an alert to show up on the dashboard:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cp\u003eYou can mouse-over the incident to get more information about it:\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cp\u003eThen click on \u0026#34;View Incident\u0026#34;. This takes you to the Incident details screen, where you can see the specific resources that triggered it—in this case, the incident is generated by the container.\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cp\u003eNext, you can click on View Logs to see the logs (in the \u003ca href=\"https://cloud.google.com/logging/docs/view/logs-viewer-preview\" track-type=\"inline link\" track-name=\"9\" track-metadata-eventdetail=\"https://cloud.google.com/logging/docs/view/logs-viewer-preview\" track-metadata-module=\"post\"\u003enew Logs Viewer\u003c/a\u003e!)—it\u0026#39;s immediately apparently that the alert is triggered by the containers restarting:\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;This is all very nicely tied together and makes troubleshooting during an incident much easier!\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;In summary\u0026amp;#8230;.\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;The latest GKE dashboard includes many improvements over previous iterations. The new alerts timeline is intuitive, and incidents are clearly marked so that you can interact with them to get the full details of exactly what happened, all the way down to the container logs that tell you the actual problem.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;As an oncall SRE or DevOps engineer for a service running on GKE, the GKE dashboard makes it easier for you to respond to incidents. You\u0026#39;re now able to go from an incident all the way to debug logs quickly and easily and reduce the time it takes to triage and mitigate incidents. For a short overview on how to troubleshoot services on GKE, check out this video:\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eThis is all very nicely tied together and makes troubleshooting during an incident much easier!\u003c/p\u003e\u003ch3\u003eIn summary….\u003c/h3\u003e\u003cp\u003eThe latest GKE dashboard includes many improvements over previous iterations. The new alerts timeline is intuitive, and incidents are clearly marked so that you can interact with them to get the full details of exactly what happened, all the way down to the container logs that tell you the actual problem.\u003c/p\u003e\u003cp\u003eAs an oncall SRE or DevOps engineer for a service running on GKE, the GKE dashboard makes it easier for you to respond to incidents. You\u0026#39;re now able to go from an incident all the way to debug logs quickly and easily and reduce the time it takes to triage and mitigate incidents. For a short overview on how to troubleshoot services on GKE, check out this video:\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003carticle-video-block _nghost-c16=\"\"\u003e\u003cp _ngcontent-c16=\"\"\u003e\u003ciframe _ngcontent-c16=\"\" allow=\"encrypted-media\" allowfullscreen=\"\" frameborder=\"0\" height=\"100%\" position=\"absolute\" width=\"100%\" src=\"https://www.youtube.com/embed/--4WWwx4Log?enablejsapi=1\u0026amp;\"\u003e\u003c/iframe\u003e\u003c/p\u003e\u003c/article-video-block\u003e\u003c/div\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cp\u003e\u003ci\u003e\u003csup\u003eA special thanks to Anthony Bushong, Specialist Customer Engineer, for his contributions to this blog post.\u003c/sup\u003e\u003c/i\u003e\u003c/p\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/article-content-stream-block\u003e\u003carticle-tag-list-block\u003e\u003c/article-tag-list-block\u003e\u003c/div\u003e\u003csection\u003e\u003carticle-up-1to3-block _nghost-c18=\"\"\u003e\u003c/article-up-1to3-block\u003e\u003c/section\u003e\u003c/div\u003e\u003c/article\u003e\u003c/main\u003e\u003c/article-page\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eApplications fail. Containers crash. It’s a fact of life that SRE and DevOps teams know all too well. To help navigate life’s hiccups, we’ve previously shared \u003ca href=\"https://cloud.google.com/blog/products/containers-kubernetes/tools-for-debugging-apps-on-google-kubernetes-engine\"\u003ehow to debug applications running on Google Kubernetes Engine (GKE)\u003c/a\u003e. We’ve also updated the GKE \u003ca href=\"https://cloud.google.com/stackdriver/docs/solutions/gke/observing\"\u003edashboard\u003c/a\u003e with new easier-to-use troubleshooting flows. Today, we go one step further and show you how you can use these flows to quickly find and resolve issues in your applications and infrastructure. \u003c/p\u003e\u003cp\u003eIn this blog, we'll walk through deploying a sample app to your cluster and configuring an alerting policy that will notify you if there are any container restarts observed. From there, we'll trigger the alert and explore how the new GKE dashboard makes it easy to identify the issue and determine exactly what's going on with your workload or infrastructure that may be causing it.\u003c/p\u003e\u003ch3\u003eSetting up\u003c/h3\u003e\u003cp\u003e\u003cb\u003eDeploy the app\u003cbr/\u003e\u003c/b\u003eThis example uses a \u003ca href=\"https://github.com/yuriatgoogle/stack-doctor/blob/master/crashing-pod-demo/main.go\" target=\"_blank\"\u003edemo app\u003c/a\u003e that exposes two endpoints: an endpoint at /, which is just a \"hello world\", and a /crashme endpoint, which uses Go's \u003ccode\u003eos.Exit(1)\u003c/code\u003e to terminate the process. To deploy the app in your own cluster, create a container image using Cloud Build and \u003ca href=\"https://github.com/yuriatgoogle/stack-doctor/blob/master/crashing-pod-demo/deployment.yaml\" target=\"_blank\"\u003edeploy\u003c/a\u003e it to GKE. Then, expose the service with a load balancer. \u003c/p\u003e\u003cp\u003eOnce the service is deployed, check the running pods:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eNotice that RESTARTS is initially at zero for each pod. Use a browser or a command line tool like curl to access the /crashme endpoint. At this point, you should see a restart:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eEach request to that endpoint will result in a restart. However, be careful to not do this more often than every 30 seconds or so, otherwise, the containers will go into CrashLoopBackOff, and it will take time for the service to be available again. You can use this simple shell script to trigger restarts when as needed:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003ewhere $IP_ADDRESS is the IP address of the load balancer you've already created. \u003c/p\u003e\u003cp\u003eWhy do container restarts matter? Well, restarts, to a certain degree, are an expected part of a container’s typical lifecycle in Kubernetes. Too many container restarts, however, could affect the availability of your service, especially when expanded over a larger number of replicas for a given Pod. Not only do excessive restarts degrade the service in question, but they also risks affecting other services downstream that use it as a dependency.\u003c/p\u003e\u003cp\u003eIn real life,the culprit for a large number of restarts could be a poorly designed liveness probe, issues like \u003ca href=\"https://en.wikipedia.org/wiki/Deadlock\" target=\"_blank\"\u003edeadlocks\u003c/a\u003e in the application itself, or misconfigured memory requests that result in \u003ca href=\"https://kubernetes.io/docs/tasks/configure-pod-container/assign-memory-resource/\" target=\"_blank\"\u003e\u003ccode\u003eOOMkilled\u003c/code\u003e\u003c/a\u003e errors. So, it is important for you to proactively alert on container restarts to preempt potential degradation that can cascade across multiple services. \u003c/p\u003e\u003cp\u003e\u003cb\u003eConfigure the alert\u003cbr/\u003e\u003c/b\u003eNow, you're ready to configure the alert that will notify you when restarts are detected. Here's how to set up your \u003ca href=\"https://cloud.google.com/monitoring/alerts\"\u003ealerting policy\u003c/a\u003e:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"1 Configure the alert.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/1_Configure_the_alert.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eYou can use the \u003ccode\u003ekubernetes.io/container/restart_count\u003c/code\u003e metric, filtered to the specific container name (as specified in the deployment yaml \u003ca href=\"https://github.com/yuriatgoogle/stack-doctor/blob/master/crashing-pod-demo/deployment.yaml\" target=\"_blank\"\u003efile\u003c/a\u003e). Configure the alert to trigger if any timeseries exceeded zero—meaning if any container restarts are observed. \u003c/p\u003e\u003cp\u003eWith the setup done, you are ready to test and see what happens!\u003c/p\u003e\u003ch3\u003eTesting the alert\u003c/h3\u003e\u003cp\u003eWhen you’re ready, start the looped script to hit the /crashme endpoint every 45 seconds. The restart_count metric is sampled every 60 seconds, so it shouldn't take very long for an alert to show up on the dashboard:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"2 Testing the alert.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/2_Testing_the_alert.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eYou can mouse-over the incident to get more information about it:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"3 incident.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/3_incident.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eThen click on \"View Incident\". This takes you to the Incident details screen, where you can see the specific resources that triggered it—in this case, the incident is generated by the container.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"4 View Incident.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/4_View_Incident.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eNext, you can click on View Logs to see the logs (in the \u003ca href=\"https://cloud.google.com/logging/docs/view/logs-viewer-preview\"\u003enew Logs Viewer\u003c/a\u003e!)—it's immediately apparently that the alert is triggered by the containers restarting:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"5 View Logs.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/5_View_Logs.max-1000x1000.jpg\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eThis is all very nicely tied together and makes troubleshooting during an incident much easier!\u003c/p\u003e\u003ch3\u003eIn summary….\u003c/h3\u003e\u003cp\u003eThe latest GKE dashboard includes many improvements over previous iterations. The new alerts timeline is intuitive, and incidents are clearly marked so that you can interact with them to get the full details of exactly what happened, all the way down to the container logs that tell you the actual problem.\u003c/p\u003e\u003cp\u003eAs an oncall SRE or DevOps engineer for a service running on GKE, the GKE dashboard makes it easier for you to respond to incidents. You're now able to go from an incident all the way to debug logs quickly and easily and reduce the time it takes to triage and mitigate incidents. For a short overview on how to troubleshoot services on GKE, check out this video:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-video\"\u003e\u003cdiv class=\"article-module article-video \"\u003e\u003cfigure\u003e\u003ca class=\"h-c-video h-c-video--marquee\" data-glue-modal-disabled-on-mobile=\"true\" data-glue-modal-trigger=\"uni-modal---4WWwx4Log-\" href=\"https://youtube.com/watch?v=--4WWwx4Log\"\u003e\u003cimg alt=\"In previous episodes, we’ve shown you how to set up monitoring and alerting for your GKE services, but what do you do when an alert fires? In this episode of Stack Doctor, we show you how to use the alerts timeline on your GKE monitoring dashboards to troubleshoot your services. Watch to learn how you can easily spot and resolve issues in your applications and infrastructure!\" src=\"//img.youtube.com/vi/--4WWwx4Log/maxresdefault.jpg\"/\u003e\u003csvg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" role=\"img\"\u003e\u003cuse xlink:href=\"#mi-youtube-icon\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv class=\"h-c-modal--video\" data-glue-modal=\"uni-modal---4WWwx4Log-\" data-glue-modal-close-label=\"Close Dialog\"\u003e\u003ca class=\"glue-yt-video\" data-glue-yt-video-autoplay=\"true\" data-glue-yt-video-height=\"99%\" data-glue-yt-video-vid=\"--4WWwx4Log\" data-glue-yt-video-width=\"100%\" href=\"https://youtube.com/watch?v=--4WWwx4Log\" ng-cloak=\"\"\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e\u003ci\u003e\u003csup\u003eA special thanks to Anthony Bushong, Specialist Customer Engineer, for his contributions to this blog post.\u003c/sup\u003e\u003c/i\u003e\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"https://gweb-cloudblog-publish.appspot.com/products/management-tools/shrinking-the-time-to-mitigate-production-incidents/\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud-01_xyGPYQS.max-500x500.png')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003eShrinking the time to mitigate production incidents—CRE life lessons\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003eSee how you can use SRE and CRE principles and tests from Google, including Wheel of Misfortune and DiRT, to reduce the time needed to mi...\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_Kubernetes_tJPVpVo.max-2200x2200.jpg",
      "date_published": "2021-02-26T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eYuri Grinshteyn\u003c/name\u003e\u003ctitle\u003eSite Reliability Engineer, CRE\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/application-development/show-me-the-money-how-you-can-see-returns-up-to-259m-with-a-devops-transformation/",
      "title": "Show me the money! How you can see returns up to $259M with a DevOps transformation",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;2020 challenged some of the best laid plans by enterprises. With nearly everything moving online, Covid-19 pushed forward years of digital transformation. DevOps was at the heart of this transformation journey. After all, delivering software quickly, reliably, and safely to meet the changing needs of customers was crucial to adapt to this new normal.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;It is unlikely that the pace of modernization will slow down in 2021. As IT and business leaders further drive digital adoption within their organizations via DevOps, the need to quantify the business benefit from a digital transformation remains top of mind. A reliable model is imperative to drive the right level of investments and measure the returns. This is precisely why we wrote \u0026lt;a href=\u0026#34;https://cloud.google.com/resources/roi-of-devops-transformation-whitepaper\u0026#34;\u0026gt;How to Measure ROI of DevOps Transformation\u0026lt;/a\u0026gt;. This white paper is backed with scientific studies conducted by \u0026lt;a href=\u0026#34;https://www.devops-research.com/research.html\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;DevOps Research and Assessment, DORA\u0026lt;/a\u0026gt;, with 31,000 professionals worldwide over 6 years to provide clear guidance based on impartial industry data. We found the financial savings of DevOps transformation varies from from $10M to $259M a year.\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Looking beyond cost to value\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;The most innovative companies undertake their technology transformations with a focus on the value they can deliver to their customers. Hence, in addition to measuring cost savings, we show how DevOps done right can be a value driver and innovation engine. Let\u0026#39;s look deeper into how we quantify the cost and value-generating power of DevOps.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Cost-driven category\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Here, we focus on quantifying the cost savings and efficiencies realized by implementing DevOps\u0026amp;#8212;for example, how an investment in DevOps reduces costs by cutting the time it takes to resolve outages and avoiding downtime as much as possible.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;However, focusing solely on reducing costs can rarely yield systemic, long-term gains; thereby increasing the importance of going beyond cost-driven strategies. The cost savings achieved in year one \u0026amp;#8220;no longer count\u0026amp;#8221; beyond year two as the organization adjusts to a new baseline of costs and performance. Worse, only focusing on cost savings signals to technical staff their job is potentially at risk due to automation rather than being liberated from drudge work to better drive business growth. This leads to negative effects on morale and productivity.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Value-driven category\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;There are two value drivers in a DevOps transformation, (1) improved efficiency through the reduction of unnecessary rework, and (2) the potential revenue gained by reinvesting the time saved in new offer capabilities.\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Adding these cost and value driven categories together, IT and business decision makers can get an estimate of the potential value their organizations can expect to gain from a DevOps transformation. This helps justify the investment needed to implement the required changes. To quantify the impact, we leverage industry benchmark data across low, medium, high, and elite DevOps teams, as described by DORA in its annual \u0026lt;a href=\u0026#34;https://cloud.google.com/devops/state-of-devops\u0026#34;\u0026gt;Accelerate: State of DevOps report\u0026lt;/a\u0026gt;.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;h3\u0026gt;Combining cost and value\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;As an example, let\u0026#39;s consider the impact of a DevOps transformation on a large organization with 8,500 technical staff and a medium IT performer. Using the data gained from the DevOps report, we can calculate both the cost and value driven categories along with total impact.\u0026amp;#160;\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003e2020 challenged some of the best laid plans by enterprises. With nearly everything moving online, Covid-19 pushed forward years of digital transformation. DevOps was at the heart of this transformation journey. After all, delivering software quickly, reliably, and safely to meet the changing needs of customers was crucial to adapt to this new normal.\u003c/p\u003e\u003cp\u003eIt is unlikely that the pace of modernization will slow down in 2021. As IT and business leaders further drive digital adoption within their organizations via DevOps, the need to quantify the business benefit from a digital transformation remains top of mind. A reliable model is imperative to drive the right level of investments and measure the returns. This is precisely why we wrote \u003ca href=\"https://cloud.google.com/resources/roi-of-devops-transformation-whitepaper\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"https://cloud.google.com/resources/roi-of-devops-transformation-whitepaper\" track-metadata-module=\"post\"\u003eHow to Measure ROI of DevOps Transformation\u003c/a\u003e. This white paper is backed with scientific studies conducted by \u003ca href=\"https://www.devops-research.com/research.html\" target=\"_blank\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://www.devops-research.com\" track-metadata-module=\"post\"\u003eDevOps Research and Assessment, DORA\u003c/a\u003e, with 31,000 professionals worldwide over 6 years to provide clear guidance based on impartial industry data. We found the financial savings of DevOps transformation varies from from $10M to $259M a year.\u003c/p\u003e\u003ch3\u003eLooking beyond cost to value\u003c/h3\u003e\u003cp\u003eThe most innovative companies undertake their technology transformations with a focus on the value they can deliver to their customers. Hence, in addition to measuring cost savings, we show how DevOps done right can be a value driver and innovation engine. Let\u0026#39;s look deeper into how we quantify the cost and value-generating power of DevOps. \u003c/p\u003e\u003ch3\u003eCost-driven category\u003c/h3\u003e\u003cp\u003eHere, we focus on quantifying the cost savings and efficiencies realized by implementing DevOps—for example, how an investment in DevOps reduces costs by cutting the time it takes to resolve outages and avoiding downtime as much as possible. \u003c/p\u003e\u003cp\u003eHowever, focusing solely on reducing costs can rarely yield systemic, long-term gains; thereby increasing the importance of going beyond cost-driven strategies. The cost savings achieved in year one “no longer count” beyond year two as the organization adjusts to a new baseline of costs and performance. Worse, only focusing on cost savings signals to technical staff their job is potentially at risk due to automation rather than being liberated from drudge work to better drive business growth. This leads to negative effects on morale and productivity. \u003c/p\u003e\u003ch3\u003eValue-driven category\u003c/h3\u003e\u003cp\u003eThere are two value drivers in a DevOps transformation, (1) improved efficiency through the reduction of unnecessary rework, and (2) the potential revenue gained by reinvesting the time saved in new offer capabilities.\u003c/p\u003e\u003cp\u003eAdding these cost and value driven categories together, IT and business decision makers can get an estimate of the potential value their organizations can expect to gain from a DevOps transformation. This helps justify the investment needed to implement the required changes. To quantify the impact, we leverage industry benchmark data across low, medium, high, and elite DevOps teams, as described by DORA in its annual \u003ca href=\"https://cloud.google.com/devops/state-of-devops\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/devops/state-of-devops\" track-metadata-module=\"post\"\u003eAccelerate: State of DevOps report\u003c/a\u003e. \u003c/p\u003e\u003ch3\u003eCombining cost and value\u003c/h3\u003e\u003cp\u003eAs an example, let\u0026#39;s consider the impact of a DevOps transformation on a large organization with 8,500 technical staff and a medium IT performer. Using the data gained from the DevOps report, we can calculate both the cost and value driven categories along with total impact. \u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003e2020 challenged some of the best laid plans by enterprises. With nearly everything moving online, Covid-19 pushed forward years of digital transformation. DevOps was at the heart of this transformation journey. After all, delivering software quickly, reliably, and safely to meet the changing needs of customers was crucial to adapt to this new normal.\u003c/p\u003e\u003cp\u003eIt is unlikely that the pace of modernization will slow down in 2021. As IT and business leaders further drive digital adoption within their organizations via DevOps, the need to quantify the business benefit from a digital transformation remains top of mind. A reliable model is imperative to drive the right level of investments and measure the returns. This is precisely why we wrote \u003ca href=\"https://cloud.google.com/resources/roi-of-devops-transformation-whitepaper\"\u003eHow to Measure ROI of DevOps Transformation\u003c/a\u003e. This white paper is backed with scientific studies conducted by \u003ca href=\"https://www.devops-research.com/research.html\" target=\"_blank\"\u003eDevOps Research and Assessment, DORA\u003c/a\u003e, with 31,000 professionals worldwide over 6 years to provide clear guidance based on impartial industry data. We found the financial savings of DevOps transformation varies from from $10M to $259M a year.\u003c/p\u003e\u003ch3\u003eLooking beyond cost to value\u003c/h3\u003e\u003cp\u003eThe most innovative companies undertake their technology transformations with a focus on the value they can deliver to their customers. Hence, in addition to measuring cost savings, we show how DevOps done right can be a value driver and innovation engine. Let's look deeper into how we quantify the cost and value-generating power of DevOps. \u003c/p\u003e\u003ch3\u003eCost-driven category\u003c/h3\u003e\u003cp\u003eHere, we focus on quantifying the cost savings and efficiencies realized by implementing DevOps—for example, how an investment in DevOps reduces costs by cutting the time it takes to resolve outages and avoiding downtime as much as possible. \u003c/p\u003e\u003cp\u003eHowever, focusing solely on reducing costs can rarely yield systemic, long-term gains; thereby increasing the importance of going beyond cost-driven strategies. The cost savings achieved in year one “no longer count” beyond year two as the organization adjusts to a new baseline of costs and performance. Worse, only focusing on cost savings signals to technical staff their job is potentially at risk due to automation rather than being liberated from drudge work to better drive business growth. This leads to negative effects on morale and productivity. \u003c/p\u003e\u003ch3\u003eValue-driven category\u003c/h3\u003e\u003cp\u003eThere are two value drivers in a DevOps transformation, (1) improved efficiency through the reduction of unnecessary rework, and (2) the potential revenue gained by reinvesting the time saved in new offer capabilities.\u003c/p\u003e\u003cp\u003eAdding these cost and value driven categories together, IT and business decision makers can get an estimate of the potential value their organizations can expect to gain from a DevOps transformation. This helps justify the investment needed to implement the required changes. To quantify the impact, we leverage industry benchmark data across low, medium, high, and elite DevOps teams, as described by DORA in its annual \u003ca href=\"https://cloud.google.com/devops/state-of-devops\"\u003eAccelerate: State of DevOps report\u003c/a\u003e. \u003c/p\u003e\u003ch3\u003eCombining cost and value\u003c/h3\u003e\u003cp\u003eAs an example, let's consider the impact of a DevOps transformation on a large organization with 8,500 technical staff and a medium IT performer. Using the data gained from the DevOps report, we can calculate both the cost and value driven categories along with total impact. \u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003cimg alt=\"roi table\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Screen_Shot_2021-01-25_at_6.08.51_PM.max-1000x1000.png\"/\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eWhile this example represents what a medium IT performer at a large organization might expect by investing in DevOps, companies of all sizes and performance profiles can leverage DevOps to drive performance. In the \u003ca href=\"https://cloud.google.com/resources/roi-of-devops-transformation-whitepaper\"\u003ewhite paper\u003c/a\u003e, we calculate the impact of DevOps across organizations of different sizes—small, medium, and large—as well as across four distinct performance profiles—low, medium, high, elite. \u003c/p\u003e\u003cp\u003eThere will be variation in these measurements based on your team’s current performance, compensation, change fail rate, benefits multiplier, and deployments per year, so we share our methodology in the white paper and invite you to customize the approach based on your specific needs and constraints. \u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-video\"\u003e\u003cdiv class=\"article-module article-video \"\u003e\u003cfigure\u003e\u003ca class=\"h-c-video h-c-video--marquee\" data-glue-modal-disabled-on-mobile=\"true\" data-glue-modal-trigger=\"uni-modal-gZ7GtQ8XzYo-\" href=\"https://youtube.com/watch?v=gZ7GtQ8XzYo\"\u003e\u003cdiv class=\"article-video__aspect-image\" style=\"background-image: url(https://storage.googleapis.com/gweb-cloudblog-publish/images/Screen_Shot_2021-01-12_at_2.49.11_PM.max-1000x1000.png);\"\u003e\u003cspan class=\"h-u-visually-hidden\"\u003eROI of DevOps Transformation\u003c/span\u003e\u003c/div\u003e\u003csvg class=\"h-c-video__play h-c-icon h-c-icon--color-white\" role=\"img\"\u003e\u003cuse xlink:href=\"#mi-youtube-icon\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/a\u003e\u003cfigcaption class=\"article-video__caption h-c-page\"\u003e\u003ch4 class=\"h-c-headline h-c-headline--four h-u-font-weight-medium h-u-mt-std\"\u003eROI of DevOps Transformation: How to quantify the impact of your modernization initiatives\u003c/h4\u003e\u003c/figcaption\u003e\u003c/figure\u003e\u003c/div\u003e\u003cdiv class=\"h-c-modal--video\" data-glue-modal=\"uni-modal-gZ7GtQ8XzYo-\" data-glue-modal-close-label=\"Close Dialog\"\u003e\u003ca class=\"glue-yt-video\" data-glue-yt-video-autoplay=\"true\" data-glue-yt-video-height=\"99%\" data-glue-yt-video-vid=\"gZ7GtQ8XzYo\" data-glue-yt-video-width=\"100%\" href=\"https://youtube.com/watch?v=gZ7GtQ8XzYo\" ng-cloak=\"\"\u003e\u003c/a\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eYears of \u003ca href=\"https://www.devops-research.com/research.html\" target=\"_blank\"\u003eDORA research\u003c/a\u003e show that undertaking a technology transformation initiative can produce sizable returns for any organization. Our goal \u003ca href=\"https://cloud.google.com/resources/roi-of-devops-transformation-whitepaper\"\u003ewith the white paper\u003c/a\u003e is to provide IT and business decision makers an industry backed, data driven foundational basis for determining their investment in DevOps. Download the white paper \u003ca href=\"https://cloud.google.com/resources/roi-of-devops-transformation-whitepaper\"\u003ehere\u003c/a\u003e to calculate the impact of DevOps on your organization, while driving your digital transformation. \u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-related_article_tout_external\"\u003e\u003cdiv class=\"uni-related-article-tout h-c-page\"\u003e\u003csection class=\"h-c-grid\"\u003e\u003ca class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" data-analytics='{\n                       \"event\": \"page interaction\",\n                       \"category\": \"article lead\",\n                       \"action\": \"related article - inline\",\n                       \"label\": \"article: {slug}\"\n                     }' href=\"\"\u003e\u003cdiv class=\"uni-related-article-tout__inner-wrapper\"\u003e\u003cp class=\"uni-related-article-tout__eyebrow h-c-eyebrow\"\u003eRelated Article\u003c/p\u003e\u003cdiv class=\"uni-related-article-tout__content-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image-wrapper\"\u003e\u003cdiv class=\"uni-related-article-tout__image\" style=\"background-image: url('')\"\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"uni-related-article-tout__content\"\u003e\u003ch4 class=\"uni-related-article-tout__header h-has-bottom-margin\"\u003e\u003c/h4\u003e\u003cp class=\"uni-related-article-tout__body\"\u003e\u003c/p\u003e\u003cdiv class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"\u003e\u003cspan class=\"nowrap\"\u003eRead Article\u003csvg class=\"icon h-c-icon\" role=\"presentation\"\u003e\u003cuse xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"\u003e\u003c/use\u003e\u003c/svg\u003e\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/a\u003e\u003c/section\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Google_Cloud_BigQuery_KHi78bE.max-2200x2200.jpg",
      "date_published": "2021-01-26T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eBrenna Washington\u003c/name\u003e\u003ctitle\u003eProduct Marketing Manager\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    },
    {
      "id": "",
      "url": "https://cloud.google.com/blog/products/operations/on-the-road-to-sre-with-cloud-operations-sandbox/",
      "title": "Take the first step toward SRE with Cloud Operations Sandbox",
      "content_html": "\u003cdiv id=\"readability-page-1\" class=\"page\"\u003e\u003cdiv\u003e\u003cparagraph-block _nghost-c19=\"\"\u003e\u003cdiv _ngcontent-c19=\"\" innerhtml=\"\u0026lt;p\u0026gt;At Google Cloud, we strive to bring Site Reliability Engineering (SRE) culture to our customers not only through training on organizational best practices, but also with the tools you need to run successful cloud services. Part and parcel of that is comprehensive observability tooling\u0026amp;#8212;logging, monitoring, tracing, profiling and debugging\u0026amp;#8212;which can help you troubleshoot production issues faster, increase release velocity and improve service reliability.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;We often hear that implementing observability is hard, especially for complex distributed applications that are implemented in different programming languages, deployed in a variety of environments, that have different operational costs, and many other factors. As a result, when migrating and modernizing workloads onto Google Cloud, observability is often an afterthought.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Nevertheless, being able to debug the system and gain insights into the system\u0026amp;#8217;s behavior is important for running reliable production systems. Customers want to learn how to instrument services for observability and implement SRE best practices using tools Google Cloud has to offer, but without risking production environments. With \u0026lt;a href=\u0026#34;http://cloud-ops-sandbox.dev\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Cloud Operations Sandbox\u0026lt;/a\u0026gt;, you can learn in practice how to kickstart your observability journey and answer the question, \u0026amp;#8220;Will it work for my use-case?\u0026amp;#8221;\u0026lt;/p\u0026gt;\u0026lt;p\u0026gt;Cloud Operations Sandbox is an \u0026lt;a href=\u0026#34;https://github.com/GoogleCloudPlatform/cloud-ops-sandbox\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;open-source tool\u0026lt;/a\u0026gt; that helps you learn SRE practices from Google and apply them on cloud services using \u0026lt;a href=\u0026#34;https://cloud.google.com/products/operations\u0026#34;\u0026gt;Google Cloud\u0026amp;#8217;s operations suite\u0026lt;/a\u0026gt; (formerly Stackdriver). Cloud Operations Sandbox has everything you need to get started in one click:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Demo service\u0026lt;/b\u0026gt; - an application built using microservices architecture on modern, cloud-native stack (a modified fork of a \u0026lt;a href=\u0026#34;https://github.com/GoogleCloudPlatform/microservices-demo\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;Online Boutique microservices\u0026lt;/a\u0026gt; demo app)\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;One-click deployment\u0026lt;/b\u0026gt; - automated script that deploys and configures the service to Google Cloud, including:\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Service Monitoring configuration\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Tracing with OpenTelemetry\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Cloud Profiling, Logging, Error Reporting, Debugging and more\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Load generator\u0026lt;/b\u0026gt; - a component that produces synthetic traffic on the demo service\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;b\u0026gt;SRE recipes\u0026lt;/b\u0026gt; - pre-built tasks that manufacture intentional errors in the demo app so you can use Cloud Operations tools to find the root cause of problems like you would in production\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;An \u0026lt;b\u0026gt;interactive walkthrough\u0026lt;/b\u0026gt; to get started with Cloud Operations\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;h3\u0026gt;Getting started\u0026lt;/h3\u0026gt;\u0026lt;p\u0026gt;Launching the Cloud Operations Sandbox is as easy as can be. Simply:\u0026lt;/p\u0026gt;\u0026lt;ul\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Go to \u0026lt;a href=\u0026#34;http://cloud-ops-sandbox.dev\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;cloud-ops-sandbox.dev\u0026lt;/a\u0026gt;\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Click on the \u0026amp;#8220;Open in Google Cloud Shell\u0026amp;#8221; button.\u0026amp;#160;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\u0026lt;/ul\u0026gt;\u0026lt;p\u0026gt;This creates a new Google Cloud project. Within that project, a Terraform script creates a Google Kubernetes Engine (GKE) cluster and deploys a sample application to it. \u0026lt;a href=\u0026#34;https://github.com/GoogleCloudPlatform/cloud-ops-sandbox/tree/master/src\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;The microservices that make up the demo app\u0026lt;/a\u0026gt; are pre-instrumented with logging, monitoring, tracing, debugging and profiling as appropriate for each microservices language runtime. As such, sending traffic to the demo app generates telemetry that can be useful for diagnosing the cloud service\u0026amp;#8217;s operation. In order to generate production-like traffic to the demo app, \u0026lt;a href=\u0026#34;https://github.com/GoogleCloudPlatform/cloud-ops-sandbox/tree/master/src/loadgenerator\u0026#34; target=\u0026#34;_blank\u0026#34;\u0026gt;an automated script\u0026lt;/a\u0026gt; deploys a synthetic load generator in a different geo-location than the demo app.\u0026lt;/p\u0026gt;\"\u003e\u003cp\u003eAt Google Cloud, we strive to bring Site Reliability Engineering (SRE) culture to our customers not only through training on organizational best practices, but also with the tools you need to run successful cloud services. Part and parcel of that is comprehensive observability tooling—logging, monitoring, tracing, profiling and debugging—which can help you troubleshoot production issues faster, increase release velocity and improve service reliability. \u003c/p\u003e\u003cp\u003eWe often hear that implementing observability is hard, especially for complex distributed applications that are implemented in different programming languages, deployed in a variety of environments, that have different operational costs, and many other factors. As a result, when migrating and modernizing workloads onto Google Cloud, observability is often an afterthought. \u003c/p\u003e\u003cp\u003eNevertheless, being able to debug the system and gain insights into the system’s behavior is important for running reliable production systems. Customers want to learn how to instrument services for observability and implement SRE best practices using tools Google Cloud has to offer, but without risking production environments. With \u003ca href=\"http://cloud-ops-sandbox.dev\" target=\"_blank\" track-type=\"inline link\" track-name=\"1\" track-metadata-eventdetail=\"http://cloud-ops-sandbox.dev\" track-metadata-module=\"post\"\u003eCloud Operations Sandbox\u003c/a\u003e, you can learn in practice how to kickstart your observability journey and answer the question, “Will it work for my use-case?”\u003c/p\u003e\u003cp\u003eCloud Operations Sandbox is an \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-ops-sandbox\" target=\"_blank\" track-type=\"inline link\" track-name=\"2\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eopen-source tool\u003c/a\u003e that helps you learn SRE practices from Google and apply them on cloud services using \u003ca href=\"https://cloud.google.com/products/operations\" track-type=\"inline link\" track-name=\"3\" track-metadata-eventdetail=\"https://cloud.google.com/products/operations\" track-metadata-module=\"post\"\u003eGoogle Cloud’s operations suite\u003c/a\u003e (formerly Stackdriver). Cloud Operations Sandbox has everything you need to get started in one click:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eDemo service\u003c/b\u003e - an application built using microservices architecture on modern, cloud-native stack (a modified fork of a \u003ca href=\"https://github.com/GoogleCloudPlatform/microservices-demo\" target=\"_blank\" track-type=\"inline link\" track-name=\"4\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eOnline Boutique microservices\u003c/a\u003e demo app)\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eOne-click deployment\u003c/b\u003e - automated script that deploys and configures the service to Google Cloud, including:\u003c/p\u003e\u003c/li\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eService Monitoring configuration\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eTracing with OpenTelemetry\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCloud Profiling, Logging, Error Reporting, Debugging and more\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eLoad generator\u003c/b\u003e - a component that produces synthetic traffic on the demo service\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eSRE recipes\u003c/b\u003e - pre-built tasks that manufacture intentional errors in the demo app so you can use Cloud Operations tools to find the root cause of problems like you would in production\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eAn \u003cb\u003einteractive walkthrough\u003c/b\u003e to get started with Cloud Operations \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eGetting started\u003c/h3\u003e\u003cp\u003eLaunching the Cloud Operations Sandbox is as easy as can be. Simply:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eGo to \u003ca href=\"http://cloud-ops-sandbox.dev\" target=\"_blank\" track-type=\"inline link\" track-name=\"5\" track-metadata-eventdetail=\"http://cloud-ops-sandbox.dev\" track-metadata-module=\"post\"\u003ecloud-ops-sandbox.dev\u003c/a\u003e \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eClick on the “Open in Google Cloud Shell” button. \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThis creates a new Google Cloud project. Within that project, a Terraform script creates a Google Kubernetes Engine (GKE) cluster and deploys a sample application to it. \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-ops-sandbox/tree/master/src\" target=\"_blank\" track-type=\"inline link\" track-name=\"6\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003eThe microservices that make up the demo app\u003c/a\u003e are pre-instrumented with logging, monitoring, tracing, debugging and profiling as appropriate for each microservices language runtime. As such, sending traffic to the demo app generates telemetry that can be useful for diagnosing the cloud service’s operation. In order to generate production-like traffic to the demo app, \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-ops-sandbox/tree/master/src/loadgenerator\" target=\"_blank\" track-type=\"inline link\" track-name=\"7\" track-metadata-eventdetail=\"https://github.com\" track-metadata-module=\"post\"\u003ean automated script\u003c/a\u003e deploys a synthetic load generator in a different geo-location than the demo app.\u003c/p\u003e\u003c/div\u003e\u003c/paragraph-block\u003e\u003c/div\u003e\u003c/div\u003e",
      "summary": "\u003chtml\u003e\u003chead\u003e\u003c/head\u003e\u003cbody\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eAt Google Cloud, we strive to bring Site Reliability Engineering (SRE) culture to our customers not only through training on organizational best practices, but also with the tools you need to run successful cloud services. Part and parcel of that is comprehensive observability tooling—logging, monitoring, tracing, profiling and debugging—which can help you troubleshoot production issues faster, increase release velocity and improve service reliability. \u003c/p\u003e\u003cp\u003eWe often hear that implementing observability is hard, especially for complex distributed applications that are implemented in different programming languages, deployed in a variety of environments, that have different operational costs, and many other factors. As a result, when migrating and modernizing workloads onto Google Cloud, observability is often an afterthought. \u003c/p\u003e\u003cp\u003eNevertheless, being able to debug the system and gain insights into the system’s behavior is important for running reliable production systems. Customers want to learn how to instrument services for observability and implement SRE best practices using tools Google Cloud has to offer, but without risking production environments. With \u003ca href=\"http://cloud-ops-sandbox.dev\" target=\"_blank\"\u003eCloud Operations Sandbox\u003c/a\u003e, you can learn in practice how to kickstart your observability journey and answer the question, “Will it work for my use-case?”\u003c/p\u003e\u003cp\u003eCloud Operations Sandbox is an \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-ops-sandbox\" target=\"_blank\"\u003eopen-source tool\u003c/a\u003e that helps you learn SRE practices from Google and apply them on cloud services using \u003ca href=\"https://cloud.google.com/products/operations\"\u003eGoogle Cloud’s operations suite\u003c/a\u003e (formerly Stackdriver). Cloud Operations Sandbox has everything you need to get started in one click:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eDemo service\u003c/b\u003e - an application built using microservices architecture on modern, cloud-native stack (a modified fork of a \u003ca href=\"https://github.com/GoogleCloudPlatform/microservices-demo\" target=\"_blank\"\u003eOnline Boutique microservices\u003c/a\u003e demo app)\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eOne-click deployment\u003c/b\u003e - automated script that deploys and configures the service to Google Cloud, including:\u003c/p\u003e\u003c/li\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eService Monitoring configuration\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eTracing with OpenTelemetry\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eCloud Profiling, Logging, Error Reporting, Debugging and more\u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eLoad generator\u003c/b\u003e - a component that produces synthetic traffic on the demo service\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003e\u003cb\u003eSRE recipes\u003c/b\u003e - pre-built tasks that manufacture intentional errors in the demo app so you can use Cloud Operations tools to find the root cause of problems like you would in production\u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eAn \u003cb\u003einteractive walkthrough\u003c/b\u003e to get started with Cloud Operations \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003ch3\u003eGetting started\u003c/h3\u003e\u003cp\u003eLaunching the Cloud Operations Sandbox is as easy as can be. Simply:\u003c/p\u003e\u003cul\u003e\u003cli\u003e\u003cp\u003eGo to \u003ca href=\"http://cloud-ops-sandbox.dev\" target=\"_blank\"\u003ecloud-ops-sandbox.dev\u003c/a\u003e \u003c/p\u003e\u003c/li\u003e\u003cli\u003e\u003cp\u003eClick on the “Open in Google Cloud Shell” button. \u003c/p\u003e\u003c/li\u003e\u003c/ul\u003e\u003cp\u003eThis creates a new Google Cloud project. Within that project, a Terraform script creates a Google Kubernetes Engine (GKE) cluster and deploys a sample application to it. \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-ops-sandbox/tree/master/src\" target=\"_blank\"\u003eThe microservices that make up the demo app\u003c/a\u003e are pre-instrumented with logging, monitoring, tracing, debugging and profiling as appropriate for each microservices language runtime. As such, sending traffic to the demo app generates telemetry that can be useful for diagnosing the cloud service’s operation. In order to generate production-like traffic to the demo app, \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-ops-sandbox/tree/master/src/loadgenerator\" target=\"_blank\"\u003ean automated script\u003c/a\u003e deploys a synthetic load generator in a different geo-location than the demo app.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Terraform_script_creates_a_GKE_cluste.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"Terraform script creates a GKE cluste.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/Terraform_script_creates_a_GKE_cluste.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIt creates 11 custom dashboards (one for each microservice) to illustrate \u003ca href=\"https://sre.google/sre-book/monitoring-distributed-systems/#xref_monitoring_golden-signals\" target=\"_blank\"\u003ethe four golden signals\u003c/a\u003e of monitoring \u003ca href=\"https://sre.google/sre-book/monitoring-distributed-systems/\" target=\"_blank\"\u003eas described in Google’s SRE book\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/creates_11_custom_dashboards.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"creates 11 custom dashboards.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/creates_11_custom_dashboards.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eIt also adds and automatically configures uptime checks, service monitoring (\u003ca href=\"https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring\"\u003eSLOs and SLIs\u003c/a\u003e), log-based metrics, alerting policies and more.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/checkout_service.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"checkout service.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/checkout_service.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eAt the end of the provisioning script you’ll get a few URLs of the newly created project:\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-image_full_width\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid\"\u003e\u003cfigure class=\"article-image--large h-c-grid__col h-c-grid__col--6 h-c-grid__col--offset-3 \"\u003e\u003ca href=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/provisioning_script.max-2800x2800.jpg\" rel=\"external\" target=\"_blank\"\u003e\u003cimg alt=\"provisioning script.jpg\" src=\"https://storage.googleapis.com/gweb-cloudblog-publish/images/provisioning_script.max-1000x1000.jpg\"/\u003e\u003c/a\u003e\u003c/figure\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003cp\u003eYou can \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-ops-sandbox/blob/master/docs/README.md\" target=\"_blank\"\u003efollow the user guide\u003c/a\u003e to learn about the entire Cloud Operations suite of tools, including tracking microservices interactions in \u003ca href=\"https://cloud.google.com/trace\"\u003eCloud Trace\u003c/a\u003e (thanks to the \u003ca href=\"https://cloud.google.com/learn/what-is-opentelemetry\"\u003eOpenTelemetry\u003c/a\u003e instrumentation of the demo app) and see how to \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-ops-sandbox/tree/master/terraform/monitoring\" target=\"_blank\"\u003eapply the learnings to your scenario\u003c/a\u003e. \u003c/p\u003e\u003cp\u003eFinally, to remove the Sandbox once you’re finished using it, you can run\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-code\"\u003e\u003cdiv class=\"article-module h-c-page\"\u003e\u003cdiv class=\"h-c-grid uni-paragraph-wrap\"\u003e\u003cdiv class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"\u003e\u003cpre\u003e\u003ccode\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003c/div\u003e\u003cdiv class=\"block-paragraph\"\u003e\u003cdiv class=\"rich-text\"\u003e\u003ch3\u003eNext steps\u003c/h3\u003e\u003cp\u003eFollowing SRE principles is a proven method for running highly reliable applications in the cloud. We hope that the Cloud Operations Sandbox gives you the understanding and confidence you need to jumpstart your SRE practice. \u003c/p\u003e\u003cp\u003eTo get started, visit  \u003ca href=\"http://cloud-ops-sandbox.dev\" target=\"_blank\"\u003ecloud-ops-sandbox.dev\u003c/a\u003e, explore the \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-ops-sandbox\" target=\"_blank\"\u003eproject repo\u003c/a\u003e, and follow along in the \u003ca href=\"https://github.com/GoogleCloudPlatform/cloud-ops-sandbox/blob/master/docs/README.md\" target=\"_blank\"\u003euser guide\u003c/a\u003e.\u003c/p\u003e\u003c/div\u003e\u003c/div\u003e\u003c/body\u003e\u003c/html\u003e",
      "image": "https://storage.googleapis.com/gweb-cloudblog-publish/images/Public-Sector-Momentum.max-1000x1000.png",
      "date_published": "2021-01-22T17:00:00Z",
      "author": {
        "name": "\u003cname\u003eDaniel Sanche\u003c/name\u003e\u003ctitle\u003eDeveloper Programs Engineer\u003c/title\u003e\u003cdepartment\u003e\u003c/department\u003e\u003ccompany\u003e\u003c/company\u003e"
      }
    }
  ]
}
