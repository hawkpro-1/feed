<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DataDog</title>
    <link>https://datadoghq.com/blog/index.xml</link>
    <description></description>
    <item>
      <title>Datadog EEA Data Processing Addendum</title>
      <link>https://www.datadoghq.com/legal/datadog-eea-data-processing-addendum/2021-09-27/</link>
      <description>This is a reference copy of the Datadog EEA Data Processing Addendum, which may be required for some Datadog customers. For a full copy of Datadog’s EEA Data Processing Addendum, including its attached schedules and the Standard Contractual Clauses effective 9/27/2021, please click here.How to Sign the DPA If you’re ready to sign the Datadog EEA DPA, please reach out to your Datadog CSM or sales representative. If you’re not sure who your CSM or sales representative is, please contact support@datadoghq.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Other capitalized terms not otherwise defined in this DPA shall have the respective meanings assigned to them in this Section.</p><p>“Account Data” means information about Customer that Customer provides to Datadog in connection with the creation or administration of its Datadog accounts, such as first and last name, user name and email address of an Authorized User or Customer’s billing contact. Customer shall ensure that all Account Data is current and accurate at all times during the term of the applicable Order.</p><p>“Adequacy” means where the European Commission has decided that the third country, a territory or one or more specified sectors within that third country, or the international organization in question, ensures an adequate level of protection.</p><p>“Affiliate” means, unless otherwise defined in the Master Agreement, a business entity that directly or indirectly controls, is controlled by or is under common control with, such Party; “control” means the direct or indirect ownership of more than 50% of the voting securities of a business entity.</p><p>“Applicable Laws” means any and all governmental laws, rules, directives, regulations or orders that are applicable to a particular Party’s performance under this DPA, including applicable EU Data Protection Law.</p><p>“AUP” means Datadog’s standard Acceptable Use Policy, currently available at <a href="https://www.datadoghq.com/legal/acceptable-use/">https://www.datadoghq.com/legal/acceptable-use/</a>.</p><p>“Authorized User” means an individual employee, agent or contractor of Customer or a Participating Affiliate for whom subscriptions to Services have been purchased pursuant to the terms of the Master Agreement and applicable Order, and who have been supplied user credentials for the Services by Customer or the Participating Affiliate (or by Datadog at Customer’s or a Participating Affiliate’s request).</p><p>“Customer Component” means each individual component of Customer’s Environment.</p><p>“Customer Credentials” means access passwords, keys, tokens or other credentials used by Customer in connection with the Services.</p><p>“Customer Data” means data from Customer’s Environment that are submitted for Processing by the Services. Through Customer’s configuration and use of the Services, Customer has control over the types and amounts of Customer Data.</p><p>“Customer’s Environment” means, exclusive of Services, the systems, platforms, services, software, devices, sites and/or networks that Customer uses in its own internal business operations.</p><p>“Customer Personal Data” means Customer Data comprising Personal Data of Data Subjects located in the EEA.</p><p>“Documentation” means Datadog’s standard user documentation for the Services, currently available at <a href="https://docs.datadoghq.com/">https://docs.datadoghq.com/</a>.</p><p>“EEA” means the European Economic Area, which constitutes the member states of the European Union (“EU”) and Norway, Iceland and Liechtenstein, as well as for purposes of this DPA, the United Kingdom.</p><p>“EU Data Protection Law” means the GDPR, and shall include the data protection or privacy laws of the United Kingdom in place after its withdrawal from the EU.</p><p>“Order” means a separate order for Services pursuant to the Master Agreement: (a) completed and submitted by Customer online at the Datadog site and accepted by Datadog or (b) executed by Datadog and Customer.</p><p>“Participating Affiliate” means an Affiliate of Customer that: (a) has not entered into an Order or other separate agreement directly with Datadog and (b) Customer has authorized to access and use the Services under an existing Order between Datadog and Customer.</p><p>“Party” means each of Datadog and Customer.</p><p>“Services” means the hosted services to which Customer subscribes through, or otherwise uses following, an Order that are made available by Datadog online via the applicable login page (currently <a href="https://app.datadoghq.com/">https://app.datadoghq.com/</a>) and other web pages designated by Datadog. Subject to the terms of an Order, the Services will support Customer’s collection, monitoring, management and analysis of Customer Data. For purposes of this DPA, the term Services does not include alpha, beta or other pre-commercial releases of a Datadog product or service (or feature of functionality of a Service).</p><p>“Standard Contractual Clauses” means the agreements executed by and between Datadog and Customer and attached to this DPA as Schedule A and Schedule B pursuant to the European Commission’s decision (EU) 2021/914 of 4 June 2021 on Standard Contractual Clauses for the transfer of personal data to processors established in third countries which do not ensure an adequate level of data protection.</p><p>“Subprocessor” means any Processor engaged by Datadog or a Datadog Affiliate to Process Customer Personal Data on Datadog’s or its Affiliate’s behalf in the course of providing the Services.</p><p>“Subprocessor List” means the list of Subprocessors available at <a href="https://www.datadoghq.com/subprocessors/">https://www.datadoghq.com/subprocessors/</a>.</p></div></div>]]></content:encoded>
      <author>Datadog</author>
      <pubDate>Fri, 24 Sep 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Best practices for writing incident postmortems</title>
      <link>https://www.datadoghq.com/blog/incident-postmortem-process-best-practices/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/hero.png&#34; width=&#34;100%&#34;/&gt;After you have stopped an incident from affecting your customers, you need a more thorough investigation in order to prevent similar incidents in the future. Postmortems record the root causes of an incident and provide insights for making your systems more resilient. At the same time, postmortems can be difficult to produce, since they require deeper analysis and coordination between teammates who are busy with the next development cycle.But with the help of workflows that streamline your data collection, centralize your discussion, and generate interactive postmortem documents automatically, you can let your team spend less time on writing and more time on finding clues—and preventing future incidents.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>After you have stopped an incident from affecting your customers, you need a more thorough investigation in order to prevent similar incidents in the future. Postmortems record the root causes of an incident and provide insights for making your systems more resilient. At the same time, postmortems can be difficult to produce, since they require deeper analysis and coordination between teammates who are busy with the next development cycle.</p><p>But with the help of workflows that streamline your data collection, centralize your discussion, and generate interactive postmortem documents automatically, you can let your team spend less time on writing and more time on finding clues—and preventing future incidents.</p><p>In this post, we will explore best practices for writing postmortems as part of your organization’s incident management process, including:</p><ul><li>Gather data in <a href="#centralize-data-as-you-go">a shared view</a></li><li><a href="#generate-your-postmortem-automatically">Automate generation</a> of postmortems from your shared view</li><li>Use your postmortem as a <a href="#use-your-postmortem-as-a-thinking-tool">thinking tool</a> that helps you further your investigation</li><li>Make your postmortems <a href="#make-it-easy-to-find-later">easy to find later</a> by your team and others</li></ul><p>We will also show you how Datadog builds these best practices into its comprehensive platform to make writing postmortems as seamless as possible.</p><p>Throughout this post, we’ll use an example postmortem we wrote for a hypothetical incident where our <code>web-store</code> service returned an elevated rate of 500 (Internal Server Error) response codes to users for a six-hour period.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-initial-doc.png?auto=format&amp;fit=max&amp;w=847" alt="The postmortem document we will use as an example throughout this post."/></picture></figure></div><h2 id="centralize-data-as-you-go"><a href="#centralize-data-as-you-go">Centralize data as you go</a></h2><p>To make coordination easier while writing a postmortem, all team members should gather data in a commonly accessible location—such as a document or message feed—as they investigate. Ideally, this shared view should be the same location they use when responding to the incident. By doing so, team members can then refer to that shared view rather than managing multiple <a href="https://www.solutionsiq.com/learning/blog-post/lines-of-communication/">lines of communication</a> in order to stay up to date. It also becomes easier to <a href="#generate-your-postmortem-automatically">convert</a> the shared view into a postmortem document later on since you don’t have to collect information from multiple sources.</p><p>Investigators should be able to easily export graphs (and other visualizations) from their monitoring platform directly to the shared view with minimal clicks. It’s also useful to be able to export conversations from your organization’s core communication channels, such as Slack. This means that even if incident responders do coordinate outside the shared view, they can easily make their conversations available to other responders as well.</p><p>Finally, your shared view should include the ability for team members to leave comments. This way, the discussion about the incident can be visible alongside the data within the shared view. All incident responders can see everything the team has concluded so far about the incident as the discussion develops, making it easier to coordinate and come up with new analysis.</p><p>Once you <a href="https://docs.datadoghq.com/monitors/incident_management/#creating-an-incident">declare an incident</a> in Datadog, for example, you can export any data you gather to the <a href="https://docs.datadoghq.com/monitors/incident_management/#updating-the-incident-and-the-incident-timeline">incident timeline</a>. And as you gather more information—such as graphs of additional relevant metrics or <a href="https://docs.datadoghq.com/integrations/slack/?tab=slackapplicationus">Slack messages</a> that provide context—you can easily add it, making the timeline a shared view that anyone responding to the incident can review for the full status of the investigation. In the incident shown below, all responders can see the timeseries graph added at 10:46 a.m. to illustrate the issue, as well as the note marking when the customer impact was updated.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-timeline-comments.png?auto=format&amp;fit=max&amp;w=847" alt="Comments within a postmortem in Datadog."/></picture></figure></div><p>If you want to assess the data you collect before you add it to an incident timeline (i.e., to ensure that teammates only see useful information) you can store it temporarily in the <a href="https://www.datadoghq.com/blog/datadog-clipboard/">Datadog Clipboard</a>, then review the Clipboard later on to determine what to export. For example, let’s say we’ve noticed in the out-of-the-box <a href="https://app.datadoghq.com/dash/integration/30322/kubernetes-pods-overview">Kubernetes Pods Overview</a> dashboard that pods for the <code>ad-server</code> and <code>product-recommendation</code> services, which <code>web-store</code> depends on, displayed an elevated rate of <code>CrashLoopBackOff</code> statuses and OOM kills during the incident, particularly during the first two hours. We copied these graphs to the Clipboard so we can export the most revealing one to the incident timeline after a bit more investigation.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-clipboard.png?auto=format&amp;fit=max&amp;w=847" alt="Exporting a graph to an incident timeline in Datadog from the Clipboard."/></picture></figure></div><h2 id="generate-your-postmortem-automatically"><a href="#generate-your-postmortem-automatically">Generate your postmortem automatically</a></h2><p>When it comes time to publish the information in your <a href="#centralize-data-as-you-go">shared view</a> as a polished document, you should automate the process as much as possible so investigators can focus on analysis and insights. You can accomplish this by creating templates, checklists, or guidelines that make it easy to start a postmortem. Automating postmortem generation lets your team focus on analysis and understanding rather than copying and pasting incident data, and ensures that no key details are left out. It’s also important to be able to edit your generated postmortems when investigators encounter <a href="#use-your-postmortem-as-a-thinking-tool">new information</a>.</p><p>Datadog enables you to <a href="https://www.datadoghq.com/blog/incident-response-with-datadog/#making-the-most-of-post-incident-reviews">automatically generate</a> a nearly-complete postmortem from incident metadata with just a few clicks. Your organization can create custom templates that match your current postmortem structure, ensuring that any postmortem you generate contains the right data before you need to start investigating an incident. Templates automatically populate with events from the incident timeline, including live graphs and key details like the causes and customer impact.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-template.png?auto=format&amp;fit=max&amp;w=847" alt="Comments in the Datadog incident timeline that we will use to generate a postmortem automatically."/></picture></figure></div><h2 id="use-your-postmortem-as-a-thinking-tool"><a href="#use-your-postmortem-as-a-thinking-tool">Use your postmortem as a thinking tool</a></h2><p>After you <a href="#generate-your-postmortem-automatically">generate</a> your postmortem, the document should enable responders to get even more insight about the incident. In other words, postmortems need to be living documents that enable readers to have conversations, get additional context, and refine their root-cause analysis. You can achieve this by allowing team members to comment on the postmortem, making it easier to add data and analysis. You can also enable incident responders to access real-time data in the postmortem so they can reach even deeper insights.</p><p>For example, Datadog’s collaborative Notebooks are fully editable and enable you to leave comments so your team can continue to assess the data and gather information even after you have generated your postmortem. In the example below, one investigator uses the earlier insights that <code>product-recommendation</code> and <code>ad-server</code> pods were crashing during the incident to suggest a way to prevent similar incidents in the future.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-notebook-comments.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog Notebooks enable you to comment directly in a postmortem document."/></picture></figure></div><p>Your postmortem should also include (or at least link to) live graphs. Static graphs tie the parameters of a graph—the timeframe, metrics, filters, and aggregation groups—to a specific point in the investigation. With live graphs, on the other hand, responders can modify these parameters so they can draw more information out of a single graph, helping them challenge their assumptions, get more context, and investigate further.</p><p>In Datadog, graphs within Notebooks (including postmortems) are live, meaning that you can expand them to view the <a href="https://docs.datadoghq.com/dashboards/querying/#graphing-editor">graphing editor</a> and adjust the timeframe, tags, and other parameters within your metric query. This makes it easier to reveal new dimensions of the graph, such as a previously unforeseen outlier or a broader timeframe that casts new light on a trend.</p><p>For example, by zooming out within one graph in our postmortem, we noticed that error rates had been elevated for at least a week prior to the incident’s recorded start time, even though we had not received support tickets from users. We can then add the zoomed-out graph to our postmortem so readers can have a full view of the data, revise our postmortem to be more accurate, and change the scope of our investigation.</p><h2 id="make-it-easy-to-find-later"><a href="#make-it-easy-to-find-later">Make it easy to find later</a></h2><p>It’s important to ensure that the findings included in your postmortems are easy to locate to help team members who may be investigating future incidents or writing a runbook down the road. If readers are searching for postmortems related to a specific service, they should be able to discover yours even if they do not know the ID of the incident you responded to.</p><p>You should include descriptive tags and titles with your incidents and postmortems to make searching easier. Organizing by incident ID or date isn’t enough, for example, if you’re interested in the possible failure modes of a single service. But if you tag your postmortems with their relevant service name as well, it becomes easier to find the ones you need. Datadog enables you to find incidents in the <a href="https://app.datadoghq.com/incidents">Incidents page</a> by service, availability zone, and other Datadog tags. In this case, for example, we are searching for all incidents related to the <code>web-store</code> service during the month prior to the one we’re investigating, so we can find a related investigation that we can use as a guide to which data we should explore first.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/incident-postmortem-process-best-practices/postmortem-best-practices-incident-search.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog enables you to find incidents by tag."/></picture></figure></div><p>If your organization stores postmortems as static files, Datadog enables you to easily <a href="https://docs.datadoghq.com/notebooks/#sharing-notebooks">export</a> a postmortem as a PDF, Markdown document, or formatted text so you can store it with your organization’s preferred method (e.g., adding it to a directory). And if you need to edit a postmortem you have already exported, Datadog Notebooks <a href="https://docs.datadoghq.com/notebooks/#graph-snapshots">retain a snapshot</a> of incident-related graphs so you can export your postmortem again even after the <a href="https://docs.datadoghq.com/developers/faq/data-collection-resolution-retention/">data retention period</a> has passed.</p><h2 id="faster-postmortems-with-datadog"><a href="#faster-postmortems-with-datadog">Faster postmortems with Datadog</a></h2><p>In this post, we have seen how Datadog speeds up the process of writing postmortems so you can focus on building more resilient systems, rather than compiling data and coordinating with teammates.</p><p>Aside from writing postmortems, Datadog <a href="https://www.datadoghq.com/blog/incident-response-with-datadog/">Incident Management</a> gives you the visibility you need for every stage of the incident response process, from investigation to mitigation and prevention. <a href="https://www.datadoghq.com/product/alerts/">Alerts</a> let you get notified about possible incidents through integrations with technologies like <a href="https://docs.datadoghq.com/integrations/pagerduty/">PagerDuty</a>—then declare an incident with data from the alert. You can then speed up your troubleshooting with <a href="https://www.datadoghq.com/blog/datadog-watchdog-insights-log-management/">Watchdog Insights</a> and <a href="https://www.datadoghq.com/blog/datadog-watchdog-automated-root-cause-analysis/">Watchdog RCA</a>, and contribute to the investigation <a href="https://www.datadoghq.com/blog/mobile-incident-management-datadog/">on mobile</a>.</p><p>If you haven’t tried Datadog yet and want to start streamlining your postmortems today, you can get started with a <a href="#">free trial</a>.</p></div></div>]]></content:encoded>
      <author>Stephanie Niu</author>
      <pubDate>Fri, 17 Sep 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Compare and optimize your code with Datadog Profile Comparison</title>
      <link>https://www.datadoghq.com/blog/code-optimization-datadog-profile-comparison/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-hero.png&#34; width=&#34;100%&#34;/&gt;Code profilers offer detailed insight into the efficiency of application code by measuring things like the execution time and resource utilization of a service. Datadog&amp;rsquo;s always-on, low overhead Continuous Profiler provides snapshots of code performance for a service that are tagged with key metadata (e.g., region, service, release), so you can easily identify and optimize inefficient code. This enables you to manage compute costs and resolve performance bottlenecks that affect your users&#39; experience.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Code profilers offer detailed insight into the efficiency of application code by measuring things like the execution time and resource utilization of a service. Datadog’s always-on, low overhead <a href="https://www.datadoghq.com/blog/datadog-continuous-profiler/">Continuous Profiler</a> provides snapshots of code performance for a service that are tagged with key metadata (e.g., <code>region</code>, <code>service</code>, <code>release</code>), so you can easily identify and optimize inefficient code. This enables you to manage compute costs and resolve performance bottlenecks that affect your users&#39; experience.</p><p>Datadog’s profiler allows you to capture code profiles continuously for all of your production instances. Now you can compare those profiles in the <a href="https://docs.datadoghq.com/tracing/profiler/compare_profiles">profile comparison view</a> to see how the performance and structure of your code change over time. This enables you to answer key questions about code-level performance such as: has a new release improved performance or caused a regression? Is your code more performant in one region, host, or pod versus another? Which functions are consuming the most CPU time for today versus last week?</p><p>The profile comparison view also helps you quantify the changes you’ve made to fix a performance bottleneck, such as optimizing a CPU-intensive method, so you can easily calculate the estimated savings on your production infrastructure costs.</p><h2 id="quickly-detect-code-performance-regressions-in-production-workloads"><a href="#quickly-detect-code-performance-regressions-in-production-workloads">Quickly detect code performance regressions in production workloads</a></h2><p>As your application grows in size and complexity, the probability of introducing regressions in code performance also increases. Continuous Profiler enables you to view your application’s code performance in production at a glance, whether it be through an instantaneous sixty-second profile or an aggregate view of a service’s performance bottlenecks within a specific timeframe. But there may still be critical performance blind spots that would otherwise go unnoticed without complete visibility into application code.</p><p>With the profile comparison view, you can efficiently troubleshoot the root cause behind performance blind spots at a method level, including regressions such as:</p><ul><li>an increase in a service’s heap memory size over the past two days</li><li>spikes in service latency since the last deployment</li><li>regressions in CPU consumption over the past seven days</li></ul><p>The profile comparison view automatically highlights changes in production code performance based on a selected profile type (e.g., CPU time, allocations, thread locks, etc.) and a timeframe that you specify. Visibility into these areas of code performance can help you monitor the efficiency of production workloads and detect problematic areas before they become more serious.</p><p>For example, you can compare a service’s live heap memory between two releases to spot potential memory leaks. The screenshot below shows a method that is contributing eight percent more to the heap live size in the newer deployed version (in purple) compared to the previous one (in blue). If the service live heap memory continues to increase over a sustained period of time then it could indicate that there is a memory leak within the service. Methods highlighted in bright red, such as the <code>doNRequests</code> method seen below, indicate areas where you can start your investigation.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-heap.png?auto=format&amp;fit=max&amp;w=847" alt="Use profile comparison to compare heap memory for a service"/></picture></figure></div><h2 id="identify-the-cause-of-increased-latency-in-service-endpoints"><a href="#identify-the-cause-of-increased-latency-in-service-endpoints">Identify the cause of increased latency in service endpoints</a></h2><p>Profile comparison can also help you identify the root cause of increased latency for a service endpoint, which can affect your end users&#39; experience and be costly if not resolved quickly. But this type of bottleneck is often difficult to detect—it could be the result of issues that resolve on their own (e.g., network latency, noisy neighbor processes) or legitimate performance regressions in your code. With the profile comparison view, you can easily confirm if the latency spike was caused by inefficient code.</p><p>For example, you can compare the elapsed time a service with stable workloads spent executing a method (i.e., wall time) to the previous week’s performance. The screenshot belows shows that the wall time for several methods in a profiled Ruby service increased significantly over several days (highlighted in red).</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-latency.png?auto=format&amp;fit=max&amp;w=847" alt="Use profile comparison to find the cause of endpoint latency"/></picture></figure></div><p>You can filter your view to show the appropriate service controller, enabling you to identify all of the downstream methods that created the spike in latency for the endpoint. Profile comparison identifies the exact methods that need further inspection, down to the line of code associated with the change in performance, so you can troubleshoot further and deploy a fix if needed.</p><h2 id="compare-code-performance-between-releases"><a href="#compare-code-performance-between-releases">Compare code performance between releases</a></h2><p>Profile comparison is tightly integrated with <a href="https://www.datadoghq.com/blog/datadog-deployment-tracking/">deployment tracking</a>, so you can track code performance for a particular service after a new release by pivoting from a high-level view of a deployment to a more granular view of application code.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-deployment-tracking.png?auto=format&amp;fit=max&amp;w=847" alt="Compare a profile from deployment tracking."/></picture></figure></div><p>This enables you to compare code before and after you deploy changes to ensure they improve service performance. For example, the screenshot below compares the CPU time for a specific function (<code>readinto</code>) over two successive releases.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/code-optimization-datadog-profile-comparison/profile-comparison-cpu-time.png?auto=format&amp;fit=max&amp;w=847" alt="Compare CPU time for a service with profile comparison"/></picture></figure></div><p>On the right, which represents the newer release, you can see that the function consumed 15 percent less CPU time than in the older version, meaning that the deployed optimizations improved performance as expected.</p><h2 id="better-visibility-into-code-performance"><a href="#better-visibility-into-code-performance">Better visibility into code performance</a></h2><p>Datadog’s Continuous Profiler enables you to monitor code performance in your production environments in real time, so you can effectively diagnose performance issues, optimize costly lines of code, and deploy fixes to your customers faster. And with the ability to compare profile data side by side, you can better understand how changes to your application code improved or degraded performance over time. Check out our <a href="https://docs.datadoghq.com/tracing/profiler/compare_profiles">documentation</a> to learn more about Datadog’s Continuous Profiler and the profile comparison view. If you don’t already have a Datadog account, you can sign up for a <a href="#">14-day free trial</a> today.</p></div></div>]]></content:encoded>
      <author>Gaurab Aryal</author>
      <pubDate>Tue, 14 Sep 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Best practices for getting started with Datadog Network Performance Monitoring</title>
      <link>https://www.datadoghq.com/blog/npm-best-practices/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-best-practices-hero.png&#34; width=&#34;100%&#34;/&gt;Whether running on a fully cloud-hosted environment, on-premise servers, or a hybrid solution, modern services and applications are heavily reliant on network and DNS performance. This makes comprehensive visibility into your network a key part of monitoring application health and performance. But as your applications grow in scale and complexity, gaining this visibility is challenging.To help identify and troubleshoot problems before they affect your application and users, Datadog Network Performance Monitoring (NPM) enables you to visualize and break down data flow across your network.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Whether running on a fully cloud-hosted environment, on-premise servers, or a hybrid solution, modern services and applications are heavily reliant on network and DNS performance. This makes comprehensive visibility into your network a key part of monitoring application health and performance. But as your applications grow in scale and complexity, gaining this visibility is challenging.</p><p>To help identify and troubleshoot problems before they affect your application and users, Datadog <a href="https://docs.datadoghq.com/network_monitoring/performance/">Network Performance Monitoring (NPM)</a> enables you to visualize and break down data flow across your network. By giving you visibility into network traffic flows, NPM enables you to quickly spot issues that manifest as traffic spikes, drops, or latency between different endpoints in your environment.</p><p>Once you’ve <a href="https://docs.datadoghq.com/network_monitoring/performance/setup">set up NPM</a>, Datadog automatically collects key transport-layer (TCP/UDP) and DNS data related to traffic between each endpoint in your environment, including VMs, containers, services, cloud regions or datacenters, and much more.</p><p>In this post, we’ll show you how you can use Datadog to monitor the health and performance of your network dependencies. In particular, we’ll cover how to:</p><ul><li>Use our out-of-the-box NPM dashboard to <a href="#view-key-network-metrics-with-the-network-overview-dashboard">view key network metrics</a> for insight into the health and performance of your network</li><li>Quickly monitor critical dependencies with <a href="#quickly-monitor-critical-dependencies-with-saved-views">Saved Views</a></li><li>Pinpoint root causes with <a href="#correlate-network-data-with-telemetry-from-each-layer-of-your-stack">correlated</a> network, application, and infrastructure telemetry data with telemetry from other layers of your stack</li></ul><h2 id="view-key-network-metrics-with-the-network-overview-dashboard"><a href="#view-key-network-metrics-with-the-network-overview-dashboard">View key network metrics with the Network Overview dashboard</a></h2><p>As you scale your applications and services, they need to reliably communicate over larger and more complex networks. Without visibility into each aspect of network communication, it can be difficult to determine which is the source of an issue and needs troubleshooting. For instance, monitoring network throughput can help determine whether excessive traffic is overloading your systems and the culprit behind a problem. Similarly, tracking TCP connection metrics and DNS server errors over time helps assess network health since either can negatively impact network communication.</p><p>Datadog automatically collects key network traffic and DNS server metrics and populates an out-of-the-box Network Overview dashboard that provides a unified, high-level view of key network health and performance across different facets of your distributed network. This helps you get up and running on NPM quickly to immediately locate problems and drill down to investigate. You can read more about the Network Overview dashboard in <a href="https://app.datadoghq.com/notebook/415397/understanding-graphing-network-metrics">this notebook</a>.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/NPM-dashboard.png?auto=format&amp;fit=max&amp;w=847" alt="NPM-dashboard.png"/></picture><figcaption>Use the Network Overview dashboard to get a high-level view of key network health and performance across your distributed network.</figcaption></figure></div><p>The Network Overview dashboard organizes network metrics into the following essential categories to make it easier to troubleshoot problems within different layers of network performance and correlate that data with other telemetry from your environment:</p><ul><li><a href="#network-load-metrics"><strong>Network load</strong></a></li><li><a href="#tcp-metrics"><strong>TCP traffic performance</strong></a></li><li><a href="#dns-metrics"><strong>DNS health</strong></a></li><li><a href="#application-overview-metrics"><strong>Application overview</strong></a></li><li><a href="#cross-regional-traffic-metrics"><strong>Cross-regional traffic overview</strong></a></li></ul><h3 id="network-load-metrics"><a href="#network-load-metrics">Network load metrics</a></h3><p>The <strong>Network Load</strong> section visualizes the volume of bytes sent and received between tagged network endpoints (e.g., services and availability zones). Data sent and received are fundamental network metrics because they provide you with an overall view of network traffic and can clue you into sudden data flow stoppages or spikes and which parts of your infrastructure are being affected. If an endpoint is hit with far more traffic than usual, its underlying hosts or containers can become overloaded and start overconsuming resources, leading to higher latencies or outages. Alternatively, if you spot services or infrastructure components that are not sending or receiving any data, you know where to focus your troubleshooting efforts.</p><h3 id="tcp-metrics"><a href="#tcp-metrics">TCP metrics</a></h3><p>Most network communication is facilitated by the Transmission Control Protocol (TCP). In order for a client and server to send data packets to each other successfully, they first need to establish a TCP connection. Problems establishing and maintaining these connections can mean that services are unable to communicate with each other. Visibility into TCP metrics can help you identify and mitigate connectivity issues.</p><p>The <strong>TCP</strong> section of the Network Overview dashboard visualizes key TCP metrics like the number of established and closed connections, as well as retransmits, so you can pinpoint sources of latency and outages. For example, if you spot a sudden spike in TCP retransmits from a particular service to a destination endpoint alongside a drop in established connections, it could be a sign of a networking issue that needs further investigation&amp;endash;such as traffic congestion, a network misconfiguration, or faulty hardware.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-tcp-retransmissions.png?auto=format&amp;fit=max&amp;w=847" alt="Spikes in TCP retransmits may be a sign of traffic congestion or a network misconfiguration."/></picture></figure></div><h3 id="dns-metrics"><a href="#dns-metrics">DNS metrics</a></h3><p>The Domain Name System (DNS) is responsible for mapping domain names to their corresponding IP addresses. DNS issues can lead to services and devices being unable to find or connect to endpoints they rely on, which can prevent users from accessing your web applications. DNS communication consists of a client requesting the IP address of a domain name from one or more DNS servers. Since an issue can occur at either end, monitoring key DNS metrics can help you distinguish between client-side issues, like misconfigured requests, and server-side issues, like resource saturation (i.e., overwhelmed by client requests) affecting your DNS servers.</p><p>You can use tags to slice and dice the Network Overview dashboard to quickly look for client- or server-side DNS issues. For example, group DNS metrics by either <code>app</code> or <code>service</code> tags to view the DNS performance of your client applications and services. Then, to look for server-side issues, we recommend grouping by either <code>dns_server</code> or <code>cluster</code>. By visualizing metrics like DNS requests, failures, and timeouts across regions, you can quickly spot issues that you need to dive into.</p><p><a href="https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml#dns-parameters-6">DNS response codes</a> are another reliable bellwether for DNS health and performance. Two common response errors to look for are <code>SERVFAIL</code> errors, which point to server issues, and <code>NXDOMAIN</code> errors, which mean clients are making requests to nonexistent domains (likely because of a misconfiguration). The Network Overview dashboard visualizes what percentage these errors make up of all responses, making it easy to identify spikes or worrisome trends that require investigation.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-dns-errors.png?auto=format&amp;fit=max&amp;w=847" alt="Pay attention to DNS error types to help pinpoint root causes."/></picture></figure></div><h3 id="application-overview-metrics"><a href="#application-overview-metrics">Application overview metrics</a></h3><p>Since modern applications are highly distributed and vulnerable to networking issues, being able to correlate network and application-level monitoring data is critical for identifying the root cause of issues. For example, customizing the Network Overview dashboard’s <strong>Application Overview</strong> section to visualize network throughput next to application performance data such as service latency that’s available through <a href="https://docs.datadoghq.com/tracing/visualization/service/">Datadog APM</a> can help you spot signs that a network issue (e.g., an unexpected drop in bytes sent from a particular service) has negatively impacted application performance (e.g., a spike in latency). You can also correlate network metrics with third-party endpoint health metrics, such as Elastic Load Balancer (ELB) 5xx errors to determine if there is a service-level issue.</p><h3 id="cross-regional-traffic-metrics"><a href="#cross-regional-traffic-metrics">Cross-regional traffic metrics</a></h3><p>In order for your cloud-hosted services to be highly available and perform well, it’s often necessary to utilize multiple availability zones and regions. However, when data flows across regions and availability zones, it can drive up costs and create more network vulnerabilities. While some traffic between regions or availability zones might be expected, you should look out for unexpected spikes in interregional traffic. The Network Overview map’s <strong>Cloud Region Overview</strong> section enables you to view key metrics covered earlier in this post in the context of cross-regional and cross-AZ communication. For instance, you can view the volume of network traffic between availability zones to reveal where you can reconfigure your network to reduce costs. This section also includes a “Top cross-AZ talkers” widget, which identifies source endpoints that send most traffic across availability zones. This means you can quickly spot the source of the spike network communication inefficiencies and begin mitigating the issue.</p><h2 id="quickly-monitor-critical-dependencies-with-saved-views"><a href="#quickly-monitor-critical-dependencies-with-saved-views">Quickly monitor critical dependencies with Saved Views</a></h2><p>Datadog’s <a href="https://app.datadoghq.com/network">Network page</a> enables you to use <a href="https://docs.datadoghq.com/network_monitoring/performance/network_page/#queries">queries</a> to scope your view to the performance of communication between specific services, pods, cloud resources, and more. When monitoring distributed architectures, you often need to switch your focus between different aspects of network communication to effectively identify issues. For instance, you may be regularly moving back and forth between viewing network traffic between services to network traffic between their underlying pods. Because these are common views to reference when monitoring network performance, writing queries each time means you may lose valuable time needed to troubleshoot. You can use preset <a href="https://www.datadoghq.com/blog/template-variable-saved-views/">Saved Views</a> to quickly access useful default and custom queries in the Network view, which enables you to immediately view monitoring data in the scope of your troubleshooting context. For example, the “traffic to external domains” Saved View groups traffic by the <code>service</code> and <code>domain</code> tags so you can see network performance metrics related to traffic between a service and an external domain endpoint.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view01.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog NPM includes saved views for traffic to external domains."/></picture></figure></div><p>Datadog also provides a built-in “cross-availability zone traffic” Saved View, which groups data by the <code>availability-zone</code> tag so you can view traffic that occurs across availability zones which, as we mentioned, can drive up costs and may increase network latency.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-saved-view02.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog NPM includes saved views for cross-availability zone traffic."/></picture></figure></div><p>Saved Views provide you with quick access to relevant network flow data so you can access the information you need and troubleshoot faster.</p><h2 id="correlate-network-data-with-telemetry-from-each-layer-of-your-stack"><a href="#correlate-network-data-with-telemetry-from-each-layer-of-your-stack">Correlate network data with telemetry from each layer of your stack</a></h2><p>Because applications rely heavily on each other, poor connectivity or slow calls may manifest as errors and latency at the application layer. For example, service latency can be the result of a code-level bug, or it could be an issue with an upstream or downstream service. If, however, you only have visibility into either your network layer or your application layer, it can be challenging to determine which is behind an issue and what team to alert so they can start troubleshooting.</p><p>Datadog NPM automatically ties together monitoring data from each layer of your stack so you can correlate them easily. For example, if you see that an availability zone has unexpectedly high TCP retransmits in the Network view, without leaving that view you can open a side panel to explore all correlated logs, traces, and <a href="https://docs.datadoghq.com/integrations/process/">processes</a> for additional context that helps identify the problem. In the screenshot below, we can see that an <a href="https://docs.datadoghq.com/integrations/nginx/?tab=host">NGINX</a> process has saturated the CPU of a host in that availability zone and may be behind the spike in TCP retransmits.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/npm-best-practices/npm-nginx01.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog automatically correlates network data with telemetry from other layers of your service."/></picture></figure></div><p>Network data is just one piece of the puzzle. By automatically correlating network data with telemetry from the rest of your stack, you can gain a deeper understanding of the health of your environment, enabling you to effectively pinpoint the origins of an issue.</p><h2 id="get-started-with-network-performance-monitoring-today"><a href="#get-started-with-network-performance-monitoring-today">Get started with Network Performance Monitoring today</a></h2><p>Datadog Network Performance Monitoring helps make troubleshooting problems with your network easier by visualizing key performance metrics, and providing preset Saved Views that let you quickly scope to relevant troubleshooting data. Additionally, Datadog NPM automatically ties network traffic to other key metrics, traces, logs, and processes to help uncover root causes. Datadog NPM uses an <a href="http://www.brendangregg.com/blog/2019-01-01/learn-ebpf-tracing.html">eBPF-powered</a> system probe for Linux and a <a href="https://www.datadoghq.com/blog/npm-windows-support/">custom driver</a> for Windows hosts so you can get network-level visibility with minimal overhead regardless of your operating system.</p><p>If you’re already a Datadog customer, you can get started with the out-of-the-box <a href="https://app.datadoghq.com/dashboard/pbu-5b3-hrz/network-overview">network performance dashboard</a>. Otherwise, sign up for a 14-day <a href="#">free trial</a>.</p></div></div>]]></content:encoded>
      <author>Jordan Obey</author>
      <pubDate>Thu, 09 Sep 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Monitor your Netlify sites with Datadog</title>
      <link>https://www.datadoghq.com/blog/monitor-netlify-with-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-hero.png&#34; width=&#34;100%&#34;/&gt;Netlify is a Jamstack web development platform that lets customers build and deploy dynamic, highly performant web apps. By uniting popular JavaScript frameworks, developer tools, and APIs into streamlined workflows, Netlify helps teams rapidly spin up and ship common Jamstack use cases, including e-commerce stores, SaaS applications, and corporate sites. Netlify supports these deployments with an integrated CI/CD tool, global multi-cloud edge network, and serverless backend.You can now use Datadog to capture your Netlify web traffic and serverless function logs for long-term retention and analysis.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><a href="https://www.netlify.com/">Netlify</a> is a <a href="https://jamstack.org/what-is-jamstack/">Jamstack</a> web development platform that lets customers build and deploy dynamic, highly performant web apps. By uniting popular JavaScript frameworks, developer tools, and APIs into streamlined workflows, Netlify helps teams rapidly spin up and ship common Jamstack use cases, including e-commerce stores, SaaS applications, and corporate sites. Netlify supports these deployments with an integrated CI/CD tool, global multi-cloud edge network, and serverless backend.</p><p>You can now use Datadog to capture your <a href="https://www.netlify.com/blog/2021/09/08/announcing-netlify-log-drains-for-datadog/">Netlify web traffic and serverless function logs</a> for long-term retention and analysis. In this post, we’ll look at how ingesting your Netlify logs into Datadog helps you monitor and visualize key web traffic and function performance data. We’ll also cover how Datadog <a href="https://www.datadoghq.com/product/synthetic-monitoring/">Synthetic Monitoring</a> can give you comprehensive visibility into the health and performance of your Netlify sites.</p><h2 id="send-your-netlify-logs-to-datadog"><a href="#send-your-netlify-logs-to-datadog">Send your Netlify logs to Datadog</a></h2><p>To send your logs to Datadog, you can use Netlify’s <a href="https://docs.netlify.com/monitor-sites/log-drains/">Log Drains</a> feature, which allows Netlify users to forward logs to third-party monitoring services. Forwarding your Netlify logs to Datadog enables you to retain them beyond the 24-hour window of the Netlify console. Once you set up the integration, your logs will begin streaming into Datadog. Datadog’s built-in <a href="https://docs.datadoghq.com/logs/log_configuration/pipelines/">log processing pipeline</a> automatically parses out key attributes from your logs, which you can then use to search, filter, analyze, and generate metrics. Datadog uses your parsed log data to populate an out-of-the-box Netlify dashboard that visualizes key telemetry from your environment, giving you a high-level overview of your Netlify apps.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-dashboard.png?auto=format&amp;fit=max&amp;w=847" alt="Default Netlify dashboard"/></picture></figure></div><p>Next, we’ll discuss how you can use your Netlify logs to get insights into:</p><ul><li><a href="#capture-and-analyze-serverless-function-logs">your backend functions and business logic</a></li><li><a href="#use-traffic-logs-to-understand-user-behavior">traffic and usage</a></li></ul><h3 id="capture-and-analyze-serverless-function-logs"><a href="#capture-and-analyze-serverless-function-logs">Capture and analyze serverless function logs</a></h3><p>Netlify Functions can be written in JavaScript, TypeScript, or Go and let you add dynamic backend processes to your websites without managing additional infrastructure. Netlify function logs contain key fields including <code>function_name</code>, <code>timestamp</code>, and <code>status</code>. Once your logs are streaming into Datadog, you can utilize these attributes in the <a href="https://app.datadoghq.com/logs">Log Explorer</a> to filter and sort your logs to surface error-prone or slow functions.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-list-2.png?auto=format&amp;fit=max&amp;w=847" alt="Viewing Netlify function logs in the Log Explorer"/></picture></figure></div><p>You can generate metrics from your logs to visualize and alert on things like 4xx/5xx error rates, latency, and request volume. For example, if you’re monitoring an ecommerce payment function, you might want to set an alert on its error rate. This way, you can be notified of issues before they might lead to lost revenue and potential customer churn.</p><p>You can also use your serverless logs to collect key business insights by adding custom information to the <code>log_message</code> field at runtime. For example, if you’re monitoring an ecommerce payment function, you can log the dollar value of the transaction, the customer ID, and any relevant product IDs. You can then visualize that information in Datadog to build context for your business analytics.</p><h3 id="use-traffic-logs-to-understand-user-behavior"><a href="#use-traffic-logs-to-understand-user-behavior">Use traffic logs to understand user behavior</a></h3><p>Your Netlify application’s web traffic logs are emitted directly from its CDN’s <a href="https://www.netlify.com/products/edge/">Edge Network</a>. Traffic logs can provide visibility into your site’s overall performance. Using key attributes like <code>duration</code> and <code>status_code</code>, you can generate the standard RED (requests, errors, and duration) metrics for your site and break down errors by status code. Creating alerts for these metrics and visualizing them in your dashboards helps you validate the health and performance of your site in real time and stay ahead of user-facing problems.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-log-metrics.png?auto=format&amp;fit=max&amp;w=847" alt="Viewing a Netlify function log event&#39;s metadata"/></picture></figure></div><p>Netlify traffic logs can also help you analyze your users’ traffic patterns to identify trends and spot anomalous behavior—such as a DDoS attack. For example, you could use the <code>status_code</code> attribute to create a log-based metric counting 504 errors, and then alert on a critical threshold. If the alert triggers you can use the Log Explorer to investigate the relevant logs to determine if they appear to be from a fraudulent source by filtering the logs by the relevant URL path then drilling into log events in the resulting list to see, for example, if a majority of requests are coming from a small group of IPs in a strange location.</p><h2 id="monitor-your-frontend-performance-with-datadog-synthetic-monitoring"><a href="#monitor-your-frontend-performance-with-datadog-synthetic-monitoring">Monitor your frontend performance with Datadog Synthetic Monitoring</a></h2><p>In addition to logs, <a href="https://www.datadoghq.com/digital-experience-monitoring/">digital experience monitoring</a> can provide a deeper view into how your webpages respond to traffic and whether they are working correctly for users. With Datadog Synthetic Monitoring, you can create multistep browser tests that enable you to view the response times of individual content fetches during a page load, alongside the performance of dynamic DOM content. By setting up browser tests for your Netlify application, you can measure the performance of key user flows and quickly spot errors and speed bottlenecks. Each step includes a detailed waterfall timeline of all the static content fetches, client-side JavaScript, and API calls required in a page load, alongside <a href="https://www.datadoghq.com/blog/core-web-vitals-monitoring-datadog-rum-synthetics/">Core Web Vitals</a>—such as Largest Contentful Paint and Cumulative Layout Shift—that help you characterize the user experience.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-browser-test.png?auto=format&amp;fit=max&amp;w=847" alt="Synthetic browser test"/></picture></figure></div><p>By adding HTTP request steps to your browser tests, you include calls to your Netlify Serverless Functions in your user flows to create a holistic picture of your site’s performance from both frontend and backend data. For example, you could create a checkout flow that includes a call to your payment function via the relevant API endpoint. You can see detailed information about the request, including the overall duration, status code, and request size, along with a waterfall showing a breakdown of the DNS request, SSL handshake, time to first byte, and download, to understand how these processes contribute to the overall latency.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/monitor-netlify-with-datadog/netlify-http-test.png?auto=format&amp;fit=max&amp;w=847" alt="Default Netlify dashboard"/></picture></figure></div><h2 id="get-started-with-datadog-and-netlify"><a href="#get-started-with-datadog-and-netlify">Get started with Datadog and Netlify</a></h2><p>​​With Datadog and Netlify Log Drains, you can easily ingest Netlify logs for full visibility into your serverless functions and site traffic. And, by using Datadog Synthetic Monitoring to track frontend performance, you get a comprehensive solution for monitoring your Netlify-powered applications. Log Drains is available now with Netlify’s <a href="https://www.netlify.com/pricing/">Enterprise plan</a>. For more information about the integration, see the <a href="https://docs.netlify.com/monitor-sites/log-drains/">Netlify Log Drains documentation</a> and our own <a href="https://docs.datadoghq.com/integrations/netlify">integration docs</a>. Or if you’re brand new to Datadog, sign up for a <a href="#">free trial</a> to get started.</p></div></div>]]></content:encoded>
      <author>Thomas Sobolik</author>
      <pubDate>Wed, 08 Sep 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Announcing support for EKS Anywhere</title>
      <link>https://www.datadoghq.com/blog/amazon-eks-anywhere/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/hero.png&#34; width=&#34;100%&#34;/&gt;Amazon Elastic Kubernetes Service (EKS) is a cloud-based compute platform that includes a fully managed Kubernetes control plane in order to simplify cluster operations. AWS introduced EKS Anywhere to bring the operational ease of EKS to organizations that manage on-premise environments (e.g., to meet data sovereignty requirements). EKS Anywhere is released as an automation tool that launches an EKS Distro cluster with opinionated defaults on vSphere virtual machines, making it easier to get started with container orchestration.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><a href="https://www.datadoghq.com/blog/eks-cluster-metrics/">Amazon Elastic Kubernetes Service</a> (EKS) is a cloud-based compute platform that includes a <a href="https://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html">fully managed</a> Kubernetes control plane in order to simplify cluster operations. AWS introduced <a href="https://aws.amazon.com/blogs/aws/amazon-eks-anywhere-now-generally-available-to-create-and-manage-kubernetes-clusters-on-premises/">EKS Anywhere</a> to bring the operational ease of EKS to organizations that manage on-premise environments (e.g., to meet <a href="https://www.oracle.com/security/saas-security/data-sovereignty">data sovereignty</a> requirements). EKS Anywhere is released as an automation tool that launches an <a href="https://aws.amazon.com/eks/eks-distro/">EKS Distro</a> cluster with opinionated defaults on vSphere virtual machines, making it easier to get started with container orchestration.</p><p>With EKS Anywhere, teams can now use consistent tooling to operate and manage both cloud-based and on-premise EKS clusters. This makes EKS Anywhere a good fit for organizations that plan to migrate their on-premise Kubernetes deployments to the cloud, as well as organizations that usually run workloads on premises but want to deploy to AWS in order to handle bursts in traffic.</p><p>We are proud to announce that Datadog is a <a href="https://aws.amazon.com/eks/eks-anywhere/partners/">launch partner</a> for EKS Anywhere. Datadog enables you to get full visibility into the health and performance of EKS Anywhere and cloud-based EKS workloads—and their underlying infrastructure, whether it’s running on premises or in the cloud.</p><h2 id="full-visibility-into-ekswherever-it-runs"><a href="#full-visibility-into-ekswherever-it-runs">Full visibility into EKS—wherever it runs</a></h2><p>Whether you deploy your EKS clusters on your own data centers, to the cloud, or both, you need to monitor the resource usage and availability of both environments in order to keep your applications running as expected. With Datadog’s <a href="https://docs.datadoghq.com/infrastructure/livecontainers/?tab=helm#kubernetes-resources-view">Kubernetes resources view</a> (part of <a href="https://www.datadoghq.com/blog/explore-kubernetes-resources-with-datadog/">Live Containers</a>), you can get real-time insights into the resource capacity and usage of your EKS and EKS Anywhere clusters, all in one platform.</p><p>In the example below, we are viewing pods from two EKS clusters: one hosted on premises (<code>prod-11287-demo-cluster-west</code>) and the other in the AWS cloud. While this view shows us that CPU and memory utilization for pods in each cluster are similar, if we run into capacity issues in our on-premise data centers, we can scale out our cloud-based EKS cluster until the issue subsides.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=847" alt="The Clusters view showing EKS clusters hosted in the cloud and on premises."/></picture></figure></div><h2 id="get-context-from-your-on-premise-infrastructure"><a href="#get-context-from-your-on-premise-infrastructure">Get context from your on-premise infrastructure</a></h2><p>While EKS Anywhere makes it easier to manage your on-premise Kubernetes deployments, you will still need to monitor your underlying infrastructure to prevent issues with scheduling your application pods. Datadog enables you to explore bespoke views of your EKS Anywhere deployments—and get full context around the vSphere VMs that host them—so you can investigate unavailable nodes, resource saturation, and other conditions that can stop EKS Anywhere from working as expected.</p><p>With Datadog, you can create <a href="https://docs.datadoghq.com/dashboards/">custom dashboards</a> to monitor Kubernetes metrics, such as the <a href="https://www.datadoghq.com/blog/eks-cluster-metrics/#metrics-to-alert-on-desired-vs-current-pods">counts</a> of available and desired pods, as well as <a href="https://www.datadoghq.com/blog/vsphere-metrics/">vSphere metrics</a>. For example, you can create a dashboard (as shown below) that graphs the number of vSphere VMs by regional data center, then graph the number of available Kubernetes nodes by region. If there are more VMs than Kubernetes nodes, you can investigate whether some <a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/">kubelets</a> running on your vSphere VMs have crashed—or failed to deploy due to a misconfiguration—causing the API server to register fewer nodes than expected.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=847" alt="A dashboard that includes vSphere and Kubernetes metrics together, plus a host map and container map."/></picture></figure></div><h2 id="eks-is-anywhereand-so-is-datadog"><a href="#eks-is-anywhereand-so-is-datadog">EKS is anywhere—and so is Datadog</a></h2><p>Datadog is well suited for monitoring EKS Anywhere as well as your cloud-based EKS deployments, giving you full visibility into your containerized workloads no matter where they run. You can quickly install Datadog in your EKS Anywhere and EKS clusters using our <a href="https://docs.datadoghq.com/agent/kubernetes/?tab=helm">Helm chart</a>.</p><p>Datadog integrates with <a href="https://docs.datadoghq.com/integrations/vsphere/">vSphere</a>—and other infrastructure technologies you might be deploying on Kubernetes, such as <a href="https://www.datadoghq.com/blog/monitor-cilium-with-datadog/">Cilium</a> and <a href="https://www.datadoghq.com/blog/monitor-coredns-with-datadog/">CoreDNS</a>—so you can visualize every layer of your EKS Anywhere environment. And with other features like <a href="https://docs.datadoghq.com/network_monitoring/devices/">Network Device Monitoring</a>, you can get even deeper insight into the health of your <a href="https://www.datadoghq.com/solutions/on-premises-monitoring/">on-premise infrastructure</a>.</p><p>If you have not yet signed up for Datadog, you can started today with a <a href="#">free trial</a>.</p></div></div>]]></content:encoded>
      <author>Paul Gottschling</author>
      <pubDate>Wed, 08 Sep 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Announcing support for EKS Anywhere</title>
      <link>https://www.datadoghq.com/blog/amazon-eks-anywhere/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/hero.png&#34; width=&#34;100%&#34;/&gt;Amazon Elastic Kubernetes Service (EKS) is a cloud-based compute platform that includes a fully managed Kubernetes control plane in order to simplify cluster operations. AWS introduced EKS Anywhere to bring the operational ease of EKS to organizations that manage on-premise environments (e.g., to meet data sovereignty requirements). EKS Anywhere is released as an automation tool that launches an EKS Distro cluster with opinionated defaults on vSphere virtual machines, making it easier to get started with container orchestration.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><a href="https://www.datadoghq.com/blog/eks-cluster-metrics/">Amazon Elastic Kubernetes Service</a> (EKS) is a cloud-based compute platform that includes a <a href="https://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html">fully managed</a> Kubernetes control plane in order to simplify cluster operations. AWS introduced <a href="https://aws.amazon.com/blogs/aws/amazon-eks-anywhere-now-generally-available-to-create-and-manage-kubernetes-clusters-on-premises/">EKS Anywhere</a> to bring the operational ease of EKS to organizations that manage on-premise environments (e.g., to meet <a href="https://www.oracle.com/security/saas-security/data-sovereignty">data sovereignty</a> requirements). EKS Anywhere is released as an automation tool that launches an <a href="https://aws.amazon.com/eks/eks-distro/">EKS Distro</a> cluster with opinionated defaults on vSphere virtual machines, making it easier to get started with container orchestration.</p><p>With EKS Anywhere, teams can now use consistent tooling to operate and manage both cloud-based and on-premise EKS clusters. This makes EKS Anywhere a good fit for organizations that plan to migrate their on-premise Kubernetes deployments to the cloud, as well as organizations that usually run workloads on premises but want to deploy to AWS in order to handle bursts in traffic.</p><p>We are proud to announce that Datadog is a <a href="https://aws.amazon.com/eks/eks-anywhere/partners/">launch partner</a> for EKS Anywhere. Datadog enables you to get full visibility into the health and performance of EKS Anywhere and cloud-based EKS workloads—and their underlying infrastructure, whether it’s running on premises or in the cloud.</p><h2 id="full-visibility-into-ekswherever-it-runs"><a href="#full-visibility-into-ekswherever-it-runs">Full visibility into EKS—wherever it runs</a></h2><p>Whether you deploy your EKS clusters on your own data centers, to the cloud, or both, you need to monitor the resource usage and availability of both environments in order to keep your applications running as expected. With Datadog’s <a href="https://docs.datadoghq.com/infrastructure/livecontainers/?tab=helm#kubernetes-resources-view">Kubernetes resources view</a> (part of <a href="https://www.datadoghq.com/blog/explore-kubernetes-resources-with-datadog/">Live Containers</a>), you can get real-time insights into the resource capacity and usage of your EKS and EKS Anywhere clusters, all in one platform.</p><p>In the example below, we are viewing pods from two EKS clusters: one hosted on premises (<code>prod-11287-demo-cluster-west</code>) and the other in the AWS cloud. While this view shows us that CPU and memory utilization for pods in each cluster are similar, if we run into capacity issues in our on-premise data centers, we can scale out our cloud-based EKS cluster until the issue subsides.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-cluster-view.png?auto=format&amp;fit=max&amp;w=847" alt="The Clusters view showing EKS clusters hosted in the cloud and on premises."/></picture></figure></div><h2 id="get-context-from-your-on-premise-infrastructure"><a href="#get-context-from-your-on-premise-infrastructure">Get context from your on-premise infrastructure</a></h2><p>While EKS Anywhere makes it easier to manage your on-premise Kubernetes deployments, you will still need to monitor your underlying infrastructure to prevent issues with scheduling your application pods. Datadog enables you to explore bespoke views of your EKS Anywhere deployments—and get full context around the vSphere VMs that host them—so you can investigate unavailable nodes, resource saturation, and other conditions that can stop EKS Anywhere from working as expected.</p><p>With Datadog, you can create <a href="https://docs.datadoghq.com/dashboards/">custom dashboards</a> to monitor Kubernetes metrics, such as the <a href="https://www.datadoghq.com/blog/eks-cluster-metrics/#metrics-to-alert-on-desired-vs-current-pods">counts</a> of available and desired pods, as well as <a href="https://www.datadoghq.com/blog/vsphere-metrics/">vSphere metrics</a>. For example, you can create a dashboard (as shown below) that graphs the number of vSphere VMs by regional data center, then graph the number of available Kubernetes nodes by region. If there are more VMs than Kubernetes nodes, you can investigate whether some <a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet/">kubelets</a> running on your vSphere VMs have crashed—or failed to deploy due to a misconfiguration—causing the API server to register fewer nodes than expected.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-eks-anywhere/eks-anywhere-dashboard.png?auto=format&amp;fit=max&amp;w=847" alt="A dashboard that includes vSphere and Kubernetes metrics together, plus a host map and container map."/></picture></figure></div><h2 id="eks-is-anywhereand-so-is-datadog"><a href="#eks-is-anywhereand-so-is-datadog">EKS is anywhere—and so is Datadog</a></h2><p>Datadog is well suited for monitoring EKS Anywhere as well as your cloud-based EKS deployments, giving you full visibility into your containerized workloads no matter where they run. You can quickly install Datadog in your EKS Anywhere and EKS clusters using our <a href="https://docs.datadoghq.com/agent/kubernetes/?tab=helm">Helm chart</a>.</p><p>Datadog integrates with <a href="https://docs.datadoghq.com/integrations/vsphere/">vSphere</a>—and other infrastructure technologies you might be deploying on Kubernetes, such as <a href="https://www.datadoghq.com/blog/monitor-cilium-with-datadog/">Cilium</a> and <a href="https://www.datadoghq.com/blog/monitor-coredns-with-datadog/">CoreDNS</a>—so you can visualize every layer of your EKS Anywhere environment. And with other features like <a href="https://docs.datadoghq.com/network_monitoring/devices/">Network Device Monitoring</a>, you can get even deeper insight into the health of your <a href="https://www.datadoghq.com/solutions/on-premises-monitoring/">on-premise infrastructure</a>.</p><p>If you have not yet signed up for Datadog, you can started today with a <a href="#">free trial</a>.</p></div></div>]]></content:encoded>
      <author>Paul Gottschling</author>
      <pubDate>Wed, 08 Sep 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Sequoia India + Datadog for Startups</title>
      <link>https://www.datadoghq.com/partner/datadog-for-startups/sequoia-india/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/partner/datadog-for-startups/sequoia-india/combined-landing-page-hero_181211_FINAL.png&#34; width=&#34;100%&#34;/&gt;</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><h2>Datadog for Startup Program Benefits:</h2><p>As a member of the Datadog for Startup program you will have access to resources you need to be successful and grow your business</p><div><div><svg width="50" height="50" viewBox="0 0 48 48" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><title>Icon/integrate</title><desc>Created with Sketch.</desc><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><path d="M33.3764336 14.2661605 21.2643837 21.2584019 21.2569486 21.2455228 19.4912488 22.264793 17.4922774 21.1094097 21.1221873 19.0140032 21.124824 19.0296221 26.6576406 15.8355476 26.6555233 15.8230056 33.3636436 11.949338 43.816175 17.9844931V30.0534694L33.3636436 36.0886245 28.1064938 33.0528335V30.7433232 30.7415867L33.3642271 33.7788499 41.816175 28.8988056V19.1391569L33.3764336 14.2661605zM4.51225765 19.4212291 4.012825 19.1328897V7.06392308L14.4641061 1.02873174 24.9166375 7.06388681V13.2504779L22.9166375 14.3335088V8.21855069L14.4641689 3.33820576 6.012825 8.21851442V17.9781728L12.5845983 21.7722799 12.5827495 21.7739016 19.7084938 25.8902687V25.9015534v2.3094377L16.9881393 26.640294 16.9962357 26.6331902 4.51213887 19.4214347 4.51225765 19.4212291zM22.9166375 32.4715599V26.1445599L22.9123625 26.1431001V23.886465l2-1.0830309000000007L24.9166375 22.8011191V39.587225H24.9042875V40.970576L14.4517561 47.0044179 4.000475 40.9705397V28.9015731L9.17326192 25.9144982 11.1717196 27.0699802 6.000475 30.0561644v9.7596584L14.4518189 44.6950696 22.9042875 39.8157865V32.4673425L22.9166375 32.4715599z" fill="#000" fill-rule="nonzero"></path></g></svg><p><strong>Datadog Pro</strong></p></div><div><svg width="50" height="50" viewBox="0 0 48 48" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><title>Icon/key</title><desc>Created with Sketch.</desc><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><path d="M15.7347263 13.0251099C13.7379154 11.8716985 11.1839716 12.5559578 10.0312589 14.5523224 8.87840737 16.5499718 9.56257805 19.1039077 11.5595694 20.2574234 13.5572135 21.4102718 16.110921 20.7260758 17.2633764 18.7291129 18.4162248 16.7314689 17.7320288 14.1777613 15.7347263 13.0251099zm-5.1751764 8.964353C7.60597842 20.283401 6.59423706 16.5066789 8.29913662 13.5524462 10.0043071 10.5992886 13.7816144 9.58726259 16.7347459 11.2930705 19.6885586 12.9977277 20.7004746 16.7746241 18.9956119 19.728793 17.2909547 22.6826056 13.5140582 23.6945216 10.5595499 21.9894629zM44.216217 31.7156873 23.8062674 19.9322936 23.9872687 19.2019342C25.1183985 14.6377049 23.1069385 9.81500238 18.9721284 7.42814746 13.8805435 4.48841961 7.3680149 6.23336307 4.42827687 11.3249657 1.48854902 16.4165507 3.23349248 22.9290792 8.32520564 25.8688811 12.4600464 28.2569174 17.6416469 27.5878703 21.0289357 24.3257247L21.570876 23.8038063 26.9024703 26.8811874 23.9906418 31.9244743 27.8621331 34.1597464 30.7738978 29.1165699 38.1094653 33.3518861 35.1977006 38.3950625 39.0691919 40.6303347 44.216217 31.7156873zM46.9483007 30.9836303 39.8012081 43.3623948 32.4656405 39.1270786 35.3774052 34.0839022 31.5059139 31.8486301 28.5941492 36.8918065 21.2585817 32.6564904 24.1702826 27.6134244 21.8538083 26.276362C17.8334397 29.7076438 12.0131247 30.3083932 7.32506961 27.6008533 1.27689203 24.1088177-.795787141 16.3731044 2.69624078 10.3249402 6.18827639 4.27676262 13.9239897 2.20408345 19.9720817 5.69606965 24.6601455 8.40229505 27.0499914 13.7437791 26.0890009 18.9408107L46.9483007 30.9836303z" fill="#000" fill-rule="nonzero"></path></g></svg><p><strong>access to datadog technical training</strong></p></div><div><svg width="50" height="50" viewBox="0 0 48 48" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><title>Icon/colab</title><desc>Created with Sketch.</desc><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><path d="M11.3783784 39.0540541H25.7027027v2H9.37837838V25.8648649H11.3783784V39.0540541zM18.8918919 11.5405405V9.54054054H38.6216216V16.7837838h-2V11.5405405H18.8918919zm-4.972973000000001-1C13.9189189 8.58531178 12.3336071 7 10.3783784 7 8.42314961 7 6.83783784 8.58531178 6.83783784 10.5405405 6.83783784 12.4957693 8.42314961 14.0810811 10.3783784 14.0810811 12.3336071 14.0810811 13.9189189 12.4957693 13.9189189 10.5405405zm2 0C15.9189189 13.6003388 13.4381766 16.0810811 10.3783784 16.0810811 7.31858012 16.0810811 4.83783784 13.6003388 4.83783784 10.5405405 4.83783784 7.48074228 7.31858012 5 10.3783784 5 13.4381766 5 15.9189189 7.48074228 15.9189189 10.5405405zM4 25.8648649H2C2 21.237445 5.75095849 17.4864865 10.3783784 17.4864865 15.0057983 17.4864865 18.7567568 21.237445 18.7567568 25.8648649h-2C16.7567568 22.3420145 13.9012288 19.4864865 10.3783784 19.4864865 6.85552799 19.4864865 4 22.3420145 4 25.8648649zm37.1621622.0C41.1621622 23.9096361 39.5768504 22.3243243 37.6216216 22.3243243 35.6663929 22.3243243 34.0810811 23.9096361 34.0810811 25.8648649 34.0810811 27.8200936 35.6663929 29.4054054 37.6216216 29.4054054 39.5768504 29.4054054 41.1621622 27.8200936 41.1621622 25.8648649zm2 0C43.1621622 28.9246631 40.6814199 31.4054054 37.6216216 31.4054054 34.5618234 31.4054054 32.0810811 28.9246631 32.0810811 25.8648649 32.0810811 22.8050666 34.5618234 20.3243243 37.6216216 20.3243243 40.6814199 20.3243243 43.1621622 22.8050666 43.1621622 25.8648649zM31.2432432 41.1891892h-2C29.2432432 36.5617693 32.9942017 32.8108108 37.6216216 32.8108108S46 36.5617693 46 41.1891892H44C44 37.6663388 41.144472 34.8108108 37.6216216 34.8108108 34.0987712 34.8108108 31.2432432 37.6663388 31.2432432 41.1891892z" fill="#000" fill-rule="nonzero"></path></g></svg><p><strong>dedicated program manager</strong></p></div><div><svg width="50" height="50" viewBox="0 0 48 48" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><title>Icon/event/check</title><desc>Created with Sketch.</desc><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><path d="M36.4 9.33333333H44V44.2666667H4V9.33333333h7.6V4h2V9.33333333H34.4V4h2V9.33333333zM6 21.4666667v20.8H42v-20.8H6zm0-2H42V11.3333333H6V19.4666667zM30.8300666 25.7811666 32.2442801 27.1953801 22.0473067 37.3923536 16.9587999 32.3038468 18.3730134 30.8896332 22.0473067 34.5639264 30.8300666 25.7811666z" fill="#000" fill-rule="nonzero"></path></g></svg><p><strong>quarterly progress check-ins</strong></p></div><div><svg width="50" height="50" viewBox="0 0 48 48" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><title>Icon/support</title><desc>Created with Sketch.</desc><g stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"><path d="M6.19788894 14.876511C4.76216286 17.6706601 4 20.7790413 4 23.99988 4 27.2866897 4.79268396 30.3881526 6.1972927 33.1235932L10.7097236 30.5182636C9.72258133 28.5101242 9.2 26.2927551 9.2 23.99988 9.2 21.706251 9.72293589 19.4879006 10.7106407 17.4820259L6.19788894 14.876511zm1.00173545-1.7310488L11.7128105 15.7512279C14.249478 11.9761989 18.3941718 9.54279952 23 9.23338857V4.02462245C16.5154703 4.34603028 10.6720887 7.77868236 7.19962439 13.1454622zM41.8024959 33.1236097C43.2383858 30.332001 44 27.2235986 44 23.99988 44 20.7132576 43.2072186 17.6117481 41.8024344 14.8761858L37.290143 17.4814348C38.2772667 19.4873865 38.8 21.7067334 38.8 23.99988 38.8 26.2929067 38.2773496 28.5104174 37.2902422 30.5183824L41.8024959 33.1236097zM40.8005199 34.8545197 36.289149 32.2498021C33.7545705 36.0245369 29.6083506 38.4572478 25 38.7664164V43.975153C31.4863252 43.6538524 37.3296327 40.2214274 40.8005199 34.8545197zM7.1988399 34.8547507C10.5922072 40.0964341 16.371858 43.6489833 23 43.9753185V38.7664165C18.3914737 38.4572375 14.2451252 36.0243737 11.7107606 32.2497157L7.1988399 34.8547507zM40.8008376 13.1450569C37.4074698 7.90365056 31.6280476 4.35081163 25 4.02444432V9.23334693C29.6079147 9.54252262 33.7529898 11.9751374 36.2884191 15.7503794L40.8008376 13.1450569zM24 1.99988C36.1506736 1.99988 46 11.849984 46 23.99988 46 27.9187854 44.9747618 31.6880529 43.0552754 35.0004857 39.1506909 41.7525127 31.9455025 45.99988 24 45.99988 11.8496983 45.99988 2 36.151348 2 23.99988 2 20.0842472 3.02584566 16.3151073 4.944868 12.9990264 8.85196063 6.24712628 16.0569437 1.99988 24 1.99988zM24 36.79988C28.6243973 36.79988 32.8162453 34.3291475 35.0876453 30.3990656 36.204178 28.4693686 36.8 26.279957 36.8 23.99988 36.8 21.7171707 36.2027856 19.5235016 35.084145 17.5960666 32.8102647 13.6679356 28.6216778 11.19988 24 11.19988 19.3800027 11.19988 15.1906326 13.6699291 12.9152892 17.5994429 11.7968774 19.5264823 11.2 21.7177776 11.2 23.99988 11.2 26.279957 11.795822 28.4693686 12.9125996 30.3994891 15.1837547 34.3291475 19.3756027 36.79988 24 36.79988z" fill="#000" fill-rule="nonzero"></path></g></svg><p><strong>dedicated success manager</strong></p></div></div></div></div>]]></content:encoded>
      <author>Datadog</author>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Monitor feature releases with Statsig&#39;s offering in the Datadog Marketplace</title>
      <link>https://www.datadoghq.com/blog/feature-monitoring-statsig-datadog-marketplace/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-hero.png&#34; width=&#34;100%&#34;/&gt;Statsig is a modern experimentation platform that provides crucial insight into how new features are received by your users, so you can make informed product decisions and deploy with confidence. Statsig automatically runs A/B tests on features as they&amp;rsquo;re rolled out, and measures their impact on key business metrics, such as user growth and engagement. This gives both your technical and business teams the context they need to decide whether to ship, abandon, or iterate on a feature—without any lengthy debates or guesswork.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><a href="https://www.statsig.com/">Statsig</a> is a modern experimentation platform that provides crucial insight into how new features are received by your users, so you can make informed product decisions and deploy with confidence. Statsig automatically runs A/B tests on features as they’re rolled out, and measures their impact on key business metrics, such as user growth and engagement. This gives both your technical and business teams the context they need to decide whether to ship, abandon, or iterate on a feature—without any lengthy debates or guesswork.</p><p>We’re excited to announce that Statsig is <a href="https://app.datadoghq.com/marketplace/app/statsig-statsig/overview">now available</a> in the Datadog Marketplace. Once you’re up and running, you can enable <a href="https://app.datadoghq.com/account/settings#integrations/statsig">the Statsig integration</a>, which allows you to monitor events related to your feature experiments alongside your application’s telemetry data in Datadog. This helps you ensure that the progress you make on business objectives does not come at the expense of reliability or performance.</p><h2 id="run-feature-experiments-to-drive-product-decisions"><a href="#run-feature-experiments-to-drive-product-decisions">Run feature experiments to drive product decisions</a></h2><p>Statsig ships with a number of <a href="https://docs.statsig.com/console/overview">out-of-the-box tools</a> for conducting experiments that can help you assess which features resonate with your end users. <a href="https://docs.statsig.com/console/featureGates/introduction">Feature Gates</a> (also known as feature flags) are a central pillar of the Statsig platform, as they allow you to control which of your users get access to new features as you roll them out. You can use Feature Gates to easily toggle a feature on or off for all of your users, or define <a href="https://docs.statsig.com/console/featureGates/rules">rules and conditions</a> to only show a feature to a certain subset of your users at a time. For example, you can target users who are part of your beta test cohort or who access your application from a particular country.</p><p>Statsig also automatically runs A/B tests for each Feature Gate you create—and shows you how your feature impacts your core business by ingesting, aggregating, and analyzing <a href="https://docs.statsig.com/guides/logging-events">events</a> that occur in your application (e.g., when a user adds an item to their cart or checks out). This requires no additional instrumentation on the user’s part. In the example below, you can see that adding relevance-based sorting to the product catalog yields largely positive effects, such as increased add-to-cart and checkout events and decreased p50 latency.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-metric-lifts.png?auto=format&amp;fit=max&amp;w=847" alt="statsig-metric-lifts.png"/></picture></figure></div><h2 id="monitor-configuration-change-events-alongside-application-telemetry-data"><a href="#monitor-configuration-change-events-alongside-application-telemetry-data">Monitor configuration change events alongside application telemetry data</a></h2><p>When it comes to making product decisions, understanding how new features impact your business is only one part of the equation. It’s equally important to know how they affect your systems, so you can catch and resolve any unexpected issues before you launch. Once enabled, the Statsig integration automatically sends configuration change events, such as when a Feature Gate is created or updated, to Datadog. You can visualize these events—and correlate them with telemetry data from across your stack— by adding the <a href="https://docs.datadoghq.com/events/">event stream</a> widget to any dashboard and filtering it by <code>sources:statsig</code>. This way, if your system begins to behave anomalously or shows signs of overloading, you can immediately identify the exact configuration change that caused the issue.</p><p>In the screenshot below, you can see that our release of the <code>instant_search</code> feature corresponded with a significant spike in CPU utilization. Because we’re able to quickly detect issues like this, we can roll back the change and make adjustments before a wider set of users is affected.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/feature-monitoring-statsig-datadog-marketplace/statsig-in-datadog.png?auto=format&amp;fit=max&amp;w=847" alt="statsig-in-datadog.png"/></picture></figure></div><h2 id="get-started-in-the-datadog-marketplace"><a href="#get-started-in-the-datadog-marketplace">Get started in the Datadog Marketplace</a></h2><p><a href="https://app.datadoghq.com/marketplace/app/statsig-statsig/overview">Statsig</a> is now available in the Datadog Marketplace. Not sure if Statsig is right for you? Take it for a test drive to experience the benefits of automated A/B testing and analytics. The dev tier is free for up to 5M events per month.</p><p>You can also enable the <a href="https://app.datadoghq.com/account/settings#integrations/statsig">Statsig integration</a> right away to monitor feature rollout events alongside your application’s telemetry data in Datadog. If you’re not yet a Datadog customer, you can learn more about the Datadog Marketplace in our <a href="https://www.datadoghq.com/blog/datadog-marketplace/">blog post</a>—and sign up for a 14-day <a href="#">free trial</a> of Datadog today.</p><p>The ability to promote branded monitoring tools in the Datadog Marketplace is one of the benefits of membership in the <a href="https://www.datadoghq.com/partner/">Datadog Partner Network</a>. If you’re interested in developing an integration or application for the Datadog Marketplace, contact us at <a href="mailto:marketplace@datadog.com">marketplace@datadog.com</a>.</p></div></div>]]></content:encoded>
      <author>Kai Xin Tai</author>
      <pubDate>Tue, 31 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Deploy ASP.NET Core applications to Azure App Service</title>
      <link>https://www.datadoghq.com/blog/deploy-dotnet-core-azure-app-service/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-azure-app-service-hero.png&#34; width=&#34;100%&#34;/&gt;The ASP.NET Core framework provides cross-platform support for web development, giving you greater control over how you build and deploy your .NET applications. With the ability to run .NET applications on more platforms, you need to ensure that you have visibility into application performance, regardless of where your applications are hosted.In previous posts, we looked at instrumenting and monitoring a .NET application deployed via Docker and AWS Fargate. In this post, we&amp;rsquo;ll show how Datadog can help you get visibility into a .</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>The <a href="https://dotnet.microsoft.com/learn/aspnet/what-is-aspnet-core">ASP.NET Core framework</a> provides cross-platform support for web development, giving you greater control over how you build and deploy your .NET applications. With the ability to run .NET applications on more platforms, you need to ensure that you have visibility into application performance, regardless of where your applications are hosted.</p><p>In previous posts, we looked at instrumenting and monitoring a .NET application deployed via <a href="https://www.datadoghq.com/blog/asp-dotnet-core-monitoring/">Docker</a> and <a href="https://www.datadoghq.com/blog/deploy-dotnet-core-aws-fargate/">AWS Fargate</a>. In this post, we’ll show how Datadog can help you get visibility into a .NET Core application on <a href="https://azure.microsoft.com/en-us/services/app-service/">Azure App Service (AAS)</a>, a cloud-based platform-as-a-service (PaaS) for deploying web and mobile applications and other resources.</p><p>We’ll walk through:</p><ul><li><a href="#create-a-sample-net-core-application">creating</a> a sample .NET Core application</li><li><a href="#deploy-a-net-core-application-on-azure-app-service">deploying</a> the application to Azure App Services</li><li><a href="#enable-datadogs-azure-integration">enabling</a> Datadog’s Azure integration and AAS extension</li><li><a href="#monitor-net-core-applications-with-datadog">monitoring</a> application performance with Datadog APM</li></ul><p>Datadog’s <a href="https://docs.datadoghq.com/integrations/azure/?tab=azurecliv20">Azure integration</a> enables you to capture metrics and logs from all of your resources on Azure, giving you visibility into the performance of your workloads and their underlying infrastructure. Datadog’s <a href="https://docs.datadoghq.com/serverless/azure_app_services/#overview">extension for Azure App Service</a> provides out-of-the-box instrumentation for .NET applications on AAS as well as support for custom instrumentation, <a href="https://docs.datadoghq.com/tracing/#connect-logs-and-distributed-traces">trace ID injection</a>, and application runtime metrics. This enables you to track requests as they move across service and process boundaries, correlate that data with code-level performance, and quickly identify any bottlenecks.</p><h2 id="create-a-sample-net-core-application"><a href="#create-a-sample-net-core-application">Create a sample .NET Core application</a></h2><p>To get started, make sure that you have at least <a href="https://dotnet.microsoft.com/download/dotnet/5.0">version 5 of the .NET Core SDK</a> installed, which includes the <a href="https://docs.microsoft.com/en-us/dotnet/core/tools/">.NET CLI</a>. The CLI lets you generate the sample ASP.NET Core application we’ll use throughout this guide. You will also need the <a href="https://docs.microsoft.com/en-us/cli/azure/install-azure-cli">Azure CLI</a> in order to publish the application to Azure App Service.</p><p>Create a new web application project with all of the files needed to run a sample application via the following .NET CLI commands:</p><div><pre><code data-lang="text"> 
dotnet new sln -n DatadogAasExample
dotnet new webapp -o DatadogAasExample -n DatadogAasExample
dotnet sln add DatadogAasExample</code></pre></div><p>These commands create a new solution file (i.e.,<strong>DatadogAasExample.sln</strong>) and add a new Razor Pages web application project and associated <strong>DatadogAasExample</strong> directory to the file. You can build and run the project locally by running the following command:</p><div><pre><code data-lang="text"> 
dotnet run --project ./DatadogAasExample -- --URLS http://localhost:8000</code></pre></div><p>You can then view your application by navigating to <code>http://localhost:8080/</code>.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/dotnet-core-app.png?auto=format&amp;fit=max&amp;w=847" alt="A sample .NET Core application"/></picture></figure></div><p>Next, we’ll show you how to set up Azure App Service to publish your application. Once you’ve done this, you can deploy your application directly to AAS, which will automatically create the runtime environment necessary to run it.</p><h2 id="deploy-a-net-core-application-on-azure-app-service"><a href="#deploy-a-net-core-application-on-azure-app-service">Deploy a .NET Core application on Azure App Service</a></h2><p>Publishing applications on AAS requires an App Service, which includes a resource group and host plan. The <a href="https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/overview#terminology">resource group</a> is a collection of all of your application resources, such as databases or APIs. The <a href="https://docs.microsoft.com/en-us/azure/app-service/overview-hosting-plans">Azure App Service host plan</a> defines the makeup of your application’s compute resources, such as the number of virtual machine instances that should be created along with their operating system, region, and size.</p><p>You can create a new resource group and host plan and publish your application via the Azure CLI. First, <a href="https://docs.microsoft.com/en-us/cli/azure/authenticate-azure-cli?view=azure-cli-latest">log into your Azure account</a>, then run the following CLI command in the <strong>DatadogAasExample</strong> project folder to create a new App Service, prepare the application, and publish it to AAS:</p><div><pre><code data-lang="text"> 
az webapp up --sku F1 -n Datadog-MySampleApp --os-type windows -g Datadog-MySampleApp-RG -p Datadog-MySampleApp-AAS</code></pre></div><p>You can append <code>--dryrun</code> to the command to view more information about what the command will do before it runs, but we’ll look at each parameter in more detail below.</p><ul><li><code>--sku F1</code>: sets the free tier as the <a href="https://azure.microsoft.com/en-us/pricing/details/app-service/windows/">pricing tier</a> for your host plan</li><li><code>-n Datadog-MySampleApp</code>: sets the name of the app</li><li><code>--os-type windows</code>: sets Windows as the operating system for the App Service, which is the required OS for installing extensions</li><li><code>-g Datadog-MySampleApp-RG</code>: creates and names the new resource group</li><li><code>-p Datadog-MySampleApp-AAS</code>: creates and names the new App Service host plan</li></ul><p>To learn more about the CLI’s commands and optional parameters, check out <a href="https://docs.microsoft.com/en-us/cli/azure/webapp?view=azure-cli-latest#az_webapp_up-optional-parameters">Azure’s documentation</a>.</p><p>When you run the command, Azure App Service automatically detects that you are deploying a .NET Core application and hosts it on a free-tier shared VM instance with the appropriate OS and runtime. The CLI will provide more details about your deployed application in logs similar to the following output:</p><div><pre><code data-lang="text"> 
The webapp &#39;Datadog-MySampleApp&#39; doesn&#39;t exist
Creating Resource group &#39;Datadog-MySampleApp-RG&#39; ...
Resource group creation complete
Creating AppServicePlan &#39;Datadog-MySampleApp-AAS&#39; ...
Creating webapp &#39;Datadog-MySampleApp&#39; ...
Configuring default logging for the app, if not already enabled
Creating zip with contents of dir /app/DatadogAasExample ...
Getting scm site credentials for zip deployment
Starting zip deployment. This operation can take a while to complete ...
Deployment endpoint responded with status code 202
You can launch the app at http://datadog-mysampleapp.azurewebsites.net
{
  &#34;URL&#34;: &#34;http://datadog-mysampleapp.azurewebsites.net&#34;,
  &#34;appserviceplan&#34;: &#34;Datadog-MySampleApp-AAS&#34;,
  &#34;location&#34;: &#34;centralus&#34;,
  &#34;name&#34;: &#34;Datadog-MySampleApp&#34;,
  &#34;os&#34;: &#34;Windows&#34;,
  &#34;resourcegroup&#34;: &#34;Datadog-MySampleApp-RG&#34;,
  &#34;runtime_version&#34;: &#34;dotnet|5.0&#34;,
  &#34;runtime_version_detected&#34;: &#34;5.0&#34;,
  &#34;sku&#34;: &#34;FREE&#34;,
  &#34;src_path&#34;: &#34;//app//DatadogAasExample&#34;
}</code></pre></div><p>To view your application on AAS, navigate to the URL in the log output (i.e., <code>http://datadog-mysampleapp.azurewebsites.net</code>).</p><p>Next, we’ll look at how you can get visibility into your Azure environment and .NET application with Datadog’s Azure integration and extension for Azure App Service.</p><h2 id="enable-datadogs-azure-integration"><a href="#enable-datadogs-azure-integration">Enable Datadog’s Azure integration</a></h2><p>Datadog’s Azure integration collects metrics and logs from your Azure services, including Azure App Service, and is required for the extension. You can <a href="https://docs.datadoghq.com/integrations/azure/?tab=azurecliv20#installation">enable the integration</a> via the <a href="https://azure.microsoft.com/en-us/features/azure-portal">Azure portal</a> or CLI, but we’ll use the CLI in this guide.</p><p>The Azure integration requires creating an <a href="https://docs.microsoft.com/en-us/azure/active-directory/develop/app-objects-and-service-principals#application-registration">app registration</a>, which uses a <a href="https://docs.microsoft.com/en-us/azure/active-directory/develop/app-objects-and-service-principals#service-principal-object">service principal</a> to generate a set of credentials that grant Datadog monitoring access to your application’s <a href="https://docs.microsoft.com/en-us/learn/modules/create-an-azure-account/4-multiple-subscriptions">subscription</a>.</p><p>To create a new service principal, run the following command and replace <code>{subscription_id}</code> with your application’s subscription ID, which you can find via the <code>az account show</code> CLI command:</p><div><pre><code data-lang="text">az ad sp create-for-rbac --role &#34;Monitoring Reader&#34; --scopes /subscriptions/{subscription_id} --name datadog-monitor-sp</code></pre></div><p>The service principal is configured with the <a href="https://docs.microsoft.com/en-us/azure/azure-monitor/roles-permissions-security#monitoring-reader">“Monitoring Reader” role</a> and scoped to your application’s subscription. Once the CLI creates the new service principal, it will display credentials similar to the following output:</p><div><pre><code data-lang="json"> 
<span>{</span>
  <span>&#34;appId&#34;</span><span>:</span> <span>&#34;12c406f7-e9aa-4b43-1234-df0aafd7cf9c&#34;</span><span>,</span>
  <span>&#34;displayName&#34;</span><span>:</span> <span>&#34;datadog-monitor-sp&#34;</span><span>,</span>
  <span>&#34;name&#34;</span><span>:</span> <span>&#34;f12345a1-7e8d-4dcc-8e3e-8f1e12e3db45&#34;</span><span>,</span>
  <span>&#34;password&#34;</span><span>:</span> <span>&#34;XYabcdEFGd3JId.FDSg1234.GRP&#34;</span><span>,</span>
  <span>&#34;tenant&#34;</span><span>:</span> <span>&#34;e12ef3b4-5e67-8b90-b1a0-1234abcd9c787&#34;</span>
<span>}</span></code></pre></div><p>Enter the <code>appId</code>, <code>tenant</code>, and <code>password</code> values into the <strong>Client ID</strong>, <strong>Tenant ID</strong>, and <strong>Client Secret</strong> fields respectively in your account’s <a href="https://app.datadoghq.com/account/settings?#integrations/azure">Azure Integration tile</a> to grant Datadog access to Azure.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-integration.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog&#39;s Azure integration tile"/></picture></figure></div><p>Datadog will start collecting <a href="https://docs.microsoft.com/en-us/azure/azure-monitor/essentials/metrics-supported">standard metrics</a> from Azure Monitor and generate <a href="https://www.datadoghq.com/blog/datadog-generated-metrics-azure/">additional metrics and tags</a> from all of your Azure services, such as service-tier tags (e.g., <code>basic</code>, <code>standard</code>, <code>premium</code>) and metrics that track the number of hosts on your Azure App Service host plan.</p><p>The Azure integration also enables you to install the extension for Azure App Service, which we’ll look at next.</p><h2 id="install-the-datadog-extension-for-azure-app-service"><a href="#install-the-datadog-extension-for-azure-app-service">Install the Datadog extension for Azure App Service</a></h2><p>Azure App Service allows you to add third-party services to your application’s environment via extensions, so you can leverage features such as automatic instrumentation and trace collection for monitoring application performance. The Datadog extension for Azure App Service supports several .NET runtimes running on Windows instances, including the .NET Core framework. Note that AAS does not currently support extensions for Linux-based applications.</p><h3 id="configure-your-application-to-use-datadogs-extension"><a href="#configure-your-application-to-use-datadogs-extension">Configure your application to use Datadog’s extension</a></h3><p>Before installing the extension, you will need to configure your application with the following environment variables:</p><ul><li><code>DD_API_KEY</code>: uses your Datadog account’s <a href="https://app.datadoghq.com/account/settings?#api">API key</a></li><li><code>DD_ENV</code>, <code>DD_SERVICE</code>, <code>DD_VERSION</code>: sets the <code>env</code>, <code>version</code>, and <code>service</code> tags on traces for <a href="https://docs.datadoghq.com/getting_started/tagging/unified_service_tagging/">unified service tagging</a></li><li><code>DD_TRACE_ROUTE_TEMPLATE_RESOURCE_NAME_ENABLED</code>: enables improved <a href="https://docs.datadoghq.com/tracing/setup_overview/setup/dotnet-core/?tab=windows#experimental-features">resource names</a> for ASP.NET Core endpoints</li></ul><p>You can add these environment variables to your application <a href="https://docs.datadoghq.com/serverless/azure_app_services/#installation">via the Azure portal</a> or by running the following Azure CLI command:</p><div><pre><code data-lang="text">az webapp config appsettings set -g Datadog-MySampleApp-RG -n Datadog-MySampleApp --settings DD_API_KEY={your_API_key} DD_ENV=aas_test DD_SERVICE=MySampleApp DD_VERSION=1.0.0 DD_SITE=datadoghq.com DD_TRACE_ROUTE_TEMPLATE_RESOURCE_NAMES_ENABLED=true</code></pre></div><p>Check out <a href="https://docs.datadoghq.com/tracing/setup_overview/setup/dotnet-framework/?tab=environmentvariables#additional-optional-configuration">our documentation</a> to learn more about the available options for customizing the extension’s tracing configuration.</p><p>Now that your application is configured with the appropriate Datadog environment variables, you can install the extension via deployment scripts or one of Azure’s UI interfaces.</p><h3 id="install-the-extension-via-a-powershell-script"><a href="#install-the-extension-via-a-powershell-script">Install the extension via a Powershell script</a></h3><p>Datadog provides <a href="https://github.com/DataDog/datadog-aas-extension/tree/master/management-scripts/extension">Powershell scripts</a> that enable you to easily install and keep extensions up to date from the command line. This streamlines the setup process and makes it easier to manage installed extensions for each of your Azure App Services and resource groups.</p><p>To install the extension via Powershell, download the <a href="https://github.com/DataDog/datadog-aas-extension/blob/master/management-scripts/extension/install-latest-extension.ps1"><code>install-latest-extension.ps1</code> script</a> to the <strong>DatadogAasExample</strong> project folder and execute it with the following command:</p><div><p>.\install-latest-extension.ps1</p><div><pre><code data-lang="powershell"> 
<span>.\</span><span>install-latest</span><span>-extension</span><span>.</span><span>ps1</span> <span>-Username</span> <span>$username</span> <span>-Password</span> <span>$password</span> <span>-SubscriptionId</span> <span>$subscriptionId</span> <span>-ResourceGroup</span> <span>$resourceGroupName</span> <span>-SiteName</span> <span>$webAppName</span> <span>-DDApiKey</span> <span>$ddApiKey</span> <span>-DDSite</span> <span>$ddSite</span> <span>-DDEnv</span> <span>$ddEnv</span> <span>-DDService</span> <span>$ddService</span> <span>-DDVersion</span> <span>$ddVersion</span></code></pre></div></div><p>The script uses your <a href="https://docs.microsoft.com/en-us/azure/app-service/deploy-configure-credentials?tabs=portal#userscope">user-scope credentials</a> and configuration data for your application to install and configure Datadog’s out-of-the-box instrumentation for each of your App Service applications, so you can <a href="#monitor-net-core-applications-with-datadog">view traces in Datadog APM</a>.</p><p>Datadog’s <a href="https://github.com/DataDog/datadog-aas-extension/blob/master/management-scripts/extension/update-all-site-extensions.ps1"><code>update-all-site-extensions.ps1</code> script</a> can be used to update all existing extensions in a resource group to the latest available version. You can run the following command to execute it:</p><div><p>.\update-all-site-extensions.ps1</p><div><pre><code data-lang="powershell"> 
<span>.\</span><span>update-all</span><span>-site-extensions</span><span>.</span><span>ps1</span> <span>-SubscriptionId</span> <span>$subscriptionId</span> <span>-ResourceGroup</span> <span>$resourceGroupName</span> <span>-Username</span> <span>$username</span> <span>-Password</span> <span>$password</span></code></pre></div></div><p>You can also install the extension through one of Azure’s UI interfaces, which provide more visibility into your application’s configuration settings and performance.</p><h3 id="install-the-extension-via-the-azure-portal"><a href="#install-the-extension-via-the-azure-portal">Install the extension via the Azure portal</a></h3><p>The Azure portal allows you to view and manage all of your applications, extensions, and application resources in one place. To get started, run the following command to fully stop your application, which is required before installing any new extensions for Azure App Service via the UI:</p><div><pre><code data-lang="text"> 
az webapp stop -n Datadog-MySampleApp -g Datadog-MySampleApp-RG </code></pre></div><p>Next, log into the <a href="https://portal.azure.com/">portal</a> and navigate to the “Azure App Services” blade to find and select your application. Click “Extension” under “Development Tools” and click “Add” to see a list of available extensions. Select the <strong>.NET Datadog APM</strong> extension to add it to your application.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-extension.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog&#39;s .NET extension for Azure App Service"/></picture></figure></div><p>You can restart your application with the following command to complete the installation process:</p><div><pre><code data-lang="text"> 
az webapp start -n Datadog-MySampleApp -g Datadog-MySampleApp-RG</code></pre></div><p>You can also view and install extensions via <a href="https://docs.microsoft.com/en-us/azure/app-service/resources-kudu">Kudu</a>, a source code management (SCM) tool for Azure App Service. Every application on AAS includes a <a href="https://github.com/projectkudu/kudu/wiki/Accessing-the-kudu-service">Kudu SCM portal</a>, which provides useful information about your application (e.g., environment variables, application settings, server configurations). You can add the Datadog extension by searching for it in the “Gallery” tab on the “Site extensions” page.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-kudu.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog&#39;s .NET extension on Kudu"/></picture></figure></div><p>Once the extension is installed for your application, Datadog will automatically collect application traces and forward them to Datadog, where you can explore them alongside other performance data.</p><h2 id="monitor-net-core-applications-with-datadog"><a href="#monitor-net-core-applications-with-datadog">Monitor .NET Core applications with Datadog</a></h2><p>Datadog’s Azure integration provides a built-in dashboard for Azure App Service, where you can get a high-level overview of all of your applications and service plans.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dashboard.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog&#39;s Azure App Service dashboard"/></picture></figure></div><p>You can also collect additional data from your application, such as <a href="https://www.datadoghq.com/blog/monitoring-azure-platform-logs/#collect-and-analyze-azure-platform-logs-with-datadog">Azure Platform logs</a>, and <a href="https://docs.datadoghq.com/tracing/connect_logs_and_traces/dotnet/?tab=serilog">connect trace IDs to logs</a>, so you can easily correlate traces with log data. This enables you to view application traces and associated logs in Datadog APM and drill down to specific traces to determine if your application is handling requests as expected.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-azure-app-service/azure-app-service-dotnet-trace.png?auto=format&amp;fit=max&amp;w=847" alt=".NET Core trace for Azure App Service application"/></picture></figure></div><p>Your trace and log data provide you with more context for troubleshooting a performance issue with your application and pinpointing its root cause, be it an application bug or a problem with an application resource, such as an overloaded server or a slow database query.</p><p>Datadog’s extension also includes support for <a href="https://docs.datadoghq.com/serverless/azure_app_services/#custom-metrics-with-dogstatsd">DogStatsD</a>, so you can collect custom metrics that help you measure key performance indicators specific to your application. This data can include anything critical to your business, from the number of completed transactions to the performance of a custom application service.</p><h2 id="net--azure-app-services"><a href="#net--azure-app-services">.NET + Azure App Services</a></h2><p>In this post, we looked at how you can deploy an ASP.NET Core application on Azure App Service and monitor its performance with Datadog’s Azure integration and extension. Check out our documentation to learn more about <a href="https://docs.datadoghq.com/tracing/setup_overview/setup/dotnet-core/?tab=windows">tracing your .NET Core applications</a> and getting full visibility into the state of your application and its resources. If you don’t already have a Datadog account, you can sign up for a <a href="#">14-day free trial</a>.</p></div></div>]]></content:encoded>
      <author>Andrew Lock</author>
      <pubDate>Fri, 27 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Monitor Conviva with Datadog</title>
      <link>https://www.datadoghq.com/blog/video-streaming-performance-monitoring-conviva/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva_hero.png&#34; width=&#34;100%&#34;/&gt;Conviva is a platform that helps businesses gain real-time insight into the overall performance and playback quality of their streaming video content. With video streaming workflows, slow start-up times and playback errors can hinder user experience and ultimately drive customers away. With Conviva, you can view key Quality of Experience (QoE) metrics, including video playback failures, rebuffering ratios, and other business-critical data to help monitor and enhance your viewer experience.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><a href="https://www.conviva.com/streaming-insights-platform/">Conviva</a> is a platform that helps businesses gain real-time insight into the overall performance and playback quality of their streaming video content. With video streaming workflows, slow start-up times and playback errors can hinder user experience and ultimately drive customers away. With Conviva, you can view key Quality of Experience (QoE) metrics, including video playback failures, rebuffering ratios, and other business-critical data to help monitor and enhance your viewer experience.</p><p>Now, with Datadog’s <a href="https://docs.datadoghq.com/integrations/conviva/">Conviva integration</a> you can monitor end viewer experience alongside the rest of your infrastructure telemetry, for an end-to-end view of your video supply chain. Once you enable the integration, key Conviva metrics will populate an out-of-the-box <a href="%E2%80%8B%E2%80%8Bhttps://app.datadoghq.com/dash/integration/30515/conviva-dashboard">dashboard</a>, providing a centralized view of your customers&#39; experience on your streaming service so you can quickly identify issues that need troubleshooting.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-ottb-dashboard.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog&#39;s Conviva integration comes with an out-of-the-box dashboard for visualizing key metrics."/></picture></figure></div><p>Datadog automatically pulls in any <strong>filters</strong> and <strong>dimensions</strong> you have created in your Conviva account as tags. In Datadog, you can then define <strong>MetricLenses</strong> using specific combinations of filters and dimensions, which let you scope the dashboard to specific views of your data. For example, you can create a MetricLens that allows you to view metrics from your content delivery networks serving traffic to the state of New York by setting the filter to “New York” and the dimension to “CDNs”.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/metriclens-screenshot.png?auto=format&amp;fit=max&amp;w=847" alt="metriclens-screenshot.png"/></picture><figcaption>A new-york-traffic-by-cdn MetricLens lets you quickly view telemetry from the content delivery networks serving traffic to New York.</figcaption></figure></div><p>With MetricLenses, you can scope your monitoring and alerting to the exact video streams you need. In this post, we’ll look at how you can use Datadog to:</p><ul><li>correlate <a href="#">playback activity</a> with telemetry from across your stack</li><li>monitor <a href="#">video performance</a> to ensure good end-user experience</li></ul><h2 id="monitor-playback-activity-alongside-your-infrastructure"><a href="#monitor-playback-activity-alongside-your-infrastructure">Monitor playback activity alongside your infrastructure</a></h2><p>Not only is it important to know how many users are viewing the content delivered to them, you also have to ensure the health and performance of the underlying infrastructure hosting and delivering that content. Datadog collects key playback activity metrics such as <strong>concurrent plays</strong> and <strong>attempted plays</strong>. You can easily correlate these user traffic metrics with telemetry from the rest of your infrastructure. For example, if you notice a spike in playback activity in a specific region, you can check resource utilization across your hosts in that region to see if you need to scale up to meet demand. Or, if you notice a drop in playback activity, you may want to check whether your CDN, such as <a href="https://docs.datadoghq.com/integrations/akamai_datastream">Akamai</a>, is experiencing elevated error rates.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-concurrent-plays.png?auto=format&amp;fit=max&amp;w=847" alt="Viewing concurrent plays by CDN can you identify if a CDN is serving significantly more traffic."/></picture></figure></div><p>Comparing your Conviva playback with CDN metrics can also help you measure the number of unauthorized users on your platform. If Conviva shows a high number of plays while your CDN indicates normal activity, it could mean there’s been a security breach that allows unauthorized users to view your streams.</p><h2 id="monitor-quality-of-experience-and-performance-metrics"><a href="#monitor-quality-of-experience-and-performance-metrics">Monitor quality of experience and performance metrics</a></h2><p>Monitoring video start up times and rebuffering ratios is important for catching potential pain points in your customers&#39; experience. For example, if videos take too long to start or often stall during playback due to network performance issues, viewers are likely to get frustrated, leading to churn and lost revenue. With Datadog, you can surface the slowest video start up times (measured in seconds) by visualizing them as a top list to help you determine where to focus your troubleshooting.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/video-streaming-performance-monitoring-conviva/conviva-toplist.png?auto=format&amp;fit=max&amp;w=847" alt="Top lists of slowest video start up times can help you focus your troubleshooting."/></picture></figure></div><p>In addition to monitoring for slow start up times, checking if videos are failing to start or are stopping unexpectedly can prevent customer churn as well. While <a href="#monitor-playback-activity">attempted plays</a> tell you how often users tried to view content, it’s important to track what percentage of those attempted video plays resulted in start up and playback failures. The percentage of <strong>video start failures (VSFs)</strong> highlights the portion of attempted videoplays that were aborted before a video is able to start due to an error, pointing to a possible video encoding or packaging problem. Similarly, the percentage of <strong>video playback failures (VPFs)</strong> highlights the portion of videos that abort <em>during</em> playback, which could be due to a network issue you can explore with Datadog Network Performance Monitoring. Looking at the percentage of video start and playback failures allows you to gain insight into the overall performance of your streaming service. With Datadog, you can set monitors that alert on high VPF and VSF percentages, so you can quickly be notified of problems and begin troubleshooting.</p><h2 id="get-full-end-to-end-visibility-with-datadog"><a href="#get-full-end-to-end-visibility-with-datadog">Get full end-to-end visibility with Datadog</a></h2><p>In addition to Conviva’s video performance and QoE metrics, Datadog enables you to visualize and alert on telemetry from over
450 other services and technologies, including video packaging and storage services like <a href="https://docs.datadoghq.com/integrations/?q=elemental">Amazon Elemental</a> and <a href="https://docs.datadoghq.com/integrations/amazon_s3/">S3</a>, as well as content delivery networks like <a href="https://docs.datadoghq.com/integrations/cloudflare/#overview">CloudFlare</a> <a href="https://docs.datadoghq.com/integrations/akamai_datastream/">Akamai</a>, <a href="https://docs.datadoghq.com/integrations/amazon_cloudfront/?tab=standardlogs">Amazon Cloudfront</a> and more. This means you get unified end-to-end visibility into your entire video supply chain on a single, unified platform.</p><p>To learn more about how to monitor Conviva with Datadog, check out our <a href="https://docs.datadoghq.com/integrations/conviva/">documentation</a>. If you aren’t already using Datadog, get started today with a 14-day <a href="#">free trial</a>.</p></div></div>]]></content:encoded>
      <author>Jordan Obey</author>
      <pubDate>Wed, 25 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Datadog&#39;s Engineering Internship Program</title>
      <link>https://www.datadoghq.com/blog/pup-culture/datadog-engineering-internship-program-2021/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/internship-program-hero.png&#34; width=&#34;100%&#34;/&gt;Every autumn, we begin our search for aspiring software developers, product managers, and product designers who are interested in participating in our Engineering Internship Program. Those who join us are able to spend several months working on meaningful projects, forging professional relationships, and getting the full Datadog experience. The high-growth nature of our company, combined with the maturity and scale of our Engineering organization, enables our interns to have an enormous impact on our product while learning from best-in-class leaders whose work is at the forefront of innovation.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div id="blog-content" data-scroll-speed="2"><p>Every autumn, we begin our search for aspiring software developers, product managers, and product designers who are interested in participating in our <a href="https://www.datadoghq.com/early-careers">Engineering Internship Program</a>. Those who join us are able to spend several months working on meaningful projects, forging professional relationships, and getting the full Datadog experience. The high-growth nature of our company, combined with the maturity and scale of our Engineering organization, enables our interns to have an enormous impact on our product while learning from best-in-class leaders whose work is at the forefront of innovation. And after more than a year of fully remote operations, we’re excited to offer the option for our newest cohort of interns to join us at Datadog offices around the world.</p><p><iframe src="https://player.vimeo.com/video/589894585?badge=0&amp;amp;autopause=0&amp;amp;player_id=0&amp;amp;app_id=58479&amp;amp;h=6fd7864e8a" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe></p><p>Our primary goal for the internship program has always been to host a supportive learning environment in which interns can hone their skills. All interns participate in weekly one-on-one sessions with managers, mentors, and buddies, and they can also check in with their colleagues throughout the week to ask questions, receive guidance, or simply chat. David Sevilla, a former intern and current Software Engineer on the Website Reliability team, remembered, “There was a large learning curve, but my team was incredibly supportive. By the end of my internship, I participated in on-call rotations, and I learned how to keep cool under pressure, escalate incidents when necessary, and investigate root causes with confidence.”</p><div><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 1x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 1x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 1x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 1x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 1x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 1x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 1x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/david_sevilla.jpg?auto=format&amp;fit=max&amp;w=847" alt="David Sevilla, Software Engineer"/></picture></figure></div><div><blockquote>I participated in on-call rotations, and I learned how to keep cool under pressure, escalate incidents when necessary, and investigate root causes with confidence.<br/>—<b>David Sevilla</b>, Software Engineer</blockquote></div></div><p>Because we treat our interns like full-fledged employees, they are able to contribute to—and even drive the development of—features that are used by thousands of customers every day. Conor Branagan, a former intern and current Director of Engineering, noted, “You’re working on the software that customers are interacting with as part of the Datadog product. You’re also working at a scale that’s really unlike any other company out there. In many cases, because of the scale we’re at, we’ve had to roll out our own custom solutions, and interns get the opportunity to work on those solutions. Plus, as an intern, you get to learn alongside incredibly seasoned engineers.”</p><div><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 1x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 1x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 1x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 1x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 1x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 1x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 1x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/conor_branagan.jpg?auto=format&amp;fit=max&amp;w=847" alt="Conor Branagan, Director of Engineering"/></picture></figure></div><div><blockquote>In many cases, because of the scale we&#39;re at, we&#39;ve had to roll out our own custom solutions, and interns get the opportunity to work on those solutions.<br/>—<b>Conor Branagan</b>, Director of Engineering</blockquote></div></div><p>Yiren Wang, a former intern and current Software Engineer based in Paris, had the opportunity to maintain a legacy Elasticsearch database during her internship, and her experience typifies the type of high-impact work that Branagan describes. “I was able to drive the entire process—from ramping up to reviews—and I had a Senior Engineer looking at and advising on my work at every step of the way,” she recalled, adding, “[The database] has grown from the beginning of my internship from about 600 terabytes of data to about 1 petabyte of data.” She also credits Datadog’s culture of blamelessness as one of the key factors that supported her growth. “If I made any mistakes, it could cause a major outage. But I never once felt as if I was at fault or like I couldn’t try out a solution,” she said.</p><div><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 1x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 1x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 1x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 1x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 1x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 1x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 1x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/yiren_wang.jpg?auto=format&amp;fit=max&amp;w=847" alt="Yiren Wang, Software Engineer"/></picture></figure></div><div><blockquote>I was able to drive the entire process—from ramping up to reviews—and I had a Senior Engineer looking at and advising on my work at every step of the way.<br/>—<b>Yiren Wang</b>, Software Engineer</blockquote></div></div><p>Half the fun of an internship comes with meeting new people and building lasting relationships, and we’re happy that our return to the office will enable our interns to get to know one another better. All Datadog interns are invited to participate in intern-specific lunches, hangout sessions, outings, and fireside chats with leaders, as well as company-wide social events such as Unleash, our annual celebration hosted in New York City. These activities give interns the opportunity to explore, unwind, and catch up with people from different teams. “One of the most memorable events, for me, was when we got to hear from Oli, the CEO and Co-founder. We were able to hear his story and even ask some questions, and, overall, it was a really great experience to be able to interact with someone in senior leadership,” Victoria Kayola, a class of 2020 intern and current Software Engineer, noted.</p><div><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 1x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 1x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 1x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 1x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 1x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 1x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 1x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/pup-culture/datadog-engineering-internship-program-2021/victoria_kayola.jpg?auto=format&amp;fit=max&amp;w=847" alt="Victoria Kayola, Software Engineer"/></picture></figure></div><div><blockquote>One of the most memorable events, for me, was when we got to hear from Oli, the CEO and Co-founder. We were able to hear his story and even ask some questions.<br/>—<b>Victoria Kayola</b>, Software Engineer</blockquote></div></div><p>Whether we’re working in the office or from home, we want our interns to leave the program with valuable experiences that will help shape their careers. All interns are offered highly competitive salaries and benefits packages, and we provide them with the equipment and guidance they need to be successful. And we’re proud to say that many graduates from our internship program—including the former interns featured in this post—go on to receive full-time job offers from us. Some are even able to grow into leadership roles at Datadog; for instance, Branagan now manages five teams as a Director of Engineering.</p><p>Datadog has become the gold standard for monitoring and security. We’re proud of the success we have achieved, and we’re on the lookout for talented interns to join us in the next phase of our journey. If you would like to be a part of our Engineering Internship Program, please check out our open positions <a href="https://www.datadoghq.com/early-careers">here</a>.</p></div></div>]]></content:encoded>
      <author>Sara Verdi</author>
      <pubDate>Tue, 24 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Best practices for collecting and managing serverless logs with Datadog</title>
      <link>https://www.datadoghq.com/blog/manage-serverless-logs-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-logs_best-practices_210720_FINAL.png&#34; width=&#34;100%&#34;/&gt;Logs are an essential part of an effective monitoring strategy, as they provide granular information about activity that occurs anywhere in your system. In serverless environments, however, you have no access to the infrastructure that supports your applications, so you must rely entirely on logs from individual AWS services when troubleshooting performance issues. But serverless applications can generate a massive amount of logs, which introduces storage concerns and makes it difficult to see the forest through the trees.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Logs are an essential part of an effective monitoring strategy, as they provide granular information about activity that occurs anywhere in your system. In serverless environments, however, you have no access to the infrastructure that supports your applications, so you must rely entirely on logs from individual AWS services when troubleshooting performance issues. But serverless applications can generate a massive amount of logs, which introduces storage concerns and makes it difficult to see the forest through the trees.</p><p>In this guide, we’ll discuss some best practices for collecting and managing your logs that will help you maximize their value. More specifically, we’ll cover:</p><ul><li><a href="#standardize-the-format-of-your-logs-with-a-logging-library">standardizing the format of your logs</a></li><li><a href="#log-at-the-appropriate-level-for-your-environment">setting an appropriate log level</a></li><li><a href="#include-useful-information-in-your-logs">including useful context in your logs</a></li><li><a href="#centralize-your-aws-serverless-logs-with-datadog">centralizing your logs with Datadog</a></li><li><a href="#control-your-logging-costs">controlling your logging costs</a></li></ul><h2 id="understanding-the-types-of-logs-that-aws-serverless-technologies-generate"><a href="#understanding-the-types-of-logs-that-aws-serverless-technologies-generate">Understanding the types of logs that AWS serverless technologies generate</a></h2><p>Before we go any further, let’s first examine the types of logs that are emitted by some of the most popular AWS serverless technologies—and how they can help you investigate issues with your applications.</p><h3 id="aws-lambda-logs"><a href="#aws-lambda-logs">AWS Lambda logs</a></h3><p><a href="https://aws.amazon.com/lambda/">AWS Lambda</a> functions are the linchpins of serverless applications, as they are responsible for running pieces of code that implement business logic in response to triggers. Lambda generates three types of logs that provide insight into how it operates and processes events: function logs, extension logs, and platform logs.</p><p>Function logs and extension logs are both useful for debugging your code. <strong>Function logs</strong> include any log written by a function to <code>stdout</code> or <code>stderr</code>, such as print statements that verify whether your code produces the correct output. Similarly, <strong>extension logs</strong> are emitted by your <a href="https://aws.amazon.com/blogs/compute/using-aws-lambda-extensions-to-send-logs-to-custom-destinations/">Lambda extension’s</a> code, and they can help you identify extension-related issues, such as a failure to subscribe to log streams.</p><p>In contrast, <strong>platform logs</strong> are generated by the Lambda runtime and record invocation- and extension-related events. For example, a function produces a <code>START</code>, <code>END</code>, and <code>REPORT</code> platform log every time it is invoked. <code>REPORT</code> platform logs are the most useful of the three, as they contain invocation metrics that can alert you to issues like high latency and cold starts.</p><div><pre><code data-lang="json"> 
<span>{</span>
	<span>&#39;time&#39;:</span> <span>&#39;2021-08-22T10:52:07.294Z&#39;,</span> 
	<span>&#39;type&#39;:</span> <span>&#39;platform.report&#39;,</span> 
	<span>&#39;record&#39;:</span> <span>{</span> <span>&#39;requestId&#39;:</span> <span>&#39;79e64213-lp42-47ef-b130-6fd29f30148e&#39;,</span> 
		<span>&#39;metrics&#39;:</span> <span>{</span> <span>&#39;durationMs&#39;:</span> <span>4.01,</span> 
			<span>&#39;billedDurationMs&#39;:</span> <span>5,</span> 
			<span>&#39;memorySizeMB&#39;:</span> <span>512,</span> 
			<span>&#39;maxMemoryUsedMB&#39;:</span> <span>87,</span> 
			<span>&#39;initDurationMs&#39;:</span> <span>2.41</span>
		<span>}</span><span>,</span> 
	<span>}</span>
<span>}]</span></code></pre></div><p>By default, Lambda logs are sent asynchronously to Amazon’s built-in log management service, <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html">CloudWatch Logs</a>. Each time you create a new function, CloudWatch Logs generates a new log group (<code>/aws/lambda/your-function-name</code>) and log stream. If you create more instances of your function to support more concurrent executions, new log streams will be created under the same log group.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/lambda-log-groups.png?auto=format&amp;fit=max&amp;w=847" alt="See a list of your Lambda log groups in Amazon CloudWatch"/></picture></figure></div><h3 id="amazon-api-gateway-logs"><a href="#amazon-api-gateway-logs">Amazon API Gateway logs</a></h3><p><a href="https://aws.amazon.com/api-gateway/">Amazon API Gateway</a> allows developers to create APIs that act as the front door to backend services, such as Lambda functions, which are hosted across different machines. API Gateway emits two types of logs: execution logs and access logs. <strong>Execution logs</strong> document the steps API Gateway takes to process a request. In these logs, you can see details of requests to APIs along with the responses from <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-integration-settings-integration-response.html">integration backends</a> and <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-use-lambda-authorizer.html">Lambda authorizers</a>.</p><p>On the other hand, <strong>access logs</strong> help you identify who accessed your API (e.g., source IP, user) and how they accessed it (e.g., HTTP method, resource path). Unlike execution logs, which are managed by API Gateway, access logs are controlled by the developer. This means that you can flexibly customize the content of your access logs and choose which log group to send them to. We will elaborate on the fields we recommend adding to your access logs <a href="#include-useful-information-in-your-logs">later in this post</a>.</p><h3 id="amazon-dynamodb-logs"><a href="#amazon-dynamodb-logs">Amazon DynamoDB logs</a></h3><p><a href="https://aws.amazon.com/dynamodb/">Amazon DynamoDB</a> is a popular key-value and document database that provides low-latency data access at scale, which makes it well-suited for serverless applications. DynamoDB captures table modifications in a <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.html">stream</a>, which Lambda polls in order to trigger the appropriate function when a new record is added. DynamoDB integrates out-of-the-box with <a href="https://aws.amazon.com/cloudtrail/">AWS CloudTrail</a>, which captures API calls to and from DynamoDB and sends them as logs to an Amazon S3 bucket. You can either view these logs in the CloudTrail console or forward them to CloudWatch Logs.</p><p>By default, CloudTrail only logs <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/logging-using-cloudtrail.html#ddb-control-plane-events-in-cloudtrail">control plane events</a>, such as when a table is created or deleted. If you’d like to record <a href="https://docs.aws.amazon.com/awscloudtrail/latest/userguide/logging-data-events-with-cloudtrail.html">data plane events</a>, such as when an item is written or retrieved from a table, you will need to <a href="https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-create-a-trail-using-the-console-first-time.html">create a separate trail</a>. Each log entry contains details of the activity performed (e.g., event name, table name, key) along with the identity of the user that performed the action (e.g., account ID, ARN). And if a request fails, you can pinpoint whether it was because of an issue with the request itself (4xx error) or with AWS (5xx error).</p><h3 id="aws-step-functions-logs"><a href="#aws-step-functions-logs">AWS Step Functions logs</a></h3><p><a href="https://aws.amazon.com/step-functions/?step-functions.sort-by=item.additionalFields.postDateTime&amp;step-functions.sort-order=desc">AWS Step Functions</a> allows you to create more complex workflows (or state machines) that incorporate multiple functions and AWS services, which can be helpful when you begin adding functionality to your serverless applications. As a state machine executes, it transitions between different states, including <a href="https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-task-state.html">Task</a>, <a href="https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-choice-state.html">Choice</a>, <a href="https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-fail-state.html">Fail</a>, and <a href="https://docs.aws.amazon.com/step-functions/latest/dg/amazon-states-language-pass-state.html">Pass</a>. Step Functions logs record the full history of your state machine’s execution, so they are useful for troubleshooting any failures that crop up. For instance, these logs enable you to pinpoint exactly when (i.e., at which state) the failure occurred and whether it was caused by a Lambda function exception, state machine misconfiguration, or a different issue altogether.</p><h2 id="best-practices-for-aws-serverless-logging"><a href="#best-practices-for-aws-serverless-logging">Best practices for AWS serverless logging</a></h2><p>In this section, we’ll recommend a few best practices for collecting and managing logs to help you get deep visibility into your AWS serverless applications.</p><h3 id="standardize-the-format-of-your-logs-with-a-logging-library"><a href="#standardize-the-format-of-your-logs-with-a-logging-library">Standardize the format of your logs with a logging library</a></h3><p>As we discussed, serverless environments generate many types of logs, which presents several challenges when it comes to standardization. For instance, Lambda function logs that are generated by Python’s <code>print()</code> function are typically unstructured, so they are difficult to query in a systematic way. And while you can parse them with a tool like <a href="https://www.elastic.co/guide/en/logstash/current/plugins-filters-grok.html">grok</a>, it can be cumbersome to define custom regular expressions or filter patterns that apply to every type of log your application generates.</p><p>Instead, you should have your application write every log in a structured format like JSON, which is both more human- and machine-readable. Logging in JSON format also ensures that multi-line logs are processed as a single CloudWatch Logs event, which helps you avoid having related information distributed across multiple events. Additionally, JSON supports the addition of custom metadata (e.g., team, environment, request ID) that you can use to search, filter, and aggregate your logs.</p><div><pre><code data-lang="json"> 
<span>{</span>
    <span>&#34;level&#34;</span><span>:</span> <span>&#34;INFO&#34;</span><span>,</span>
    <span>&#34;message&#34;</span><span>:</span> <span>&#34;Collecting payment&#34;</span><span>,</span>
    <span>&#34;timestamp&#34;</span><span>:</span> <span>&#34;2021-05-03 11:47:12,494+0200&#34;</span><span>,</span>
    <span>&#34;service&#34;</span><span>:</span> <span>&#34;payment&#34;</span><span>,</span>
    <span>&#34;team&#34;</span><span>:</span> <span>&#34;payment-infra&#34;</span><span>,</span>
    <span>&#34;cold_start&#34;</span><span>:</span> <span>true</span><span>,</span>
    <span>&#34;lambda_function_name&#34;</span><span>:</span> <span>&#34;test&#34;</span><span>,</span>
    <span>&#34;lambda_function_memory_size&#34;</span><span>:</span> <span>128</span><span>,</span>
    <span>&#34;lambda_function_arn&#34;</span><span>:</span> <span>&#34;arn:aws:lambda:eu-west-1:12345678910:function:test&#34;</span><span>,</span>
    <span>&#34;lambda_request_id&#34;</span><span>:</span> <span>&#34;23fdfc09-2002-154e-183a-5p0f9a611d02&#34;</span>
<span>}</span></code></pre></div><p>There are various logging libraries that you can use to collect logs from your AWS serverless environments, such as <a href="https://www.npmjs.com/package/lambda-log"><code>lambda-log</code></a>, <a href="https://pypi.org/project/aws-lambda-logging/"><code>aws-logging-library</code></a>, and <a href="https://logging.apache.org/log4j/2.x/">Log4j2</a> (with the <a href="https://github.com/aws/aws-lambda-java-libs/tree/master/aws-lambda-java-log4j2"><code>aws-lambda-java-log4j2</code></a> appender). Many of these libraries are lightweight, which helps reduce cold start times, and write logs in JSON by default. They can also be flexibly configured to route your logs to multiple destinations and log at different levels (which we will discuss in the next section).</p><h3 id="log-at-the-appropriate-level-for-your-environment"><a href="#log-at-the-appropriate-level-for-your-environment">Log at the appropriate level for your environment</a></h3><p>Log levels categorize how important a particular log message is. For instance, Log4j2 uses the following levels, in addition to any <a href="https://logging.apache.org/log4j/2.x/manual/customloglevels.html">custom levels</a> you configure, to categorize logs from the most to least severe:</p><ul><li><code>FATAL</code>: Indicates a severe issue that might cause the application to terminate</li><li><code>ERROR</code>: Indicates a serious problem that should be investigated, although the application might still continue to operate</li><li><code>WARN</code>: Designates unexpected issues that are potentially adverse</li><li><code>INFO</code>: Records information on routine application operations</li><li><code>DEBUG</code>: Records granular informational events for debugging purposes</li><li><code>TRACE</code>: Designates informational events at an even more granular level than <code>DEBUG</code></li><li><code>ALL</code>: Collects all logs</li><li><code>OFF</code>: Turns off logging</li></ul><p>Each log level is inclusive of the levels above it; that is, if you choose <code>WARN</code> as your logging level, you will receive logs at the <code>WARN</code>, <code>ERROR</code>, and <code>FATAL</code> levels. It’s important to choose the logging level that is as selective as possible for the environment you’re operating in. For instance, logging at a low level like <code>DEBUG</code> is appropriate for ironing out code-level issues in your local development environment, but it can be too noisy for production and staging environments, where you only want to surface the most critical issues. In those environments, it might be more fitting to set the log level to <code>INFO</code> so that you only see logs at the <code>INFO</code>, <code>WARN</code>, <code>ERROR</code>, and <code>FATAL</code> levels.</p><h3 id="include-useful-information-in-your-logs"><a href="#include-useful-information-in-your-logs">Include useful information in your logs</a></h3><p>Another best practice is to include sufficient context in your logs so that anyone on your team can easily understand and analyze them. At the very minimum, each log should include a timestamp, log level, identifier (e.g., request ID, customer ID), and descriptive message. As we discussed above, Log4j2 makes it easy to add log levels, and it also includes an appender that adds request IDs to your Lambda logs by default. This enables you to quickly drill down to entries generated, for example, by a specific Lambda invocation or API request.</p><p>It’s also worth noting that of the types of logs we discussed <a href="#understanding-the-types-of-logs-that-aws-serverless-technologies-generate">earlier in this post</a>, API Gateway access logs are unique in that they are managed by the developer, instead of Amazon. API Gateway provides more than 80 <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-mapping-template-reference.html">$context variables</a>, which you can use to flexibly customize the content of your access logs. There are three main categories of information you should include, and we list some of the most useful variables for each category below:</p><h4 id="requests"><a href="#requests">Requests</a></h4><p>The first category is related to requests made to API Gateway. These fields can help you pinpoint problematic endpoints that could be causing issues, such as a spike in API Gateway response errors.</p><ul><li><code>requestTime</code>: The timestamp of the request</li><li><code>requestId</code>: The API request ID given by API Gateway</li><li><code>httpMethod</code>: The HTTP method used (e.g., DELETE, GET, POST, PUT)</li><li><code>resourcePath</code>: The path to your resource (e.g., <code>/root/child</code>)</li><li><code>status</code>: The status code of the response</li><li><code>responseLatency</code>: The amount of time API Gateway took to respond to the request (in milliseconds)</li></ul><p>The next category records information about the client and Lambda authorizers, which are functions that control access to your APIs. When a client makes an API request, API Gateway calls your Lambda authorizer, which authenticates the client and returns an IAM policy. You can use the fields below as a starting point when you need to investigate whether a request failed because the client lacked the necessary permissions or the authorizer was not properly functioning.</p><ul><li><code>authorizer.requestId</code>: The Lambda invocation request ID</li><li><code>authorizer.status</code>: The status code returned by an authorizer, which indicates whether the authorizer responded successfully</li><li><code>authorize.status</code>: The status code returned from an authorization attempt, which indicates whether the authorizer allowed or denied the request</li><li><code>authorizer.latency</code>: The amount of time the authorizer took (in milliseconds) to run</li><li><code>identity.user</code>: The principal identifier of the IAM user that made the request</li><li><code>identity.sourceIP</code>: The source IP address of the TCP connection making the request to API Gateway endpoint</li></ul><h4 id="integration"><a href="#integration">Integration</a></h4><p>Last but not least, it is important to log about your integration endpoints, which process requests to API Gateway. Each API method integrates with an endpoint in the backend, which can be a Lambda function, a different AWS service, or a HTTP web page.</p><ul><li><code>integration.requestId</code>: The integration’s request ID</li><li><code>integration.status</code>: The status code returned by the integration’s code</li><li><code>integration.integrationStatus</code>: The status code returned by the integration service</li><li><code>integration.error</code>: The error message returned by the integration</li><li><code>integration.latency</code>: The amount of time the integration took (in milliseconds) to run</li></ul><h3 id="centralize-your-aws-serverless-logs-with-datadog"><a href="#centralize-your-aws-serverless-logs-with-datadog">Centralize your AWS serverless logs with Datadog</a></h3><p>As your serverless applications become more complex and generate more logs over time, it can be challenging to find what you need to troubleshoot an issue. By centralizing all of your logs in one platform, you can easily analyze and correlate them with other types of monitoring data in order to identify the root cause. CloudWatch Logs provides quick insight into logs from <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/aws-services-sending-logs.html">many AWS services</a> by default, but third-party observability tools like Datadog enable you to perform more sophisticated visualization, alerting, and analysis.</p><p>You can send Lambda logs directly to Datadog—without having to forward them from CloudWatch Logs—by deploying the <a href="https://docs.datadoghq.com/serverless/libraries_integrations/extension/">Datadog Lambda extension</a> as a Lambda Layer across all of your Python and Node.js functions. To submit logs from your Lambda integrations to Datadog, you’ll need to install the Datadog Forwarder Lambda function and subscribe it to your CloudWatch Logs log groups, as detailed in our <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-lambda-function/?tab=awsconsole">documentation</a>.</p><p>Once you’ve configured Datadog to collect logs from your serverless environment, you can begin exploring and analyzing them in real time in the <a href="https://app.datadoghq.com/logs">Log Explorer</a>. Datadog’s built-in log processing pipelines automatically extract metadata from your logs and turn them into tags, which you can use to slice and dice your data.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-explorer-v2.png?auto=format&amp;fit=max&amp;w=847" alt="View and explore all your AWS serverless logs in the Log Explorer"/></picture></figure></div><p>You can also use the <a href="https://app.datadoghq.com/functions">Serverless view</a> to see all the logs generated during a specific function invocation.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/serverless-view-logs-invocation-v2.png?auto=format&amp;fit=max&amp;w=847" alt="View logs for each function invocation in the Serverless view"/></picture></figure></div><p>Datadog correlates your logs with distributed traces and metrics, including those from your containerized and on-premise workloads, to give you a full picture of your application’s performance. For example, if your traces reveal that a request is slow because of an error in API Gateway, you can pivot seamlessly to the corresponding logs to further investigate the issue.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/correlate-logs-traces-v2.png?auto=format&amp;fit=max&amp;w=847" alt="Correlate logs with traces in the Serverless view"/></picture></figure></div><h3 id="control-your-logging-costs"><a href="#control-your-logging-costs">Control your logging costs</a></h3><p>Logs stored in CloudWatch Logs are retained indefinitely by default, which can become prohibitively expensive as your application grows. It is possible to adjust their retention period, but it can be difficult to know ahead of time which logs you will need and which ones are safe to discard. Datadog’s <a href="https://www.datadoghq.com/blog/logging-without-limits/">Logging without Limits™</a> eliminates this tradeoff between cost and visibility by enabling you to ingest all of your logs and dynamically decide later on which ones to index.</p><p>For instance, when you’re investigating the cause of high latency in your application, you can use Log Patterns to help you identify noisy log types that might be complicating your efforts, as shown in the example below. You can then add these logs to an exclusion filter to stop them from being indexed.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/manage-serverless-logs-datadog/log-patterns-v2.png?auto=format&amp;fit=max&amp;w=847" alt="Use Log Patterns to identify noisy logs"/></picture></figure></div><p>You can still leverage the information in the logs you’ve chosen not to index by turning them into <a href="https://www.datadoghq.com/blog/log-based-metrics/">metrics</a>, which can be tracked over the long term. This enables you to continue monitoring performance trends at the log level without incurring unnecessary indexing costs. And just like any other metric in Datadog, you can graph, alert on, and correlate log-based metrics with the rest of your application’s telemetry data.</p><h2 id="start-monitoring-your-aws-serverless-logs-with-datadog"><a href="#start-monitoring-your-aws-serverless-logs-with-datadog">Start monitoring your AWS serverless logs with Datadog</a></h2><p>In this post, we’ve seen how logs are indispensable for investigating issues in your AWS serverless applications. We’ve also shared some best practices for collecting and managing your logs to help you get deep visibility into your applications. Additionally, we showed you how you can cost-effectively send your serverless logs to Datadog—and correlate them with the rest of your telemetry data, all in one place. If you’re an existing Datadog customer, start monitoring your <a href="https://docs.datadoghq.com/serverless/">serverless applications</a> today. Otherwise, sign up for a 14-day <a href="#">free trial</a>.</p></div></div>]]></content:encoded>
      <author>Kai Xin Tai</author>
      <pubDate>Mon, 23 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>How to detect security threats in your systems&#39; Linux processes</title>
      <link>https://www.datadoghq.com/blog/linux-security-threat-detection-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/linux-process-hero.png&#34; width=&#34;100%&#34;/&gt;Almost all tasks within a Linux system, whether it&amp;rsquo;s an application, system daemon, or certain types of user activity, are executed by one or more processes. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we&amp;rsquo;ll look at: how understanding the Linux process tree can help you identify security threats what process information can help you determine the scope of a breach We&amp;rsquo;ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Almost all tasks within a Linux system, whether it’s an application, system daemon, or certain types of user activity, are executed by one or more <a href="https://tldp.org/LDP/tlk/kernel/processes.html">processes</a>. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we’ll look at:</p><ul><li>how <a href="#a-primer-on-the-process-tree">understanding the Linux process tree</a> can help you identify security threats</li><li>what <a href="#use-process-data-to-determine-the-scope-of-an-attack">process information</a> can help you determine the scope of a breach</li></ul><p>We’ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.</p><h2 id="a-primer-on-the-process-tree"><a href="#a-primer-on-the-process-tree">A primer on the process tree</a></h2><p>In Linux, each process is generated by a preceding <strong>parent</strong> process and can generate one or more <strong>child</strong> processes. Following this parent/child structure, active processes form a <strong>process tree</strong> that starts with the <code>systemd</code> process that runs when Linux first boots and ends with the most recently generated processes. This parent/child structure is particularly useful for revealing security threats because, unlike simple indicators of compromise (IOCs) like adversarial IP addresses or file hashes, it’s difficult to fake or change. For instance, while attackers can change an IP address, it’s much harder to hide that an application has spawned a new suspicious child process.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847" alt="process-tree.png"/></picture><figcaption>Active processes are structured as a process tree which can be used to help you spot signs of a security breach.</figcaption></figure></div><h2 id="identify-suspicious-processes"><a href="#identify-suspicious-processes">Identify suspicious processes</a></h2><p>As you monitor your applications, it’s important to look out for any launched shells or utilities (e.g., <code>bash</code> or <code>curl</code>) that are children of key processes in your environment. For example, if a Java application process generates a shell you aren’t anticipating, it could indicate that a malicious actor has infiltrated your app and launched a <a href="https://us-cert.cisa.gov/ncas/alerts/TA15-314A">web shell attack</a>. When these attacks are successful, they can create backdoors to your infrastructure that allow attackers to access sensitive data and execute commands without authorization.</p><p>Likewise, you should check if a process spawned utilities like <code>nmap</code>, which an attacker can use to survey your network for further vulnerabilities to exploit, or <code>passwd</code>, which can be used to change user passwords and grant attackers higher privileges.</p><p>Once you’ve identified a malicious process, it’s important to investigate the scope of the attack, including what information the attacker has potentially gained access to.</p><h2 id="use-process-data-to-determine-the-scope-of-an-attack"><a href="#use-process-data-to-determine-the-scope-of-an-attack">Use process data to determine the scope of an attack</a></h2><p>Linux processes include metadata that can help you determine the scope of an attack. The key types of information to look at are:</p><ul><li>environment variables</li><li>command-line arguments</li></ul><h3 id="environment-variables"><a href="#environment-variables">Environment variables</a></h3><p>Due to their <a href="#a-primer-on-the-process-tree">relationship</a>, child processes inherit access to any environment variables available to the parent process. Though it’s not considered best practice, environment variables are often used to store sensitive data like API and GitHub keys, or even database credentials. Using our example of an attacker successfully creating a web shell from a Java application process, the shell would be able to see any environment variables associated with your application process, such as database credentials for a SQL server containing sensitive customer data.</p><p>Examining what environment variables a process includes can help you determine the full scope of a threat. You can quickly view a list of a process’s environment variables by using the Linux command <code>ps faux</code> to get its PID and then running the following:</p><div><pre><code data-lang="text">cat /proc/&lt;PROCESS_PID&gt;/environ </code></pre></div><p>Please note, however, that this detection method only works while the process is running. This makes it challenging to view potential attacks without a <a href="#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security">continuous monitoring</a> tool.</p><h3 id="command-line-arguments"><a href="#command-line-arguments">Command-line arguments</a></h3><p>In addition to environment variables, it’s important to know what command-line arguments an attacker used when starting a malicious process. Command-line arguments hold information that’s critical to determining the nature of a security threat. Arguments may include identifying data like the IP address an attacker used when they issued a <code>curl</code> command to download a malicious payload, as well as activity data like <a href="https://stackabuse.com/encoding-and-decoding-base64-strings-in-python">encoded Python scripts</a> that were run directly in the command line. Insight into a process’s command-line arguments can help you view what occurred during an attack so you can plan how to respond.</p><p>For a quick look at a process’s command line arguments, get its PID and run a command like the following:</p><div><pre><code data-lang="text">ps -p &lt;PROCESS_PID&gt; -o args</code></pre></div><p>This approach, however, is limited because you need to be able to catch the process before it terminates. Next, we’ll look at how Datadog’s Cloud Workload Security helps you detect attacks and view relevant metadata.</p><h2 id="detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security"><a href="#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security">Detect threats in your Linux processes with Datadog Cloud Workload Security</a></h2><p>Datadog <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/">Cloud Workload Security (CWS)</a> analyzes the full process tree across all your Linux hosts and containers in real time to automatically detect the kind of threats we’ve looked at. Datadog includes <a href="https://docs.datadoghq.com/security_platform/default_rules/#cat-workload-security">out-of-the-box workload threat detection rules</a> that help you immediately respond to potential security threats by flagging suspicious behavior like the execution of <code>passwd</code> and <code>nmap</code> utilities.</p><p>In addition to out-of-the-box workload security rules, Datadog enables you to write your own custom rules. Security rules are constructed with <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/agent_expressions/"><strong>Agent Expressions</strong></a> that enable you to define what process activity to look for with as much specificity as you want. For example, you can instruct Datadog to detect if a Java process generated a <code>bash</code> shell, or even watch for processes run with specific command-line arguments. To learn more about how to construct your own custom workload security rules, check out our <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/workload_security_rules/">documentation</a>.</p><p>If Datadog detects any processes that match a rule, it will generate a <a href="https://docs.datadoghq.com/security_platform/security_monitoring/getting_started/#explore-security-signals">Security Signal</a>. Security Signals include full context around the suspicious process, including environment variable keys (without collecting the associated values), command-line arguments, and other metadata. You can use this information to quickly determine the scope of an attack before planning your response.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847" alt="Security signals include environment variables and command-line arguments which can help you determine the scope of security attacks."/></picture></figure></div><h2 id="start-today"><a href="#start-today">Start today</a></h2><p>No matter which distribution you work with, processes are at the heart of any Linux system. In this post, we looked at how understanding processes and their relationships can help you spot suspicious behavior and determine the severity of a security breach. Datadog Cloud Workload Security monitors process activity throughout your infrastructure at the kernel level in real time to reveal any suspicious or malicious behavior. Read our <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/getting_started/?tab=kubernetes">documentation</a> to learn more or sign up today for a 14-day <a href="#">free trial.</a></p></div></div>]]></content:encoded>
      <author>Jordan Obey</author>
      <pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>How to detect security threats in your systems&#39; Linux processes</title>
      <link>https://www.datadoghq.com/blog/linux-security-threat-detection-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/linux-process-hero.png&#34; width=&#34;100%&#34;/&gt;Almost all tasks within a Linux system, whether it&amp;rsquo;s an application, system daemon, or certain types of user activity, are executed by one or more processes. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we&amp;rsquo;ll look at: how understanding the Linux process tree can help you identify security threats what process information can help you determine the scope of a breach We&amp;rsquo;ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Almost all tasks within a Linux system, whether it’s an application, system daemon, or certain types of user activity, are executed by one or more <a href="https://tldp.org/LDP/tlk/kernel/processes.html">processes</a>. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we’ll look at:</p><ul><li>how <a href="#a-primer-on-the-process-tree">understanding the Linux process tree</a> can help you identify security threats</li><li>what <a href="#use-process-data-to-determine-the-scope-of-an-attack">process information</a> can help you determine the scope of a breach</li></ul><p>We’ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.</p><h2 id="a-primer-on-the-process-tree"><a href="#a-primer-on-the-process-tree">A primer on the process tree</a></h2><p>In Linux, each process is generated by a preceding <strong>parent</strong> process and can generate one or more <strong>child</strong> processes. Following this parent/child structure, active processes form a <strong>process tree</strong> that starts with the <code>systemd</code> process that runs when Linux first boots and ends with the most recently generated processes. This parent/child structure is particularly useful for revealing security threats because, unlike simple indicators of compromise (IOCs) like adversarial IP addresses or file hashes, it’s difficult to fake or change. For instance, while attackers can change an IP address, it’s much harder to hide that an application has spawned a new suspicious child process.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847" alt="process-tree.png"/></picture><figcaption>Active processes are structured as a process tree which can be used to help you spot signs of a security breach.</figcaption></figure></div><h2 id="identify-suspicious-processes"><a href="#identify-suspicious-processes">Identify suspicious processes</a></h2><p>As you monitor your applications, it’s important to look out for any launched shells or utilities (e.g., <code>bash</code> or <code>curl</code>) that are children of key processes in your environment. For example, if a Java application process generates a shell you aren’t anticipating, it could indicate that a malicious actor has infiltrated your app and launched a <a href="https://us-cert.cisa.gov/ncas/alerts/TA15-314A">web shell attack</a>. When these attacks are successful, they can create backdoors to your infrastructure that allow attackers to access sensitive data and execute commands without authorization.</p><p>Likewise, you should check if a process spawned utilities like <code>nmap</code>, which an attacker can use to survey your network for further vulnerabilities to exploit, or <code>passwd</code>, which can be used to change user passwords and grant attackers higher privileges.</p><p>Once you’ve identified a malicious process, it’s important to investigate the scope of the attack, including what information the attacker has potentially gained access to.</p><h2 id="use-process-data-to-determine-the-scope-of-an-attack"><a href="#use-process-data-to-determine-the-scope-of-an-attack">Use process data to determine the scope of an attack</a></h2><p>Linux processes include metadata that can help you determine the scope of an attack. The key types of information to look at are:</p><ul><li>environment variables</li><li>command-line arguments</li></ul><h3 id="environment-variables"><a href="#environment-variables">Environment variables</a></h3><p>Due to their <a href="#a-primer-on-the-process-tree">relationship</a>, child processes inherit access to any environment variables available to the parent process. Though it’s not considered best practice, environment variables are often used to store sensitive data like API and GitHub keys, or even database credentials. Using our example of an attacker successfully creating a web shell from a Java application process, the shell would be able to see any environment variables associated with your application process, such as database credentials for a SQL server containing sensitive customer data.</p><p>Examining what environment variables a process includes can help you determine the full scope of a threat. You can quickly view a list of a process’s environment variables by using the Linux command <code>ps faux</code> to get its PID and then running the following:</p><div><pre><code data-lang="text">cat /proc/&lt;PROCESS_PID&gt;/environ </code></pre></div><p>Please note, however, that this detection method only works while the process is running. This makes it challenging to view potential attacks without a <a href="#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security">continuous monitoring</a> tool.</p><h3 id="command-line-arguments"><a href="#command-line-arguments">Command-line arguments</a></h3><p>In addition to environment variables, it’s important to know what command-line arguments an attacker used when starting a malicious process. Command-line arguments hold information that’s critical to determining the nature of a security threat. Arguments may include identifying data like the IP address an attacker used when they issued a <code>curl</code> command to download a malicious payload, as well as activity data like <a href="https://stackabuse.com/encoding-and-decoding-base64-strings-in-python">encoded Python scripts</a> that were run directly in the command line. Insight into a process’s command-line arguments can help you view what occurred during an attack so you can plan how to respond.</p><p>For a quick look at a process’s command line arguments, get its PID and run a command like the following:</p><div><pre><code data-lang="text">ps -p &lt;PROCESS_PID&gt; -o args</code></pre></div><p>This approach, however, is limited because you need to be able to catch the process before it terminates. Next, we’ll look at how Datadog’s Cloud Workload Security helps you detect attacks and view relevant metadata.</p><h2 id="detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security"><a href="#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security">Detect threats in your Linux processes with Datadog Cloud Workload Security</a></h2><p>Datadog <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/">Cloud Workload Security (CWS)</a> analyzes the full process tree across all your Linux hosts and containers in real time to automatically detect the kind of threats we’ve looked at. Datadog includes <a href="https://docs.datadoghq.com/security_platform/default_rules/#cat-workload-security">out-of-the-box workload threat detection rules</a> that help you immediately respond to potential security threats by flagging suspicious behavior like the execution of <code>passwd</code> and <code>nmap</code> utilities.</p><p>In addition to out-of-the-box workload security rules, Datadog enables you to write your own custom rules. Security rules are constructed with <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/agent_expressions/"><strong>Agent Expressions</strong></a> that enable you to define what process activity to look for with as much specificity as you want. For example, you can instruct Datadog to detect if a Java process generated a <code>bash</code> shell, or even watch for processes run with specific command-line arguments. To learn more about how to construct your own custom workload security rules, check out our <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/workload_security_rules/">documentation</a>.</p><p>If Datadog detects any processes that match a rule, it will generate a <a href="https://docs.datadoghq.com/security_platform/security_monitoring/getting_started/#explore-security-signals">Security Signal</a>. Security Signals include full context around the suspicious process, including environment variable keys (without collecting the associated values), command-line arguments, and other metadata. You can use this information to quickly determine the scope of an attack before planning your response.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847" alt="Security signals include environment variables and command-line arguments which can help you determine the scope of security attacks."/></picture></figure></div><h2 id="start-today"><a href="#start-today">Start today</a></h2><p>No matter which distribution you work with, processes are at the heart of any Linux system. In this post, we looked at how understanding processes and their relationships can help you spot suspicious behavior and determine the severity of a security breach. Datadog Cloud Workload Security monitors process activity throughout your infrastructure at the kernel level in real time to reveal any suspicious or malicious behavior. Read our <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/getting_started/?tab=kubernetes">documentation</a> to learn more or sign up today for a 14-day <a href="#">free trial.</a></p></div></div>]]></content:encoded>
      <author>Jordan Obey</author>
      <pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>How to detect security threats in your systems&#39; Linux processes</title>
      <link>https://www.datadoghq.com/blog/linux-security-threat-detection-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/linux-process-hero.png&#34; width=&#34;100%&#34;/&gt;Almost all tasks within a Linux system, whether it&amp;rsquo;s an application, system daemon, or certain types of user activity, are executed by one or more processes. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we&amp;rsquo;ll look at: how understanding the Linux process tree can help you identify security threats what process information can help you determine the scope of a breach We&amp;rsquo;ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Almost all tasks within a Linux system, whether it’s an application, system daemon, or certain types of user activity, are executed by one or more <a href="https://tldp.org/LDP/tlk/kernel/processes.html">processes</a>. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we’ll look at:</p><ul><li>how <a href="#a-primer-on-the-process-tree">understanding the Linux process tree</a> can help you identify security threats</li><li>what <a href="#use-process-data-to-determine-the-scope-of-an-attack">process information</a> can help you determine the scope of a breach</li></ul><p>We’ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.</p><h2 id="a-primer-on-the-process-tree"><a href="#a-primer-on-the-process-tree">A primer on the process tree</a></h2><p>In Linux, each process is generated by a preceding <strong>parent</strong> process and can generate one or more <strong>child</strong> processes. Following this parent/child structure, active processes form a <strong>process tree</strong> that starts with the <code>systemd</code> process that runs when Linux first boots and ends with the most recently generated processes. This parent/child structure is particularly useful for revealing security threats because, unlike simple indicators of compromise (IOCs) like adversarial IP addresses or file hashes, it’s difficult to fake or change. For instance, while attackers can change an IP address, it’s much harder to hide that an application has spawned a new suspicious child process.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847" alt="process-tree.png"/></picture><figcaption>Active processes are structured as a process tree which can be used to help you spot signs of a security breach.</figcaption></figure></div><h2 id="identify-suspicious-processes"><a href="#identify-suspicious-processes">Identify suspicious processes</a></h2><p>As you monitor your applications, it’s important to look out for any launched shells or utilities (e.g., <code>bash</code> or <code>curl</code>) that are children of key processes in your environment. For example, if a Java application process generates a shell you aren’t anticipating, it could indicate that a malicious actor has infiltrated your app and launched a <a href="https://us-cert.cisa.gov/ncas/alerts/TA15-314A">web shell attack</a>. When these attacks are successful, they can create backdoors to your infrastructure that allow attackers to access sensitive data and execute commands without authorization.</p><p>Likewise, you should check if a process spawned utilities like <code>nmap</code>, which an attacker can use to survey your network for further vulnerabilities to exploit, or <code>passwd</code>, which can be used to change user passwords and grant attackers higher privileges.</p><p>Once you’ve identified a malicious process, it’s important to investigate the scope of the attack, including what information the attacker has potentially gained access to.</p><h2 id="use-process-data-to-determine-the-scope-of-an-attack"><a href="#use-process-data-to-determine-the-scope-of-an-attack">Use process data to determine the scope of an attack</a></h2><p>Linux processes include metadata that can help you determine the scope of an attack. The key types of information to look at are:</p><ul><li>environment variables</li><li>command-line arguments</li></ul><h3 id="environment-variables"><a href="#environment-variables">Environment variables</a></h3><p>Due to their <a href="#a-primer-on-the-process-tree">relationship</a>, child processes inherit access to any environment variables available to the parent process. Though it’s not considered best practice, environment variables are often used to store sensitive data like API and GitHub keys, or even database credentials. Using our example of an attacker successfully creating a web shell from a Java application process, the shell would be able to see any environment variables associated with your application process, such as database credentials for a SQL server containing sensitive customer data.</p><p>Examining what environment variables a process includes can help you determine the full scope of a threat. You can quickly view a list of a process’s environment variables by using the Linux command <code>ps faux</code> to get its PID and then running the following:</p><div><pre><code data-lang="text">cat /proc/&lt;PROCESS_PID&gt;/environ </code></pre></div><p>Please note, however, that this detection method only works while the process is running. This makes it challenging to view potential attacks without a <a href="#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security">continuous monitoring</a> tool.</p><h3 id="command-line-arguments"><a href="#command-line-arguments">Command-line arguments</a></h3><p>In addition to environment variables, it’s important to know what command-line arguments an attacker used when starting a malicious process. Command-line arguments hold information that’s critical to determining the nature of a security threat. Arguments may include identifying data like the IP address an attacker used when they issued a <code>curl</code> command to download a malicious payload, as well as activity data like <a href="https://stackabuse.com/encoding-and-decoding-base64-strings-in-python">encoded Python scripts</a> that were run directly in the command line. Insight into a process’s command-line arguments can help you view what occurred during an attack so you can plan how to respond.</p><p>For a quick look at a process’s command line arguments, get its PID and run a command like the following:</p><div><pre><code data-lang="text">ps -p &lt;PROCESS_PID&gt; -o args</code></pre></div><p>This approach, however, is limited because you need to be able to catch the process before it terminates. Next, we’ll look at how Datadog’s Cloud Workload Security helps you detect attacks and view relevant metadata.</p><h2 id="detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security"><a href="#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security">Detect threats in your Linux processes with Datadog Cloud Workload Security</a></h2><p>Datadog <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/">Cloud Workload Security (CWS)</a> analyzes the full process tree across all your Linux hosts and containers in real time to automatically detect the kind of threats we’ve looked at. Datadog includes <a href="https://docs.datadoghq.com/security_platform/default_rules/#cat-workload-security">out-of-the-box workload threat detection rules</a> that help you immediately respond to potential security threats by flagging suspicious behavior like the execution of <code>passwd</code> and <code>nmap</code> utilities.</p><p>In addition to out-of-the-box workload security rules, Datadog enables you to write your own custom rules. Security rules are constructed with <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/agent_expressions/"><strong>Agent Expressions</strong></a> that enable you to define what process activity to look for with as much specificity as you want. For example, you can instruct Datadog to detect if a Java process generated a <code>bash</code> shell, or even watch for processes run with specific command-line arguments. To learn more about how to construct your own custom workload security rules, check out our <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/workload_security_rules/">documentation</a>.</p><p>If Datadog detects any processes that match a rule, it will generate a <a href="https://docs.datadoghq.com/security_platform/security_monitoring/getting_started/#explore-security-signals">Security Signal</a>. Security Signals include full context around the suspicious process, including environment variable keys (without collecting the associated values), command-line arguments, and other metadata. You can use this information to quickly determine the scope of an attack before planning your response.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847" alt="Security signals include environment variables and command-line arguments which can help you determine the scope of security attacks."/></picture></figure></div><h2 id="start-today"><a href="#start-today">Start today</a></h2><p>No matter which distribution you work with, processes are at the heart of any Linux system. In this post, we looked at how understanding processes and their relationships can help you spot suspicious behavior and determine the severity of a security breach. Datadog Cloud Workload Security monitors process activity throughout your infrastructure at the kernel level in real time to reveal any suspicious or malicious behavior. Read our <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/getting_started/?tab=kubernetes">documentation</a> to learn more or sign up today for a 14-day <a href="#">free trial.</a></p></div></div>]]></content:encoded>
      <author>Jordan Obey</author>
      <pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>How to detect security threats in your systems&#39; Linux processes</title>
      <link>https://www.datadoghq.com/blog/linux-security-threat-detection-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/linux-process-hero.png&#34; width=&#34;100%&#34;/&gt;Almost all tasks within a Linux system, whether it&amp;rsquo;s an application, system daemon, or certain types of user activity, are executed by one or more processes. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we&amp;rsquo;ll look at: how understanding the Linux process tree can help you identify security threats what process information can help you determine the scope of a breach We&amp;rsquo;ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Almost all tasks within a Linux system, whether it’s an application, system daemon, or certain types of user activity, are executed by one or more <a href="https://tldp.org/LDP/tlk/kernel/processes.html">processes</a>. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we’ll look at:</p><ul><li>how <a href="#a-primer-on-the-process-tree">understanding the Linux process tree</a> can help you identify security threats</li><li>what <a href="#use-process-data-to-determine-the-scope-of-an-attack">process information</a> can help you determine the scope of a breach</li></ul><p>We’ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.</p><h2 id="a-primer-on-the-process-tree"><a href="#a-primer-on-the-process-tree">A primer on the process tree</a></h2><p>In Linux, each process is generated by a preceding <strong>parent</strong> process and can generate one or more <strong>child</strong> processes. Following this parent/child structure, active processes form a <strong>process tree</strong> that starts with the <code>systemd</code> process that runs when Linux first boots and ends with the most recently generated processes. This parent/child structure is particularly useful for revealing security threats because, unlike simple indicators of compromise (IOCs) like adversarial IP addresses or file hashes, it’s difficult to fake or change. For instance, while attackers can change an IP address, it’s much harder to hide that an application has spawned a new suspicious child process.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847" alt="process-tree.png"/></picture><figcaption>Active processes are structured as a process tree which can be used to help you spot signs of a security breach.</figcaption></figure></div><h2 id="identify-suspicious-processes"><a href="#identify-suspicious-processes">Identify suspicious processes</a></h2><p>As you monitor your applications, it’s important to look out for any launched shells or utilities (e.g., <code>bash</code> or <code>curl</code>) that are children of key processes in your environment. For example, if a Java application process generates a shell you aren’t anticipating, it could indicate that a malicious actor has infiltrated your app and launched a <a href="https://us-cert.cisa.gov/ncas/alerts/TA15-314A">web shell attack</a>. When these attacks are successful, they can create backdoors to your infrastructure that allow attackers to access sensitive data and execute commands without authorization.</p><p>Likewise, you should check if a process spawned utilities like <code>nmap</code>, which an attacker can use to survey your network for further vulnerabilities to exploit, or <code>passwd</code>, which can be used to change user passwords and grant attackers higher privileges.</p><p>Once you’ve identified a malicious process, it’s important to investigate the scope of the attack, including what information the attacker has potentially gained access to.</p><h2 id="use-process-data-to-determine-the-scope-of-an-attack"><a href="#use-process-data-to-determine-the-scope-of-an-attack">Use process data to determine the scope of an attack</a></h2><p>Linux processes include metadata that can help you determine the scope of an attack. The key types of information to look at are:</p><ul><li>environment variables</li><li>command-line arguments</li></ul><h3 id="environment-variables"><a href="#environment-variables">Environment variables</a></h3><p>Due to their <a href="#a-primer-on-the-process-tree">relationship</a>, child processes inherit access to any environment variables available to the parent process. Though it’s not considered best practice, environment variables are often used to store sensitive data like API and GitHub keys, or even database credentials. Using our example of an attacker successfully creating a web shell from a Java application process, the shell would be able to see any environment variables associated with your application process, such as database credentials for a SQL server containing sensitive customer data.</p><p>Examining what environment variables a process includes can help you determine the full scope of a threat. You can quickly view a list of a process’s environment variables by using the Linux command <code>ps faux</code> to get its PID and then running the following:</p><div><pre><code data-lang="text">cat /proc/&lt;PROCESS_PID&gt;/environ </code></pre></div><p>Please note, however, that this detection method only works while the process is running. This makes it challenging to view potential attacks without a <a href="#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security">continuous monitoring</a> tool.</p><h3 id="command-line-arguments"><a href="#command-line-arguments">Command-line arguments</a></h3><p>In addition to environment variables, it’s important to know what command-line arguments an attacker used when starting a malicious process. Command-line arguments hold information that’s critical to determining the nature of a security threat. Arguments may include identifying data like the IP address an attacker used when they issued a <code>curl</code> command to download a malicious payload, as well as activity data like <a href="https://stackabuse.com/encoding-and-decoding-base64-strings-in-python">encoded Python scripts</a> that were run directly in the command line. Insight into a process’s command-line arguments can help you view what occurred during an attack so you can plan how to respond.</p><p>For a quick look at a process’s command line arguments, get its PID and run a command like the following:</p><div><pre><code data-lang="text">ps -p &lt;PROCESS_PID&gt; -o args</code></pre></div><p>This approach, however, is limited because you need to be able to catch the process before it terminates. Next, we’ll look at how Datadog’s Cloud Workload Security helps you detect attacks and view relevant metadata.</p><h2 id="detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security"><a href="#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security">Detect threats in your Linux processes with Datadog Cloud Workload Security</a></h2><p>Datadog <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/">Cloud Workload Security (CWS)</a> analyzes the full process tree across all your Linux hosts and containers in real time to automatically detect the kind of threats we’ve looked at. Datadog includes <a href="https://docs.datadoghq.com/security_platform/default_rules/#cat-workload-security">out-of-the-box workload threat detection rules</a> that help you immediately respond to potential security threats by flagging suspicious behavior like the execution of <code>passwd</code> and <code>nmap</code> utilities.</p><p>In addition to out-of-the-box workload security rules, Datadog enables you to write your own custom rules. Security rules are constructed with <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/agent_expressions/"><strong>Agent Expressions</strong></a> that enable you to define what process activity to look for with as much specificity as you want. For example, you can instruct Datadog to detect if a Java process generated a <code>bash</code> shell, or even watch for processes run with specific command-line arguments. To learn more about how to construct your own custom workload security rules, check out our <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/workload_security_rules/">documentation</a>.</p><p>If Datadog detects any processes that match a rule, it will generate a <a href="https://docs.datadoghq.com/security_platform/security_monitoring/getting_started/#explore-security-signals">Security Signal</a>. Security Signals include full context around the suspicious process, including environment variable keys (without collecting the associated values), command-line arguments, and other metadata. You can use this information to quickly determine the scope of an attack before planning your response.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847" alt="Security signals include environment variables and command-line arguments which can help you determine the scope of security attacks."/></picture></figure></div><h2 id="start-today"><a href="#start-today">Start today</a></h2><p>No matter which distribution you work with, processes are at the heart of any Linux system. In this post, we looked at how understanding processes and their relationships can help you spot suspicious behavior and determine the severity of a security breach. Datadog Cloud Workload Security monitors process activity throughout your infrastructure at the kernel level in real time to reveal any suspicious or malicious behavior. Read our <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/getting_started/?tab=kubernetes">documentation</a> to learn more or sign up today for a 14-day <a href="#">free trial.</a></p></div></div>]]></content:encoded>
      <author>Jordan Obey</author>
      <pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Release code confidently with Automatic Faulty Deployment Detection</title>
      <link>https://www.datadoghq.com/blog/faulty-deployment-detection/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/automatic_faulty_deployment_detection.png&#34; width=&#34;100%&#34;/&gt;Modern software development teams use CI/CD tools to ship features quickly and rely on best practices like shift-left testing to find application errors before they become user-facing bugs. But you still face the risk that any code you deploy could contain errors that your testing did not surface. To help you deploy with confidence and mitigate the effects of a bad deployment, Datadog APM now provides Automatic Faulty Deployment Detection.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Modern software development teams use CI/CD tools to ship features quickly and rely on best practices like <a href="https://www.datadoghq.com/blog/shift-left-testing-best-practices/">shift-left testing</a> to find application errors before they become user-facing bugs. But you still face the risk that any code you deploy could contain errors that your testing did not surface. To help you deploy with confidence and mitigate the effects of a bad deployment, <a href="https://www.datadoghq.com/knowledge-center/distributed-tracing/">Datadog APM</a> now provides Automatic Faulty Deployment Detection.</p><p>This post will show you how Automatic Faulty Deployment Detection helps you prevent faulty deployments from affecting the performance of your application. We’ll explain how you can:</p><ul><li><a href="#automatically-detect-faulty-deployments">Spot a deployment that appears to be faulty</a> (even if the deployment itself didn’t fail)</li><li><a href="#troubleshoot-faulty-deployments-quickly">Troubleshoot faulty deployments</a></li><li><a href="#proactively-set-alerts-to-monitor-future-deployments">Create alerts to notify your team</a> of a faulty deployment</li></ul><h2 id="automatically-detect-faulty-deployments"><a href="#automatically-detect-faulty-deployments">Automatically detect faulty deployments</a></h2><p>Automatic Faulty Deployment Detection uses <a href="https://www.datadoghq.com/blog/watchdog/">Watchdog’s machine learning algorithms</a> to spot faulty deployments within minutes, reducing your mean time to detection (MTTD). As your team continuously deploys code to production, Watchdog compares the performance of each new version of a service with its previous versions to spot new types of errors introduced in a deployment (instead of an increase in the rate of an existing error that you might expect with a new deployment). If Watchdog determines that a new deployment is faulty, you’ll see details about the affected service in the service-level dashboard, including error types, error rates, request rates, and latency metrics for each version you’ve deployed.</p><p>In the screenshot below, the yellow banner at the top of the page indicates that the most recent deployment of the <code>inventory-api</code> service may be faulty, and a previously unseen error is affecting this serivce’s <code>http.request</code> operation. The <strong>Deployments</strong> table at the bottom of the screen shows a history of the service’s deployments and indicates an error rate of 100 percent for the most recently deployed version, indicating that you may need to roll back the deployment and investigate the source of the errors.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=847" alt="The Services page shows service-level information including rate of requests, rate of errors, and latency. A yellow banner states that the most recent deployment of the service may be faulty."/></picture></figure></div><p>You can click <strong>View Details</strong>—or any deployment listed in the <strong>Deployments</strong> table—to open up the <a href="https://www.datadoghq.com/blog/datadog-deployment-tracking/">Deployment Tracking</a> view, shown in the screenshot below. This view provides details about the faulty deployment, including the new type of error detected (<code>db.utils.OperationalError</code>), the affected endpoint (<code>/inventory</code>), and the HTTP status code (<code>500</code>), which can help you understand how the error is affecting your service. In this case, the application is trying to create the <code>products</code> table each time it calls the endpoint, rather than executing an <code>UPDATE</code> statement against the existing table.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=847" alt="A detailed view of the faulty deployment shows the time it was detected, the error type, the relevant endpoint, and the HTTP status code."/></picture></figure></div><h2 id="troubleshoot-faulty-deployments-quickly"><a href="#troubleshoot-faulty-deployments-quickly">Troubleshoot faulty deployments quickly</a></h2><p>When Automatic Faulty Deployment Detection spots an error in a deployment, you can start troubleshooting by exploring the service’s <a href="https://docs.datadoghq.com/tracing/">traces</a>, which visualize your application’s activity and surface details that can help you understand the source of the error.</p><p>To see the traces for a service affected by a faulty deployment, click the <strong>Traces</strong> tab on the service-level dashboard or the <strong>previously unseen errors</strong> table in the Deployment Tracking view.</p><p>You can view your trace data as a <a href="https://www.datadoghq.com/knowledge-center/distributed-tracing/flame-graph/">flame graph</a>, which shows the performance of each of your services as your application processes a request. The screenshot below shows a flame graph corresponding to the error shown earlier in the Deployment Tracking view. The <code>200 OK</code> response at the top indicates that the request was successful overall. But the purple span shows the response from the <code>inventory</code> service, which took 166 microseconds and resulted in a <code>500</code> error, whose details are shown in the bottom half of the screen.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=847" alt="A flame graph shows four requests. The final request, in purple, represents the HTTP request to the inventory service which resulted in a 500 error."/></picture></figure></div><p>As you gain an understanding of the error that was detected in the deployment, you can collaborate with your team to troubleshoot and resolve the issue. You can easily share what you learn by creating a <a href="https://www.datadoghq.com/blog/collaborative-notebooks-datadog/">notebook</a> that your team can use to collaborate, or you can declare an <a href="https://www.datadoghq.com/blog/incident-response-with-datadog/">incident</a> to initiate your team’s defined process for responding to an error in production. The screenshot below highlights the buttons you can use to start your collaboration with just a single click.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=847" alt="A highlighted area of the faulty deployment detailed view shows buttons to create a Notebook and an incident."/></picture></figure></div><p>If you click the <strong>Create Incident</strong> button, Datadog will automatically generate an incident that your team can use to troubleshoot the faulty deployment. The incident automatically includes a link to the relevant service dashboard to provide context that can help collaborators quickly identify and mitigate the impact of the incident.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=847" alt="The new incident form includes fields to designate incident severity, incident commander, team members to be notified, and a link to the APM page that describes the faulty deployment."/></picture></figure></div><p>See the documentation for more information about <a href="https://docs.datadoghq.com/monitors/incident_management/">Datadog Incident Management</a>.</p><h2 id="proactively-set-alerts-to-monitor-future-deployments"><a href="#proactively-set-alerts-to-monitor-future-deployments">Proactively set alerts to monitor future deployments</a></h2><p>To further support your team’s ability to release features rapidly, you can create alerts that automatically page you if a release appears to be faulty. Automatic Faulty Deployment Detection suggests monitors that you can enable with a single click to proactively address any errors that affect your most critical services. These automated alerts can help your team react quickly and mitigate faulty deployments before they degrade your user experience.</p><p>In the screenshot below, the <code>inventory-api</code> service dashboard shows a faulty deployment and includes a <strong>Suggested Monitor</strong> button that allows you to create an alert that will automatically notify you if the same service exhibits new errors in a future deployment. Once you’ve set the alert, Datadog will monitor your deployments so your team can focus on shipping your next release.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=847" alt="A highlighted area on the service page shows the Suggested Monitor button."/></picture></figure></div><h2 id="deploy-safely-with-datadog"><a href="#deploy-safely-with-datadog">Deploy safely with Datadog</a></h2><p>Along with best practices like <a href="https://www.datadoghq.com/blog/introducing-synthetic-monitoring/">synthetic monitoring</a> and automated <a href="https://www.datadoghq.com/blog/datadog-synthetic-ci-cd-testing/">CI/CD pipeline testing</a>, Automatic Faulty Deployment Detection can help you maintain both the velocity of your development and the quality of your service. To get started, enable <a href="https://docs.datadoghq.com/tracing/setup_overview/">APM</a> and then enable <a href="https://docs.datadoghq.com/tracing/deployment_tracking/">Deployment Tracking</a> by tagging your deployments with a <a href="https://docs.datadoghq.com/getting_started/tagging/unified_service_tagging/"><code>version</code> tag</a>—which may be provided <a href="https://www.datadoghq.com/blog/unified-service-tagging/#use-the-version-tag-to-identify-problematic-deployments">automatically</a> by your CI/CD tool. If you’re not already using Datadog, you can start today with a <a href="#">free 14-day trial</a>.</p></div></div>]]></content:encoded>
      <author>David Asker</author>
      <pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>How to detect security threats in your systems&#39; Linux processes</title>
      <link>https://www.datadoghq.com/blog/linux-security-threat-detection-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/linux-process-hero.png&#34; width=&#34;100%&#34;/&gt;Almost all tasks within a Linux system, whether it&amp;rsquo;s an application, system daemon, or certain types of user activity, are executed by one or more processes. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we&amp;rsquo;ll look at: how understanding the Linux process tree can help you identify security threats what process information can help you determine the scope of a breach We&amp;rsquo;ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Almost all tasks within a Linux system, whether it’s an application, system daemon, or certain types of user activity, are executed by one or more <a href="https://tldp.org/LDP/tlk/kernel/processes.html">processes</a>. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we’ll look at:</p><ul><li>how <a href="#a-primer-on-the-process-tree">understanding the Linux process tree</a> can help you identify security threats</li><li>what <a href="#use-process-data-to-determine-the-scope-of-an-attack">process information</a> can help you determine the scope of a breach</li></ul><p>We’ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.</p><h2 id="a-primer-on-the-process-tree"><a href="#a-primer-on-the-process-tree">A primer on the process tree</a></h2><p>In Linux, each process is generated by a preceding <strong>parent</strong> process and can generate one or more <strong>child</strong> processes. Following this parent/child structure, active processes form a <strong>process tree</strong> that starts with the <code>systemd</code> process that runs when Linux first boots and ends with the most recently generated processes. This parent/child structure is particularly useful for revealing security threats because, unlike simple indicators of compromise (IOCs) like adversarial IP addresses or file hashes, it’s difficult to fake or change. For instance, while attackers can change an IP address, it’s much harder to hide that an application has spawned a new suspicious child process.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847" alt="process-tree.png"/></picture><figcaption>Active processes are structured as a process tree which can be used to help you spot signs of a security breach.</figcaption></figure></div><h2 id="identify-suspicious-processes"><a href="#identify-suspicious-processes">Identify suspicious processes</a></h2><p>As you monitor your applications, it’s important to look out for any launched shells or utilities (e.g., <code>bash</code> or <code>curl</code>) that are children of key processes in your environment. For example, if a Java application process generates a shell you aren’t anticipating, it could indicate that a malicious actor has infiltrated your app and launched a <a href="https://us-cert.cisa.gov/ncas/alerts/TA15-314A">web shell attack</a>. When these attacks are successful, they can create backdoors to your infrastructure that allow attackers to access sensitive data and execute commands without authorization.</p><p>Likewise, you should check if a process spawned utilities like <code>nmap</code>, which an attacker can use to survey your network for further vulnerabilities to exploit, or <code>passwd</code>, which can be used to change user passwords and grant attackers higher privileges.</p><p>Once you’ve identified a malicious process, it’s important to investigate the scope of the attack, including what information the attacker has potentially gained access to.</p><h2 id="use-process-data-to-determine-the-scope-of-an-attack"><a href="#use-process-data-to-determine-the-scope-of-an-attack">Use process data to determine the scope of an attack</a></h2><p>Linux processes include metadata that can help you determine the scope of an attack. The key types of information to look at are:</p><ul><li>environment variables</li><li>command-line arguments</li></ul><h3 id="environment-variables"><a href="#environment-variables">Environment variables</a></h3><p>Due to their <a href="#a-primer-on-the-process-tree">relationship</a>, child processes inherit access to any environment variables available to the parent process. Though it’s not considered best practice, environment variables are often used to store sensitive data like API and GitHub keys, or even database credentials. Using our example of an attacker successfully creating a web shell from a Java application process, the shell would be able to see any environment variables associated with your application process, such as database credentials for a SQL server containing sensitive customer data.</p><p>Examining what environment variables a process includes can help you determine the full scope of a threat. You can quickly view a list of a process’s environment variables by using the Linux command <code>ps faux</code> to get its PID and then running the following:</p><div><pre><code data-lang="text">cat /proc/&lt;PROCESS_PID&gt;/environ </code></pre></div><p>Please note, however, that this detection method only works while the process is running. This makes it challenging to view potential attacks without a <a href="#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security">continuous monitoring</a> tool.</p><h3 id="command-line-arguments"><a href="#command-line-arguments">Command-line arguments</a></h3><p>In addition to environment variables, it’s important to know what command-line arguments an attacker used when starting a malicious process. Command-line arguments hold information that’s critical to determining the nature of a security threat. Arguments may include identifying data like the IP address an attacker used when they issued a <code>curl</code> command to download a malicious payload, as well as activity data like <a href="https://stackabuse.com/encoding-and-decoding-base64-strings-in-python">encoded Python scripts</a> that were run directly in the command line. Insight into a process’s command-line arguments can help you view what occurred during an attack so you can plan how to respond.</p><p>For a quick look at a process’s command line arguments, get its PID and run a command like the following:</p><div><pre><code data-lang="text">ps -p &lt;PROCESS_PID&gt; -o args</code></pre></div><p>This approach, however, is limited because you need to be able to catch the process before it terminates. Next, we’ll look at how Datadog’s Cloud Workload Security helps you detect attacks and view relevant metadata.</p><h2 id="detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security"><a href="#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security">Detect threats in your Linux processes with Datadog Cloud Workload Security</a></h2><p>Datadog <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/">Cloud Workload Security (CWS)</a> analyzes the full process tree across all your Linux hosts and containers in real time to automatically detect the kind of threats we’ve looked at. Datadog includes <a href="https://docs.datadoghq.com/security_platform/default_rules/#cat-workload-security">out-of-the-box workload threat detection rules</a> that help you immediately respond to potential security threats by flagging suspicious behavior like the execution of <code>passwd</code> and <code>nmap</code> utilities.</p><p>In addition to out-of-the-box workload security rules, Datadog enables you to write your own custom rules. Security rules are constructed with <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/agent_expressions/"><strong>Agent Expressions</strong></a> that enable you to define what process activity to look for with as much specificity as you want. For example, you can instruct Datadog to detect if a Java process generated a <code>bash</code> shell, or even watch for processes run with specific command-line arguments. To learn more about how to construct your own custom workload security rules, check out our <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/workload_security_rules/">documentation</a>.</p><p>If Datadog detects any processes that match a rule, it will generate a <a href="https://docs.datadoghq.com/security_platform/security_monitoring/getting_started/#explore-security-signals">Security Signal</a>. Security Signals include full context around the suspicious process, including environment variable keys (without collecting the associated values), command-line arguments, and other metadata. You can use this information to quickly determine the scope of an attack before planning your response.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847" alt="Security signals include environment variables and command-line arguments which can help you determine the scope of security attacks."/></picture></figure></div><h2 id="start-today"><a href="#start-today">Start today</a></h2><p>No matter which distribution you work with, processes are at the heart of any Linux system. In this post, we looked at how understanding processes and their relationships can help you spot suspicious behavior and determine the severity of a security breach. Datadog Cloud Workload Security monitors process activity throughout your infrastructure at the kernel level in real time to reveal any suspicious or malicious behavior. Read our <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/getting_started/?tab=kubernetes">documentation</a> to learn more or sign up today for a 14-day <a href="#">free trial.</a></p></div></div>]]></content:encoded>
      <author>Jordan Obey</author>
      <pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>How to detect security threats in your systems&#39; Linux processes</title>
      <link>https://www.datadoghq.com/blog/linux-security-threat-detection-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/linux-process-hero.png&#34; width=&#34;100%&#34;/&gt;Almost all tasks within a Linux system, whether it&amp;rsquo;s an application, system daemon, or certain types of user activity, are executed by one or more processes. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we&amp;rsquo;ll look at: how understanding the Linux process tree can help you identify security threats what process information can help you determine the scope of a breach We&amp;rsquo;ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Almost all tasks within a Linux system, whether it’s an application, system daemon, or certain types of user activity, are executed by one or more <a href="https://tldp.org/LDP/tlk/kernel/processes.html">processes</a>. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we’ll look at:</p><ul><li>how <a href="#a-primer-on-the-process-tree">understanding the Linux process tree</a> can help you identify security threats</li><li>what <a href="#use-process-data-to-determine-the-scope-of-an-attack">process information</a> can help you determine the scope of a breach</li></ul><p>We’ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.</p><h2 id="a-primer-on-the-process-tree"><a href="#a-primer-on-the-process-tree">A primer on the process tree</a></h2><p>In Linux, each process is generated by a preceding <strong>parent</strong> process and can generate one or more <strong>child</strong> processes. Following this parent/child structure, active processes form a <strong>process tree</strong> that starts with the <code>systemd</code> process that runs when Linux first boots and ends with the most recently generated processes. This parent/child structure is particularly useful for revealing security threats because, unlike simple indicators of compromise (IOCs) like adversarial IP addresses or file hashes, it’s difficult to fake or change. For instance, while attackers can change an IP address, it’s much harder to hide that an application has spawned a new suspicious child process.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847" alt="process-tree.png"/></picture><figcaption>Active processes are structured as a process tree which can be used to help you spot signs of a security breach.</figcaption></figure></div><h2 id="identify-suspicious-processes"><a href="#identify-suspicious-processes">Identify suspicious processes</a></h2><p>As you monitor your applications, it’s important to look out for any launched shells or utilities (e.g., <code>bash</code> or <code>curl</code>) that are children of key processes in your environment. For example, if a Java application process generates a shell you aren’t anticipating, it could indicate that a malicious actor has infiltrated your app and launched a <a href="https://us-cert.cisa.gov/ncas/alerts/TA15-314A">web shell attack</a>. When these attacks are successful, they can create backdoors to your infrastructure that allow attackers to access sensitive data and execute commands without authorization.</p><p>Likewise, you should check if a process spawned utilities like <code>nmap</code>, which an attacker can use to survey your network for further vulnerabilities to exploit, or <code>passwd</code>, which can be used to change user passwords and grant attackers higher privileges.</p><p>Once you’ve identified a malicious process, it’s important to investigate the scope of the attack, including what information the attacker has potentially gained access to.</p><h2 id="use-process-data-to-determine-the-scope-of-an-attack"><a href="#use-process-data-to-determine-the-scope-of-an-attack">Use process data to determine the scope of an attack</a></h2><p>Linux processes include metadata that can help you determine the scope of an attack. The key types of information to look at are:</p><ul><li>environment variables</li><li>command-line arguments</li></ul><h3 id="environment-variables"><a href="#environment-variables">Environment variables</a></h3><p>Due to their <a href="#a-primer-on-the-process-tree">relationship</a>, child processes inherit access to any environment variables available to the parent process. Though it’s not considered best practice, environment variables are often used to store sensitive data like API and GitHub keys, or even database credentials. Using our example of an attacker successfully creating a web shell from a Java application process, the shell would be able to see any environment variables associated with your application process, such as database credentials for a SQL server containing sensitive customer data.</p><p>Examining what environment variables a process includes can help you determine the full scope of a threat. You can quickly view a list of a process’s environment variables by using the Linux command <code>ps faux</code> to get its PID and then running the following:</p><div><pre><code data-lang="text">cat /proc/&lt;PROCESS_PID&gt;/environ </code></pre></div><p>Please note, however, that this detection method only works while the process is running. This makes it challenging to view potential attacks without a <a href="#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security">continuous monitoring</a> tool.</p><h3 id="command-line-arguments"><a href="#command-line-arguments">Command-line arguments</a></h3><p>In addition to environment variables, it’s important to know what command-line arguments an attacker used when starting a malicious process. Command-line arguments hold information that’s critical to determining the nature of a security threat. Arguments may include identifying data like the IP address an attacker used when they issued a <code>curl</code> command to download a malicious payload, as well as activity data like <a href="https://stackabuse.com/encoding-and-decoding-base64-strings-in-python">encoded Python scripts</a> that were run directly in the command line. Insight into a process’s command-line arguments can help you view what occurred during an attack so you can plan how to respond.</p><p>For a quick look at a process’s command line arguments, get its PID and run a command like the following:</p><div><pre><code data-lang="text">ps -p &lt;PROCESS_PID&gt; -o args</code></pre></div><p>This approach, however, is limited because you need to be able to catch the process before it terminates. Next, we’ll look at how Datadog’s Cloud Workload Security helps you detect attacks and view relevant metadata.</p><h2 id="detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security"><a href="#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security">Detect threats in your Linux processes with Datadog Cloud Workload Security</a></h2><p>Datadog <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/">Cloud Workload Security (CWS)</a> analyzes the full process tree across all your Linux hosts and containers in real time to automatically detect the kind of threats we’ve looked at. Datadog includes <a href="https://docs.datadoghq.com/security_platform/default_rules/#cat-workload-security">out-of-the-box workload threat detection rules</a> that help you immediately respond to potential security threats by flagging suspicious behavior like the execution of <code>passwd</code> and <code>nmap</code> utilities.</p><p>In addition to out-of-the-box workload security rules, Datadog enables you to write your own custom rules. Security rules are constructed with <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/agent_expressions/"><strong>Agent Expressions</strong></a> that enable you to define what process activity to look for with as much specificity as you want. For example, you can instruct Datadog to detect if a Java process generated a <code>bash</code> shell, or even watch for processes run with specific command-line arguments. To learn more about how to construct your own custom workload security rules, check out our <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/workload_security_rules/">documentation</a>.</p><p>If Datadog detects any processes that match a rule, it will generate a <a href="https://docs.datadoghq.com/security_platform/security_monitoring/getting_started/#explore-security-signals">Security Signal</a>. Security Signals include full context around the suspicious process, including environment variable keys (without collecting the associated values), command-line arguments, and other metadata. You can use this information to quickly determine the scope of an attack before planning your response.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847" alt="Security signals include environment variables and command-line arguments which can help you determine the scope of security attacks."/></picture></figure></div><h2 id="start-today"><a href="#start-today">Start today</a></h2><p>No matter which distribution you work with, processes are at the heart of any Linux system. In this post, we looked at how understanding processes and their relationships can help you spot suspicious behavior and determine the severity of a security breach. Datadog Cloud Workload Security monitors process activity throughout your infrastructure at the kernel level in real time to reveal any suspicious or malicious behavior. Read our <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/getting_started/?tab=kubernetes">documentation</a> to learn more or sign up today for a 14-day <a href="#">free trial.</a></p></div></div>]]></content:encoded>
      <author>Jordan Obey</author>
      <pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Detect security threats with anomaly detection rules</title>
      <link>https://www.datadoghq.com/blog/anomaly-detection-rules-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/security-monitoring-anomaly-detection-hero.png&#34; width=&#34;100%&#34;/&gt;Securing your environment requires being able to quickly detect abnormal activity that could represent a threat. But today&amp;rsquo;s modern cloud infrastructure is large, complex, and can generate vast volumes of logs. This makes it difficult to determine what activity is normal and harder to identify anomalous behavior. Now, in addition to threshold and new term–based Threat Detection Rules, Datadog Security Monitoring provides the ability to create anomaly detection rules. With this detection method, Datadog will analyze relevant logs for the specific entities you query—hosts, IP addresses, users, etc.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Securing your environment requires being able to quickly detect abnormal activity that could represent a threat. But today’s modern cloud infrastructure is large, complex, and can generate vast volumes of logs. This makes it difficult to determine what activity is normal and harder to identify anomalous behavior. Now, in addition to <a href="https://docs.datadoghq.com/security_platform/security_monitoring/log_detection_rules/?tab=threshold#define-a-search-query">threshold</a> and <a href="https://www.datadoghq.com/blog/new-term-detection-method-datadog/#security-on-your-terms">new term</a>–based <a href="https://docs.datadoghq.com/security_platform/detection_rules/">Threat Detection Rules</a>, Datadog Security Monitoring provides the ability to create <a href="https://docs.datadoghq.com/security_platform/security_monitoring/log_detection_rules/?tab=anomaly">anomaly</a> detection rules. With this detection method, Datadog will analyze relevant logs for the specific entities you query—hosts, IP addresses, users, etc.—to identify historical trends and determine baseline behavior. Then, when it detects any type of deviation from this baseline, Datadog will create a <a href="https://www.datadoghq.com/blog/announcing-security-monitoring/#correlate-and-triage-security-signals">Security Signal</a> that includes a timeseries graph to illustrate what happened, enabling you to triage the event and take any necessary action.</p><h2 id="spot-anomalies-in-dynamic-activity"><a href="#spot-anomalies-in-dynamic-activity">Spot anomalies in dynamic activity</a></h2><p>Threshold-based detection rules can notify you if the frequency of certain activity exceeds a specific value (e.g., there are more than 100 access-denied requests from a user within a one-hour timeframe). For situations where you’re not able to establish a set threshold, you can use anomaly detection rules to dynamically generate thresholds based on historical behavior. This can be particularly helpful for monitoring unusual behavior across events like unique API calls, an influx in access denied requests, and more. In these cases, baseline activity is different entity to entity, so it can be difficult to define a set threshold that won’t potentially result in many false positives.</p><p>Let’s say you are monitoring your organization’s <a href="https://docs.datadoghq.com/integrations/google_cloud_platform/">Google Cloud Platform</a> service accounts. Service accounts connect to APIs to access the resources they need to run their workloads, so you expect to see API calls made regularly. If, however, a service account makes an unusual amount of API calls, it could mean that an account has been compromised and an attacker is attempting to access sensitive data. You can create an anomaly-based rule that monitors your audit logs for API activity and alerts you if an unusual volume of calls have been made.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=847" alt="anomaly-detection01.png"/></picture><figcaption>An anomaly detection rule that looks for an unusual number of API calls from a GCP service account.</figcaption></figure></div><p>Similarly, if you’re monitoring <a href="https://www.datadoghq.com/blog/monitor-salesforce-logs-datadog/#monitor-salesforce-user-activity-in-real-time">Salesforce user activity</a>, Datadog provides an out-of-the-box Threat Detection Rule that notifies you of any anomalous <a href="https://docs.datadoghq.com/security_platform/default_rules/salesforce-large-volume-of-query-activity/">spikes in query results</a>. While there may be periods when spikes in Salesforce user activity is the norm, anomalous spikes can signal that an unauthorized user may be attempting to access protected data and may require further investigation.</p><h2 id="analyze-security-signals"><a href="#analyze-security-signals">Analyze Security Signals</a></h2><p>If Datadog ingests logs that trigger an anomaly detection rule, Datadog will generate a Security Signal, notifying you of the nature of the anomaly as well as the window of time it occurred in so you can investigate further. Security Signals include key event data like IP addresses and usernames so you can, for instance, look at the user ID associated with an anomalous spike in Salesforce query results to determine if it is a recognized account or an attacker.</p><p>Any Security Signals that Datadog generates based on anomaly detection rules will remain “open” (i.e., continue to report data about the anomaly) as long as analyzed logs indicate the same anomalous behavior over a set interval, or until the anomaly exceeds a specified maximum signal duration (e.g., 24 hours), and has become the new baseline. This helps you determine when an anomaly first occurred, and whether it is still ongoing or has concluded.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=847" alt="Security signals can be generated by triggered anomaly detection rules."/></picture></figure></div><h2 id="get-started-today"><a href="#get-started-today">Get started today</a></h2><p>Datadog Security Monitoring’s anomaly-based detection rules identify and alert on anomalous behavior in your dynamic environment, making it easier to identify and investigate suspicious behavior when it appears. If you’re currently a Datadog customer, you can learn more about creating security rules <a href="https://docs.datadoghq.com/security_platform/security_monitoring/log_detection_rules/?tab=anomaly">here</a>. Otherwise, get started today with a 14-day <a href="#">free trial.</a></p></div></div>]]></content:encoded>
      <author>Jordan Obey</author>
      <pubDate>Wed, 18 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Datadog Announces Deep Database Monitoring</title>
      <link>https://www.datadoghq.com/about/latest-news/press-releases/datadog-announces-deep-database-monitoring/</link>
      <description>NEW YORK &amp;ndash; Datadog, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced the general availability of Database Monitoring (DBM). With insights into query performance and explain plans, as well as automatic correlation of query metrics with application and infrastructure metrics, Database Monitoring provides engineers and database administrators the visibility they need to quickly find and fix application performance issues that arise from slow running database queries.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><strong>NEW YORK</strong> – <a href="http://www.datadoghq.com">Datadog</a>, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced the general availability of Database Monitoring (DBM). With insights into query performance and explain plans, as well as automatic correlation of query metrics with application and infrastructure metrics, Database Monitoring provides engineers and database administrators the visibility they need to quickly find and fix application performance issues that arise from slow running database queries. </p><p>Database queries are often the root cause of incidents and application performance issues. When applications make unnecessary queries or fail to use indices, they burden the entire database, causing performance degradation for all applications using the database. Databases do not store historical query performance metrics, which makes it extremely difficult to understand the context around an issue and identify trends. This becomes even harder as engineers typically need to dig into each database individually to investigate, which prolongs downtime and exacerbates the impact on the customer experience.</p><p>Datadog Database Monitoring builds on the existing ability to monitor the general health and availability of the database and underlying infrastructure by allowing users to pinpoint the exact queries that impact application performance and user experience. With DBM, users can see the performance of database queries, troubleshoot slow queries with detailed execution breakdowns, and analyze historical trends in query latencies and overhead. This allows organizations to unlock improvements not only in database performance, but also in the performance of the upstream applications, APIs, and microservices that the database underpins.</p><p>DBM users are also able to automatically correlate query performance data with Datadog infrastructure metrics to easily identify resource bottlenecks. This allows engineers to quickly understand whether performance issues are at the database or infrastructure level, without needing to manually export and reconcile information from multiple, disconnected point solutions. Datadog’s unified data model makes it easy to search and filter information at scale with the same tags that are used everywhere in Datadog.</p><p>“Databases underpin today’s digital experiences. Consequently, a disruption in database uptime and performance can quickly have dramatic effects on business operations,” said Renaud Boutet, Senior Vice President, Product Management, Datadog. “The Datadog platform now enables database administrators and application engineers to detect and act on database issues by sharing the same data. This allows organizations to discover and implement improvements while saving time communicating and reconciling information.”</p><p>“The biggest observability challenge we face is proactively monitoring our databases&#39; performance,” said Chris Seltzer, Engineering Manager, Compass. “Datadog Database Monitoring enables our engineers on both the Product and Infrastructure teams to pinpoint query performance issues and ultimately avoid prolonged downtime that disrupts the end-user experience. The best part is that it’s all within a single tool.”</p><p>Datadog DBM delivers deep visibility into databases and enables organizations to:</p><ul><li>Quickly detect and isolate drops in performance. Users can track the performance of normalized queries across their entire fleet of databases, see which types of queries are executed the most and where they run, and get alerts for long running or expensive queries. For each query, they can drill down further to the hosts that are running that query, and leverage log and network information to understand host performance.</li><li>Pinpoint the root cause of performance drops. DBM provides quick access to explain plans, so users can view the sequence of steps that make up a query. This allows them to localize bottlenecks and identify opportunities to optimize performance and resource efficiency. </li><li>Improve and maintain database health, preventing incidents and saving costs. DBM enables organizations to keep historical query performance data for up to three months, so they can understand changes over time and prevent regressions. </li><li>Provide engineers access to database performance telemetry, without compromising data security. DBM offers a centralized view of database performance data, automatically correlated with infrastructure and application metrics, without requiring direct user access to database instances.</li></ul><p>Datadog DBM for Postgres and MySQL starts at $70 per database server. For more information, please visit <a href="https://www.datadoghq.com/product/database-monitoring/">https://www.datadoghq.com/product/database-monitoring/</a></p><div><p><strong>About Datadog</strong></p><p>Datadog is the monitoring and security platform for cloud applications. Our SaaS platform integrates and automates infrastructure monitoring, application performance monitoring and log management to provide unified, real-time observability of our customers’ entire technology stack. Datadog is used by organizations of all sizes and across a wide range of industries to enable digital transformation and cloud migration, drive collaboration among development, operations, security and business teams, accelerate time to market for applications, reduce time to problem resolution, secure applications and infrastructure, understand user behavior and track key business metrics.</p></div><p><strong>Forward-Looking Statements</strong></p><p>This press release may include certain “forward-looking statements” within the meaning of Section 27A of the Securities Act of 1933, as amended, or the Securities Act, and Section 21E of the Securities Exchange Act of 1934, as amended. These forward-looking statements reflect our current views about our plans, intentions, expectations, strategies and prospects, which are based on the information currently available to us and on assumptions we have made. Actual results may differ materially from those described in the forward-looking statements and are subject to a variety of assumptions, uncertainties, risks and factors that are beyond our control, including those risks detailed under the caption “Risk Factors” and elsewhere in our Securities and Exchange Commission filings and reports, including the Quarterly Report on Form 10-Q filed with the Securities and Exchange Commission on August 6, 2021, as well as future filings and reports by us. Except as required by law, we undertake no duty or obligation to update any forward-looking statements contained in this release as a result of new information, future events, changes in expectations or otherwise.</p></div></div>]]></content:encoded>
      <author>Datadog</author>
      <pubDate>Tue, 17 Aug 2021 21:43:00 +0000</pubDate>
    </item>
    <item>
      <title>Monitor and visualize database performance with Datadog Database Monitoring</title>
      <link>https://www.datadoghq.com/blog/database-performance-monitoring-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/database_monitoring_feature_announcement_210716_v3a.png&#34; width=&#34;100%&#34;/&gt;When you’re running databases at scale, finding performance bottlenecks can often feel like looking for a needle in a haystack. In any troubleshooting scenario, you need to know the exact state of your database at the onset of an issue, as well as its behavior leading up to it. But databases themselves do not store historical performance metrics, which makes it extremely difficult to identify trends and determine whether the issue is caused by inefficient queries, suboptimal database design, or resource saturation.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>When you’re running databases at scale, finding performance bottlenecks can often feel like looking for a needle in a haystack. In any troubleshooting scenario, you need to know the exact state of your database at the onset of an issue, as well as its behavior leading up to it. But databases themselves do not store historical performance metrics, which makes it extremely difficult to identify trends and determine whether the issue is caused by inefficient queries, suboptimal database design, or resource saturation. Developers also typically need to dig into each database individually to investigate, which prolongs downtime and other customer-facing issues.</p><p>Today, we’re excited to announce the release of <a href="https://app.datadoghq.com/databases">Database Monitoring</a>, which delivers deep visibility into databases across all of your hosts. With historical query performance metrics, explain plans, and host-level metrics all in one place, developers and database administrators can easily understand the health and performance of their databases and quickly troubleshoot any issues that arise.</p><p>In this post, we’ll show you how Database Monitoring enables you to:</p><ul><li><a href="#see-the-performance-of-normalized-queries-at-a-glance">See the performance of normalized queries at a glance</a></li><li><a href="#troubleshoot-slow-queries-with-detailed-explain-plans">Troubleshoot slow queries with detailed explain plans</a></li><li><a href="#analyze-historical-trends-in-query-performance">Analyze historical trends in query performance</a></li><li><a href="#explore-and-visualize-sampled-queries">Explore and visualize sampled queries</a></li><li><a href="#detect-infrastructure-level-issues-impacting-your-database">Detect infrastructure-level issues impacting your database</a></li></ul><h2 id="see-the-performance-of-normalized-queries-at-a-glance"><a href="#see-the-performance-of-normalized-queries-at-a-glance">See the performance of normalized queries at a glance</a></h2><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=847" alt="Track the performance of normalized queries with Datadog Database Monitoring"/></picture></figure></div><p>Inefficient queries can deplete your database’s resources and block other queries from running, so it’s important to identify and optimize them in order to ensure your application remains performant. Databases aggregate similar query statements into <a href="https://dev.mysql.com/doc/refman/8.0/en/performance-schema-statement-digests.html">normalized queries</a>—in which literal values, such as names, passwords, and dates, are replaced with question marks—to generate statistics that help database administrators troubleshoot issues with query execution. But because databases do not provide a way to sort or filter normalized queries, it can be challenging to identify the most problematic ones.</p><p>Database Monitoring enables you to track the performance of normalized queries across all of your hosts in a summary graph and sortable list, so you can see at a glance which types of queries are executed the most, how long they’re taking, how many rows are returned, and more. This helps you identify, for instance, if there are any long-running queries that return only a small number of rows, which could be a sign that your data is not indexed properly. You can also drill down to a smaller subset of queries using tags like <code>service</code>, <code>host</code>, and <code>cluster_name</code> to create a more focused view for your investigation.</p><h2 id="troubleshoot-slow-queries-with-detailed-explain-plans"><a href="#troubleshoot-slow-queries-with-detailed-explain-plans">Troubleshoot slow queries with detailed explain plans</a></h2><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=847" alt="View more details for each normalized query"/></picture></figure></div><p>If you notice that a particular normalized query is taking a long time to execute, you can click on it to open the Query Details panel, which includes detailed <a href="https://dev.mysql.com/doc/refman/8.0/en/execution-plan-information.html">explain plans</a> (also known as execution plans) for that particular query. An explain plan uses a node tree to map the sequence of steps chosen by the query planner to execute the query. Each node in the tree represents a single operation such as a table scan, sort, join, or aggregation.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=847" alt="See explain plans used to execute each query"/></picture></figure></div><p>In Database Monitoring, you can see the estimated cost of running each node, as well as the number of rows and bytes expected to be returned, which can help you identify operation hotspots. For instance, if your plan includes a costly sequential scan, you might want to consider creating indexes on important columns to encourage the database to use an index scan instead. Explain plans also show you how table joins are performed (i.e., which joins are used and in which order) so you can adjust your query if the query planner has selected a suboptimal plan.</p><h2 id="analyze-historical-trends-in-query-performance"><a href="#analyze-historical-trends-in-query-performance">Analyze historical trends in query performance</a></h2><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=847" alt="View timeseries graphs for key database performance metrics in the Metrics tab"/></picture></figure></div><p>Historical performance data provides crucial insight into changes in database behavior and the efficacy of your optimizations, but the database itself can only report statistics on its present state. Database Monitoring addresses this issue by providing timeseries graphs for key performance indicators of normalized queries, such as total execution time, number of requests, and shared block activity. These metrics, which are available in the Metrics tab of the Query Details panel, are stored at full granularity for three months, allowing you to track performance trends over the long term. You can easily add these graphs to any dashboard, such as your <a href="https://app.datadoghq.com/dash/integration/30404/mysql">MySQL</a> or <a href="https://app.datadoghq.com/dash/integration/235/postgres---overview">PostgreSQL</a> dashboards, and correlate them with higher-level metrics like throughput, replication, and connections for a more comprehensive view of your database’s performance.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=847" alt="Creating an anomaly monitor to notify us if any of our queries take abnormally long to execute"/></picture></figure></div><p>You can also set up automated alerts on any query metric to stay ahead of potential issues. For instance, you can create an <a href="https://docs.datadoghq.com/monitors/monitor_types/anomaly/">anomaly monitor</a> that will notify you if any query to your production cluster takes unusually long to execute, as shown in the screenshot above.</p><h2 id="explore-and-visualize-sampled-queries"><a href="#explore-and-visualize-sampled-queries">Explore and visualize sampled queries</a></h2><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=847" alt="Explore query samples from all of your databases"/></picture></figure></div><p>While normalized queries give you a high-level overview of database performance, sampled queries provide more granular insights. Datadog periodically collects a random sample of queries from all your databases—and enables you to see where each sample query was executed (i.e., on which host or application), along with other details such as its duration, cost, and explain plan. Datadog also converts sample query metadata into tags, which you can use to search, filter, and visualize individual queries when troubleshooting an issue or performing open-ended exploration. For example, you can use a table to group your most expensive queries by application in order to determine which ones you should optimize first.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=847" alt="Visualizing the execution plan cost of queries for each application in a table"/></picture></figure></div><h2 id="detect-infrastructure-level-issues-impacting-your-database"><a href="#detect-infrastructure-level-issues-impacting-your-database">Detect infrastructure-level issues impacting your database</a></h2><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=847" alt="Database Monitoring brings host metrics into the same view as your queries"/></picture></figure></div><p>Query optimization can resolve some database issues, but others may be rooted in the underlying infrastructure. Database Monitoring automatically correlates normalized queries with host metrics to help you easily identify resource bottlenecks that degrade the performance of your databases. In the Query Details panel, you can see which of your hosts are running that normalized query, along with throughput and client connection metrics that indicate how busy those hosts are. If you see that a particular host is handling a disproportionate amount of traffic, you may need to adjust your load balancer or scale up your resources. To gather more context, you can click on the host and navigate to its default dashboard, which can be customized to include data from any part of your stack. Similarly, as you’re performing analysis in Query Samples, you can click on a sampled query and pivot to its host’s dashboard, logs, and network data for lower-level insights.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=847" alt="Seamlessly pivot from a sampled query to its host&#39;s dashboard, logs, and network data"/></picture></figure></div><h2 id="start-using-database-monitoring-today"><a href="#start-using-database-monitoring-today">Start using Database Monitoring today</a></h2><p>Datadog Database Monitoring tracks historical query performance metrics, explain plans, and host-level metrics from every database in your environment, so you can better understand their performance and troubleshoot issues effectively. Database Monitoring currently supports MySQL 5.6+ and PostgreSQL 9.6+ databases, regardless of whether they’re self-hosted or fully managed. Check out our <a href="https://docs.datadoghq.com/database_monitoring/">documentation</a> to learn how to get started. And if you’re not yet using Datadog, sign up for a 14-day <a href="#">free trial</a> today.</p></div></div>]]></content:encoded>
      <author>Kai Xin Tai</author>
      <pubDate>Tue, 17 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Highlights from Black Hat USA 2021</title>
      <link>https://www.datadoghq.com/blog/blackhat-2021-highlights-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/blackhat-2021-highlights-datadog/black_hat_event_recap_210809_FINAL.png&#34; width=&#34;100%&#34;/&gt;Black Hat USA is one of the industry&amp;rsquo;s oldest and most well-established security events. Last year, the conference was held virtually for the first time in its history. This year’s conference brought together the best of both worlds, with a hybrid event that was held virtually and in person in Las Vegas.Historically, Black Hat has seen about 20,000 attendees at its in-person conference. This year’s Black Hat was no different from a numbers perspective, but the bulk of attendees actually attended virtually.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><a href="https://www.blackhat.com/us-21/">Black Hat USA</a> is one of the industry’s oldest and most well-established security events. Last year, the conference was held virtually for the first time in its history. This year’s conference brought together the best of both worlds, with a hybrid event that was held virtually and in person in Las Vegas.</p><p>Historically, Black Hat has seen <a href="https://www.crn.com/slide-shows/security/black-hat-is-back-scenes-from-the-show">about 20,000 attendees</a> at its in-person conference. This year’s Black Hat was no different from a numbers perspective, but the bulk of attendees actually attended virtually. <a href="https://www.businesswire.com/news/home/20210809005548/en/Black-Hat-USA-2021-Closes-on-the-Industry%E2%80%99s-First-and-Largest-Hybrid-Event">Black Hat reported</a> that nearly 14,600 attendees logged into Swapcard (the platform that hosted the virtual event), which likely makes it the largest hybrid conference in cybersecurity since the shift to virtual.</p><p>The Datadog team was excited to participate in this year’s conference as both an exhibitor and speaker. In this post, we’ll share highlights from the show floor, major themes from the conference, and our picks for noteworthy Briefings.</p><h2 id="notes-from-the-show-floor"><a href="#notes-from-the-show-floor">Notes from the show floor</a></h2><p>This year’s conference marked Datadog’s first time participating in the Black Hat Business Hall. Even though attendance was a little lower in person this year, we were especially excited to share our <a href="https://www.datadoghq.com/blog/cloud-security-posture-management/">Cloud Security Posture Management</a> product with this particular audience. We also announced the general availability of <a href="https://www.datadoghq.com/blog/datadog-workload-security/">Datadog Cloud Workload Security</a>, which monitors real-time file, process, and kernel activity in hosts and containers across your environment. Both are part of the <a href="https://www.datadoghq.com/product/security-platform/">Datadog Cloud Security Platform</a>, which protects an organization’s production environment with a full-stack offering providing threat detection and posture management, as well as workload and application security.</p><p>We were not surprised to see a good number of threat detection solutions on the show floor. SIEM (Security Information Event Management) has been a hot-ticket item for years now, and this event made it clear that it is still very much in high demand. Regardless of your choice of SIEM vendor, it’s clear that companies are increasingly seeking solutions that are cloud native, managed, and integrated with other security tooling, which can be key for maximizing usage.</p><p>Black Hat was also a treat for swag seekers everywhere. Whether you wanted to find a new T-shirt, socks, or even shop for an XDR solution, you’d find it all in the Black Hat Business Hall.</p><h2 id="black-hat-keynotes"><a href="#black-hat-keynotes">Black Hat keynotes</a></h2><p>With more than half of attendees joining the conference virtually, Black Hat’s keynotes were enhanced by an especially lively chat. Whether you attended a keynote from <a href="https://www.blackhat.com/us-21/briefings/schedule/#keynote-hacking-the-cybersecurity-puzzle-25068">Jen Easterly</a> (Director of the Cybersecurity and Infrastructure Security Agency), <a href="https://www.blackhat.com/us-21/briefings/schedule/index.html#keynote-secretary-alejandro-mayorkas-25100">Alejandro N. Mayorkas</a> (Secretary, Department of Homeland Security), <a href="https://www.blackhat.com/us-21/briefings/schedule/#supply-chain-infections-and-the-future-of-contactless-deliveries-24987">Matt Tait</a> (Chief Operating Officer, Corellium), or all of the above, you would have seen a ton of great questions coming in from the audience.</p><p>Across all three keynotes, the message was clear: collaboration will be key for moving our security efforts forward. DevOps has heralded breaking down barriers since its inception. With the rapid evolution of DevSecOps, the industry is now placing even greater emphasis on driving collaboration among development, security, and operations teams. We also expect that external government partnerships like CISA will help catapult private and public security to the next level.</p><h2 id="black-hat-briefings"><a href="#black-hat-briefings">Black Hat Briefings</a></h2><p>Every year, it seems like the breadth of material covered in Black Hat Briefings grows. It was refreshing to see a mixture of Black Hat veteran speakers and new faces. This year, two of the briefings stood out to us:</p><ul><li><a href="https://www.blackhat.com/us-21/briefings/schedule/index.html#cloudy-with-a-chance-of-apt-novel-microsoft--attacks-in-the-wild-23682">Cloudy with a Chance of APT: Novel Microsoft 365 Attacks in the Wild</a> was a great Briefing on the rise of cloud-targeted attacks. It’s worth noting that advanced nation-state threat actors are specifically targeting SaaS applications such as Microsoft 365. If you want to learn more about securing your Microsoft 365 environment, check out our <a href="https://www.datadoghq.com/blog/microsoft-365-integration/">blog post</a>.</li><li><a href="https://www.blackhat.com/us-21/briefings/schedule/#im-a-hacker-get-me-out-of-here-breaking-network-segregation-using-esoteric-command--control-channels-22851">I’m a Hacker Get Me Out of Here! Breaking Network Segregation Using Esoteric Command &amp; Control Channels</a> was one of the few Briefings that focused on privilege escalation and lateral movements. These topics often don’t get as much attention as they deserve in the cybersecurity space, as there is a lot of focus on infiltration. A <a href="https://www.datadoghq.com/product/security-platform/cloud-security-posture-management/">CSPM solution</a> can help with applying the principles of least privilege, while a <a href="https://www.datadoghq.com/product/security-platform/cloud-workload-security/">cloud workload security solution</a> can detect lateral movements.</li></ul><p>Datadog’s team of researchers also spoke at <a href="https://defcon.org/">DEF CON</a> and Black Hat on the relative attack surface of eBPF. We also shared <a href="https://github.com/Gui774ume/ebpfkit-monitor">ebpfkit-monitor</a>, an ethical hacking toolkit that detects and protects against suspicious eBPF activity at runtime. More information about our Black Hat Briefing is available <a href="https://www.blackhat.com/us-21/briefings/schedule/index.html#with-friends-like-ebpf-who-needs-enemies-23619">here</a>, and you can watch our DEF CON talk <a href="https://www.youtube.com/watch?v=5zixNDolLrg">here</a>.</p><h2 id="full-stack-security-with-datadog"><a href="#full-stack-security-with-datadog">Full-stack security with Datadog</a></h2><p>This year’s Black Hat conference gave us an invaluable opportunity to connect with the rest of the cybersecurity community, and we look forward to participating in more Black Hat events in the future. <a href="https://docs.datadoghq.com/security_platform/">Check out our docs</a> to learn more about how Datadog’s Cloud Security Platform can help break down barriers by helping every team across your organization leverage detailed observability data. If you’re not yet using Datadog, you can sign up for a <a href="#">free trial</a> today.</p></div></div>]]></content:encoded>
      <author>Huxley Barbee</author>
      <pubDate>Tue, 17 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Tracking Cloud Security Posture in a Dynamic Environment</title>
      <link>https://www.datadoghq.com/case-studies/marketplacer/</link>
      <description>About Marketplacer Established in 2017 in Australia, Marketplacer is a global technology platform-as-a-service (PaaS) company equipped with all the tools and functionality needed to build a successful and scalable online marketplace at speed. The Marketplacer platform exists to make growth simple. To date, the company has helped over 90 businesses execute their own successful marketplace strategies and connected over 20,000 businesses worldwide. Key Results Reduced MTTD and MTTR Datadog helps Marketplacer reduce the time it takes to identify and mitigate compliance issues via easy filtering and remediation guidance.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><h2 id="about-marketplacer">About Marketplacer</h2><p>Established in 2017 in Australia, Marketplacer is a global technology platform-as-a-service (PaaS) company equipped with all the tools and functionality needed to build a successful and scalable online marketplace at speed. The Marketplacer platform exists to make growth simple. To date, the company has helped over 90 businesses execute their own successful marketplace strategies and connected over 20,000 businesses worldwide.</p><span><hr/><h2 id="key-results">Key Results</h2><h4 id="reduced-mttd-and-mttr">Reduced MTTD and MTTR</h4><p>Datadog helps Marketplacer reduce the time it takes to identify and mitigate compliance issues via easy filtering and remediation guidance.</p><h4 id="unified-platform">Unified platform</h4><p>CSPM is built on the unified Datadog agent and cloud integrations, increasing cost and operational efficiency.</p><h4 id="600-resources-audited">600+ resources audited</h4><p>With Datadog, Marketplacer gets live configuration check results on the 600+ resources so they can track their compliance over time.</p><hr/><h2 id="challenge">Challenge</h2><p>Marketplacer is pursuing ISO:27001 certification and needed a solution to help them identify issues and track their progress along that journey. They needed visibility into the state of their compliance across their dynamic environment, and across different points in time. With a small security team, they wanted an easy-to-use solution that wouldn’t induce alert fatigue or require a high barrier to entry.</p><hr/><h2 id="why-datadog">Why Datadog?</h2><p>Datadog offers Marketplacer a fully integrated Cloud Security Posture Management solution that enables everyone on their team to easily drill down into security posture issues and get actionable links to resources for mitigation.</p><hr/></span></div><div><span><p>Understanding the state of your cloud security posture and the steps you need to take to mitigate misconfigurations is crucial for maintaining a strong security posture. At Marketplacer, keeping up to date with the state of their infrastructure compliance as they progressed toward an ISO:27001 certification was proving to be a challenge.</p><p>As Marketplacer began to expand internationally and work with larger customers, the infrastructure and security team organized around the goal of becoming compliant with ISO:27001 in order to meet the requirements of these new customers. As a cloud-native organization running on AWS, cloud security posture was a core element they needed to track and maintain. However, visibility into this area was limited—developers were working in silos when it came to configuring resources, and lacked a centralized way to manage configurations across the organization.</p><blockquote><p><em>“ Building a compliant and secure platform is a high priority for our customers. We want to be proactive with our security.”</em></p><p>Christian Kornacker<br/>DevOps Lead, Marketplacer</p></blockquote><p>Marketplacer increasingly saw the need for a solution that could help them detect and remediate misconfigurations and other issues quickly in a rapidly changing environment. Furthermore, as big proponents of infrastructure as code, they could easily provision large swathes of resources with a single command—but they needed guardrails in place to help them understand how each deployment would affect both their security posture and adherence to ISO:27001.</p><p>They set out to find a Cloud Security Posture Management solution that could meet their growing needs, but they didn’t like the high expertise requirements, noisy alerting, and complexity of the first few platforms they explored.</p><p>Marketplacer ultimately chose Datadog because it gives the engineers on the infrastructure and security team the ability to drill down into security posture issues as they crop up, with links to resources on how to remediate them. Additionally, Datadog allows them to track the results of their configuration checks each time they deploy, so they can better compare their security posture status across releases, and find ways to move closer to ISO:27001 compliance.</p><blockquote><p><em>“ Datadog is easy to use, but at the same time, very comprehensive. What I like about Datadog is that you don’t need to be a security or compliance expert to go through your misconfigurations and fix them across the team.”</em></p><p>Christian Kornacker<br/>DevOps Lead, Marketplacer</p></blockquote><p>Marketplacer leverages Datadog’s dashboards and executive reporting to get summaries and track conformance to specific industry benchmarking criteria. The out-of-the-box cloud configuration rules map to various benchmarks and relevant controls, making it easy for everyone across the company to understand and get value out of the platform. For a small but growing team, the dashboards and mitigation advice help reduce complexity. Marketplacer also sets up bespoke, actionable alerts for each team, enabling everyone to maximize the impact of time spent on monitoring and maintaining their security posture.</p><p>Each time Markerplacer updates or deploys new resources, the team can check their security posture dashboard in Datadog to see which resource configurations don’t match the available rules. Because Datadog provides rich context around those resources, the team can easily go back to their infrastructure as code definitions to mitigate any issues that arise that may impact their compliance.</p><blockquote><p><em>“ Datadog is the best I’ve seen when it comes to alerting. We can drill down to only see the issues that matter and reduce the noise. Each alert tells us why it exists and what to do about it—which is particularly helpful if you’re a junior infrastructure engineer.”</em></p><p>Christian Kornacker<br/>DevOps Lead, Marketplacer</p></blockquote><p>Additionally, Datadog continuously scans and surveys every resource, no matter how short-lived, so Marketplacer can answer tough questions and identify the state of their security posture down to specific resources and time frames.</p><p>Cloud Security Posture Management is part of the Datadog Cloud Security Platform, which helps an organization protect its production environment with a full-stack offering providing threat detection, posture management, workload security, and application security.</p><p>Because Datadog Cloud Security Posture Management is fully integrated with the rest of the Datadog platform as well, the Marketplacer team can get a single unified view of their environment. They also leverage Datadog for APM and logging, with a focus on finding problems before they impact customers. With the addition of Cloud Security Posture Management, Datadog lets them bring that same focus to security.</p><p>With a Cloud Security Posture Management solution that not only gives them visibility into their security posture, but also enables them to find actionable industry recommendations for resolving issues, Marketplacer is seeing significant reductions in their MTTD and MTTR. As they move closer to ISO:27001 certification, Marketplacer has also been able to proactively address any issues that arise before they impact customers.</p><blockquote><p><em>“ The speed and number of new configuration checks that Datadog adds on a regular basis is incredible. The trajectory of the product is so impressive.”</em></p><p>Christian Kornacker<br/>DevOps Lead, Marketplacer</p></blockquote></span></div></div>]]></content:encoded>
      <author>Datadog</author>
      <pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Monitor your entire serverless stack in the Serverless view</title>
      <link>https://www.datadoghq.com/blog/datadog-serverless-view/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/datadog-serverless-view/Serverless-view_Feature-Announcement_210729_v4a.png&#34; width=&#34;100%&#34;/&gt;Serverless event-driven architectures are composed of AWS Lambda functions that regularly interact with databases, APIs, message queues, and other resources to facilitate complex workflows and functionalities. It is therefore crucial to monitor every component of your stack to ensure your applications perform optimally at scale. But traditionally, telemetry data for AWS resources has lived in silos, making it difficult to quickly get the context you need to debug issues. For instance, if the end-to-end latency of a customer request to your application&amp;rsquo;s backend suddenly spiked, you would need to dig into each resource&amp;rsquo;s Amazon CloudWatch metrics and logs to figure out whether an overloaded database, throttled Lambda function, or misconfigured API Gateway endpoint was to blame.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Serverless event-driven architectures are composed of AWS Lambda functions that regularly interact with databases, APIs, message queues, and other resources to facilitate complex workflows and functionalities. It is therefore crucial to monitor every component of your stack to ensure your applications perform optimally at scale. But traditionally, telemetry data for AWS resources has lived in silos, making it difficult to quickly get the context you need to debug issues. For instance, if the end-to-end latency of a customer request to your application’s backend suddenly spiked, you would need to dig into each resource’s Amazon CloudWatch metrics and logs to figure out whether an overloaded database, throttled Lambda function, or misconfigured API Gateway endpoint was to blame.</p><p>As today’s serverless applications become increasingly complex, we’re excited to announce that we’ve fully redesigned the <a href="https://app.datadoghq.com/functions">Serverless view</a> to meet our customers&#39; need for a more seamless debugging experience. The new Serverless view unifies telemetry data from Lambda functions and other AWS resources to give you a full overview of your entire serverless stack—making it the ideal starting point for monitoring, debugging, and optimizing your applications.</p><h2 id="create-a-logical-view-of-your-serverless-application"><a href="#create-a-logical-view-of-your-serverless-application">Create a logical view of your serverless application</a></h2><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=847" alt="See all your serverless resources, grouped by service, in the newly-redesigned Serverless view"/></picture></figure></div><p>By default, the Serverless view groups your serverless resources by service to help you easily visualize how each part of your application is performing. For each service, you will see the functions that belong to it, along with the resources (Amazon API Gateway, SNS, SQS, DynamoDB, S3, EventBridge, Kinesis) that invoked them.</p><p>While grouping by service is the default, you can also group your resources by AWS CloudFormation stack name, as well as any other tags you’ve configured (e.g., team, project, or environment). Additionally, <a href="https://docs.datadoghq.com/logs/explorer/saved_views/">Saved Views</a> allows you to preserve your preferred way of grouping, so you don’t need to manually enter it every time you visit the page.</p><h2 id="detect-and-debug-performance-issues-across-your-stack"><a href="#detect-and-debug-performance-issues-across-your-stack">Detect and debug performance issues across your stack</a></h2><p>The Serverless view enables you to correlate high-level metrics from AWS resources with those of Lambda functions, so you can quickly spot issues and jump-start your investigation. In the example below, we can see that one of our Lambda functions is frequently invoked, which is causing our cloud costs to increase. But the age of the oldest message in the SQS queue that invokes the function is 0 seconds, which indicates that SQS is not under heavy load.</p><p>By clicking on the queue, we can seamlessly pivot to the default dashboard for SQS and view additional statistics on message and queue activity. As our application is not latency-sensitive, we can increase the <a href="https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html#events-sqs-eventsource">queue’s batch size</a>, such that more requests are processed by each Lambda invocation—reducing invocation count and costs.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=847" alt="Increased traffic to a SQS queue is causing a Lambda function to be frequently invoked"/></picture></figure></div><p>Or, say that in a different case, a monitor alerts us of elevated latency in API Gateway. In the Serverless view, we can immediately see that the <code>theme-park-initstate</code> function, which is invoked by our API, is experiencing increased throttling.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=847" alt="Correlated error rates in API Gateway and Lambda"/></picture></figure></div><p>To investigate, we can click on the problematic Lambda function to view a full list of its invocations, along with key metrics, traces, and logs. Datadog APM visualizes Lambda functions and the AWS resources they invoke all in one trace, so we can track the flow of requests across our distributed architecture and determine whether the issue has propagated to downstream resources.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=847" alt="Visualize the full lifespan of a request with Datadog APM"/></picture></figure></div><h2 id="start-monitoring-your-serverless-applications-in-the-serverless-view"><a href="#start-monitoring-your-serverless-applications-in-the-serverless-view">Start monitoring your serverless applications in the Serverless view</a></h2><p>All customers can now group their serverless resources using any tag in the new <a href="https://app.datadoghq.com/functions">Serverless view</a>. At this time, only Python and Node.js functions are tied to their related resources, but we plan to add support for more runtimes in the future. To get started, <a href="https://docs.datadoghq.com/serverless/installation">enable Datadog APM for tracing</a> and ensure you’re running Lambda Library v28+ for <a href="https://github.com/DataDog/datadog-lambda-python/releases">Python</a> and v49+ for Node.js. Or if you’re already using AWS X-Ray to trace your applications, all you need to do is <a href="https://docs.datadoghq.com/serverless/troubleshooting/connect_invoking_resources">add the Lambda Library to your functions</a>.</p><p>New to Datadog? Get started with a 14-day <a href="#">free trial</a> today.</p></div></div>]]></content:encoded>
      <author>Alex Cuoci</author>
      <pubDate>Fri, 06 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>How to monitor containerized and service-meshed network communication with Datadog NPM</title>
      <link>https://www.datadoghq.com/blog/monitor-containers-with-npm/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers-hero.png&#34; width=&#34;100%&#34;/&gt;Containers are lightweight, portable, easily scalable, and enable you to run multiple workloads on the same host efficiently, particularly when using an orchestration platform like Kubernetes or Amazon ECS. But containers also introduce monitoring challenges. Containerized environments may comprise vast webs of distributed endpoints and dependencies that rely on complex network communication. Adding further complexity, you need to ensure that each node in your cluster maintains contact with almost every other node.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><a href="https://www.datadoghq.com/container-report/">Containers</a> are lightweight, portable, easily scalable, and enable you to run multiple workloads on the same host efficiently, particularly when using an orchestration platform like Kubernetes or Amazon ECS. But containers also introduce monitoring challenges. Containerized environments may comprise vast webs of distributed endpoints and dependencies that rely on complex network communication. Adding further complexity, you need to ensure that each node in your cluster maintains contact with almost every other node. And containers are highly ephemeral, which makes IP-level connection data unreliable for tracking network traffic between these components, especially in the cloud.</p><p>Datadog <a href="https://docs.datadoghq.com/network_monitoring/performance/">Network Performance Monitoring</a> visualizes network traffic between objects within your entire containerized environment. This makes it easy to monitor network dependencies across all of your containers, services, and deployments so you can spot architectural and performance issues quickly. If you’re using a service mesh in your environment, Datadog NPM also enables you to analyze service mesh traffic to help identify traffic management misconfigurations and ensure the services in your mesh communicate efficiently.</p><p>In this post we’ll look at how you can use Datadog NPM to help you:</p><ul><li><a href="#visualize-your-containerized-architecture-with-the-network-map">visualize</a> network communication across your dynamic containerized infrastructure</li><li><a href="#get-full-visibility-into-each-layer-of-your-containerized-applications">troubleshoot</a> performance issues in containerized applications</li><li><a href="#analyze-service-mesh-and-proxied-traffic-health">analyze</a> service mesh traffic health</li></ul><h2 id="visualize-your-containerized-architecture-with-the-network-map"><a href="#visualize-your-containerized-architecture-with-the-network-map">Visualize your containerized architecture with the Network Map</a></h2><p>Containerized environments are highly distributed and can quickly grow in size and complexity, making them especially vulnerable to network issues. And, because each service may have many dependencies, an isolated problem can have an outsize impact on the rest of your application. This means visibility into network communication across your containerized workloads is key to monitoring the health and performance of your applications. But because containers churn often, tracking communication between them can be difficult.</p><p>Datadog’s <a href="https://docs.datadoghq.com/network_monitoring/performance/network_map/">Network Map</a> uses directional arrows, or <strong>edges</strong>, to visualize traffic flows between containers, pods, deployments, or other tagged objects in your environment, regardless of whether their constituent containers change. This gives you a real-time view of your network’s topology do you can spot architectural inefficiencies and misconfigurations. Visualizing traffic with edges can quickly reveal, for example, if Kubernetes pods in the same cluster are communicating through an <a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/">ingress controller</a> rather than directly to each other. Since you’d expect an ingress controller to be used for traffic between different clusters, intra-cluster ingress traffic indicates misconfiguration which can lead to increased latency.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=847" alt="npm-for-containers00.png"/></picture><figcaption>Use the Network Map to ensure there&#39;s expected traffic between pods. If there are no edges between pods, it could indicate a misconfiguration.</figcaption></figure></div><p>The Network Map’s visualization options enable you to tie issues like high TCP retransmits and latency to objects within your containerized infrastructure, like ECS tasks or Kubernetes deployments and pods. This enables you to determine at which layer of your environment network problems are occurring. Let’s say you use the Network Map to visualize the TCP latency across your services and see that there’s high latency between two services. You can inspect one of the services and then break the map down further by selecting <code>pod_name</code> in the View dropdown menu, enabling you to dig deeper by viewing latency in the context of your services&#39; underlying pods. This way, you can see if a particular pod is contributing to latency, indicated by thicker lines connected to a pod’s node.</p><p>Once you’ve identified a pod to investigate, you can view it in the <a href="https://app.datadoghq.com/orchestration/overview/pod">Orchestration Center</a> and see its specs (including status), resource consumption down to the process level, logs, and more. If the pod’s CPU usage is high, that is likely the culprit behind the latency you observed. Now that you’ve pinpointed the root cause, you can start taking mitigating steps to reduce latency, like scaling the pod.</p><h2 id="get-full-visibility-into-each-layer-of-your-containerized-applications"><a href="#get-full-visibility-into-each-layer-of-your-containerized-applications">Get full visibility into each layer of your containerized applications</a></h2><p>In containerized environments, requests can propagate across a number of components in your infrastructure. Because of this, it can be difficult to determine whether problems are due to network issues or possible code-level bugs. For example, pod connectivity problems can manifest as application latency or errors if your service can’t reach a dependency.</p><p><a href="https://docs.datadoghq.com/tracing/">Datadog APM</a> provides insight into issues at the application layer of your containerized environment in order to help determine the root cause of a problem. For instance, if you’ve identified a container running on EC2 that’s experiencing high request latency, you can dig into its traces to try to establish whether the cause is a code-level issue. If not, you can then easily pivot to the “Network” tab to view all network connections that are related to that service and identify if the problem stems from an upstream service (i.e., one application’s pods are overwhelmed with traffic from another application and can no longer respond to requests).</p><p>Datadog NPM also supports <a href="https://www.datadoghq.com/blog/monitor-dns-with-datadog/">DNS monitoring</a>, which means you can view the health of the communication between your pods and DNS servers to determine if a service discovery issue is preventing your client pod from finding the pods it needs to reach. You can easily identify which DNS servers (such as CoreDNS pods) may be contributing to the high response time or error rate of incoming DNS requests. Or, you can look for spikes in <code>NXDOMAIN</code> DNS responses. This can help determine whether a DNS server’s latency is a consequence of a client-side issue, like a pod making multiple invalid requests for every valid request, which may be overloading the DNS server.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog NPM supports DNS montiroing so you can view the health of the traffic between pods and DNS servers."/></picture></figure></div><h2 id="analyze-service-mesh-and-proxied-traffic-health"><a href="#analyze-service-mesh-and-proxied-traffic-health">Analyze service mesh and proxied traffic health</a></h2><p>Service meshes like <a href="https://istio.io/">Istio</a> help manage the access parameters and routing of microservice communication. But they also introduce further monitoring challenges by adding a layer of abstraction across your environment, making it challenging to get visibility into container communication. With Datadog Network Performance Monitoring, you can easily visualize traffic flow across <a href="https://www.datadoghq.com/blog/monitor-istio-with-npm/">Istio-managed networks</a>. And, Datadog’s <a href="https://docs.datadoghq.com/integrations/istio/#pagetitle">Istio integration</a> provides full visibility into every other aspect of your Istio environment. Datadog collects key <a href="https://docs.datadoghq.com/integrations/istio/#metrics">Istio metrics</a> to monitor bandwidth and request performance, <a href="https://docs.datadoghq.com/integrations/istio/#log-collection">logs</a> to investigate control plane health, and distributed <a href="https://docs.datadoghq.com/tracing/setup_overview/proxy_setup/?tab=istio">traces</a> from application requests propagating across your mesh.</p><p>Additionally, Datadog supports <a href="https://istio.io/latest/docs/ops/deployment/architecture/#envoy">Envoy</a> monitoring, enabling you to easily correlate Istio monitoring data with data from its Envoy proxy mesh. Because application containers route traffic through Envoy <strong>sidecars</strong> installed on their local pods to sidecars on separate pods, latency between pods could either be due to latency between application containers and their local Envoy sidecar or to latency between sidecars themselves. Datadog NPM tags Envoy sidecars as containers, which means if you do see latency between pods, you can use the Network Map to visualize the underlying container traffic and determine if it’s a service mesh issue.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=847" alt="npm-for-containers04.png"/></picture><figcaption>Visualize service mesh traffic by container_name to look at network communication between Envoy sidecars.</figcaption></figure></div><h2 id="start-monitoring-your-containerized-workloads-with-npm-today"><a href="#start-monitoring-your-containerized-workloads-with-npm-today">Start monitoring your containerized workloads with NPM today</a></h2><p>Whether you’re using orchestration tools like Kubernetes and Amazon ECS, relying on an Istio service mesh, or migrating to any of these platforms, Datadog Network Performance Monitoring provides you with full visibility into your containerized applications and their communication. To get started with NPM, follow the installation instructions <a href="https://docs.datadoghq.com/network_monitoring/performance/setup/?tab=agent#setup">here</a>. And, to learn about how <a href="https://www.deliveryhero.com/">Delivery Hero</a> was able to safely scale to meet 2X their orders in 2020 using Datadog NPM for visibility into their Kubernetes network, <a href="https://www.datadoghq.com/case-studies/deliveryhero-2021/">see the case study</a>.</p><p>If you’re new to Datadog, sign up today for a 14-day <a href="#">free trial.</a></p></div></div>]]></content:encoded>
      <author>Jordan Obey</author>
      <pubDate>Thu, 05 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>EFS Monitoring with Datadog</title>
      <link>https://www.datadoghq.com/blog/amazon-efs-monitoring-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/amazon_efs_longform_part-3v2.png&#34; width=&#34;100%&#34;/&gt;In Part 1 of this series, we looked at the key EFS metrics you should monitor, and in Part 2 we showed you how you can use tools from AWS and Linux to collect and alert on EFS metrics and logs. Monitoring EFS in isolation, however, can lead to visibility gaps as you try to understand the full context of your application&amp;rsquo;s health and performance. To meet the challenge of monitoring this dynamic storage system and its heterogeneous clients, you need to explore and alert on metrics and logs from EFS alongside data from your clients, related AWS services, and other key technologies.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>In <a href="https://www.datadoghq.com/blog/amazon-efs-metrics">Part 1</a> of this series, we looked at the key EFS metrics you should monitor, and in <a href="https://www.datadoghq.com/blog/amazon-efs-monitoring-tools">Part 2</a> we showed you how you can use tools from AWS and Linux to collect and alert on EFS metrics and logs. Monitoring EFS in isolation, however, can lead to visibility gaps as you try to understand the full context of your application’s health and performance. To meet the challenge of monitoring this dynamic storage system and its heterogeneous clients, you need to explore and alert on metrics and logs from EFS alongside data from your clients, related AWS services, and other key technologies.</p><p>Datadog provides complete EFS visibility, allowing you to monitor the size of your file systems and the behavior of the many different clients—EC2 instances, EKS pods, Lambda functions, and more—that access your data. In this post, we’ll show you how to:</p><ul><li><a href="#integrate-efs-with-datadog">Integrate EFS with Datadog</a></li><li><a href="#bring-on-the-metrics">Visualize EFS metrics</a></li><li><a href="#alert-on-efs-activity-and-performance">Alert on EFS activity and performance</a></li><li><a href="#collect-efs-logs">Collect EFS logs</a></li></ul><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=847" alt="The out-of-the-box EFS dashboard shows metrics that describe I/O, operation size, and configuration of multiple EFS file systems."/></picture></figure></div><h2 id="integrate-efs-with-datadog"><a href="#integrate-efs-with-datadog">Integrate EFS with Datadog</a></h2><p>Datadog’s AWS integration gives you deep visibility into EFS and the other AWS services you’re using, all in a single platform. In this section, we’ll show you how to add EFS to your AWS monitoring—or how to enable the AWS integration if you’re just getting started—so you can visualize, analyze, and alert on the performance of the AWS services you rely on.</p><h3 id="add-efs-to-your-aws-monitoring"><a href="#add-efs-to-your-aws-monitoring">Add EFS to your AWS monitoring</a></h3><p>If you’re already monitoring some AWS services, you can add EFS to the mix by clicking the <strong>Configuration</strong> tab on the <a href="https://app.datadoghq.com/account/settings#integrations/amazon-web-services">AWS Integration tile</a>. Check the “EFS” box under the “Limit metric collection by AWS Service” list, as well as the boxes for any other AWS services you want to add to your monitoring. If you’re using Lambda with EFS, check the “Lambda” box and follow the steps for <a href="https://docs.datadoghq.com/integrations/amazon_efs/#amazon-efs-for-lambda">enabling EFS for Lambda</a>.</p><p>Once you’ve checked the boxes for all the AWS services you want to monitor, click the “Update Configuration” button. Metrics will begin flowing into your Datadog account within a few minutes so you can quickly get started using EFS <a href="#bring-on-the-metrics">dashboards, tags, and alerts</a>.</p><h3 id="start-monitoring-efs-and-other-aws-services"><a href="#start-monitoring-efs-and-other-aws-services">Start monitoring EFS and other AWS services</a></h3><p>If you’re not yet monitoring AWS services with Datadog, you can start by installing the AWS integration with our <a href="https://www.datadoghq.com/blog/aws-1-click-integration/">1-click installation</a> process. The 1-click process is based on CloudFormation, and you’ll need to create an IAM role and an associated policy. Once you’ve completed the installation steps described in our <a href="https://www.datadoghq.com/blog/aws-1-click-integration/#click-here">blog post</a>, Datadog will begin automatically <a href="#bring-on-the-metrics">collecting EFS metrics</a>, as well as metrics from the other AWS services in your stack.</p><h2 id="bring-on-the-metrics"><a href="#bring-on-the-metrics">Bring on the metrics</a></h2><p>The <a href="https://app.datadoghq.com/screen/integration/30330/aws-efs">built-in EFS dashboard</a>—shown in the screenshot at the beginning of this post—brings together I/O metrics, throughput metrics, and burst credit balance data for all of the file systems in your account, so you can understand each file system’s health and performance at a glance.</p><p>You can easily <a href="https://docs.datadoghq.com/getting_started/dashboards/#start-by-reusing-other-dashboards">customize the dashboard</a> to graph EFS metrics alongside metrics from other AWS services. For example, <a href="https://docs.datadoghq.com/agent/amazon_ecs/?tab=awscli">Amazon ECS</a> Auto Scaling metrics could explain changes in the number of clients connecting to your file system and <a href="https://docs.datadoghq.com/integrations/amazon_sqs/">Amazon SQS</a> metrics might reveal a backlog of work your clients need to process. And you can add even more context to your EFS metrics by correlating them with data from any of Datadog’s more than
450 other integrations.</p><p>You can also leverage Datadog’s tagging system to organize, filter, and explore specific subsets of your data, such as the performance of an individual file system or even a specific client. Datadog automatically tags your EFS metrics to show the AWS account, file system, and region where they came from, and you can also add custom tags (for example, to identify the application for which a file system provides storage) from within the EFS console or by including them in a <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/quickref-efs.html">CloudFormation template</a>.</p><p>You can even <a href="https://docs.datadoghq.com/getting_started/tagging/">create common tags</a> across your metrics, logs, and traces so you can correlate them to understand the context of what you see on your dashboards. For example, if EFS metrics show that a file system’s burst credits are exhausted, you can seamlessly navigate to APM to see if any of your application’s services shows a corresponding increase in latency.</p><h2 id="alert-on-efs-activity-and-performance"><a href="#alert-on-efs-activity-and-performance">Alert on EFS activity and performance</a></h2><p>Dashboards let you visualize real-time metrics, but you can also create alerts to automatically notify you if the value of a metric crosses a threshold that could affect your file systems&#39; performance and your EFS costs.</p><p>For example, you may want to be notified if your file system is running out of <a href="https://www.datadoghq.com/blog/amazon-efs-metrics#metric-to-alert-on-i-o-utilization">IOPS</a> (by creating an alert on the <code>aws.efs.percent_iolimit</code> metric) or <a href="https://www.datadoghq.com/blog/amazon-efs-metrics#metric-to-alert-on-burst-credit-balance">burst credits</a> (<code>aws.efs.burst_credit_balance</code>) so you can proactively address an issue before it causes your application to slow down. And if you want to watch your file system for changes that could indicate cost anomalies or security concerns, you can create alerts to notify you of any unusual changes in metrics like <code>aws.efs.data_write_iobytes*</code> or <code>aws.efs.storage_bytes</code>, as shown in the screenshot below.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog&#39;s New Monitor screen defines an alert with a warning threshold of 180 GB and an alert threshold of 200 GB."/></picture></figure></div><p>An alert based on a threshold can keep you informed of unexpected changes in your metrics, but it can be hard to determine the value you should use for the threshold. <a href="https://docs.datadoghq.com/monitors/monitor_types/anomaly/">Anomaly-based monitors</a> can notify you automatically of changes that are out of line with a metric’s history so you don’t have to choose a threshold value to define what’s normal and expected. For example, the number of <a href="https://www.datadoghq.com/blog/amazon-efs-metrics#metric-to-alert-on-client-connections">clients connected</a> to your file system may be dynamic, but if it drops due to a configuration error that prevents new instances from connecting, an anomaly monitor can notify you of the unexpected change. In the screenshot below, the recent history of the <code>aws.efs.client_connections</code> metric appears on the left, and the expected future values of this metric appear in the gray band in the graph on the right.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=847" alt="The New Monitor screen for an Anomaly Monitor shows the history and the expected range of values of the connected clients metric."/></picture></figure></div><h2 id="collect-efs-logs"><a href="#collect-efs-logs">Collect EFS logs</a></h2><p>In Part 2 of this series, we showed you how you can publish <a href="https://www.datadoghq.com/blog/amazon-efs-monitoring-tools#mount-helper-logs">mount helper logs</a> and <a href="https://www.datadoghq.com/blog/amazon-efs-monitoring-tools#vpc-flow-logs">flow logs</a> to CloudWatch. In this section, we’ll show you how to forward those logs from CloudWatch to Datadog so you can explore and correlate them with logs from other technologies in your stack.</p><h3 id="enable-log-collection"><a href="#enable-log-collection">Enable log collection</a></h3><p>Once you’re sending your EFS logs to CloudWatch Logs, you can <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination/">route them to Datadog</a> by way of a <a href="https://docs.aws.amazon.com/firehose/latest/dev/what-is-this-service.html">Kinesis Data Firehose delivery stream</a>. Sending logs from EFS—and other AWS services—through Kinesis allows you to leverage AWS’s managed service for streaming logs and frees you from the challenges of managing concurrency and throttling that come with deploying your own <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-lambda-function/">Lambda forwarder</a>.</p><p>If you’re already collecting AWS service logs into a delivery stream in Firehose, you can add your EFS logs to the same stream. They’ll be delivered to Datadog alongside your other logs, but they’ll be distinguished by <code>service</code> and <code>source</code> values that show the name of the <a href="https://www.datadoghq.com/blog/amazon-efs-monitoring-tools#mount-helper-logs">CloudWatch log</a> group you configured to collect them.</p><p>If you’re not yet collecting AWS service logs through Firehose, create a delivery stream and <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination">configure Datadog as the destination</a>. Then, <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination/?tab=kinesisfirehosedeliverystream#send-aws-logs-to-your-kinesis-stream">add a subscription filter</a> to the CloudWatch log group where you’re collecting your EFS logs and set your Kinesis Data Firehose delivery stream as the filter’s destination. See the <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination/">documentation</a> for more information about sending AWS service logs into Datadog via Kinesis.</p><h3 id="explore-and-analyze-your-logs"><a href="#explore-and-analyze-your-logs">Explore and analyze your logs</a></h3><p>Datadog brings together logs from AWS services—including EFS—and many other technologies into a single platform, where you can explore and analyze them with the help of tags. Just as with <a href="#bring-on-the-metrics">metrics</a>, Datadog automatically tags your EFS logs to show the AWS account, region, and file system where they originated, and you can apply custom tags by adding parameters when you configure Datadog as the <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination">destination</a> for your delivery stream.</p><p>You can also add <a href="https://docs.datadoghq.com/logs/explorer/facets/">facets</a> to your tags to make it easy to group logs from related sources and present a fuller picture of activity across your stack. For example, if you apply an <code>application</code> tag to identify EFS logs originating from a specific application, you can apply the same tag to logs from your clients and related AWS services (e.g., an ELB that distributes incoming requests to your EC2 fleet). Then, you can <a href="https://docs.datadoghq.com/logs/explorer/facets/#create-facets">create a facet</a> based on that tag to group logs from all layers of your application.</p><p>In the screenshot below, we’ve created a facet on the <code>datadog_app</code> tag to isolate logs from a single application, and we’ve grouped them by <code>region</code> to show relative amounts of EFS traffic by geography. We’ve also filtered the logs using a <a href="https://docs.datadoghq.com/logs/explorer/facets/#quantitative-facets">measure</a>—a type of facet based on the value of a log field—to reveal logs that represent a large amount of write activity.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=847" alt="An area graph shows the rate of bytes written by EFS clients in each AWS region."/></picture></figure></div><h2 id="gain-full-visibility-into-efs-with-datadog"><a href="#gain-full-visibility-into-efs-with-datadog">Gain full visibility into EFS with Datadog</a></h2><p>EFS can serve a key role in your application, supporting simultaneous access across numerous clients, including <a href="https://docs.datadoghq.com/integrations/amazon_ec2/">EC2</a> instances, <a href="https://docs.datadoghq.com/integrations/amazon_lambda/">Lambda</a> functions, and <a href="https://www.datadoghq.com/blog/amazon-ecs-metrics/">Amazon Elastic Container Service (ECS)</a> tasks. Datadog gives you full visibility into each of these services, in addition to more than
450 other technologies, so you can monitor the health and performance of your file systems in context. If you’re not already using Datadog, start today with a <a href="#">14-day free trial</a>.</p><p><em>Source Markdown for this post is available <a href="https://github.com/DataDog/the-monitor/blob/master/efs/amazon-efs-monitoring-datadog.md">on GitHub</a>. Questions, corrections, additions, etc.? Please <a href="https://github.com/DataDog/the-monitor/issues">let us know</a></em></p></div></div>]]></content:encoded>
      <author>David M. Lentz</author>
      <pubDate>Thu, 05 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Key metrics for monitoring Amazon EFS</title>
      <link>https://www.datadoghq.com/blog/amazon-efs-metrics/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/amazon_efs_longform_part-1.png&#34; width=&#34;100%&#34;/&gt;Amazon Elastic File System (EFS) provides shared, persistent, and elastic storage in the AWS cloud. Like Amazon S3, EFS is a highly available managed service that scales with your storage needs, and it also enables you to mount a file system to an EC2 instance, similar to Amazon Elastic Block Store (EBS). But EFS offers other features—like simultaneous access from multiple clients and AWS Lambda integration—that make it well-suited for use cases such as big data workloads, machine learning, and serving web content.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><a href="https://aws.amazon.com/efs/">Amazon Elastic File System (EFS)</a> provides shared, persistent, and elastic storage in the AWS cloud. Like <a href="https://aws.amazon.com/s3/">Amazon S3</a>, EFS is a highly available managed service that scales with your storage needs, and it also enables you to mount a file system to an EC2 instance, similar to <a href="https://aws.amazon.com/ebs/">Amazon Elastic Block Store (EBS)</a>. But EFS offers other features—like simultaneous access from multiple clients and <a href="https://aws.amazon.com/blogs/compute/using-amazon-efs-for-aws-lambda-in-your-serverless-applications/">AWS Lambda integration</a>—that make it well-suited for use cases such as big data workloads, machine learning, and serving web content.</p><p>It’s important to monitor EFS latency, I/O, throughput, and connections in order to ensure the performance of the services and applications that access your file systems. Monitoring EFS can also help you understand costs, which are determined in part by the size and settings of your file systems. In this post, we’ll show you which Amazon EFS metrics are important to monitor, but first, let’s look at how EFS works.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=1140 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=1140&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=942 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=942&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=847" alt="I/O, throughput, and connection graphs shown on a Datadog built-in dashboard are useful in monitoring Amazon EFS."/></picture></figure></div><h2 id="an-overview-of-efs"><a href="#an-overview-of-efs">An overview of EFS</a></h2><p>EFS is based on the <a href="https://en.wikipedia.org/wiki/Network_File_System">Network File System (NFS)</a> protocol, and it automatically handles <a href="https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html#consistency">data consistency</a> and manages <a href="https://en.wikipedia.org/wiki/File_locking">file locking</a> to safely allow for parallel access from multiple clients. You can access EFS from EC2 instances, Lambda functions, <a href="https://aws.amazon.com/sagemaker/">Amazon SageMaker</a> notebook instances, and AWS <a href="https://aws.amazon.com/blogs/storage/best-practices-for-using-amazon-efs-for-container-storage/">container services</a> (ECS tasks and EKS pods running on EC2 or Fargate). If you’re using Direct Connect, you can also connect to EFS from on-premise hosts. This flexibility makes EFS appropriate for a variety of use cases: for example, you can store static website data in EFS and serve it from a fleet of EC2 instances or ECS tasks, or run a big data application comprised of Lambda functions that read the data, normalize it, and write it back to the file system.</p><p>By default, EFS stores copies of your data in multiple availability zones (AZs) and provides access to clients via <a href="https://docs.aws.amazon.com/efs/latest/ug/accessing-fs.html"><strong>mount targets</strong></a>. When you create a mount target, AWS creates an <a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_ElasticNetworkInterfaces.html">Elastic Network Interface (ENI)</a> in a subnet you specify, providing a local endpoint for all clients in that subnet (or clients that can <a href="https://docs.aws.amazon.com/efs/latest/ug/manage-fs-access-vpc-peering.html">route to it</a>). AWS recommends creating a mount target in each AZ to minimize latency and avoid cross-zone data transfer charges.</p><p>The diagram below shows an EFS file system that stores its data across two availability zones. A subnet in each AZ contains a mount target, and EC2 instances within the subnet communicate with the local mount target. The diagram also shows a Lambda function accessing the mount target in each subnet via ENIs that are <a href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html">created automatically</a> when the function is connected to the VPC.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=847" alt="A diagram of EFS architecture shows a file system inside a VPC. Two availability zones in the VPC contain EC2 instances connected to EFS mount targets. From outside the VPC, a Lambda function connects to the mount targets."/></picture></figure></div><p><a href="https://docs.aws.amazon.com/efs/latest/ug/efs-access-points.html"><strong>Access points</strong></a> enable you to limit a client’s access to a subset of a file system by specifying a path for the client to use as its root directory. You can create multiple access points to give different applications access to different subdirectories, and you can optionally configure an access point to <a href="https://docs.aws.amazon.com/efs/latest/ug/efs-access-points.html#enforce-identity-access-points">enforce a user identity</a> so that all clients access the data as a single user. You can also create a <a href="https://docs.aws.amazon.com/efs/latest/ug/iam-access-control-nfs-efs.html"><strong>file system policy</strong></a> to allow or deny connections to an access point.</p><p>A file system must have an access point in order for Lambda functions to connect to it. Other clients—EC2 instances, ECS tasks, EKS pods, and SageMaker notebooks—can mount a file system without using an access point if the file system policy will allow it, but this may give your applications <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#grant-least-privilege">greater access than necessary</a>.</p><h3 id="performance-modes"><a href="#performance-modes">Performance modes</a></h3><p>EFS operates in one of two <a href="https://docs.aws.amazon.com/efs/latest/ug/performance.html#performancemodes"><strong>performance modes</strong></a>, which influence the file system’s latency and I/O operations per second (IOPS). General Purpose mode is the default, and it provides the lowest latency for most use cases. Max I/O mode provides higher IOPS, although it adds some <a href="https://aws.amazon.com/premiumsupport/knowledge-center/linux-efs-performance-modes/">latency</a> to each operation. If your workload’s data access is parallelized across a large number of clients or processes—for example, training a machine learning algorithm—Max I/O can improve your application’s data storage and retrieval performance.
You can choose either performance mode without affecting your EFS costs, but you can’t change the performance mode of a file system after you’ve created it.</p><h3 id="throughput-modes"><a href="#throughput-modes">Throughput modes</a></h3><p>You can also choose your file system’s <a href="https://docs.aws.amazon.com/efs/latest/ug/performance.html#throughput-modes"><strong>throughput mode</strong></a>, which determines the amount of data your clients can read and write in each disk operation.
Bursting Throughput is the default mode. It provides a consistent baseline level of throughput that is proportional to your file system’s size, but it also allows you to burst above the baseline for relatively short periods of time. Your baseline throughput scales up as your file system grows, and your ability to burst increases (i.e., you accrue <strong>burst credits</strong>) as your file system operates below the baseline throughput rate.</p><p>If your application consistently requires throughput above the baseline level provided by Bursting Throughput mode, you can choose to use Provisioned Throughput mode instead. This mode allows you to specify a level of throughput that is always available regardless of the size of your file system. Provisioned Throughput mode carries an additional cost, but if the amount of data your application uses is small relative to your throughput needs—for example, a static website with high traffic—it can help you ensure that your file system is not a bottleneck for your application’s performance.</p><h3 id="storage-classes"><a href="#storage-classes">Storage classes</a></h3><p>Each file system you create in EFS keeps your data in one or more <a href="https://docs.aws.amazon.com/efs/latest/ug/storage-classes.html"><strong>storage classes</strong></a>, which provide different levels of availability and performance, and which incur different costs. The Standard storage class keeps data in multiple availability zones within the VPC where you created your file system. In contrast, the One Zone class stores data in a single AZ, which reduces both the <a href="https://docs.aws.amazon.com/efs/latest/ug/storage-classes.html#sc-compare">availability</a> of your data and the costs associated with storing it. These tradeoffs make the One Zone class most appropriate for storing temporary data that can be easily recreated, such as staging or build environments.</p><p>You can configure EFS to automatically move data from either of these classes to an infrequent access (IA) class—Standard-Infrequent Access or One Zone-Infrequent Access—if it is not accessed within a <a href="https://docs.aws.amazon.com/efs/latest/ug/lifecycle-management-efs.html">time frame you specify</a>. It’s less expensive to use IA classes, so storing unused data there can help you manage your EFS costs. But you must pay a per-access charge any time you retrieve data from IA, and the latency is higher, so it may or may not be your preferred storage option, depending on your data access patterns.</p><h2 id="key-amazon-efs-metrics-to-monitor"><a href="#key-amazon-efs-metrics-to-monitor">Key Amazon EFS metrics to monitor</a></h2><p>So far in this post, we’ve shown you how EFS provides shared storage to a variety of clients, and we’ve looked at the configuration options that let you balance availability, performance, and cost. In this section, we’ll walk you through the key metrics you should monitor to fully understand the health and performance of your file system. We’ll show you metrics from the following categories:</p><ul><li><a href="#storage-metrics">storage</a></li><li><a href="#latency-metrics">latency</a></li><li><a href="#io-metrics">I/O</a></li><li><a href="#throughput-metrics">throughput</a></li><li><a href="#connection-metrics">client connections</a></li></ul><p>Terminology in this section comes from our <a href="https://www.datadoghq.com/blog/monitoring-101-collecting-data/">Monitoring 101</a> series. Most of the metrics in this section are available from <a href="https://aws.amazon.com/cloudwatch/">Amazon CloudWatch</a>, but some come from Linux utilities. We’ll explore these and some other tools you can use to collect Amazon EFS metrics in <a href="https://www.datadoghq.com/blog/amazon-efs-monitoring-tools">Part 2</a> of this series.</p><h3 id="storage-metrics"><a href="#storage-metrics">Storage metrics</a></h3><p>EFS is elastic and will scale to provide more storage as your needs increase. But the size of your file system affects your EFS costs, so it’s important to track how much data you’re storing—overall and in each storage class—in order to understand and anticipate your monthly charges.</p><table><thead><tr><th>Name</th><th>Description</th><th>Metric type</th><th>Availability</th></tr></thead><tbody><tr><td>File size</td><td>Storage space used by a single file or directory</td><td>Resource: Utilization</td><td>Linux utilities</td></tr><tr><td>File system size</td><td>Aggregate storage space used by a file system</td><td>Resource: Utilization</td><td>CloudWatch, Linux utilities</td></tr></tbody></table><h4 id="metric-to-watch-file-size"><a href="#metric-to-watch-file-size">Metric to watch: File size</a></h4><p>Monitoring the size of individual files or directories can give you granular insight into your EFS usage. You should track the growth of files that contribute significantly to your overall usage—for example, fast-growing log files—to understand and accurately predict your application’s storage needs.</p><h4 id="metric-to-watch-file-system-size"><a href="#metric-to-watch-file-system-size">Metric to watch: File system size</a></h4><p>A typical disk utilization metric doesn’t apply in the case of EFS, which has no fixed upper limit on the amount of data you can store. But monitoring your file system size over time can show you how your application is storing and accessing data in three dimensions: the Standard storage classes, the IA storage classes, and in total.
If you’re using <a href="https://docs.aws.amazon.com/efs/latest/ug/lifecycle-management-efs.html">lifecycle management</a>, this metric will provide insight into how data shifts from Standard to IA storage classes. Seeing the rate of that shift can illustrate patterns in how your application accesses existing data.</p><h3 id="latency-metrics"><a href="#latency-metrics">Latency metrics</a></h3><p>Your file system’s performance mode and storage class can influence its latency, so you’ll want to keep an eye on your latency metrics to ensure that you’ve chosen the most optimal configuration. Because EFS is based on NFS, you can use the <code>nfsiostat</code> tool on an EC2 instance, ECS task (via <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/execute-command.html"><code>execute-command</code></a>), or EKS pod (via <a href="https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html"><code>kubectl</code></a>) to see the round-trip time required for that client to access data on any attached EFS file system. If you’re using EFS with Lambda, <a href="https://aws.amazon.com/codeguru/">Amazon CodeGuru Profiler</a> can help you visualize the time your application spends <a href="https://docs.aws.amazon.com/codeguru/latest/profiler-ug/working-with-visualizations-summary-page.html">waiting for disk operations</a> to complete.</p><table><thead><tr><th>Name</th><th>Description</th><th>Metric type</th><th>Availability</th></tr></thead><tbody><tr><td>Read round-trip time</td><td>The time between when the client sends a request to read data and when it receives the reply from EFS</td><td>Work: Performance</td><td>Linux utilities</td></tr><tr><td>Write round-trip time</td><td>The time between when the client sends a request to write data and when it receives the reply from EFS</td><td>Work: Performance</td><td>Linux utilities</td></tr></tbody></table><h4 id="metric-to-watch-readwrite-round-trip-time"><a href="#metric-to-watch-readwrite-round-trip-time">Metric to watch: Read/write round-trip time</a></h4><p>You can monitor EFS’s round-trip time (RTT) to understand how storage access contributes to your application’s overall latency. You may be able to reduce average RTT across all of your clients by ensuring that they are connecting to <a href="https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html">mount targets in their local availability zone</a> and by minimizing any competing network traffic within the VPC. If only some clients have a slow RTT, you should optimize the network performance of the relevant nodes—for example, by scaling up to a larger instance size—to prevent sporadic latency in your application. You should also ensure that your file system is using the optimal performance mode and storage class, as Infrequent Access storage classes and Max I/O performance mode generally have higher latencies.</p><h3 id="io-metrics"><a href="#io-metrics">I/O metrics</a></h3><p>Your I/O rate will increase as more clients access a shared file system, and your application’s access to storage could get throttled if your clients collectively require more IOPS than your file system can provide. It’s therefore important for you to monitor I/O utilization, especially if you’ve parallelized storage access across a large number of clients or processes.</p><p>You can use CloudWatch to monitor the I/O utilization of file systems that use General Purpose mode, but this metric isn’t available if you’re using Max I/O mode.</p><table><thead><tr><th>Name</th><th>Description</th><th>Metric type</th><th>Availability</th></tr></thead><tbody><tr><td>I/O utilization</td><td>The percentage of the file system’s available IOPS that is in use</td><td>Resource: Utilization</td><td>Availability: CloudWatch</td></tr></tbody></table><h4 id="metric-to-alert-on-io-utilization"><a href="#metric-to-alert-on-io-utilization">Metric to alert on: I/O utilization</a></h4><p>If your file system reaches its IOPS limit, your application could slow down as it waits to read and write data. You should create an alert that triggers when your file system approaches a specified percentage of its IOPS limit to give your team time to refactor or re-architect your application (e.g., to introduce a caching layer) before its performance degrades. Alternatively, you should consider moving to a new file system configured to use <a href="#performance-modes">Max I/O mode</a>.</p><h3 id="throughput-metrics"><a href="#throughput-metrics">Throughput metrics</a></h3><p>A file system’s throughput limit is determined by its performance mode, size, and level of activity. In Bursting Mode, the throughput limit changes based on the file system’s size and burst credit balance. In Provisioned Throughput mode, you specify the limit in the file system’s configuration. Monitoring the metrics described in this section can help you see whether insufficient throughput presents a risk to your application’s performance—or whether you’ve provisioned more throughput than your application requires.</p><table><thead><tr><th>Name</th><th>Description</th><th>Metric type</th><th>Availability</th></tr></thead><tbody><tr><td>Burst credit balance</td><td>The number of bytes of bursting throughput the file system has available</td><td>Resource: Utilization</td><td>CloudWatch</td></tr><tr><td>Permitted throughput</td><td>The amount of throughput available to the file system, in bytes per second</td><td>Work: Throughput</td><td>CloudWatch</td></tr><tr><td>Metered I/O bytes</td><td>The number of bytes used in reads, writes, and metadata operations on the file system</td><td>Resource: Utilization</td><td>CloudWatch</td></tr></tbody></table><h4 id="metric-to-alert-on-burst-credit-balance"><a href="#metric-to-alert-on-burst-credit-balance">Metric to alert on: Burst credit balance</a></h4><p>In Bursting Throughput mode, your file system can temporarily attain throughput rates above the baseline. The more burst credits you have, the longer you can sustain a higher throughput.</p><p>You accrue burst credits when you’re operating below the baseline throughput, and you spend burst credits when you’re operating above the baseline (i.e., bursting). If your burst credit balance reaches zero, your application’s access to your file system will be limited to the baseline throughput, which could cause user-facing latency.</p><p>Monitor burst credit balance to ensure that you have sufficient credits to support the data access patterns of your workloads. If you find that you are consistently running out of burst credits, you should consider switching to <a href="#throughput-modes">Provisioned Throughput mode</a>, which will enable you to define the amount of throughput you require.</p><h4 id="metric-to-watch-permitted-throughput"><a href="#metric-to-watch-permitted-throughput">Metric to watch: Permitted throughput</a></h4><p>Permitted throughput illustrates the throughput available to you at any moment, and it is calculated differently depending on which performance mode you’re using. In Bursting Throughput mode, this metric changes along with burst credit balance and file system size. If no burst credits are available, permitted throughput will be equal to the file system’s baseline throughput. In Provisioned Throughput mode, the value of this metric will equal the larger of your provisioned amount of throughput or the baseline throughput. If its value is lower than you expected, it could help explain any errors or latency in your application.</p><h4 id="metric-to-alert-on-meterediobytes"><a href="#metric-to-alert-on-meterediobytes">Metric to alert on: MeteredIOBytes</a></h4><p>CloudWatch aggregates the data used on read, write, and metadata operations into a <a href="https://docs.aws.amazon.com/efs/latest/ug/efs-metrics.html"><code>MeteredIOBytes</code></a> metric. If the value of this metric reaches your file system’s permitted throughput, your application’s access will be limited, which could cause user-facing latency. Create an alert on <code>MeteredIOBytes</code> as a percentage of permitted throughput so you can <a href="#throughput-modes">provision</a> enough throughput to meet your application’s requirements and prevent application latency.</p><h3 id="connection-metrics"><a href="#connection-metrics">Connection metrics</a></h3><p>EFS supports <a href="https://docs.aws.amazon.com/efs/latest/ug/limits.html#limits-efs-resources-per-account-per-region">thousands of connections per file system</a>, but even if you’re not at risk of surpassing that limit, it can be helpful to monitor each file system’s connection count to watch for unexpected changes. Fewer connections than usual could indicate a problem with an application or the network. And if you see more connections than you expect, you could have a security issue or an auto-scaling anomaly that you need to investigate.</p><table><thead><tr><th>Name</th><th>Description</th><th>Metric type</th><th>Availability</th></tr></thead><tbody><tr><td>Client connections</td><td>A count of all the clients connected to the file system</td><td>Resource: Utilization</td><td>CloudWatch</td></tr></tbody></table><h4 id="metric-to-alert-on-client-connections"><a href="#metric-to-alert-on-client-connections">Metric to alert on: Client connections</a></h4><p>Your file system’s I/O is a limited resource—especially if you’re using General Purpose mode—and an upward trend in your connection count could be one cause of an increase in <a href="#io-metrics">IOPS</a>. If your application typically has a steady number of clients accessing your file system, you should create an alert to notify you if the client connections metric rises above normal so you can evaluate whether you’re at risk of running out of IOPS.</p><h2 id="monitor-efs-performance-for-healthy-storage"><a href="#monitor-efs-performance-for-healthy-storage">Monitor EFS performance for healthy storage</a></h2><p>In this post, we’ve shown you how EFS works and which EFS metrics you can track to understand your file system’s performance. It’s important to monitor your file system’s latency, I/O, and throughput, as well as your usage, to ensure the health of your application and troubleshoot any bottlenecks that arise. Coming up in <a href="https://www.datadoghq.com/blog/amazon-efs-monitoring-tools">Part 2</a>, we’ll show you some of the tools you can use to gather logs and metrics from EFS.</p><h2 id="acknowledgments"><a href="#acknowledgments">Acknowledgments</a></h2><p>We’d like to thank Ray Zaman at AWS for their technical review of this post.</p><p><em>Source Markdown for this post is available <a href="https://github.com/DataDog/the-monitor/blob/master/efs/amazon-efs-metrics.md">on GitHub</a>. Questions, corrections, additions, etc.? Please <a href="https://github.com/DataDog/the-monitor/issues">let us know</a>.</em></p></div></div>]]></content:encoded>
      <author>David M. Lentz</author>
      <pubDate>Thu, 05 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Amazon EFS monitoring tools</title>
      <link>https://www.datadoghq.com/blog/amazon-efs-monitoring-tools/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/amazon_efs_longform_part-2.png&#34; width=&#34;100%&#34;/&gt;In Part 1 of this series, we looked at EFS metrics from several different categories—storage, latency, I/O, throughput, and client connections. In this post, we&amp;rsquo;ll show you how you can collect those metrics—as well as EFS logs—using built-in and external tools. We&amp;rsquo;ll look at how to: view metrics in the EFS console use the CloudWatch console and API collect metrics with Linux tools collect EFS logs with AWS logging services and Linux logging tools Collect EFS metricsCollecting and analyzing EFS metrics can help you understand your file systems&#39; role in the health and performance of your applications.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>In <a href="https://www.datadoghq.com/blog/amazon-efs-metrics">Part 1</a> of this series, we looked at EFS metrics from several different categories—storage, latency, I/O, throughput, and client connections. In this post, we’ll show you how you can collect those metrics—as well as EFS logs—using built-in and external tools. We’ll look at how to:</p><ul><li>view metrics in <a href="#the-efs-console">the EFS console</a></li><li>use the <a href="#cloudwatch">CloudWatch</a> console and API</li><li>collect metrics with <a href="#linux-tools">Linux tools</a></li><li>collect EFS logs with <a href="#aws-logging-services">AWS logging services</a> and <a href="#non-aws-logging-tools">Linux logging tools</a></li></ul><h2 id="collect-efs-metrics"><a href="#collect-efs-metrics">Collect EFS metrics</a></h2><p>Collecting and analyzing EFS metrics can help you understand your file systems&#39; role in the health and performance of your applications. Because EFS is a managed service, some standard approaches to monitoring, such as monitoring server resource metrics, are not applicable. In this section, we’ll look at some tools provided by AWS and some that are built into Linux that let you collect and visualize key EFS metrics.</p><h3 id="the-efs-console"><a href="#the-efs-console">The EFS console</a></h3><p>You can use the EFS console, which is available from within the <a href="https://console.aws.amazon.com/">AWS Management Console</a>, to create and delete file systems, define their settings, and manage mount targets and access points. You can also see graphs of key metrics we looked at in <a href="https://www.datadoghq.com/blog/amazon-efs-metrics">Part 1</a> of this series, such as throughput, I/O, client connections, and storage, to visualize the performance of each file system over time.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=847" alt="Graphs of file system metrics shown on the EFS console include throughput, IOPS, connection, and storage data."/></picture></figure></div><h3 id="cloudwatch"><a href="#cloudwatch">CloudWatch</a></h3><p>While the EFS console is a good way to quickly begin monitoring your EFS file systems, <a href="https://aws.amazon.com/cloudwatch/">Amazon CloudWatch</a> allows you to monitor, correlate, and alert on the performance of EFS and the other AWS services you use. In this section, we’ll show you how to use the CloudWatch console to visualize the data that CloudWatch collects, and we’ll introduce you to the CloudWatch API, which allows you to retrieve EFS metrics programmatically.</p><h4 id="cloudwatch-console"><a href="#cloudwatch-console">CloudWatch console</a></h4><p>The CloudWatch console for EFS—shown in the screenshot below—includes a built-in dashboard that expands on the data shown in the <a href="#the-efs-console">EFS console</a> and visualizes connections, IOPS, burst credits, and throughput data from multiple file systems at once.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=847" alt="The CloudWatch service dashboard for EFS graphs data from multiple file systems, visualizing connection, IOPS, burst credit, and throughput data."/></picture></figure></div><p>You can open any one of these graphs in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/working_with_metrics.html">CloudWatch metrics</a>, where you can modify it and add it to a custom dashboard. Custom dashboards allow you to graph metrics from multiple AWS services in a single view or even on the same graph, so you can quickly explore possible causes of an issue you need to troubleshoot.
For example, the graph in the screenshot below shows the <code>BurstCreditBalance</code> value for an EFS file system decreasing as the rate of a Lambda function’s <code>Invocations</code> rises. This correlation suggests that the Lambda function’s increased disk activity could be consuming the available burst credits, which, as discussed in the section on <a href="https://www.datadoghq.com/blog/amazon-efs-metrics#throughput-metrics">throughput metrics</a> in Part 1 of this series, could ultimately cause user-facing latency.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=847" alt="A CloudWatch graph shows the burst credit balance metric for a file system declining while the rate of invocations of a Lambda function increases."/></picture></figure></div><p>You can create an <a href="https://docs.aws.amazon.com/efs/latest/ug/creating_alarms.html">alarm</a> for any metric you see in the CloudWatch console by defining a threshold value for the metric and an <a href="https://aws.amazon.com/sns/">SNS topic</a> to which AWS will automatically send a message if the metric breaches that value. You can also create anomaly-based CloudWatch Alarms to automatically notify you, for example, if the number of clients connected to your file system changes significantly from its historical range of values.</p><h4 id="cloudwatch-api"><a href="#cloudwatch-api">CloudWatch API</a></h4><p>In the previous section, we discussed how the CloudWatch console lets you visualize and alert on EFS metrics. You can also fetch EFS metrics programmatically from the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/making-api-requests.html">CloudWatch API</a> via AWS SDKs or the AWS command-line interface (CLI). The AWS <a href="https://aws.amazon.com/tools/">SDKs</a> enable you to call the API with Python, Ruby, Go, and <a href="https://aws.amazon.com/tools/#SDKs">many other languages</a>, so you can integrate EFS monitoring into your processes or applications. In contrast, the <a href="https://aws.amazon.com/cli/">CLI</a> is useful for manually executing ad hoc queries or creating scripts that automatically collect metrics.</p><p>To use the AWS CLI, you’ll first need to <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html">install it</a> on the host where you’ll execute the API calls. You’ll also need to configure the necessary authentication, for example by using an <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html">EC2 instance profile</a>.</p><p>To get CloudWatch metrics through the CLI, you use the <code>cloudwatch</code> subcommand. The example below uses the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_GetMetricStatistics.html"><code>get-metric-statistics</code></a> action to retrieve the value of the <code>StorageBytes</code> metric from the <code>AWS/EFS</code> <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Namespace">namespace</a>. The command includes <code>start-time</code> and <code>end-time</code> parameters to scope the request to a one-hour time frame, a <code>period</code> parameter to aggregate the metrics every 15 minutes, and a <code>statistics</code> parameter to request a sum of the collected metric values. The <code>dimensions</code> parameter holds key-value pairs to define the file system (<code>FileSystemId</code>) and the <a href="https://www.datadoghq.com/blog/amazon-efs-metrics#metric-to-watch-file-system-size">storage class</a> (<code>StorageClass</code>) to query.</p><div><pre><code data-lang="text">aws cloudwatch get-metric-statistics \
--metric-name StorageBytes \
--start-time 2021-04-02T16:35:00 \
--end-time 2021-04-02T17:35:00 \
--period 900 \
--statistics Sum \
--namespace AWS/EFS \
--dimensions Name=FileSystemId,Value=&lt;MY-FILE-SYSTEM-ID&gt; Name=StorageClass,Value=Total</code></pre></div><p>The <code>get-metric-statistics</code> action returns a JSON object like the one shown below. This example result contains four records, one every 15 minutes over the one-hour time frame specified in the request. Note that CloudWatch does not guarantee that records returned by <code>get-metric-statistics</code> will appear in chronological order.</p><div><pre><code data-lang="text">{
    &#34;Label&#34;: &#34;StorageBytes&#34;,
    &#34;Datapoints&#34;: [
        {
            &#34;Timestamp&#34;: &#34;2021-04-02T16:50:00+00:00&#34;,
            &#34;Sum&#34;: 4220928.0,
            &#34;Unit&#34;: &#34;Bytes&#34;
        },
        {
            &#34;Timestamp&#34;: &#34;2021-04-02T17:05:00+00:00&#34;,
            &#34;Sum&#34;: 4220928.0,
            &#34;Unit&#34;: &#34;Bytes&#34;
        },
        {
            &#34;Timestamp&#34;: &#34;2021-04-02T16:35:00+00:00&#34;,
            &#34;Sum&#34;: 2123776.0,
            &#34;Unit&#34;: &#34;Bytes&#34;
        },
        {
            &#34;Timestamp&#34;: &#34;2021-04-02T17:20:00+00:00&#34;,
            &#34;Sum&#34;: 4220928.0,
            &#34;Unit&#34;: &#34;Bytes&#34;
        }
    ]
}</code></pre></div><p>See the <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/efs/index.html">AWS CLI documentation</a> to learn more about interacting with the <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudwatch/index.html">CloudWatch API</a>. And to find more information on the CloudWatch metrics available in the EFS namespace, see the <a href="https://docs.aws.amazon.com/efs/latest/ug/efs-metrics.html">EFS documentation</a>.</p><h3 id="linux-tools"><a href="#linux-tools">Linux tools</a></h3><p>If your EFS client is a Linux-based EC2 instance (EFS does not support Windows), you can use Linux utilities to collect metrics that describe the file system and the performance of the client. In this section, we’ll show you how to query an instance to see the size of its mounted file systems, as well as per-client metrics that aren’t available in CloudWatch: the <a href="https://www.datadoghq.com/blog/amazon-efs-metrics#latency-metrics">latency</a>, <a href="https://www.datadoghq.com/blog/amazon-efs-metrics#throughput-metrics">throughput</a>, and error rate of its EFS read and write operations.
To execute the commands shown in this section, you can SSH to your instance’s command line or use <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/execute-remote-commands.html">AWS Systems Manager Run Command</a>. On EKS, you can use <a href="https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html"><code>kubectl</code></a> to execute these commands, and on ECS, you can use <a href="https://aws.amazon.com/blogs/containers/new-using-amazon-ecs-exec-access-your-containers-fargate-ec2/">ECS Exec</a>. And although Lambda doesn’t provide a CLI, we’ll show you an example of how you can query a file system’s size from within a Lambda function.</p><h4 id="determine-the-storage-used-by-a-file-system"><a href="#determine-the-storage-used-by-a-file-system">Determine the storage used by a file system</a></h4><p>AWS calculates and charges for EFS storage based on <a href="https://docs.aws.amazon.com/efs/latest/ug/metered-sizes.html"><strong>metered size</strong></a>—the space required to store your objects and metadata. Knowing the size of your file system can help you spot unexpected changes in the amount of data your application is storing and can even help you estimate your EFS costs. On a Linux host, you can use the <a href="https://en.wikipedia.org/wiki/Df_(Unix)"><code>df</code></a> tool to see the total space used by a mounted file system, which means you can use <code>df</code> to view the metered size of your EFS file systems. It’s important to note, however, that because the data <code>df</code>provides is <a href="https://docs.aws.amazon.com/efs/latest/ug/metered-sizes.html#metered-sizes-fs">eventually consistent</a>, you should not rely on it for real-time data.</p><p>In addition to viewing the aggregate size of your file system, you may also need to track the sizes of individual objects. Log files, for example, accumulate data over time and can influence your overall storage needs. You can use the <a href="https://en.wikipedia.org/wiki/Du_(Unix)"><code>du</code></a> and <code>stat</code> tools to view the size of any single file you’ve stored in EFS. The command below allows you to see the size of the file <strong>myFile</strong> located in the file system mounted at <strong>/mnt/myFileSystem</strong>:</p><div><pre><code data-lang="text">stat /mnt/myFileSystem/myFile</code></pre></div><p>As shown below, <code>stat</code>’s output includes additional information beyond the file’s size, such as the number of blocks used by the file, its inode, its permissions, and the file’s creation and modification history.</p><div><pre><code data-lang="text">  File: ‘/mnt/myFileSystem/myFile’
  Size: 3048448000	Blocks: 5954000    IO Block: 1048576 regular file
Device: 26h/38d	Inode: 16195615950234888882  Links: 1
Access: (0664/-rw-rw-r--)  Uid: ( 1000/ec2-user)   Gid: ( 1000/ec2-user)
Access: 2021-04-27 21:48:50.398000000 +0000
Modify: 2021-04-27 21:48:50.398000000 +0000
Change: 2021-04-27 21:48:50.398000000 +0000</code></pre></div><p>See the <a href="https://docs.aws.amazon.com/efs/latest/ug/metered-sizes.html">AWS documentation</a> for more information about how to view the metered size of both your file system and the individual objects it contains.</p><h4 id="see-the-aggregate-size-of-a-file-system-from-a-lambda-function"><a href="#see-the-aggregate-size-of-a-file-system-from-a-lambda-function">See the aggregate size of a file system from a Lambda function</a></h4><p>If your EFS client is a Lambda function, you don’t have access to a command line, but some Lambda runtimes allow you to include code in your function that can collect storage metrics. For example, Python’s <a href="https://docs.python.org/3/library/index.html">standard library</a> includes a <a href="https://docs.python.org/3/library/shutil.html"><code>shutil</code></a> package that you can use to check the size of a file system. The following function uses the <code>disk_usage</code> method to check the disk space used by the file system mounted at <strong>/mnt/myFileSystem</strong>:</p><div><pre><code data-lang="text">import shutil

def lambda_handler(event, context):
    return {
        &#39;output&#39;: shutil.disk_usage(&#34;/mnt/myFileSystem&#34;)
    }</code></pre></div><p>This function returns a JSON object like the one shown below. In our case, it shows that the file system is using slightly less than 3,600 MB of storage space.</p><div><pre><code data-lang="text">{
  &#34;output&#34;: {
    &#34;total&#34;: 9223372036853727000,
    &#34;used&#34;: 3598712832,
    &#34;free&#34;: 9223372033255014000
  }
}</code></pre></div><h4 id="measure-efs-performance-with-nfsiostat"><a href="#measure-efs-performance-with-nfsiostat">Measure EFS performance with <code>nfsiostat</code></a></h4><p>To attach your EC2 instance to EFS, AWS recommends that you install the <a href="https://github.com/aws/efs-utils"><code>amazon-efs-utils</code></a> package, which includes an NFS client. This means you can use the <code>nfsiostat</code> utility to view some of the key metrics covered in <a href="https://www.datadoghq.com/blog/amazon-efs-metrics">Part 1</a> of this series, including throughput (<code>kB/s</code>) and latency (<code>avg RTT</code>). For example, to see metrics from the file system mounted at <strong>/mnt/myFileSystem</strong>, you can use this command:</p><div><pre><code data-lang="text">nfsiostat /mnt/myFileSystem</code></pre></div><p>The output, shown below, details the client’s read and write activity since the file system was mounted or since <code>nfsiostat</code> was last executed.</p><div><pre><code data-lang="text">   op/s		rpc bklog
   2.81	   	0.00
read:	ops/s	kB/s	 	kB/op		retrans	avg RTT (ms)	avg exe (ms)
0.000	0.000	 	0.000		0 (0.0%)	0.000		0.000
write:	ops/s	kB/s	 	kB/op		retrans	avg RTT (ms)	avg exe (ms)
2.266	2284.646	1008.283	0 (0.0%)	129.606	356.155</code></pre></div><h2 id="collect-efs-logs"><a href="#collect-efs-logs">Collect EFS logs</a></h2><p>To gain even deeper insight into the performance of your file systems, you can collect logs from your EFS clients. Logs reveal details of each client’s activity—such as when a given client mounted an EFS file system and how much data it sent to the mount target—that can be useful when you need to analyze and troubleshoot EFS performance. In this section, we’ll show you how you can collect and view EFS logs using AWS services and Linux tools.</p><h3 id="aws-logging-services"><a href="#aws-logging-services">AWS logging services</a></h3><p>AWS provides logging services that allow you to gather EFS logs from <a href="#mount-helper-logs">EC2 instances</a>, as well as <a href="#vpc-flow-logs">network logs</a> that show connection activity to your EFS mount targets. You can analyze and alert on these logs using Amazon <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html">CloudWatch Logs</a> and query them with <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html">CloudWatch Logs Insights</a>.</p><h4 id="mount-helper-logs"><a href="#mount-helper-logs">Mount helper logs</a></h4><p>The <a href="https://github.com/aws/efs-utils">EFS client software</a> includes a <a href="https://docs.aws.amazon.com/efs/latest/ug/efs-mount-helper.html">mount helper</a> tool which allows you to collect <a href="https://docs.aws.amazon.com/efs/latest/ug/efs-mount-helper.html#mount-helper-logs">logs</a> from your EC2 instances and forward them to <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html">CloudWatch Logs</a>. To collect logs from an instance, <a href="https://github.com/aws/efs-utils#step-1-install-botocore">install botocore</a>—the foundation of the <a href="https://aws.amazon.com/sdk-for-python/">AWS SDK for Python</a>—onto the instance, attach the necessary <a href="https://github.com/aws/efs-utils#step-3-attach-the-cloudwatch-logs-policy-to-the-iam-role-attached-to-instance">IAM policy</a> to the instance’s role, and then install the <a href="https://docs.aws.amazon.com/efs/latest/ug/using-amazon-efs-utils.html">EFS client software</a>.</p><p>Logging is disabled by default, so you need to <a href="https://github.com/aws/efs-utils#step-2-enable-cloudwatch-log-feature-in-efs-utils-config-file-etcamazonefsefs-utilsconf">update</a> the client’s configuration file (<a href="https://github.com/aws/efs-utils/blob/master/dist/efs-utils.conf"><strong>/etc/amazon/efs/efs-utils.conf</strong></a>) to enable logging and configure the helper to forward logs to CloudWatch Logs. The <strong>efs-utils.conf</strong> excerpt shown below sets <code>enabled = true</code> in the <code>[cloudwatch-log]</code> section of the configuration file. As a result, this instance will automatically forward its mount helper logs to the CloudWatch Logs group named <code>/aws/my-efs-mount-helper-logs</code>.</p><div><p>efs-utils.conf</p><div><pre><code data-lang="text">[cloudwatch-log]
enabled = true
log_group_name = /aws/my-efs-mount-helper-logs</code></pre></div></div><p>Once you’ve aggregated your mount helper logs in CloudWatch Logs, you can explore the status and history of mount activity across all of the EC2 instances that connect to your file system. You can also use CloudWatch Logs Insights to search and filter your logs, which can reveal patterns and trends in EFS performance and client activity. For example, the CloudWatch Logs Insights query in the screenshot below searches the <code>/aws/my-efs-mount-helper-logs</code> logs group and displays the timestamp, message, and log stream identifier fields from the 20 most recent logs across all of the streams in the group. The timeseries graph above the results visualizes the rate at which the logs occur.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=847" alt="A CloudWatch Logs Insights query searches across all logs streams in the log group and returns three records, each from different log streams."/></picture></figure></div><h4 id="vpc-flow-logs"><a href="#vpc-flow-logs">VPC Flow Logs</a></h4><p><a href="https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html">VPC Flow Logs</a> allow you to monitor traffic on the network interfaces your AWS resources use. The clients connected to an EFS file system interact with it by sending requests to port 2049 on the <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html">Elastic Network Interface (ENI)</a> of one of its <a href="https://www.datadoghq.com/blog/amazon-efs-metrics#an-overview-of-efs">mount targets</a>. By capturing these requests in a flow log, you can aggregate network activity from multiple clients in a single log, which you can then <a href="https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs-cwl.html">publish to Cloudwatch Logs</a>. This allows you to see, for example, the IP addresses of all the <a href="https://aws.amazon.com/premiumsupport/knowledge-center/list-instances-connected-to-efs/">clients that have connected</a> to your file system. You can also <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html">filter</a> your results based on the values contained in fields you identify. For example, the screenshot below illustrates a CloudWatch Logs Insights query that finds flow logs showing data transfers greater than 102,400 bytes to and from the file system’s mount targets.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=847" alt="A CloudWatch Logs Insights query shows logs from all logs streams in the log group where the bytes field is greater than 102.4 kilobytes."/></picture></figure></div><p>See <a href="https://aws.amazon.com/premiumsupport/knowledge-center/list-instances-connected-to-efs/">the AWS documentation</a> for more examples about collecting and querying VPC Flow Logs in CloudWatch Logs.</p><h3 id="non-aws-logging-tools"><a href="#non-aws-logging-tools">Non-AWS logging tools</a></h3><p>If your EFS clients are running on EC2 instances, including EC2-backed EKS or ECS clusters, their log activity can reveal important details about changes within the file systems they mount. In this section, we’ll show you Linux utilities you can use to log the activity of clients making changes to the EFS file system.
The <a href="https://aws.amazon.com/premiumsupport/knowledge-center/ec2-monitor-file-system-changes#Short_description">Linux auditing system</a> provides tools that allow you to monitor your Linux hosts for changes that could indicate security concerns. Linux security is a topic that extends beyond file system monitoring, but you can use these tools to <a href="https://aws.amazon.com/premiumsupport/knowledge-center/ec2-monitor-file-system-changes/">increase your visibility into EFS</a> by logging file creation, deletion, modification, and access.
<code>auditd</code> is the process that monitors and logs activity on the host, and <code>auditctl</code> is the program you use to configure <code>auditd</code>. To log changes to your file system, you create rules that tell <code>auditd</code> which directories to monitor and which activities to watch for. When a change takes place in the file system that aligns with a rule you’ve defined—for example, when a client writes to a file that’s being monitored—<code>auditd</code> will create a new log in <strong>/var/log/audit/audit.log</strong>.</p><p>You can then use two complementary utilities—<code>ausearch</code> to filter the log contents and <code>aureport</code> to format the output—to view the contents of <strong>audit.log</strong> and see the activity on the file system. The command below searches for logs created by the <code>mykeyname</code> rule. It includes the <code>-i</code> flag to interpret the <a href="https://man7.org/linux/man-pages/man8/aureport.8.html">output</a> and the <code>-f</code> flag to return log entries related to file activity.</p><div><pre><code data-lang="text">sudo ausearch -k mykeyname | aureport -f -i


File Report
===============================================
# date time file syscall success exe auid event
===============================================
1. 04/16/2021 16:50:27 /mnt/myFileSystem/myFile openat yes /usr/bin/bash ec2-user 124
2. 04/16/2021 16:50:43 /mnt/myFileSystem/myOtherFile openat yes /usr/bin/bash ec2-user 125</code></pre></div><p>You can also use the <code>rpcdebug</code> tool to log an instance’s interactions with an EFS file system, which includes creating, modifying, reading, and executing files. For example, if your application creates and writes to a file named <strong>myNewFile</strong> in the root directory of an EFS file system, <code>rpcdebug</code> will add the following messages to the instance’s system log:</p><div><pre><code data-lang="text">Apr  5 22:17:06 ip-172-31-46-92 kernel: NFS: open file(/myNewFile)
Apr  5 22:17:06 ip-172-31-46-92 kernel: NFS: flush(/myNewFile)
Apr  5 22:17:06 ip-172-31-46-92 kernel: NFS: fsync file(/myNewFile) datasync 0
Apr  5 22:17:06 ip-172-31-46-92 kernel: NFS: write(/myNewFile, 5@0)
Apr  5 22:17:06 ip-172-31-46-92 kernel: NFS: flush(/myNewFile)
Apr  5 22:17:06 ip-172-31-46-92 kernel: NFS: fsync file(/myNewFile) datasync 0
Apr  5 22:17:06 ip-172-31-46-92 kernel: NFS: release(/myNewFile)
Apr  5 22:18:31 ip-172-31-46-92 dhclient[2818]: XMT: Solicit on eth0, interval 121000ms.</code></pre></div><h2 id="monitor-efs-and-your-whole-stack"><a href="#monitor-efs-and-your-whole-stack">Monitor EFS and your whole stack</a></h2><p>In this post, we’ve looked at how you can collect and alert on EFS metrics and logs using AWS and Linux tools. In <a href="https://www.datadoghq.com/blog/amazon-efs-monitoring-datadog">Part 3</a> of this series, we’ll show you how Datadog enables you to visualize and analyze this data alongside telemetry from more than 450 other technologies, so you can gain full visibility into your EFS file systems and the applications they support.</p><h2 id="acknowledgments"><a href="#acknowledgments">Acknowledgments</a></h2><p>We’d like to thank Ray Zaman at AWS for their technical review of this post.</p><p><em>Source Markdown for this post is available <a href="https://github.com/DataDog/the-monitor/blob/master/efs/amazon-efs-monitoring-tools.md">on GitHub</a>. Questions, corrections, additions, etc.? Please <a href="https://github.com/DataDog/the-monitor/issues">let us know</a></em></p></div></div>]]></content:encoded>
      <author>David M. Lentz</author>
      <pubDate>Thu, 05 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Datadog Launches Cloud Security Platform to Provide Security Teams with Unprecedented Observability Capabilities</title>
      <link>https://www.datadoghq.com/about/latest-news/press-releases/datadog-launches-cloud-security-platform-to-provide-security-teams-with-unprecedented-observability-capabilities/</link>
      <description>NEW YORK &amp;ndash; Datadog, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced the launch of the Datadog Cloud Security Platform, adding full-stack security context to Datadog’s deep observability capabilities. This new offering enables organizations to use a single platform to correlate security insights with monitoring data across infrastructure, network and application tiers, providing Security teams with the visibility they need to understand and respond to potential threats faster.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><strong>NEW YORK</strong> – <a href="https://www.datadoghq.com/">Datadog</a>, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced the launch of the Datadog Cloud Security Platform, adding full-stack security context to Datadog’s deep observability capabilities. This new offering enables organizations to use a single platform to correlate security insights with monitoring data across infrastructure, network and application tiers, providing Security teams with the visibility they need to understand and respond to potential threats faster. </p><p>In recent years, security attacks have increasingly focused on the application level, prompting DevOps and Security teams to work more closely together to “shift left” and infuse security into the full software development life cycle. Traditionally, this has been difficult because of siloed tools and processes, which has been further exacerbated as organizations move to the cloud and security teams are left with even less visibility.</p><p>Datadog’s Cloud Security Platform addresses these challenges by enabling DevOps and Security teams to access a shared source of truth supported by a common data model. With Datadog, in parallel to detecting potential threats, Security leaders now have access to the underlying infrastructure, network and application data at the time of an attack, meaning they have deeper insights that enable more accurate threat detection and accelerated incident response. And, unlike point solutions, Datadog’s platform approach ensures that this data is automatically correlated and presented in context, without requiring manual analysis.</p><p>“As organizations embark on their digital transformation journey, unifying once disparate security, compliance and engineering practices has become a key requirement to deliver best-in-class customer experiences,” said Amit Agarwal, Chief Product Officer, Datadog. “Built for cloud scale, the Datadog Cloud Security Platform supports organizations in adopting a modern DevSecOps practice that will enable a more holistic and, ultimately, a more robust approach to security, without increasing the operational burden of deploying and maintaining multiple, disconnected point solutions.”</p><p>“With Lemonade’s growth, cloud security has become a primary focus,” said Jonathan Jaffe, Chief Information Security Officer, Lemonade. “Within the first week of an easy integration, Datadog’s security offerings helped my team manage potential threats faster, with less effort, and with higher fidelity and accuracy. What’s more, collaboration with our DevOps colleagues became easier and has helped tie security to the business. We have many security tools and services; Datadog Cloud Security Platform has become one of our top-three tools. We see it supporting our current and future growth with security, and in lockstep with DevOps.” </p><p>Forrester’s State of Application Security report notes that “Applications remain a top cause of external breaches, and the prevalence of open source, API, and containers only adds complexity to the security team. Happily, organizations have started to recognize the importance of application security and are embedding security more tightly into the development phase.” </p><p>The Datadog Cloud Security Platform includes:</p><ul><li>Cloud Security Posture Management (CSPM) makes it easy to track whether your production environment complies with industry standards, such as PCI DSS, SOC 2 and HIPAA, and catches misconfigurations that leave your organization vulnerable to potential attacks.</li><li>Cloud Workload Security (CWS) detects threats to your production workloads by monitoring file and process activity across your environments to help catch host and infrastructure-based attacks.</li><li>Security Monitoring identifies threats to your cloud environments by analyzing operational and security logs. As an easy-to-use cloud-native SIEM, Security Monitoring provides out-of-the-box security integrations and threat detection rules that are easy to extend and customize.</li><li>Application Security, currently in beta, provides protection against application-level threats by identifying and blocking attacks that target code-level vulnerabilities, such as SQL injections and cross-site scripting (XSS) exploits.</li><li>Unified Observability and Security Reporting allows seamless pivots between DevOps telemetry and security insights. This unified experience enables Security teams to understand the operational and business impact of security incidents, and DevOps teams to see security signals alongside the metrics, traces and logs of their services.</li></ul><p><br/>For more information and to get started with the Datadog Cloud Security Platform, please visit <a href="https://www.datadoghq.com/product/security-platform/">https://www.datadoghq.com/product/security-platform/</a>. </p><p>Datadog will be at Black Hat’s USA Summit—both in person and virtually. To listen in on our session, With Friends Like eBPF, Who Needs Enemies? please visit <a href="https://www.blackhat.com/us-21/briefings/schedule/index.html#with-friends-like-ebpf-who-needs-enemies-23619">Black Hat speaker sessions</a>. </p><div><p><strong>About Datadog</strong></p><p>Datadog is the monitoring and security platform for cloud applications. Our SaaS platform integrates and automates infrastructure monitoring, application performance monitoring and log management to provide unified, real-time observability of our customers’ entire technology stack. Datadog is used by organizations of all sizes and across a wide range of industries to enable digital transformation and cloud migration, drive collaboration among development, operations, security and business teams, accelerate time to market for applications, reduce time to problem resolution, secure applications and infrastructure, understand user behavior and track key business metrics.</p></div><p><strong>Forward-Looking Statements</strong> </p><p>This press release may include certain “forward-looking statements” within the meaning of Section 27A of the Securities Act of 1933, as amended, or the Securities Act, and Section 21E of the Securities Exchange Act of 1934, as amended. These forward-looking statements reflect our current views about our plans, intentions, expectations, strategies and prospects, which are based on the information currently available to us and on assumptions we have made. Actual results may differ materially from those described in the forward-looking statements and are subject to a variety of assumptions, uncertainties, risks and factors that are beyond our control, including those risks detailed under the caption “Risk Factors” and elsewhere in our Securities and Exchange Commission filings and reports, including the Quarterly Report on Form 10-Q filed with the Securities and Exchange Commission on May 7, 2021, as well as future filings and reports by us. Except as required by law, we undertake no duty or obligation to update any forward-looking statements contained in this release as a result of new information, future events, changes in expectations or otherwise.</p></div></div>]]></content:encoded>
      <author>Datadog</author>
      <pubDate>Wed, 04 Aug 2021 20:30:44 +0000</pubDate>
    </item>
    <item>
      <title>Best practices for monitoring a cloud migration</title>
      <link>https://www.datadoghq.com/blog/cloud-migration-monitoring/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration_monitoring_210628_FINAL.png&#34; width=&#34;100%&#34;/&gt;When you migrate workloads from on-premise infrastructure into a public cloud, you can improve the performance, reliability, and security of your application, and you might also lower your costs. To execute a successful cloud migration, you need a detailed inventory of your current deployments, visibility into your application&amp;rsquo;s performance as you shift traffic to the cloud, and confirmation that—once you&amp;rsquo;ve landed in the cloud—you&amp;rsquo;re still providing a high-quality user experience.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>When you migrate workloads from on-premise infrastructure into a public cloud, you can improve the performance, reliability, and security of your application, and you might also lower your costs. To execute a successful cloud migration, you need a detailed inventory of your current deployments, visibility into your application’s performance as you shift traffic to the cloud, and confirmation that—once you’ve landed in the cloud—you’re still providing a high-quality user experience.</p><p>In this post, we’ll explore best practices for monitoring your cloud migration and show you how Datadog can give you visibility throughout every phase. We’ll show you how to:</p><ul><li><a href="#take-inventory-to-plan-your-migration">Plan what cloud resources you need</a></li><li><a href="#prepare-create-and-test-your-new-environment">Build visibility into your cloud environment</a></li><li><a href="#cut-over-and-watch-your-cloud-migration-metrics">Monitor your newly migrated application</a></li></ul><h2 id="take-inventory-to-plan-your-migration"><a href="#take-inventory-to-plan-your-migration">Take inventory to plan your migration</a></h2><p>In order to plan a cloud environment that’s capable of supporting your applications, you’ll need a deep understanding of your current environment. In this section, we’ll show you how Datadog can help you plan your migration by understanding the topology and resource requirements of your application in its current state.</p><h3 id="map-your-application-and-infrastructure"><a href="#map-your-application-and-infrastructure">Map your application and infrastructure</a></h3><p>The <a href="https://www.datadoghq.com/blog/service-map/">Service Map</a> helps you gain a complete understanding of your services, their dependencies, and the rate of requests between them. In the screenshot below, the Service Map highlights the <code>web-store</code> service and shows its request, latency, and error rates as well as its request traffic to and from other services. From here, you can click any service to drill down to view request data gathered by <a href="https://www.datadoghq.com/knowledge-center/distributed-tracing/">Application Performance Monitoring (APM) and distributed tracing</a>.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=847" alt="The Service Map shows the request, latency, and error rate of the web store service, and maps its requests to and from other services."/></picture></figure></div><p>The <a href="https://www.datadoghq.com/blog/introducing-host-maps-know-thy-infrastructure/">host map</a> visualizes your current environment and uses colors to represent the real-time value of a metric your hosts are reporting. You can use metadata from your hosts to aggregate, explore, and better understand your infrastructure. The screenshot below shows hosts grouped by environment and color coded to show hosts with high CPU usage in red and low CPU usage in green.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=847" alt="The Host map shows hosts grouped by availability zone and uses red to indicate a host with high CPU usage and green to show low CPU usage."/></picture></figure></div><p>The host map can reveal resource-utilization hotspots that help you decide the number, size, and type of the VMs you launch in the cloud. You can click any node on the map to see a dashboard that shows you detailed resource usage patterns. This data can help you understand your infrastructure needs and <a href="https://aws.amazon.com/aws-cost-management/aws-cost-optimization/right-sizing/">right-size</a> your new cloud infrastructure. For example, if the host map shows you that a specific application is running on a large number of underutilized instances, you may be able to save money by migrating it to fewer cloud instances. You could also choose a less expensive instance type, such as one that features fewer CPU cores or provides general-purpose capabilities rather than a compute-optimized instance.</p><h3 id="analyze-your-network"><a href="#analyze-your-network">Analyze your network</a></h3><p>To ensure that your new cloud environment can accommodate the volume and type of network traffic your application generates, you’ll need to take a close look at the behavior of your current network. <a href="https://www.datadoghq.com/blog/network-performance-monitoring/">Datadog Network Performance Monitoring (NPM)</a> gives you visibility into the traffic within and between your on-premise data centers, so you can design the <a href="https://en.wikipedia.org/wiki/Virtual_private_cloud">VPCs</a>, <a href="https://en.wikipedia.org/wiki/Subnetwork">subnets</a>, and other network constructs in your cloud environment to support your application’s traffic.</p><p>The <a href="https://docs.datadoghq.com/network_monitoring/performance/network_map/">Network Map</a> visualizes the traffic between the hosts, pods, containers, and other components of your environment. This can help you spot bottlenecks as you migrate—and provision appropriate cloud network resources to resolve them. The screenshot below shows a Network Map of a testing-related application that generates a small amount of traffic. An application like this could be a preferred, lower-risk candidate for migrating first, ahead of higher-traffic applications.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=847" alt="The network map shows an application called test comprised of only two services."/></picture></figure></div><p><a href="https://www.datadoghq.com/blog/cloud-service-autodetection-datadog/">In the cloud</a>, your network can dynamically scale to include new hosts, subnets, and VPCs. As these cloud resources come and go, you can continue to rely on the Network Map and <a href="https://docs.datadoghq.com/network_monitoring/performance/network_page/">Network Overview</a> to track network flows within your cloud environment. You can sort your NPM data by geography to identify traffic between regions or availability zones. Using this information, you may be able to revise your network traffic flows so you can minimize latency and transit costs in the cloud.</p><h3 id="understand-your-storage"><a href="#understand-your-storage">Understand your storage</a></h3><p>As you plan to provide storage for your application in the cloud (e.g., managed databases, file storage, and object storage), you should have a detailed inventory of the types and amounts of storage required. Our <a href="https://docs.datadoghq.com/integrations/#cat-data-store">data store integrations</a> provide out-of-the-box dashboards that visualize usage metrics like:</p><ul><li><code>postgresql.total_size</code>: the total disk space used by a PostgreSQL table, in bytes</li><li><code>ibm_db2.tablespace.size</code>: the total disk space used by an IBM DB2 table, in bytes</li><li><code>sap_hana.disk.used</code>: the total disk space used by SAP HANA to persist data, in bytes</li></ul><p>And to estimate your future storage costs, you can apply a <a href="https://docs.datadoghq.com/dashboards/functions/algorithms/#forecast">forecast function</a> when you graph these metrics to see where your data storage needs are headed.</p><h2 id="prepare-create-and-test-your-new-environment"><a href="#prepare-create-and-test-your-new-environment">Prepare, create, and test your new environment</a></h2><p>Once you’ve identified the resources to include in your cloud environment, you should make plans to ensure that you’ll have the visibility you need. In this section, we’ll describe steps you can take to leverage monitoring throughout the process of creating your cloud environment. We’ll look at three phases of moving an application to the cloud: preparation, setup, and validation.</p><h3 id="prepare-your-slos-and-dashboards"><a href="#prepare-your-slos-and-dashboards">Prepare your SLOs and dashboards</a></h3><p>You should expect the cloud-based version of your application to be at least as reliable as the on-premise version, so you can continue to use the same <a href="https://www.datadoghq.com/blog/slo-monitoring-tracking/">service level objectives (SLOs)</a>—performance and reliability targets for the services you operate—across the old and new versions. But you may need to adjust what you measure—your service level indicators (SLIs)—to include performance metrics from your newly migrated workloads.</p><p>For example, let’s say you’re planning to move a Redis cache to the managed version that AWS provides—Amazon ElastiCache for Redis—and you’ve created an SLO to ensure that your cache hit rate stays above 90 percent over each seven-day period. You may need to operate that cache temporarily as a hybrid while you transition to the cloud. During this hybrid phase, your SLOs should be based on a combination of SLIs from both the legacy infrastructure (on-premise Redis) and the target infrastructure (ElastiCache). In this case, you could update your SLO to track metrics that reflect cache hits and misses from both services. As you phase out your legacy infrastructure, the legacy Redis deployment will eventually stop reporting any data, and you can remove the <code>redis.stats.keyspace_*</code> metrics from your SLIs.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=847" alt="An SLO shows a numerator of Redis cache hits plus Elasticache hits and a denominator of hits from both caches added to misses from both caches."/></picture></figure></div><p>To ensure that you have visibility into your cloud infrastructure from day one, you can leverage the dashboards and alerts you already use to track the health of your application. Export any of your <a href="https://docs.datadoghq.com/dashboards/#copy-import-or-export-dashboard-json">dashboards</a> or <a href="https://docs.datadoghq.com/monitors/monitor_types/#import">alerts</a> to JSON and edit the file to revise the metric names to align with your cloud services. Then import the modified JSON to begin monitoring your application in the cloud.</p><h3 id="set-up-a-cloud-environment-with-monitoring-built-in"><a href="#set-up-a-cloud-environment-with-monitoring-built-in">Set up a cloud environment with monitoring built in</a></h3><p>When you launch your cloud environment, you can use your cloud provider’s resource management service (e.g., AWS CloudFormation) to automatically enable the integrations that will help you track the performance of your cloud services and infrastructure. For example, you can create a CloudFormation template that defines the necessary AWS resources and also enables the Datadog AWS integration that allows you to <a href="https://www.datadoghq.com/blog/monitoring-as-code-with-datadog-and-cloudformation/#automatically-enable-datadogs-aws-integration">monitor them</a>. You can even <a href="https://github.com/DataDog/datadog-cloudformation-resources#resources-available">automatically deploy Datadog resources</a>—such as <a href="#prepare-your-slos-and-dashboards">dashboards, monitors, and SLOs</a>—as part of your migration to the cloud. This way, you can have monitoring in place before you even begin shifting traffic to your new cloud infrastructure.</p><p>Resource management tools also make it easy to apply tags to the infrastructure and services you launch in your cloud environment. For example, you could apply an <code>env:production_cloud</code> tag that allows you to monitor the new version of your application separately from the legacy version. You can add a tag like this automatically by specifying it in the templates or commands you use in <a href="https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/tag-resources">Azure Resource Manager</a>, <a href="https://cloud.google.com/deployment-manager/docs/creating-managing-labels">Google Cloud Platform</a>, and <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-resource-tags.html">AWS CloudFormation</a>.</p><h3 id="validate-test-and-protect-your-cloud-architecture"><a href="#validate-test-and-protect-your-cloud-architecture">Validate, test, and protect your cloud architecture</a></h3><p>When you migrate your application to the cloud, you could be subject to data-protection regulations such as HIPAA, PCI, and GDPR. Datadog <a href="https://www.datadoghq.com/product/security-platform/cloud-security-posture-management/">Cloud Security Posture Management (CSPM)</a> helps you track the compliance posture of your cloud environment to ensure that your application meets the applicable regulations. CSPM provides <a href="https://docs.datadoghq.com/security_platform/cspm/frameworks_and_benchmarks/">out-of-the-box rules</a> that are automatically enabled to continuously evaluate your cloud environment against compliance standards and industry benchmarks. For example, if you’re migrating to Azure Kubernetes Service, Datadog provides a built-in rule to help you confirm that <a href="https://docs.datadoghq.com/security_platform/default_rules/cis-azure-1.3.0-8.5/">RBAC is enabled</a> at all times.</p><p>As you shift traffic to your cloud environment, Datadog <a href="https://www.datadoghq.com/product/security-platform/security-monitoring/">Security Monitoring</a> can help you spot security threats by automatically analyzing application and infrastructure logs in real time. Security Monitoring provides threat detection rules so you can get started quickly. You can also <a href="https://docs.datadoghq.com/security_platform/detection_rules/#creating-and-managing-rules">create custom rules</a> to watch for specific security concerns.</p><p>Once you’ve created your cloud environment and deployed your application there, you can use <a href="https://www.datadoghq.com/product/synthetic-monitoring/">Synthetic Monitoring</a> to automatically test the availability of your API endpoints and key user workflows within your application. It can simulate user journeys—even ones that include <a href="https://www.datadoghq.com/blog/mfa-synthetic-testing-datadog/">multi-factor authentication</a>—and execute simple or <a href="https://www.datadoghq.com/blog/monitor-apis-with-datadog/">multistep API tests</a> to help you proactively identify issues before your users do.</p><p>Once you start running Synthetic tests on your cloud environment, that traffic will appear in the <a href="#map-your-application-and-infrastructure">Service Map</a>. You can compare this to the Service Map of your legacy environment to check for any missing or unexpected request paths in your newly migrated workloads.</p><h2 id="cut-over-and-watch-your-cloud-migration-metrics"><a href="#cut-over-and-watch-your-cloud-migration-metrics">Cut over and watch your cloud migration metrics</a></h2><p>As you shift traffic to the cloud, you can use Datadog to verify that your application’s performance and end user experience remain optimal. In this section, we’ll describe how to use SLOs, dashboards, RUM, and APM to monitor your new cloud environment while you complete your migration.</p><h3 id="track-slos-and-migration-progress-on-dashboards"><a href="#track-slos-and-migration-progress-on-dashboards">Track SLOs and migration progress on dashboards</a></h3><p>To ensure that your migration is not affecting the performance of your application, you can continue to rely on the SLOs you’ve already created. You can <a href="https://www.datadoghq.com/blog/define-and-manage-slos/">share SLO information</a> by displaying <a href="https://docs.datadoghq.com/dashboards/widgets/slo/">SLO widgets</a> and other curated monitoring data on your <a href="https://docs.datadoghq.com/dashboards/">dashboards</a>. These dashboards enable you to easily share a real-time status report of your migration-in-progress—both internally and with stakeholders <a href="https://www.datadoghq.com/blog/dashboard-sharing/">outside of your organization</a>.</p><p>Datadog also provides <a href="https://docs.datadoghq.com/getting_started/dashboards/#explore-out-of-the-box-dashboards">out-of-the-box dashboards</a> for cloud services like <a href="https://docs.datadoghq.com/agent/amazon_ecs/">Amazon ECS</a>, <a href="https://docs.datadoghq.com/integrations/google_cloud_functions/">Google Cloud Functions</a>, and <a href="https://docs.datadoghq.com/integrations/azure_sql_database/">Azure SQL Database</a> to give you real-time information about the health and performance of the services that run your application. You can expect some metrics to rise steadily as you send more traffic to the cloud—for example, the rate of requests and the size of your data stores. And you can watch to ensure that other metrics—such as latency and error rates—hold steady or even decrease as the cloud version of your application begins to outperform the legacy version. To be fully prepared, of course, you should create <a href="https://docs.datadoghq.com/monitors/">alerts</a> to notify you if those metrics increase unexpectedly.</p><h3 id="monitor-end-to-end-with-rum-and-apm"><a href="#monitor-end-to-end-with-rum-and-apm">Monitor end-to-end with RUM and APM</a></h3><p><a href="https://www.datadoghq.com/blog/real-user-monitoring-with-datadog/">Real User Monitoring (RUM)</a> gives you visibility into the experience of your users by measuring their interactions with your application. For example, the <code>view.first_input_delay</code> metric tracks how long your users are waiting for the app to react to their first action on a page, and <code>view.largest_contentful_paint</code> measures how long it takes before the largest object in the DOM is rendered. RUM also shows you data on the rate of errors and crashes in your <a href="https://www.datadoghq.com/blog/datadog-mobile-rum/">mobile apps</a>.</p><p>RUM collects your application’s frontend data—metrics, events, and browser information—and links automatically with Datadog <a href="https://www.datadoghq.com/blog/announcing-apm/">APM</a> to provide <a href="https://www.datadoghq.com/blog/unify-apm-rum-datadog/">end-to-end visibility</a>. If RUM metrics and error rates reveal that your shift to the cloud has caused crashes or introduced latency, you can use APM to pinpoint the source of the problem. <a href="https://www.datadoghq.com/knowledge-center/distributed-tracing/flame-graph/">Flame graphs</a> visualize the sequence of service calls your application executes to fulfill each request, making it easy to spot services that are returning errors or adding latency.</p><p>APM can also help you understand whether the cloud-based version of your application is resource-constrained—for example, running on VMs that are too small or serverless functions that are underprovisioned. If a flame graph reveals a bottleneck in a request, you can click the <a href="https://docs.datadoghq.com/tracing/visualization/#spans">span</a> that represents the slow service call to see resource utilization metrics from the relevant host. In the screenshot below, the <code>check-token</code> call took 3.43 seconds. The <strong>Metrics</strong> tab below the flame graph shows high CPU usage on the host that received the request, indicating that the slow response could be due to insufficient resources.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=847" alt="A flame graph shows one call taking 3.43 seconds or 97.6 percent of the execution time, along with CPU utilization near 100 percent."/></picture></figure></div><h3 id="finalizing"><a href="#finalizing">Finalizing</a></h3><p>Before you call your migration complete, you should confirm that all traffic has shifted and that it’s safe to decommission your legacy infrastructure. The screenshot below shows an example of a graph that you can create to verify the progress of your traffic shift. This <a href="https://www.datadoghq.com/blog/timeseries-metric-graphs-101/#stacked-area-graphs">area graph</a> shows that the combined volume of requests to our legacy and cloud infrastructure has remained consistent throughout the migration. It also indicates that the new cloud environment (represented by the darker area on the bottom and tagged <code>env:production_cloud</code>) has been servicing an increasing share of the traffic, while the on-premise environment’s share (the lighter area on top) has decreased.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=847" alt="An area graph shows an static total of overall requests, with requests to &#39;production cloud&#39; increasing over 45 minutes."/></picture></figure></div><p>You should also confirm that all sessions have been drained from on-premise servers, and that message queues (e.g., ActiveMQ or RabbitMQ) and data streams (e.g., Kafka or Apache Flink) no longer hold any records.</p><p>When you’ve completed your migration, you can continue to use RUM and APM—along with your SLOs, dashboards, and alerts—to give you ongoing visibility as you operate your applications in the cloud. And as the new version of your application establishes traffic patterns in the cloud, you can take advantage of features like <a href="https://www.datadoghq.com/blog/watchdog/">Watchdog</a> and <a href="https://www.datadoghq.com/blog/introducing-anomaly-detection-datadog/">anomaly detection</a> to help you spot and troubleshoot anomalies in your application’s performance.</p><h2 id="migrate-and-monitor"><a href="#migrate-and-monitor">Migrate and monitor</a></h2><p>By building monitoring into your cloud migration process, you’ll have the visibility you need to confirm a successful launch and take advantage of the increased performance and reliability of the cloud. Datadog provides integrations with more than
450 technologies to ensure that you can always monitor all the layers of your application. If you’re not yet using Datadog, you can start today with a <a href="#">14-day free trial</a>.</p></div></div>]]></content:encoded>
      <author>David M. Lentz</author>
      <pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Monitor containerized ASP.NET Core applications on AWS Fargate</title>
      <link>https://www.datadoghq.com/blog/deploy-dotnet-core-aws-fargate/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-hero.png&#34; width=&#34;100%&#34;/&gt;The ASP.NET Core framework enables you to build and deploy .NET applications on a wide variety of platforms, each of which has different observability concerns. In a previous post, we looked at monitoring a containerized ASP.NET Core application. In this guide, we&amp;rsquo;ll show how Datadog provides visibility into ASP.NET Core applications running on AWS Fargate. We&amp;rsquo;ll walk through: instrumenting and packaging a sample .NET application publishing the application to Docker Hub deploying the instrumented .</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>The <a href="https://dotnet.microsoft.com/learn/aspnet/what-is-aspnet-core">ASP.NET Core framework</a> enables you to build and deploy .NET applications on a wide variety of platforms, each of which has different observability concerns. <a href="https://www.datadoghq.com/blog/asp-dotnet-core-monitoring/">In a previous post</a>, we looked at monitoring a containerized ASP.NET Core application. In this guide, we’ll show how Datadog provides visibility into ASP.NET Core applications running on <a href="https://aws.amazon.com/fargate/">AWS Fargate</a>. We’ll walk through:</p><ul><li><a href="#package-an-instrumented-application-with-docker">instrumenting and packaging a sample .NET application</a></li><li><a href="#publish-your-image-to-docker-hub">publishing the application</a> to Docker Hub</li><li><a href="#deploy-a-containerized-net-application-with-aws-fargate">deploying the instrumented .NET application</a> using AWS Fargate</li><li><a href="#monitor-application-performance-with-datadog">monitoring</a> application performance with Datadog APM</li></ul><p>Instrumenting your application enables you to track requests as they move across the application’s service and process boundaries, so you can identify performance bottlenecks and resolve them before they affect end users. Datadog offers out-of-the-box instrumentation for .NET Core and other .NET frameworks with the <a href="https://docs.datadoghq.com/tracing/setup_overview/setup/dotnet-core/?tab=windows">.NET tracer</a>, which submits trace data to Datadog via the Datadog Agent. The Agent can also collect performance data from your Fargate resources, giving you complete visibility into your application and its underlying infrastructure.</p><h3 id="get-started-with-a-sample-application"><a href="#get-started-with-a-sample-application">Get started with a sample application</a></h3><p>To get started, make sure you have at least <a href="https://dotnet.microsoft.com/download/dotnet/5.0">version 5 of the .NET Core SDK</a> installed, which includes <a href="https://docs.microsoft.com/en-us/dotnet/core/tools/">the .NET CLI</a>. This will let you generate the sample ASP.NET Core application we’ll use throughout this guide. We’ll also use <a href="https://hub.docker.com/">Docker Hub</a> to publish the containerized application, though you can use other container registry services such as <a href="https://aws.amazon.com/ecr/">Amazon ECR</a>.</p><p>You can create a new web application project with all of the files needed to run a sample application via the following .NET CLI commands:</p><div><pre><code data-lang="text"> 
dotnet new sln -n DatadogFargateExample
dotnet new webapp -o DatadogFargateExample -n DatadogFargateExample
dotnet sln add DatadogFargateExample</code></pre></div><p>These commands create a new solution file (i.e., <strong>DatadogFargateExample.sln</strong>) and add a new <a href="https://docs.microsoft.com/en-us/aspnet/core/razor-pages/?view=aspnetcore-5.0&amp;tabs=visual-studio">Razor Pages</a> web application project and associated <strong>DatadogFargateExample</strong> directory to the file. Next, we’ll instrument the application with Datadog’s .NET tracer and publish it on Docker Hub as a Linux container.</p><h2 id="package-an-instrumented-application-with-docker"><a href="#package-an-instrumented-application-with-docker">Package an instrumented application with Docker</a></h2><p>Docker enables you to easily package applications and their dependencies together in a single container, which you can then deploy to any environment, such as a Fargate cluster. AWS Fargate currently only supports Linux-based containers, so we will use a Linux container to package the application. To create a container, add the following Dockerfile to your project’s <strong>DatadogFargateExample</strong> directory:</p><div><p>./DatadogFargateExample/Dockerfile</p><div><pre><code data-lang="text">#See https://aka.ms/containerfastmode to understand how Visual Studio uses this Dockerfile to build your images for faster debugging.
 
FROM mcr.microsoft.com/dotnet/aspnet:5.0 AS base
WORKDIR /app
EXPOSE 80
EXPOSE 443
 
FROM mcr.microsoft.com/dotnet/sdk:5.0 AS build
 
# Download the latest version of the tracer but don&#39;t install yet
RUN TRACER_VERSION=$(curl -s \https://api.github.com/repos/DataDog/dd-trace-dotnet/releases/latest | grep tag_name | cut -d &#39;&#34;&#39; -f 4 | cut -c2-) \
    &amp;&amp; curl -Lo /tmp/datadog-dotnet-apm.deb https://github.com/DataDog/dd-trace-dotnet/releases/download/v${TRACER_VERSION}/datadog-dotnet-apm_${TRACER_VERSION}_amd64.deb
 
WORKDIR /src
COPY [&#34;DatadogFargateExample/DatadogFargateExample.csproj&#34;, &#34;DatadogFargateExample/&#34;]
RUN dotnet restore &#34;DatadogFargateExample/DatadogFargateExample.csproj&#34;
COPY . .
WORKDIR &#34;/src/DatadogFargateExample&#34;
RUN dotnet build &#34;DatadogFargateExample.csproj&#34; -c Release -o /app/build
 
FROM build AS publish
RUN dotnet publish &#34;DatadogFargateExample.csproj&#34; -c Release -o /app/publish
 
FROM base AS final
 
# Copy the tracer from build target
COPY --from=build /tmp/datadog-dotnet-apm.deb /tmp/datadog-dotnet-apm.deb
# Install the tracer
RUN mkdir -p /opt/datadog \
    &amp;&amp; mkdir -p /var/log/datadog \
    &amp;&amp; dpkg -i /tmp/datadog-dotnet-apm.deb \
    &amp;&amp; rm /tmp/datadog-dotnet-apm.deb
 
# Enable the tracer
ENV CORECLR_ENABLE_PROFILING=1
ENV CORECLR_PROFILER={846F5F1C-F9AE-4B07-969E-05C26BC060D8}
ENV CORECLR_PROFILER_PATH=/opt/datadog/Datadog.Trace.ClrProfiler.Native.so
ENV DD_DOTNET_TRACER_HOME=/opt/datadog
ENV DD_INTEGRATIONS=/opt/datadog/integrations.json
 
WORKDIR /app
COPY --from=publish /app/publish .
ENTRYPOINT [&#34;dotnet&#34;, &#34;DatadogFargateExample.dll&#34;]</code></pre></div></div><p>The Dockerfile uses <a href="https://docs.docker.com/develop/develop-images/multistage-build/">multi-stage builds</a> to optimize the build process and ensure compatibility with Visual Studio so you can debug issues locally via Visual Studio’s container tools. You can check out <a href="https://docs.microsoft.com/visualstudio/containers/container-build">Microsoft’s documentation</a> for details.</p><p>There are four build stages in the Dockerfile above: <code>base</code>, <code>build</code>, <code>publish</code>, and <code>final</code>. The <code>mcr.microsoft.com/dotnet/aspnet:5.0</code> Docker image in the <code>base</code> stage is based on the Debian operating system and serves as the main image to run the application in the <code>final</code> stage.</p><p>In the <code>build</code> stage, the Dockerfile uses the <code>mcr.microsoft.com/dotnet/sdk:5.0</code> Docker image to first download the latest version of the Datadog .NET tracer (this image has the <code>curl</code> utility needed to download the tracer) then build the <a href="#get-started-with-a-sample-application"><strong>DatadogFargateExample</strong> project</a>. To use a specific version of the tracer, you can remove the <code>RUN TRACER_VERSION</code> step from the Dockerfile and set the <code>TRACER_VERSION</code> environment variable via <a href="https://docs.docker.com/engine/reference/builder/#arg">a build argument</a> instead.</p><p>The <code>publish</code> stage publishes the project and its dependencies to the <strong>/app/publish</strong> directory for deployment, and the <code>final</code> stage installs and enables the tracer with the necessary file configurations and environment variables to auto-instrument your application. This allows the tracer to submit data to the Agent, which we will install via <a href="#create-an-ecs-task-definition">an ECS task definition</a> in a later section.</p><p>You can build your Docker image and launch the container locally using the following commands:</p><div><pre><code data-lang="text">docker build -t test/datadog-fargate-example -f ./DatadogFargateExample/Dockerfile .
docker run --rm --name datadog-test -p 8080:80 datadog-fargate-example</code></pre></div><p>The <code>test/datadog-fargate-example</code> tag allows you to easily push the image to a container registry platform or pull it as a source image for a container deployed via Fargate. Once your container spins up, you can view your instrumented application by navigating to <code>http://localhost:8080/</code>.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=847" alt="A sample .NET Core appliction"/></picture></figure></div><h3 id="publish-your-image-to-docker-hub"><a href="#publish-your-image-to-docker-hub">Publish your image to Docker Hub</a></h3><p>You can push the Docker image to a container registry platform like Docker Hub using the following command:</p><div><pre><code data-lang="text">docker image push test/datadog-fargate-example</code></pre></div><p>This publishes the image to the registry so you can use it in other environments or platforms. We’ll look at how to use the published image to deploy your .NET application via Fargate next.</p><h2 id="deploy-a-containerized-net-application-with-aws-fargate"><a href="#deploy-a-containerized-net-application-with-aws-fargate">Deploy a containerized .NET application with AWS Fargate</a></h2><p><a href="https://www.datadoghq.com/blog/aws-fargate-metrics/">AWS Fargate</a> is a service that enables you to run Amazon Elastic Container Service (Amazon ECS) tasks or Amazon Elastic Kubernetes Service (Amazon EKS) containers without needing to manage any underlying infrastructure. For this guide, we’ll look at leveraging Fargate with ECS by creating:</p><ul><li><a href="#create-an-amazon-ecs-cluster">a new ECS cluster</a></li><li><a href="#create-an-ecs-task-definition">an ECS task definition</a></li><li><a href="#create-an-application-load-balancer">an application load balancer</a></li><li><a href="#create-an-ecs-service">an ECS service</a> for the cluster</li></ul><h3 id="create-an-amazon-ecs-cluster"><a href="#create-an-amazon-ecs-cluster">Create an Amazon ECS cluster</a></h3><p>A core part of the ECS infrastructure is <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_clusters.html">the cluster</a>, which is a group of tasks and services necessary for deploying an application. You can <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/create_cluster.html">create an ECS cluster</a> by navigating to the <a href="https://console.aws.amazon.com/ecs/">Amazon ECS console</a> in your AWS account. Select “Networking Only” as the cluster template and use the default values for the remaining configuration settings. Once provisioned, you can view your new cluster by clicking the “View Cluster” button on the “Launch status” page.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=847" alt="The cluster&#39;s configuration settings"/></picture></figure></div><p>Next, we’ll walk through how to add the Datadog Agent and the application container you <a href="#publish-your-image-to-docker-hub">published to Docker Hub</a> to the new cluster.</p><h3 id="create-an-ecs-task-definition"><a href="#create-an-ecs-task-definition">Create an ECS task definition</a></h3><p>ECS clusters use <a href="https://docs.aws.amazon.com/AmazonECS/latest/userguide/task_definitions.html">task definitions</a> to specify which containers should be created as part of a deployment. For this guide, we will add two containers to the task definition. The first will run the containerized Datadog Agent and the second your instrumented application. You can <a href="https://docs.datadoghq.com/integrations/ecs_fargate/#web-ui">check out our documentation</a> for detailed steps on creating a new task definition with a Datadog Agent container, but we will highlight some of the key container configurations below.</p><h4 id="create-the-datadog-agent-container"><a href="#create-the-datadog-agent-container">Create the Datadog Agent container</a></h4><p>The first container uses the <code>datadog/agent:latest</code> image to run the Agent, which will gather data from the .NET tracer and host and submit it to Datadog. The Agent image uses environment variables (seen below) to enable APM and listen for non-local traffic, which is required when the Agent and application are running in different containers. It also uses a <code>DD_API_KEY</code> environment variable for connecting the Agent to your Datadog account—your unique API key can be found in <a href="https://app.datadoghq.com/account/settings?#api">your account’s settings</a>.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=847" alt="Environment variables for the Datadog Agent"/></picture></figure></div><h4 id="create-the-application-container"><a href="#create-the-application-container">Create the application container</a></h4><p>You can use <a href="https://docs.datadoghq.com/integrations/ecs_fargate/#web-ui">the same steps</a> to create the second container, which will launch the instrumented application and use the Agent container as a startup dependency. Make sure that you set the image name to the name of the application container on Docker Hub (e.g., <code>datadog-fargate-example</code>) and, under “Port mappings,” add port 80 over TCP, which is the port we defined in the application’s Dockerfile. There are also a few environment variables that you will need to add to the “Advanced container configuration” section, as seen in the screenshot below.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=847" alt="Environment variables for the application container"/></picture></figure></div><p>These variables configure the Agent to collect the following data from your application:</p><ul><li><code>DD_ENV</code>, <code>DD_VERSION</code>, <code>DD_SERVICE</code>: sets the <code>env</code>, <code>version</code>, and <code>service</code> tags on traces for <a href="https://docs.datadoghq.com/getting_started/tagging/unified_service_tagging/?tab=kubernetes">Unified Service Tagging</a></li><li><code>DD_TRACE_ROUTE_TEMPLATE_RESOURCE_NAMES_ENABLED</code>: enables <a href="https://docs.datadoghq.com/tracing/setup_overview/setup/dotnet-core/?tab=windows#experimental-features">improved resource names</a> for ASP.NET Core endpoints</li><li><code>DD_RUNTIME_METRICS_ENABLED</code>: enables <a href="https://www.datadoghq.com/blog/monitor-dotnet-runtime-metrics/">runtime metrics for the .NET runtime</a> like thread counts and garbage collection (GC) pressure</li></ul><p>Finally, in the “Startup Dependency Ordering” section, add the Agent container as a dependency by setting the “Container name” to <code>datadog-agent</code> and the “Condition” to “START”.</p><p>In the next section, we will create an application load balancer (ALB) that can automatically route public network traffic to our Agent and application containers.</p><h3 id="create-an-application-load-balancer"><a href="#create-an-application-load-balancer">Create an application load balancer</a></h3><p>Fargate supports <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/load-balancer-types.html">several different types</a> of load balancers for ECS, but we’ll use <a href="https://docs.amazonaws.cn/en_us/AmazonECS/latest/developerguide/create-load-balancer.html">an ALB</a> for this guide. Create a new load balancer by following steps in <a href="https://docs.aws.amazon.com/AmazonECS/latest/userguide/create-application-load-balancer.html">the AWS documentation</a>. You can use the default values for most of the available configuration options, but there are a few new security group rules that you will need to create.</p><p>Load balancer security groups determine what traffic is allowed to access the load balancer. On the “Assign Security Groups” page, <a href="https://docs.aws.amazon.com/AmazonECS/latest/userguide/create-application-load-balancer.html#alb-configure-security-groups">create a new security group</a> with a rule that uses the TCP protocol on port 80 and <code>0.0.0.0/0, ::/0</code> as a custom source. This ensures that the ALB is accessible from the public internet.</p><p>Next, on the “Configure Routing” page, <a href="https://docs.aws.amazon.com/AmazonECS/latest/userguide/create-application-load-balancer.html#alb-configure-routing">create a new target group</a> that uses the “IP address” target type and the HTTP protocol on port 80. You can use <code>/</code> as the health check path. Complete the remaining steps to create your load balancer.</p><p>Once the ALB is created, make note of its DNS name (found in the “Description” tab for the load balancer) as you will need it to access your application. Next, we will create a service to launch the application and all of its resources.</p><h3 id="create-an-ecs-service"><a href="#create-an-ecs-service">Create an ECS service</a></h3><p>The final step for deploying the Agent and .NET application is to create a new <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html">ECS service</a> for the cluster. We can use this service to schedule and launch all of the necessary components to run the application, such as the load balancer we created previously and the containers defined in our task definition.</p><p>You can <a href="https://docs.aws.amazon.com/AmazonECS/latest/userguide/create-service-console-v2.html">create a new service</a> on the “Clusters” page of the Amazon ECS console. Select your ECS cluster and click the “Create” button in the “Services” tab. There are a few settings that you will need to configure for the service. First, make sure the service uses “Fargate” as the launch type and the task definition you created earlier. In the “VPC and security groups” section, use your application load balancer’s VPC, subnets, and security group. In the “Load balancing” section of the “Configure network” page, select the <a href="#create-an-application-load-balancer">load balancer you created earlier</a> and add the application container in the “Container to load balance” section. Finally, the “Production listener port” needs to use the existing “80:HTTP” listener and the “Target group name” needs to use the name of your application container that you defined in your task definition.</p><p>Once the service launches successfully, navigate to the service’s “Details” tab to view the security group and add a new inbound rule. The new rule should use “All TCP&#39;&#39; as the type and your ALB security group as the custom source. This setting allows the ALB to route traffic to your cluster; without it, your cluster may restart repeatedly due to “failed health checks”.</p><p>After finishing these steps, you can use the DNS name associated with the ALB you created earlier to navigate to your application and generate traffic. Since the application is instrumented with the .NET tracer and configured to submit traces via the Agent, you will start seeing real-time performance data for your ECS cluster and .NET application in Datadog.</p><h2 id="monitor-application-performance-with-datadog"><a href="#monitor-application-performance-with-datadog">Monitor application performance with Datadog</a></h2><p>Datadog provides full visibility into the <a href="https://www.datadoghq.com/blog/aws-fargate-monitoring-with-datadog/">health and performance</a> of your Fargate resources, such as the memory and CPU utilization of your ECS tasks. You can use the built-in integration dashboard to get a high-level overview of your Fargate environment and ensure that the underlying infrastructure supporting your .NET application is performing optimally.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog&#39;s built-in AWS Fargate dashboard"/></picture></figure></div><p>The dashboard can alert you to significant changes in container performance, such as a sudden increase in memory usage for your application’s container, which you can troubleshoot further using Datadog APM.</p><h3 id="visualize-traces-with-datadog"><a href="#visualize-traces-with-datadog">Visualize traces with Datadog</a></h3><p>Datadog APM enables you to track distributed traces from your .NET application so you can get a better understanding of how application services process requests. To view your application’s traces, navigate to the <a href="https://app.datadoghq.com/apm/services/">service page</a> in your Datadog account and locate the <code>DatadogFargateExample</code> service under the <code>my-container-test</code> environment, which reflects the values you set for your <a href="#create-the-application-container">application container’s <code>DD_SERVICE</code> and <code>DD_ENV</code> environment variables</a>. You can select that service to see a high-level overview of application performance and visualizations for key metrics, such as the total number of requests, errors, and request latency.</p><p>You can also view your application’s runtime metrics alongside trace data in order to troubleshoot common performance issues, such as <a href="https://www.datadoghq.com/blog/monitor-dotnet-runtime-metrics/#monitor-first-chance-exceptions">first-chance exceptions</a>, so you have more context for resolving the problem before it becomes more serious.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=847" alt="Runtime metrics for a .NET Core application service"/></picture></figure></div><p>For even greater visibility into your application, you can <a href="https://docs.datadoghq.com/tracing/connect_logs_and_traces/dotnet/">connect .NET logs to your traces</a> by automatically injecting trace and span IDs into your logs. This enables you to quickly pivot between your traces and .NET logs to get a better picture of what is going on in your application. You can also add <a href="https://docs.datadoghq.com/tracing/setup_overview/custom_instrumentation/dotnet/">custom instrumentation</a> to your application’s business logic to monitor critical services, such as those that process payments, and ensure they are performing optimally.</p><h2 id="net-core--aws-fargate"><a href="#net-core--aws-fargate">.NET Core + AWS Fargate</a></h2><p>In this post, we’ve shown how you can instrument a .NET Core application with Datadog’s .NET tracer and deploy it as a container via AWS Fargate. We also looked at how you can use Datadog to monitor application and infrastructure performance in one place. Check out our documentation for more information about <a href="https://docs.datadoghq.com/tracing/setup_overview/">tracing your applications</a> and getting visibility into application performance, regardless of the environment or platform. If you don’t already have a Datadog account, you can sign up for a <a href="#">free trial</a>.</p></div></div>]]></content:encoded>
      <author>Andrew Lock</author>
      <pubDate>Tue, 03 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Monitor AWS FSx audit logs with Datadog</title>
      <link>https://www.datadoghq.com/blog/amazon-fsx-audit-logs-monitoring/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/AWS-FSx_integration_FINAL.png&#34; width=&#34;100%&#34;/&gt;Amazon FSx for Windows File Server is a fully managed file storage service built on Windows Server. Migrating on-premise Windows file systems to a managed service like FSx enables organizations to reduce operational overhead and take advantage of the flexibility and scalability of the cloud. But having visibility into file access activity across their environment is key for security and compliance requirements, particularly in sectors such as financial services and healthcare.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><a href="https://aws.amazon.com/fsx/windows/">Amazon FSx for Windows File Server</a> is a fully managed file storage service built on Windows Server. Migrating on-premise Windows file systems to a managed service like FSx enables organizations to reduce operational overhead and take advantage of the flexibility and scalability of the cloud. But having visibility into file access activity across their environment is key for security and compliance requirements, particularly in sectors such as financial services and healthcare. In order to provide this visibility, <a href="https://aws.amazon.com/blogs/aws/file-access-auditing-is-now-available-for-amazon-fsx-for-windows-file-server/">AWS recently added file access auditing to the Amazon FSx service</a>. With this update, Amazon FSx now publishes and stores audit event logs that summarize file system access activity at user-level for all files, folders, and file shares.</p><p>As an <a href="https://partners.amazonaws.com/partners/001E000000Rp57sIAB/Datadog%20Inc">AWS Partner solution</a>, you can use Datadog as an endpoint to send Amazon FSx audit event logs for retention and real-time analysis. You can use Datadog’s <a href="https://app.datadoghq.com/logs">Log Explorer</a> to easily search for file access events of interest or use <a href="https://www.datadoghq.com/blog/announcing-security-monitoring/">Datadog Security Monitoring</a> to look for and alert you to any unusual activity. This way, in addition to monitoring FSx metrics via <a href="https://docs.datadoghq.com/integrations/amazon_fsx/">Datadog’s integration</a>, your teams can audit any suspicious or unauthorized activity and take immediate steps to address any detected violations.</p><p>In this post, we’ll look at what information these logs contain and how you can use Datadog to:</p><ul><li><a href="#analyze-and-monitor-amazon-fsx-audit-event-logs-in-datadog">Monitor access activity</a> across your file systems</li><li><a href="#automatically-detect-security-threats-to-your-fsx-file-system">Create security rules</a> to alert you to possible threats</li></ul><h2 id="analyze-and-monitor-amazon-fsx-audit-event-logs-in-datadog"><a href="#analyze-and-monitor-amazon-fsx-audit-event-logs-in-datadog">Analyze and monitor Amazon FSx audit event logs in Datadog</a></h2><p>Amazon FSx audit event logs record all user attempts to access, create, modify, or delete a <a href="https://docs.aws.amazon.com/fsx/latest/WindowsGuide/using-file-shares.html">file share</a> or individual file or folder object. Each log follows the standard Windows event log format and contains important information regarding the access event, including:</p><ul><li>the type of event (indicated by the <code>EventID</code>)</li><li>the user who performed the action (<code>SubjectUserName</code>)</li><li>the object being accessed (<code>ObjectName</code> or <code>ShareName</code>)</li><li>whether it was successful (<code>Keywords</code>)</li><li>in the case of file shares, the access action performed (<code>AccessMask</code>).</li></ul><p>Datadog’s built-in <a href="https://docs.datadoghq.com/logs/processing/pipelines/">log processing pipeline</a> parses and extracts these key fields from your logs as <a href="https://docs.datadoghq.com/logs/processing/attributes_naming_convention/">attributes</a>, which you can then use to query, sort, and filter your logs. This enables you to perform complex analysis of user and file activity across your logs. For example, you can easily search for activity related to particularly sensitive folders.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog parses AWS FSx logs"/></picture><figcaption>Datadog parses out key data from your Amazon FSx event audit logs.</figcaption></figure></div><p>It’s also important to track overall trends in file system activity to surface any unusual behavior. For example, aggregating logs by file access event type, like create, modify, or delete, makes it easy to spot anomalous spikes in certain activity. You can then dive into the relevant logs to look at the users behind the spikes.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog AWS FSx audit log analytics"/></picture></figure></div><p>Using the <code>Keywords</code> attribute, you can further break down events by whether they were successful or not. This can help you identify spikes in failed operations, which might indicate an unauthorized user trying to access files.</p><h2 id="automatically-detect-security-threats-to-your-fsx-file-system"><a href="#automatically-detect-security-threats-to-your-fsx-file-system">Automatically detect security threats to your FSx file system</a></h2><p>Real-time knowledge of potentially suspicious activity across your file system is key to ensuring the security of your sensitive data. Datadog Security Monitoring provides out-of-the-box Threat Detection Rules to notify you when Datadog identifies specific activity. For example, the rule below looks for more than 10 failed file access attempts from a single user, which might indicate someone attempting to access files they don’t have permissions for.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog AWS FSx logs threat detection rule"/></picture></figure></div><p>You can easily create custom rules for your specific environment. For example, if you have particularly important file shares (<code>ShareName</code>), or even entire file systems (<code>Computer</code>), you can create rules to monitor them for any delete or modify attempts. You might also want to be alerted to any file share event from an IP address outside your organization. You can create a <a href="https://www.datadoghq.com/blog/new-term-detection-method-datadog/">new term–based</a> rule that notifies you of any activity from an address that Datadog hasn’t seen before, helping alert you to a possible threat.</p><p>Whenever a rule is triggered, Datadog generates a Security Signal that includes key metadata about the relevant event, so you can determine if you need to take further action, such as adjusting security policy settings to modify who can access certain files.</p><h2 id="get-deeper-insight-into-your-amazon-fsx-file-systems"><a href="#get-deeper-insight-into-your-amazon-fsx-file-systems">Get deeper insight into your Amazon FSx file systems</a></h2><p>Amazon FSx’s file access audit event logs give your teams immediate visibility into activity across your Windows Server file directory that, when paired with Datadog’s log management and security platforms, helps ensure that your files are secure. You can send your Amazon FSx logs to Datadog either with our <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-lambda-function/">Forwarder Lambda function</a> or by using a <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination/">Kinesis Firehose data stream</a>. See our <a href="https://docs.datadoghq.com/integrations/amazon_fsx/#log-collection">documentation</a> to get started. Or, if you’re not a Datadog customer, sign up today for a <a href="#">free 14-day trial</a>.</p></div></div>]]></content:encoded>
      <author>Jonathan Epstein</author>
      <pubDate>Fri, 30 Jul 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Datadog Announces Availability on Google Cloud Marketplace to Support Customers’ Cloud Migrations</title>
      <link>https://www.datadoghq.com/about/latest-news/press-releases/datadog-announces-availability-on-google-cloud-marketplace-to-support-customers-cloud-migrations/</link>
      <description>NEW YORK &amp;ndash; Datadog, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced its availability on Google Cloud Marketplace, deepening its partnership with Google Cloud. Google Cloud customers can now purchase Datadog with just a few clicks on the Google Cloud Marketplace, allowing them to quickly and easily monitor the health of their applications and infrastructure across their Google Cloud and hybrid cloud environments. Google Cloud Marketplace offers integrated solutions vetted by Google Cloud, to support customers’ enterprise IT needs.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><strong>NEW YORK</strong> – <a href="https://www.datadoghq.com/">Datadog</a>, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced its availability on <a href="https://console.cloud.google.com/marketplace/product/datadog-public/datadog">Google Cloud Marketplace</a>, deepening its partnership with Google Cloud. Google Cloud customers can now purchase Datadog with just a few clicks on the Google Cloud Marketplace, allowing them to quickly and easily monitor the health of their applications and infrastructure across their Google Cloud and hybrid cloud environments. </p><p>Google Cloud Marketplace offers integrated solutions vetted by Google Cloud, to support customers’ enterprise IT needs. Customers rely on Google Cloud Marketplace to identify and purchase the third-party tools that help them move to, build on and work in Google Cloud. In addition to easier access, customers who purchase Datadog through Google Cloud Marketplace will benefit from consolidated billing and streamlined procurement. Datadog usage will appear directly on customers’ Google Cloud invoices, and customers will be able to pay for a portion of this usage with their committed Google Cloud spend.</p><p>“By making Datadog available on Google Cloud via Marketplace, customers will have access to Datadog’s advanced monitoring and security capabilities,” said Amy Bray, Global Head, Google Cloud Marketplace, Google. “With Datadog on Google Cloud, customers can quickly begin leveraging its capabilities in application monitoring and security, ultimately helping them accelerate their cloud migrations and digital transformations.”</p><p>“We’re excited that Datadog is now available in the Google Cloud Marketplace,” said Marc Weisman, Vice President, Product Management, Datadog. “Monitoring and security are crucial for companies as they move their infrastructure and applications to the cloud, and we look forward to supporting Google Cloud customers as they undertake these initiatives.”</p><p>Datadog’s existing partnership and support for Google Cloud includes:</p><ul><li>Access to Datadog’s 450+ integrations on Google Cloud’s scalable and secure infrastructure, including integrations with Google Cloud services such as Compute Engine, Cloud Storage, BigQuery and more.</li><li>The ability to deploy the Datadog Agent directly on hosts and compute instances in Google Cloud, to collect metrics with greater granularity.</li><li>Extended go-to-market collaboration and deeper sales alignment with Google Cloud and Datadog sales teams.</li><li>Continued investment into product co-innovation with more native joint solutions around Anthos, Open Telemetry and the Google Cloud operations suite.</li></ul><p>For more information and to get started with Datadog, visit <a href="https://console.cloud.google.com/marketplace/product/datadog-public/datadog">Datadog in Google Cloud Marketplace</a>.</p><div><p><strong>About Datadog</strong></p><p>Datadog is the monitoring and security platform for cloud applications. Our SaaS platform integrates and automates infrastructure monitoring, application performance monitoring and log management to provide unified, real-time observability of our customers’ entire technology stack. Datadog is used by organizations of all sizes and across a wide range of industries to enable digital transformation and cloud migration, drive collaboration among development, operations, security and business teams, accelerate time to market for applications, reduce time to problem resolution, secure applications and infrastructure, understand user behavior and track key business metrics.</p></div><p><strong>Forward-Looking Statements</strong></p><p>This press release may include certain “forward-looking statements” within the meaning of Section 27A of the Securities Act of 1933, as amended, or the Securities Act, and Section 21E of the Securities Exchange Act of 1934, as amended. These forward-looking statements reflect our current views about our plans, intentions, expectations, strategies and prospects, which are based on the information currently available to us and on assumptions we have made. Actual results may differ materially from those described in the forward-looking statements and are subject to a variety of assumptions, uncertainties, risks and factors that are beyond our control, including those risks detailed under the caption “Risk Factors” and elsewhere in our Securities and Exchange Commission filings and reports, including the Quarterly Report on Form 10-Q filed with the Securities and Exchange Commission on May 7, 2021, as well as future filings and reports by us. Except as required by law, we undertake no duty or obligation to update any forward-looking statements contained in this release as a result of new information, future events, changes in expectations or otherwise.</p></div></div>]]></content:encoded>
      <author>Datadog</author>
      <pubDate>Thu, 29 Jul 2021 20:30:00 +0000</pubDate>
    </item>
    <item>
      <title>Use Datadog Session Replay to view real-time user journeys</title>
      <link>https://www.datadoghq.com/blog/session-replay-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-hero-1.png&#34; width=&#34;100%&#34;/&gt;When developing large, customer-facing applications, it’s paramount to have visibility into real user behavior in order to optimize your UX. Without a direct view into what users are actually doing when navigating your app, it can be difficult to reproduce bugs and understand how aspects of your frontend design are causing user frustration and churn. With Datadog RUM’s Session Replay feature, currently available in beta, you can watch individual user sessions using a video-like interface.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>When developing large, customer-facing applications, it’s paramount to have visibility into real user behavior in order to optimize your UX. Without a direct view into what users are actually doing when navigating your app, it can be difficult to reproduce bugs and understand how aspects of your frontend design are causing user frustration and churn. With Datadog RUM’s Session Replay feature, currently available in beta, you can watch individual user sessions using a video-like interface. This allows you to view exactly how your users interact with your website, saving you time and guesswork recreating bugs and helping you understand patterns in your users’ behavior. In this post, we’ll discuss how Session Replay can help you <a href="#reproduce-bugs-and-troubleshoot-faster">speed up your debugging</a> and <a href="#understand-user-behavior">find patterns in your users’ behavior</a>.</p><h2 id="reproduce-bugs-and-troubleshoot-faster"><a href="#reproduce-bugs-and-troubleshoot-faster">Reproduce bugs and troubleshoot faster</a></h2><p>As a frontend or support engineer, an essential—and often time-consuming—part of the debugging process is reproducing bugs. But it can be difficult to do so without a clear understanding of the actions a user took before your application threw an error. By recording real user journeys, Session Replay effectively reproduces the bug for you, saving time and eliminating any guesswork.</p><p>For example, let’s say you’re a frontend engineer monitoring a recent release and notice a new issue pop up in <a href="https://www.datadoghq.com/blog/error-tracking/">Error Tracking</a>. After viewing key information about the error, such as the error message, stacktrace, and browser info, you can immediately pivot directly from the issue summary to a live reproduction of the most recent session that experienced the error.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=847" alt="Pivot to a Session Replay from Error Tracking"/></picture></figure></div><p>When viewing a replay, you can see a video-like reproduction of the entire user journey. Datadog also displays an event timeline that breaks the session down into every page load and DOM change resulting from the user’s actions so you can jump to individual events. The timeline flags any user interaction that results in an error so you can pinpoint when and where issues occurred.</p><p>For example, let’s say you notice a rise in timeout errors on a particular page load. With Session Replay, you can easily identify the exact user action that’s causing the timeout, without needing to guess about how users are triggering the error.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=847" alt="Session Replay"/></picture></figure></div><p>Once you’ve found the user action or page load triggering the timeout error, you can see more details to start troubleshooting. For example, you can see a <a href="https://docs.datadoghq.com/real_user_monitoring/browser/monitoring_page_performance">waterfall</a> of the resources loaded—along with <a href="https://www.datadoghq.com/blog/core-web-vitals-monitoring-datadog-rum-synthetics/">key performance metrics</a>. This helps you determine, for example, if there is a particularly slow asset that is causing a bottleneck for users. For further context, you can pivot to relevant <a href="https://www.datadoghq.com/blog/unify-apm-rum-datadog/">traces, logs, and errors</a> to continue investigating whether, for instance, the root cause of the timeouts is a backend problem like a hanging API call.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=847" alt="RUM waterfall"/></picture></figure></div><h2 id="understand-user-behavior"><a href="#understand-user-behavior">Understand user behavior</a></h2><p>If you’re a UI or UX designer, real user data can be an important source of truth for understanding the efficacy of your designs. Using Session Replay, you can observe how users traverse your website to get insight into how long it takes them to make decisions, what they hover over before clicking on something else, how they respond to broken UI elements and other errors, and more.</p><p>Let’s say you’re a designer investigating a drop in click-through rate for a key part of your application, such as a checkout page. You might first want to check if something in a common user flow to this endpoint is causing a bottleneck. By filtering the RUM Sessions view to sessions that include common gateways to the checkout page, such as the shopping cart, and sorting the resulting list by duration, you can surface replays that represent cases where the user spent a particularly long time on the previous page.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=847" alt="Session Replays query"/></picture></figure></div><p>Examining Session Replays for these slow cases, you can directly observe users’ behavior to not only understand what is happening, but also form hypotheses about why. For example, you might watch the user unsuccessfully attempt to enter their password several times before churning away. Then, you can use the insight you’ve gathered to create design interventions to try and guide these situations. For example, you could build a new password recovery workflow, or add an option to check out as a guest so users can bypass the sign-in form that is causing them to churn. After deploying your change, you can monitor key RUM metrics like the pageview count for the checkout page to see if it rises, indicating more users are successfully getting through the sign-in page.</p><h2 id="get-started-with-session-replay"><a href="#get-started-with-session-replay">Get started with Session Replay</a></h2><p>RUM’s Session Replay feature is a powerful tool for providing qualitative context around your frontend performance metrics, helping designers understand user behavior, and automatically reproducing bugs so your frontend developers can iterate fixes faster. Session Replay is currently available in beta—if you’re a Datadog customer, you can sign up for the beta <a href="https://www.datadoghq.com/session-replay-beta-request-form/">here</a>. Or, you can get started using Datadog with a <a href="#">14-day free trial</a>.</p></div></div>]]></content:encoded>
      <author>Thomas Sobolik</author>
      <pubDate>Wed, 28 Jul 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Datadog at GitLab Commit 2021</title>
      <link>https://www.datadoghq.com/event/micro-gitlabcommit-2021/</link>
      <description>Datadog at GitLab Commit 2021</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><section><a name="main"></a></section><section><a name="raffle"></a><div><p>No purchase necessary to enter or win. Limit 1 entry per person. Void where prohibited. The contest ends August 4, 2021, at 5:00pm EDT. Open to legal residents of Australia, Austria, Belgium, Brazil, Canada, Denmark, France, Germany, Ireland, Japan, Norway, Poland, Singapore, Spain, Sweden, Switzerland, The Netherlands, UK, and USA (excluding Puerto Rico) who are 18 years of age or older (or the age of majority in their state or country of residence, whichever is older) as of the date of entry who attended the event. The Sweepstakes is not open to any employee of a current Datadog customer, any current students or any employee of a competitor of Datadog. In addition, the Sweepstakes is not open to any agent or employee of Datadog or its affiliates or marketing firms, or to any immediate family or household member of those individuals. The winner will be notified via email. By submitting an entry to the contest, the entrant agrees to be bound by the Official Rules. See <a href="http://dtdg.co/gitlabrafflelegal" target="_blank">here</a> for Official Rules. Sponsor: Datadog, Inc., 620 8th Avenue, 45th Floor, New York, NY 10018.</p></div></section><section><a name="trial"></a><div><p>No purchase necessary to enter or win. Limit 1 entry per person. Void where prohibited. The contest ends August 24, 2021, at 11:59pm EDT. Open to legal residents of Australia, Austria, Belgium, Brazil, Canada, Denmark, France, Germany, Ireland, Japan, Norway, Poland, Singapore, Spain, Sweden, Switzerland, The Netherlands, UK, and USA (excluding Puerto Rico) who are 18 years of age or older (or the age of majority in their state or country of residence, whichever is older) as of the date of entry who attended the event. The Sweepstakes is not open to any employee of a current Datadog customer, any current students or any employee of a competitor of Datadog. In addition, the Sweepstakes is not open to any agent or employee of Datadog or its affiliates or marketing firms, or to any immediate family or household member of those individuals. The winner will be notified via email. By submitting an entry to the contest, the entrant agrees to be bound by the Official Rules. See <a href="http://dtdg.co/gitlabcommitlegal" target="_blank">here</a> for Official Rules. Sponsor: Datadog, Inc., 620 8th Avenue, 45th Floor, New York, NY 10018.</p></div></section></div></div>]]></content:encoded>
      <author>Datadog</author>
      <pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Monitor your CI pipelines and tests with Datadog CI Visibility</title>
      <link>https://www.datadoghq.com/blog/datadog-ci-visibility/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/ci-visibility-hero.png&#34; width=&#34;100%&#34;/&gt;Datadog CI Visibility, now available in beta, provides critical visibility into your organization’s CI/CD workflows. CI Visibility complements Datadog’s turn-key CI provider integrations and the integration of synthetic tests in CI pipelines to give you deep insight into key pipeline metrics and help you identify issues with your builds and testing.With modern agile development methods and advances in CI/CD automation, organizations are able to build and ship releases quickly and regularly to deliver new value to customers.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Datadog CI Visibility, now available in beta, provides critical visibility into your organization’s CI/CD workflows. CI Visibility complements Datadog’s <a href="https://www.datadoghq.com/blog/monitor-ci-pipelines/">turn-key CI provider integrations</a> and the integration of <a href="https://www.datadoghq.com/blog/datadog-synthetic-ci-cd-testing/">synthetic tests in CI pipelines</a> to give you deep insight into key pipeline metrics and help you identify issues with your builds and testing.</p><p>With modern agile development methods and advances in CI/CD automation, organizations are able to build and ship releases quickly and regularly to deliver new value to customers. But without granular visibility into the performance of their pre-production testing and deployment pipelines, organizations can experience development outages due to slow builds or increases in failing or flaky tests.</p><p>Datadog CI Visibility provides deep insight into the performance of your CI pipelines, making it easy to identify issues—like error-prone jobs or flaky tests that cause your builds to fail randomly—and enabling you to make your CI workflows faster and more reliable. In this post, we’ll discuss how you can use CI Visibility to:</p><ul><li><a href="#monitor-your-CI-pipelines">Monitor pipeline builds, stages, and jobs to locate problems</a></li><li><a href="#monitor-test-trends-and-identify-problems">Track test performance and identify flaky tests</a></li></ul><h2 id="monitor-your-ci-pipelines"><a href="#monitor-your-ci-pipelines">Monitor your CI pipelines</a></h2><p>Datadog CI Pipeline Visibility provides comprehensive visibility into all your pipelines—across CI providers—by generating key performance metrics to help you understand, for example, which pipelines, build stages, or jobs are run the most, how often they fail, and how long they take to complete. Datadog visualizes this information in a customizable out-of-the-box Pipelines dashboard. This gives you a high-level overview of performance across all your pipelines, stages, and jobs so you can track trends at a glance and identify where to focus your troubleshooting efforts.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=847" alt="Pipelines dashboard"/></picture></figure></div><p>The Pipelines Visibility page provides more granular insight into your CI workflows by breaking down health and performance metrics by pipeline. You can sort and filter the list to quickly surface which pipelines are the slowest or experience the most errors. In the example below, we have sorted pipelines by average build duration to show which ones are the slowest.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=847" alt="Pipeline Visibility overview page"/></picture></figure></div><h3 id="drill-into-individual-pipelines"><a href="#drill-into-individual-pipelines">Drill into individual pipelines</a></h3><p>Once you’ve identified a pipeline with a high error rate or long build duration, you can drill into it to get more detailed information about its performance over time. The pipeline summary shows a breakdown of duration and failure rates across the pipeline’s individual stages and jobs to spot where slowdowns or failures might be occurring.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=847" alt="Pipeline summary"/></picture></figure></div><p>A pipeline’s summary includes a table of all of that pipeline’s executions. You can easily filter your executions by key attributes like branch, status, and duration, or scope the table to a specific stage or job.</p><p>Once you’ve integrated Datadog with your CI provider, Datadog automatically instruments your pipelines. This means that, if you spot a slow or failing build and need to understand what’s happening, you can drill into a flame graph visualization of the build to look for high duration or errorful jobs. Then, you can dive into the error details to understand the source of the error, or look in the tags for the job URL to find the context you need to identify and remediate the underlying issue.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=847" alt="Pipeline trace"/></picture></figure></div><h2 id="monitor-test-trends-and-identify-problems"><a href="#monitor-test-trends-and-identify-problems">Monitor test trends and identify problems</a></h2><p>Monitoring your tests is key to identifying faulty tests and understanding overall test suite performance. With Datadog CI Testing Visibility, you can easily monitor your tests across all of your builds to surface common errors and visualize test performance over time to spot regressions. In the Testing Visibility page, you can see each of your services’ test suites along with the corresponding branch, duration, and number of fails, passes, and skips. Datadog also tracks the number of new flaky tests, or tests that variably pass and fail for the same commit, which were previously unseen in the default branch.</p><h3 id="identify-and-troubleshoot-flaky-tests"><a href="#identify-and-troubleshoot-flaky-tests">Identify and troubleshoot flaky tests</a></h3><p>Flaky tests can compromise the effectiveness of your testing and break builds seemingly at random. Locating and debugging flaky tests is important for ensuring the reliability of your test suites. Datadog automatically detects when commits introduce flaky tests and displays that data for the relevant branch.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=847" alt="Test Visibility overview page"/></picture></figure></div><p>Once you’ve spotted a branch with new flaky tests to examine, you can dive into the commit overviews for that service. Looking at the Latest Commit Overview, you can see which tests failed and the most common errors between them.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=847" alt="Test summary"/></picture></figure></div><p>The Flaky Tests summary surfaces all the tests in this service’s test suite that flaked. Selecting a test row, you can view runs of the test from the commit that first flaked, which is likely to contain the code change responsible for making the test flaky.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=847" alt="Flaky tests overview"/></picture></figure></div><h3 id="analyze-test-performance"><a href="#analyze-test-performance">Analyze test performance</a></h3><p>Just like with CI Pipeline Visibility, Datadog Testing Visibility automatically instruments each of your tests so you can trace them from end to end without spending time reproducing test failures. For example, once you’ve found a flaky test you want to debug, you can drill into the test trace for more information. Using the flame graph, you can, for example, easily find the point(s) of failure in a complex integration test. Clicking on an errorful span, you can examine the stacktrace along with related error messages to examine what caused the test to fail in that instance. For more context, Datadog links to the relevant pipeline so you can jump into your CI provider to examine the console output from the test run.</p><h2 id="ensure-smooth-reliable-builds"><a href="#ensure-smooth-reliable-builds">Ensure smooth, reliable builds</a></h2><p>Datadog CI Visibility enables you to fill in the pre-production observability gap. It gives you deep visibility into your test performance, so you can ensure your tests will catch performance issues before they reach customers, while also empowering you to manage your pipelines—saving precious developer time and computing resources. Combined with Datadog’s extensive support for synthetic testing within your CI, you can use Datadog to shift full-stack observability to the left, nipping outages and regressions in the bud.</p><p>CI Visibility is currently in a public beta—see our <a href="https://docs.datadoghq.com/continuous_integration/">documentation</a> for detailed installation steps. Or, if you’re brand new to Datadog, sign up for a <a href="#">14-day free trial</a> to get started.</p></div></div>]]></content:encoded>
      <author>Thomas Sobolik</author>
      <pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Test internal applications with Datadog&#39;s testing tunnel and private locations</title>
      <link>https://www.datadoghq.com/blog/internal-application-testing-with-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-hero.png&#34; width=&#34;100%&#34;/&gt;As part of your monitoring and testing strategy, you may run tests on different types of applications that are not publicly available—from local versions of production-level websites to internal applications that directly support your employees. Testing each one requires leveraging tools that allow you to verify functionality across a wide range of devices, browsers, and workflows while maintaining a secure environment. Datadog Synthetic Monitoring already lets you create your own custom probes (on-premise test runners) with private locations to routinely test and monitor all of your internal-facing applications.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>As part of your monitoring and testing strategy, you may run tests on different types of applications that are not publicly available—from local versions of production-level websites to internal applications that directly support your employees. Testing each one requires leveraging tools that allow you to verify functionality across a wide range of devices, browsers, and workflows while maintaining a secure environment. <a href="https://docs.datadoghq.com/synthetics/">Datadog Synthetic Monitoring</a> already lets you create your own custom probes (on-premise test runners) with <a href="https://docs.datadoghq.com/synthetics/private_locations?tab=docker">private locations</a> to routinely test and monitor all of your internal-facing applications. Now, for on-demand testing, you can also use Datadog’s <a href="https://docs.datadoghq.com/synthetics/testing_tunnel">testing tunnel</a>, a secure tunnel connection that requires little setup.</p><p>Private locations and the testing tunnel give you more flexibility over how you test applications in your internal environments, but each tool offers some unique benefits to support different testing goals.</p><p>In this post, we’ll look at:</p><ul><li>using the <a href="#ci-and-local-testing-with-the-testing-tunnel">testing tunnel</a> for on-demand testing in local and continuous integration (CI) environments</li><li>creating <a href="#durable-testing-and-monitoring-using-private-locations">private locations</a> for durable testing and monitoring</li></ul><h2 id="ci-and-local-testing-with-the-testing-tunnel"><a href="#ci-and-local-testing-with-the-testing-tunnel">CI and local testing with the testing tunnel</a></h2><p>The testing tunnel leverages Datadog’s <a href="https://docs.datadoghq.com/synthetics/ci/?tab=apitest">command line interface (CLI)</a> to create an end-to-end encrypted HTTP proxy between your infrastructure and Datadog. The CLI is an <a href="https://www.npmjs.com/package/@datadog/datadog-ci">NPM package</a> that enables you to launch Datadog Synthetic tests <a href="https://www.datadoghq.com/blog/datadog-synthetic-ci-cd-testing/">as part of your CI/CD pipelines</a>, so you can identify and fix regressions in your applications before they impact your users. When used in conjunction with the testing tunnel feature, any test requests you send using the CLI are automatically routed through the <code>datadog-ci</code> client, allowing Datadog to access and test your internal applications.</p><p>Datadog’s testing tunnel is designed to support CI pipelines and local development, so you can use it for:</p><ul><li>verifying hotfixes or new features locally before committing code</li><li>running tests in environments reserved for CI pipelines (e.g., staging, user acceptance testing, etc.) or in ephemeral cloud environments</li></ul><p>We’ll look at how the tunnel’s unique features and benefits can support these particular testing goals next.</p><h3 id="an-easy-to-use-tool-for-testing-on-demand"><a href="#an-easy-to-use-tool-for-testing-on-demand">An easy-to-use tool for testing on demand</a></h3><p>A key benefit of the testing tunnel is its ease of use within existing infrastructure; it enables you to incorporate API and end-to-end tests into all of your workflows. For example, your teams (e.g., developers, testers) can use this tool out of the box to quickly verify that a hotfix for a time-sensitive issue, such as a service outage, works as expected locally before deploying it to end users. You can also use the tunnel service to run test suites as part of your CI pipelines without launching multiple browsers directly on CI servers, where processing power may be limited.</p><p>You can instantly create a tunnel connection to run tests using a simple command:</p><div><pre><code data-lang="text"> 
datadog-ci synthetics run-tests --config synthetics.global.json --tunnel</code></pre></div><p>The example command above will open a WebSocket Secure <a href="https://docs.datadoghq.com/synthetics/testing_tunnel/#what-is-the-testing-tunnel">tunnel connection</a> and launch the suite of tests defined in your local machine’s or CI server’s <a href="https://docs.datadoghq.com/synthetics/ci/?tab=apitest#configure-tests">test configuration files</a>. These files include the public IDs of the tests that you want to run, along with other configuration attributes, such as endpoint URLs, device IDs, and locations.</p><p>Since the tunnel is built into Datadog’s CLI, it enables you to quickly start testing your internal applications at any time.</p><h3 id="launch-tests-with-minimal-overhead"><a href="#launch-tests-with-minimal-overhead">Launch tests with minimal overhead</a></h3><p>The tunnel is independent of existing infrastructure, so you can use it without deploying, maintaining, or monitoring additional services. Tests launched via the tunnel are executed from Datadog-managed locations. This means that as long as the host running Datadog’s CI client can create the connections needed to run multiple tests, Datadog will automatically scale to support the increased load as needed. Tunnel connections then end when the Datadog CI client receives all necessary results, so you do not need to track long-running connections to your network.</p><p>The tunnel also makes it easy to dynamically override where your tests run with Datadog’s <a href="https://docs.datadoghq.com/synthetics/ci/?tab=apitest#start-url">built-in environment variables</a>, so you can continue testing your applications without interruption, even as the environment you are testing changes. This includes environments that rely on ephemeral cloud instances and containers. For example, you can automatically pass the URL of a newly deployed application instance as the starting URL for any tests launched with the tunnel, instead of hard coding that data into your tests.</p><p>Datadog shows which tests were launched through the tunnel service so you can monitor them alongside the rest of your synthetic tests. For any test failures, Datadog provides <a href="https://www.datadoghq.com/blog/introducing-synthetic-monitoring/#end-to-end-visibility">end-to-end visibility</a> for troubleshooting and resolving issues, including details such as screenshots of the UI, JavaScript and network errors, load times for page resources, and APM traces if your test is hitting an instrumented service endpoint.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=847" alt="View test results after using the testing tunnel for local testing"/></picture></figure></div><p>Now that we’ve covered the benefits of using the testing tunnel for straightforward, on-demand testing, we’ll look at how Datadog’s private locations support your long-term testing and monitoring goals.</p><h2 id="durable-testing-and-monitoring-using-private-locations"><a href="#durable-testing-and-monitoring-using-private-locations">Durable testing and monitoring using private locations</a></h2><p>As we’ve seen, the testing tunnel offers a turn-key solution for secure, rapid testing in short-lived environments. For organizations who need to regularly test and monitor applications hosted on permanent environments, Datadog provides <a href="https://www.datadoghq.com/blog/private-synthetic-monitoring/">private locations</a>: Docker containers that you can deploy as custom <a href="https://en.wikipedia.org/wiki/Point_of_presence">points of presence</a> (e.g., data centers, geographic locations) inside of your infrastructure <a href="https://docs.datadoghq.com/synthetics/private_locations/?tab=docker#install-your-private-location">using orchestration tools</a> like Docker Compose, Kubernetes, AWS Fargate, and Amazon ECS.</p><p>Because private locations are deployed as a durable probing service for launching your tests, they can be useful for:</p><ul><li>customizing and managing a centralized testing tool that is readily available for teams across your organization</li><li>triggering tests on long-running environments (e.g., staging, pre-production) as part of your CI/CD pipelines</li><li>regularly running tests on internal applications that are hosted on private networks to ensure you can maintain your availability SLOs</li></ul><p>We’ll look at how you can use private locations to create a customizable, scalable, and easily accessible service in more detail next.</p><h3 id="a-fully-fledged-and-customizable-testing-service-for-internal-applications"><a href="#a-fully-fledged-and-customizable-testing-service-for-internal-applications">A fully-fledged and customizable testing service for internal applications</a></h3><p>Since testing is a crucial part of building resilient applications, you need a system that can support testing a growing network of services as your organization scales. Using private locations, your SRE teams have greater flexibility in not only customizing a probing service for every use case—via their <a href="https://docs.datadoghq.com/synthetics/private_locations/?tab=docker#install-your-private-location">preferred orchestration tool</a>—but also ensuring it can scale to continually verify functionality and monitor application performance.</p><p>Private locations come with a number of parameters you can use to match your infrastructure and private network configurations, such as built-in controls to <a href="https://docs.datadoghq.com/synthetics/private_locations/?tab=docker#blocking-reserved-ips">block IPs</a> in order to prevent users from creating synthetic tests on potentially sensitive endpoints in reserved IP ranges. And, as your applications grow, you can horizontally or vertically <a href="https://docs.datadoghq.com/synthetics/private_locations?tab=docker#scale-your-private-locations">scale your locations</a> in order to run more synthetic tests concurrently, enabling you to seamlessly test newly added features alongside existing functionality. Leveraging these measures ensure your applications—and your test infrastructure—remain secure and continue supporting your users.</p><h4 id="monitoring-private-locations"><a href="#monitoring-private-locations">Monitoring private locations</a></h4><p>Private locations are designed to regularly test and monitor your applications long term. Because of their longevity—and since tests run on the servers where you’ve deployed private locations—you need to ensure that every location is working as expected. Datadog provides visibility into your entire infrastructure, so you can monitor the performance of your custom locations in one place. For example, you can create custom dashboards to get a high-level overview of all of your private locations and easily monitor usage, as seen below.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=847" alt="Create custom dashboards to monitor private locations"/></picture></figure></div><p>You can also use the Datadog Agent to <a href="https://docs.datadoghq.com/infrastructure/livecontainers/?tab=helm">get deeper visibility</a> into the state of your private locations&#39; underlying containers and confirm that they are performing optimally. If you notice unusual changes in the tests executed by your private location, such as a significant increase in response time, you can then drill down to the affected container in order to troubleshoot further.</p><h3 id="self-service-testing-for-every-team"><a href="#self-service-testing-for-every-team">Self-service testing for every team</a></h3><p>Once deployed, private locations provide a centralized and readily available service for testing, so your teams can create their own tests and assign them to specific locations in one click.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=847" alt="Teams can easily set up tests using any deployed private location for internal application monitoring."/></picture><figcaption>All of your teams can easily add available private locations when creating new tests</figcaption></figure></div><p>This enables your teams to routinely test applications under a wide variety of conditions. For example, your corporate IT team can launch tests on private locations deployed to multiple data centers to ensure that your company intranet or a key SaaS provider is performing optimally for a growing team of distributed employees, regardless of their location.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=847" alt="View test results for monitoring behind the firewall using private locations"/></picture></figure></div><p>Or, your QA team can leverage the same tests and private locations as part of their CI/CD pipelines to verify that key workflows are still accessible to users after a canary deployment of new intranet features.</p><h2 id="your-map-for-comprehensive-internal-application-testing"><a href="#your-map-for-comprehensive-internal-application-testing">Your map for comprehensive internal application testing</a></h2><p>With private locations and the testing tunnel, you have more options for testing and monitoring your internal-facing applications. Each service offers unique features to help you accomplish your testing goals, whether they require long-running probing services or the ability to quickly launch tests on demand and with little setup. Check out the documentation for <a href="https://docs.datadoghq.com/synthetics/private_locations?tab=docker">private locations</a> and the <a href="https://docs.datadoghq.com/synthetics/testing_tunnel">tunnel service</a> (currently in public beta) to learn how to get started with both. If you don’t already have a Datadog account, you can sign up for a <a href="#">free 14-day trial</a>.</p></div></div>]]></content:encoded>
      <author>Mallory Mooney</author>
      <pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Partnership Brings Joint Success in LATAM</title>
      <link>https://www.datadoghq.com/case-studies/econocom/</link>
      <description>About Econocom Econocom is a B2B reseller and technology consulting company with an annual revenue of more than $3 billion. As part of their global operations, Econocom Brazil has joined the Datadog Partner Network to better equip their customers with cloud-native monitoring. Key Results 15+ logos New major logos closed via the Datadog + Econocom partnership in the first year3 expansions The number of times Econocom landed and expanded in a single account in 3 months with Datadog</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><span><h2 id="span-classheader-purplegrowing-demand-for-consulting-servicesspan"></h2><p>Econocom Brazil offers a suite of services, including technology resale and consultation work, to help their customers modernize their IT infrastructure, development and operation practices. As their customer base has grown, Econocom has seen an increase in demand not only for implementation of new technologies, but for consultation on cultural changes like shifting to DevOps, as well. “About one-third of our revenue comes from project and consultation activities, and two-thirds are related to other services. We’re really interested in increasing the volume of projects and consulting work that we offer, because it’s such a big value-add for our customers,” said Rodrigo Bocchi, the CEO of Econocom Brazil. “We expect this will be the main portion of the company’s revenue in the near future.”</p><p>To ensure their readiness to help their clients adopt modern technology and practices successfully, Econocom needed to offer a modern monitoring platform designed to facilitate DevOps-style communication within ephemeral, cloud-based and Kubernetes-based systems. Additionally, Econocom was looking for a product that could cover any customer’s stack—and that could be implemented quickly to accelerate their deal cycles. In the end, Econocom Brazil chose to partner with Datadog to provide these services for their customers because of Datadog’s expansive coverage, ease of use, and rapid implementation speed.</p><p>With Datadog, users have access to a unified platform encompassing infrastructure metrics, application management, logs, security, monitoring, and more. Bringing these capabilities together into one platform allows end users to quickly find a reported issue and the root cause in just a few clicks, with all the context they need at hand. This accelerates resolution time, which leads to more productive engineering teams, reduces risk during migrations and transitions, and improves end-user experiences.</p><p>Datadog also provides coverage across modern environments as well as legacy or on-premise installations. With extensive support for containers, including container Autodiscovery, a dedicated Kubernetes Cluster Agent, and out-of-the-box dashboards, Datadog makes it easier for Econocom’s customers to enact digital transformations. “In some cases, we are replacing old technologies (which support systems, applications and logs separately and are from different vendors) inside our client. We are helping them to transform their monitoring and adapt to cloud environments and Kubernetes environments with a unified and fully correlated view, quickly identifying the root cause,” said Rosano Moraes, Head of Sales, Brazil.</p><blockquote><p><em>&#34; We’re replacing old technologies […] and helping them transform their monitoring and adapt to cloud environments and Kubernetes environments.&#34;</em></p><p>Rosano Moraes
Head of Sales, Econocom Brazil</p></blockquote><p>Another big appeal for Econocom is Datadog’s ease of use. The Datadog platform itself can be used by both Dev and Ops teams with minimal training, and it doesn’t require certification or knowledge of a query language. All dashboards can be created using a point-and-click interface, which allows companies to democratize their data so that centralized monitoring teams aren’t backlogged with routine work. Ease of use also reduces troubleshooting time when problems do arise, because the teams that are closest to the problem feel empowered to use Datadog to understand and address the root cause.</p><p>The simplicity of a unified platform is core to Econocom’s DevOps consulting practices. Using Datadog as the single source of truth eliminates the messy communication silos that come from having tooling divisions across teams. “The Datadog platform was attractive because it unifies so many other products. It all drives towards simplicity—so it’s easier to solve problems. That’s something our customers really respond to,” said Moraes. “We use Datadog with our DevOps Excellence consulting program, and it helps our customers adopt DevOps culture more easily,” he added.</p><blockquote><p><em>&#34; It all drives towards simplicity—so it’s easier to solve problems. That’s something our customers really respond to.&#34;</em></p><p>Rosano Moraes
Head of Sales, Econocom Brazil</p></blockquote><p>Datadog also helps Econocom deploy quickly and consistently in every customer’s environment. “Implementation is so simple and fast with Datadog,” said Moraes. Implementation speed is driven by Datadog’s 450+ integrations, which provide key metrics, out-of-the-box dashboards, and recommended monitors for popular technologies. And because Datadog is a SaaS product, it can be deployed as a single agent for all data collection, doesn’t require the setup of any dedicated hosts or collectors, and can be rolled out automatically with a variety of tools like Chef, Puppet, or Helm. This not only saves the customer time, but also gives Econocom more opportunity to focus on the unique needs of each customer while providing higher value-add services like consulting. It also accelerates overall deal cycles, which improves Econocom’s operational efficiency.</p><blockquote><p><em>&#34; Implementation is so simple and fast with Datadog&#34;</em></p><p>Rosano Moraes
Head of Sales, Econocom Brazil</p></blockquote><p>Econocom took advantage of training courses provided by the Datadog Partner Network to enable their staff to understand and position Datadog effectively. Econocom Brazil was one of the first Gold-tier Datadog Partner Network members in Latin America, due to their technical qualifications and certifications, which led to a close relationship with Datadog’s sales team and unlocked better prices for their customers. Within the first year, Datadog and Econocom worked together to land over 15 major new logos, spanning industries like financial services, cloud technology, hospitality, and marketing.</p><p>“Our first year with Datadog has been very successful. The solution is strong, which makes it easy to position, and easy to prove the value. On top of that, Datadog’s commercial and enterprise teams in Brazil have worked really closely with us-” said Bocchi. “It feels like we’re an extension of the Datadog sales team,” added Moraes.</p><p>Bocchi also praised the high demand he’s seen for Datadog, as well as the flexibility it gives Econocom. “With one of our major customers, it took us about nine months to close the deal initially. But in the three months after deploying Datadog, they loved it so much they came back to us twice looking to expand,” said Bocchi, adding: “Datadog’s fresh, it’s easier, it’s more flexible in terms of sizing. There’s no delay in implementation. Our customers are more confident in what they’re getting from us.”</p><blockquote><p><em>&#34; Datadog’s fresh, it’s easier, it’s more flexible in terms of sizing. There’s no delay in implementation. Our customers are more confident in what they’re getting from us.&#34;</em></p><p>Rodrigo Bocchi
CEO, Econocom Brazil</p></blockquote></span></div></div>]]></content:encoded>
      <author>Datadog</author>
      <pubDate>Mon, 26 Jul 2021 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>