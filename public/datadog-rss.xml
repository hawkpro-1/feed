<?xml version="1.0" encoding="UTF-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>DataDog</title>
    <link>https://datadoghq.com/blog/index.xml</link>
    <description></description>
    <item>
      <title>How to detect security threats in your systems&#39; Linux processes</title>
      <link>https://www.datadoghq.com/blog/linux-security-threat-detection-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/linux-process-hero.png&#34; width=&#34;100%&#34;/&gt;Almost all tasks within a Linux system, whether it&amp;rsquo;s an application, system daemon, or certain types of user activity, are executed by one or more processes. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we&amp;rsquo;ll look at: how understanding the Linux process tree can help you identify security threats what process information can help you determine the scope of a breach We&amp;rsquo;ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Almost all tasks within a Linux system, whether it’s an application, system daemon, or certain types of user activity, are executed by one or more <a href="https://tldp.org/LDP/tlk/kernel/processes.html">processes</a>. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we’ll look at:</p><ul><li>how <a href="#a-primer-on-the-process-tree">understanding the Linux process tree</a> can help you identify security threats</li><li>what <a href="#use-process-data-to-determine-the-scope-of-an-attack">process information</a> can help you determine the scope of a breach</li></ul><p>We’ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.</p><h2 id="a-primer-on-the-process-tree"><a href="#a-primer-on-the-process-tree">A primer on the process tree</a></h2><p>In Linux, each process is generated by a preceding <strong>parent</strong> process and can generate one or more <strong>child</strong> processes. Following this parent/child structure, active processes form a <strong>process tree</strong> that starts with the <code>systemd</code> process that runs when Linux first boots and ends with the most recently generated processes. This parent/child structure is particularly useful for revealing security threats because, unlike simple indicators of compromise (IOCs) like adversarial IP addresses or file hashes, it’s difficult to fake or change. For instance, while attackers can change an IP address, it’s much harder to hide that an application has spawned a new suspicious child process.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847" alt="process-tree.png"/></picture><figcaption>Active processes are structured as a process tree which can be used to help you spot signs of a security breach.</figcaption></figure></div><h2 id="identify-suspicious-processes"><a href="#identify-suspicious-processes">Identify suspicious processes</a></h2><p>As you monitor your applications, it’s important to look out for any launched shells or utilities (e.g., <code>bash</code> or <code>curl</code>) that are children of key processes in your environment. For example, if a Java application process generates a shell you aren’t anticipating, it could indicate that a malicious actor has infiltrated your app and launched a <a href="https://us-cert.cisa.gov/ncas/alerts/TA15-314A">web shell attack</a>. When these attacks are successful, they can create backdoors to your infrastructure that allow attackers to access sensitive data and execute commands without authorization.</p><p>Likewise, you should check if a process spawned utilities like <code>nmap</code>, which an attacker can use to survey your network for further vulnerabilities to exploit, or <code>passwd</code>, which can be used to change user passwords and grant attackers higher privileges.</p><p>Once you’ve identified a malicious process, it’s important to investigate the scope of the attack, including what information the attacker has potentially gained access to.</p><h2 id="use-process-data-to-determine-the-scope-of-an-attack"><a href="#use-process-data-to-determine-the-scope-of-an-attack">Use process data to determine the scope of an attack</a></h2><p>Linux processes include metadata that can help you determine the scope of an attack. The key types of information to look at are:</p><ul><li>environment variables</li><li>command-line arguments</li></ul><h3 id="environment-variables"><a href="#environment-variables">Environment variables</a></h3><p>Due to their <a href="#a-primer-on-the-process-tree">relationship</a>, child processes inherit access to any environment variables available to the parent process. Though it’s not considered best practice, environment variables are often used to store sensitive data like API and GitHub keys, or even database credentials. Using our example of an attacker successfully creating a web shell from a Java application process, the shell would be able to see any environment variables associated with your application process, such as database credentials for a SQL server containing sensitive customer data.</p><p>Examining what environment variables a process includes can help you determine the full scope of a threat. You can quickly view a list of a process’s environment variables by using the Linux command <code>ps faux</code> to get its PID and then running the following:</p><div><pre><code data-lang="text">cat /proc/&lt;PROCESS_PID&gt;/environ </code></pre></div><p>Please note, however, that this detection method only works while the process is running. This makes it challenging to view potential attacks without a <a href="#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security">continuous monitoring</a> tool.</p><h3 id="command-line-arguments"><a href="#command-line-arguments">Command-line arguments</a></h3><p>In addition to environment variables, it’s important to know what command-line arguments an attacker used when starting a malicious process. Command-line arguments hold information that’s critical to determining the nature of a security threat. Arguments may include identifying data like the IP address an attacker used when they issued a <code>curl</code> command to download a malicious payload, as well as activity data like <a href="https://stackabuse.com/encoding-and-decoding-base64-strings-in-python">encoded Python scripts</a> that were run directly in the command line. Insight into a process’s command-line arguments can help you view what occurred during an attack so you can plan how to respond.</p><p>For a quick look at a process’s command line arguments, get its PID and run a command like the following:</p><div><pre><code data-lang="text">ps -p &lt;PROCESS_PID&gt; -o args</code></pre></div><p>This approach, however, is limited because you need to be able to catch the process before it terminates. Next, we’ll look at how Datadog’s Cloud Workload Security helps you detect attacks and view relevant metadata.</p><h2 id="detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security"><a href="#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security">Detect threats in your Linux processes with Datadog Cloud Workload Security</a></h2><p>Datadog <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/">Cloud Workload Security (CWS)</a> analyzes the full process tree across all your Linux hosts and containers in real time to automatically detect the kind of threats we’ve looked at. Datadog includes <a href="https://docs.datadoghq.com/security_platform/default_rules/#cat-workload-security">out-of-the-box workload threat detection rules</a> that help you immediately respond to potential security threats by flagging suspicious behavior like the execution of <code>passwd</code> and <code>nmap</code> utilities.</p><p>In addition to out-of-the-box workload security rules, Datadog enables you to write your own custom rules. Security rules are constructed with <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/agent_expressions/"><strong>Agent Expressions</strong></a> that enable you to define what process activity to look for with as much specificity as you want. For example, you can instruct Datadog to detect if a Java process generated a <code>bash</code> shell, or even watch for processes run with specific command-line arguments. To learn more about how to construct your own custom workload security rules, check out our <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/workload_security_rules/">documentation</a>.</p><p>If Datadog detects any processes that match a rule, it will generate a <a href="https://docs.datadoghq.com/security_platform/security_monitoring/getting_started/#explore-security-signals">Security Signal</a>. Security Signals include full context around the suspicious process, including environment variable keys (without collecting the associated values), command-line arguments, and other metadata. You can use this information to quickly determine the scope of an attack before planning your response.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847" alt="Security signals include environment variables and command-line arguments which can help you determine the scope of security attacks."/></picture></figure></div><h2 id="start-today"><a href="#start-today">Start today</a></h2><p>No matter which distribution you work with, processes are at the heart of any Linux system. In this post, we looked at how understanding processes and their relationships can help you spot suspicious behavior and determine the severity of a security breach. Datadog Cloud Workload Security monitors process activity throughout your infrastructure at the kernel level in real time to reveal any suspicious or malicious behavior. Read our <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/getting_started/?tab=kubernetes">documentation</a> to learn more or sign up today for a 14-day <a href="#">free trial.</a></p></div></div>]]></content:encoded>
      <author>Jordan Obey</author>
      <pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Release code confidently with Automatic Faulty Deployment Detection</title>
      <link>https://www.datadoghq.com/blog/faulty-deployment-detection/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/automatic_faulty_deployment_detection.png&#34; width=&#34;100%&#34;/&gt;Modern software development teams use CI/CD tools to ship features quickly and rely on best practices like shift-left testing to find application errors before they become user-facing bugs. But you still face the risk that any code you deploy could contain errors that your testing did not surface. To help you deploy with confidence and mitigate the effects of a bad deployment, Datadog APM now provides Automatic Faulty Deployment Detection.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Modern software development teams use CI/CD tools to ship features quickly and rely on best practices like <a href="https://www.datadoghq.com/blog/shift-left-testing-best-practices/">shift-left testing</a> to find application errors before they become user-facing bugs. But you still face the risk that any code you deploy could contain errors that your testing did not surface. To help you deploy with confidence and mitigate the effects of a bad deployment, <a href="https://www.datadoghq.com/knowledge-center/distributed-tracing/">Datadog APM</a> now provides Automatic Faulty Deployment Detection.</p><p>This post will show you how Automatic Faulty Deployment Detection helps you prevent faulty deployments from affecting the performance of your application. We’ll explain how you can:</p><ul><li><a href="#automatically-detect-faulty-deployments">Spot a deployment that appears to be faulty</a> (even if the deployment itself didn’t fail)</li><li><a href="#troubleshoot-faulty-deployments-quickly">Troubleshoot faulty deployments</a></li><li><a href="#proactively-set-alerts-to-monitor-future-deployments">Create alerts to notify your team</a> of a faulty deployment</li></ul><h2 id="automatically-detect-faulty-deployments"><a href="#automatically-detect-faulty-deployments">Automatically detect faulty deployments</a></h2><p>Automatic Faulty Deployment Detection uses <a href="https://www.datadoghq.com/blog/watchdog/">Watchdog’s machine learning algorithms</a> to spot faulty deployments within minutes, reducing your mean time to detection (MTTD). As your team continuously deploys code to production, Watchdog compares the performance of each new version of a service with its previous versions to spot new types of errors introduced in a deployment (instead of an increase in the rate of an existing error that you might expect with a new deployment). If Watchdog determines that a new deployment is faulty, you’ll see details about the affected service in the service-level dashboard, including error types, error rates, request rates, and latency metrics for each version you’ve deployed.</p><p>In the screenshot below, the yellow banner at the top of the page indicates that the most recent deployment of the <code>inventory-api</code> service may be faulty, and a previously unseen error is affecting this serivce’s <code>http.request</code> operation. The <strong>Deployments</strong> table at the bottom of the screen shows a history of the service’s deployments and indicates an error rate of 100 percent for the most recently deployed version, indicating that you may need to roll back the deployment and investigate the source of the errors.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-services-page.png?auto=format&amp;fit=max&amp;w=847" alt="The Services page shows service-level information including rate of requests, rate of errors, and latency. A yellow banner states that the most recent deployment of the service may be faulty."/></picture></figure></div><p>You can click <strong>View Details</strong>—or any deployment listed in the <strong>Deployments</strong> table—to open up the <a href="https://www.datadoghq.com/blog/datadog-deployment-tracking/">Deployment Tracking</a> view, shown in the screenshot below. This view provides details about the faulty deployment, including the new type of error detected (<code>db.utils.OperationalError</code>), the affected endpoint (<code>/inventory</code>), and the HTTP status code (<code>500</code>), which can help you understand how the error is affecting your service. In this case, the application is trying to create the <code>products</code> table each time it calls the endpoint, rather than executing an <code>UPDATE</code> statement against the existing table.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/faulty-deployment-detail.png?auto=format&amp;fit=max&amp;w=847" alt="A detailed view of the faulty deployment shows the time it was detected, the error type, the relevant endpoint, and the HTTP status code."/></picture></figure></div><h2 id="troubleshoot-faulty-deployments-quickly"><a href="#troubleshoot-faulty-deployments-quickly">Troubleshoot faulty deployments quickly</a></h2><p>When Automatic Faulty Deployment Detection spots an error in a deployment, you can start troubleshooting by exploring the service’s <a href="https://docs.datadoghq.com/tracing/">traces</a>, which visualize your application’s activity and surface details that can help you understand the source of the error.</p><p>To see the traces for a service affected by a faulty deployment, click the <strong>Traces</strong> tab on the service-level dashboard or the <strong>previously unseen errors</strong> table in the Deployment Tracking view.</p><p>You can view your trace data as a <a href="https://www.datadoghq.com/knowledge-center/distributed-tracing/flame-graph/">flame graph</a>, which shows the performance of each of your services as your application processes a request. The screenshot below shows a flame graph corresponding to the error shown earlier in the Deployment Tracking view. The <code>200 OK</code> response at the top indicates that the request was successful overall. But the purple span shows the response from the <code>inventory</code> service, which took 166 microseconds and resulted in a <code>500</code> error, whose details are shown in the bottom half of the screen.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/flame-graph.png?auto=format&amp;fit=max&amp;w=847" alt="A flame graph shows four requests. The final request, in purple, represents the HTTP request to the inventory service which resulted in a 500 error."/></picture></figure></div><p>As you gain an understanding of the error that was detected in the deployment, you can collaborate with your team to troubleshoot and resolve the issue. You can easily share what you learn by creating a <a href="https://www.datadoghq.com/blog/collaborative-notebooks-datadog/">notebook</a> that your team can use to collaborate, or you can declare an <a href="https://www.datadoghq.com/blog/incident-response-with-datadog/">incident</a> to initiate your team’s defined process for responding to an error in production. The screenshot below highlights the buttons you can use to start your collaboration with just a single click.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/create-notebook-declare-incident.png?auto=format&amp;fit=max&amp;w=847" alt="A highlighted area of the faulty deployment detailed view shows buttons to create a Notebook and an incident."/></picture></figure></div><p>If you click the <strong>Create Incident</strong> button, Datadog will automatically generate an incident that your team can use to troubleshoot the faulty deployment. The incident automatically includes a link to the relevant service dashboard to provide context that can help collaborators quickly identify and mitigate the impact of the incident.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/new-incident.png?auto=format&amp;fit=max&amp;w=847" alt="The new incident form includes fields to designate incident severity, incident commander, team members to be notified, and a link to the APM page that describes the faulty deployment."/></picture></figure></div><p>See the documentation for more information about <a href="https://docs.datadoghq.com/monitors/incident_management/">Datadog Incident Management</a>.</p><h2 id="proactively-set-alerts-to-monitor-future-deployments"><a href="#proactively-set-alerts-to-monitor-future-deployments">Proactively set alerts to monitor future deployments</a></h2><p>To further support your team’s ability to release features rapidly, you can create alerts that automatically page you if a release appears to be faulty. Automatic Faulty Deployment Detection suggests monitors that you can enable with a single click to proactively address any errors that affect your most critical services. These automated alerts can help your team react quickly and mitigate faulty deployments before they degrade your user experience.</p><p>In the screenshot below, the <code>inventory-api</code> service dashboard shows a faulty deployment and includes a <strong>Suggested Monitor</strong> button that allows you to create an alert that will automatically notify you if the same service exhibits new errors in a future deployment. Once you’ve set the alert, Datadog will monitor your deployments so your team can focus on shipping your next release.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/faulty-deployment-detection/suggested-monitor.png?auto=format&amp;fit=max&amp;w=847" alt="A highlighted area on the service page shows the Suggested Monitor button."/></picture></figure></div><h2 id="deploy-safely-with-datadog"><a href="#deploy-safely-with-datadog">Deploy safely with Datadog</a></h2><p>Along with best practices like <a href="https://www.datadoghq.com/blog/introducing-synthetic-monitoring/">synthetic monitoring</a> and automated <a href="https://www.datadoghq.com/blog/datadog-synthetic-ci-cd-testing/">CI/CD pipeline testing</a>, Automatic Faulty Deployment Detection can help you maintain both the velocity of your development and the quality of your service. To get started, enable <a href="https://docs.datadoghq.com/tracing/setup_overview/">APM</a> and then enable <a href="https://docs.datadoghq.com/tracing/deployment_tracking/">Deployment Tracking</a> by tagging your deployments with a <a href="https://docs.datadoghq.com/getting_started/tagging/unified_service_tagging/"><code>version</code> tag</a>—which may be provided <a href="https://www.datadoghq.com/blog/unified-service-tagging/#use-the-version-tag-to-identify-problematic-deployments">automatically</a> by your CI/CD tool. If you’re not already using Datadog, you can start today with a <a href="#">free 14-day trial</a>.</p></div></div>]]></content:encoded>
      <author>David Asker</author>
      <pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>How to detect security threats in your systems&#39; Linux processes</title>
      <link>https://www.datadoghq.com/blog/linux-security-threat-detection-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/linux-process-hero.png&#34; width=&#34;100%&#34;/&gt;Almost all tasks within a Linux system, whether it&amp;rsquo;s an application, system daemon, or certain types of user activity, are executed by one or more processes. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we&amp;rsquo;ll look at: how understanding the Linux process tree can help you identify security threats what process information can help you determine the scope of a breach We&amp;rsquo;ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Almost all tasks within a Linux system, whether it’s an application, system daemon, or certain types of user activity, are executed by one or more <a href="https://tldp.org/LDP/tlk/kernel/processes.html">processes</a>. This means that monitoring processes is key to detecting potentially malicious activity in your systems, such as the creation of unexpected web shells or other utilities. In this post, we’ll look at:</p><ul><li>how <a href="#a-primer-on-the-process-tree">understanding the Linux process tree</a> can help you identify security threats</li><li>what <a href="#use-process-data-to-determine-the-scope-of-an-attack">process information</a> can help you determine the scope of a breach</li></ul><p>We’ll also look at how Datadog Cloud Workload Security can help you monitor processes across your entire environment to surface security threats.</p><h2 id="a-primer-on-the-process-tree"><a href="#a-primer-on-the-process-tree">A primer on the process tree</a></h2><p>In Linux, each process is generated by a preceding <strong>parent</strong> process and can generate one or more <strong>child</strong> processes. Following this parent/child structure, active processes form a <strong>process tree</strong> that starts with the <code>systemd</code> process that runs when Linux first boots and ends with the most recently generated processes. This parent/child structure is particularly useful for revealing security threats because, unlike simple indicators of compromise (IOCs) like adversarial IP addresses or file hashes, it’s difficult to fake or change. For instance, while attackers can change an IP address, it’s much harder to hide that an application has spawned a new suspicious child process.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/process-tree.png?auto=format&amp;fit=max&amp;w=847" alt="process-tree.png"/></picture><figcaption>Active processes are structured as a process tree which can be used to help you spot signs of a security breach.</figcaption></figure></div><h2 id="identify-suspicious-processes"><a href="#identify-suspicious-processes">Identify suspicious processes</a></h2><p>As you monitor your applications, it’s important to look out for any launched shells or utilities (e.g., <code>bash</code> or <code>curl</code>) that are children of key processes in your environment. For example, if a Java application process generates a shell you aren’t anticipating, it could indicate that a malicious actor has infiltrated your app and launched a <a href="https://us-cert.cisa.gov/ncas/alerts/TA15-314A">web shell attack</a>. When these attacks are successful, they can create backdoors to your infrastructure that allow attackers to access sensitive data and execute commands without authorization.</p><p>Likewise, you should check if a process spawned utilities like <code>nmap</code>, which an attacker can use to survey your network for further vulnerabilities to exploit, or <code>passwd</code>, which can be used to change user passwords and grant attackers higher privileges.</p><p>Once you’ve identified a malicious process, it’s important to investigate the scope of the attack, including what information the attacker has potentially gained access to.</p><h2 id="use-process-data-to-determine-the-scope-of-an-attack"><a href="#use-process-data-to-determine-the-scope-of-an-attack">Use process data to determine the scope of an attack</a></h2><p>Linux processes include metadata that can help you determine the scope of an attack. The key types of information to look at are:</p><ul><li>environment variables</li><li>command-line arguments</li></ul><h3 id="environment-variables"><a href="#environment-variables">Environment variables</a></h3><p>Due to their <a href="#a-primer-on-the-process-tree">relationship</a>, child processes inherit access to any environment variables available to the parent process. Though it’s not considered best practice, environment variables are often used to store sensitive data like API and GitHub keys, or even database credentials. Using our example of an attacker successfully creating a web shell from a Java application process, the shell would be able to see any environment variables associated with your application process, such as database credentials for a SQL server containing sensitive customer data.</p><p>Examining what environment variables a process includes can help you determine the full scope of a threat. You can quickly view a list of a process’s environment variables by using the Linux command <code>ps faux</code> to get its PID and then running the following:</p><div><pre><code data-lang="text">cat /proc/&lt;PROCESS_PID&gt;/environ </code></pre></div><p>Please note, however, that this detection method only works while the process is running. This makes it challenging to view potential attacks without a <a href="#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security">continuous monitoring</a> tool.</p><h3 id="command-line-arguments"><a href="#command-line-arguments">Command-line arguments</a></h3><p>In addition to environment variables, it’s important to know what command-line arguments an attacker used when starting a malicious process. Command-line arguments hold information that’s critical to determining the nature of a security threat. Arguments may include identifying data like the IP address an attacker used when they issued a <code>curl</code> command to download a malicious payload, as well as activity data like <a href="https://stackabuse.com/encoding-and-decoding-base64-strings-in-python">encoded Python scripts</a> that were run directly in the command line. Insight into a process’s command-line arguments can help you view what occurred during an attack so you can plan how to respond.</p><p>For a quick look at a process’s command line arguments, get its PID and run a command like the following:</p><div><pre><code data-lang="text">ps -p &lt;PROCESS_PID&gt; -o args</code></pre></div><p>This approach, however, is limited because you need to be able to catch the process before it terminates. Next, we’ll look at how Datadog’s Cloud Workload Security helps you detect attacks and view relevant metadata.</p><h2 id="detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security"><a href="#detect-threats-in-your-linux-processes-with-datadog-cloud-workload-security">Detect threats in your Linux processes with Datadog Cloud Workload Security</a></h2><p>Datadog <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/">Cloud Workload Security (CWS)</a> analyzes the full process tree across all your Linux hosts and containers in real time to automatically detect the kind of threats we’ve looked at. Datadog includes <a href="https://docs.datadoghq.com/security_platform/default_rules/#cat-workload-security">out-of-the-box workload threat detection rules</a> that help you immediately respond to potential security threats by flagging suspicious behavior like the execution of <code>passwd</code> and <code>nmap</code> utilities.</p><p>In addition to out-of-the-box workload security rules, Datadog enables you to write your own custom rules. Security rules are constructed with <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/agent_expressions/"><strong>Agent Expressions</strong></a> that enable you to define what process activity to look for with as much specificity as you want. For example, you can instruct Datadog to detect if a Java process generated a <code>bash</code> shell, or even watch for processes run with specific command-line arguments. To learn more about how to construct your own custom workload security rules, check out our <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/workload_security_rules/">documentation</a>.</p><p>If Datadog detects any processes that match a rule, it will generate a <a href="https://docs.datadoghq.com/security_platform/security_monitoring/getting_started/#explore-security-signals">Security Signal</a>. Security Signals include full context around the suspicious process, including environment variable keys (without collecting the associated values), command-line arguments, and other metadata. You can use this information to quickly determine the scope of an attack before planning your response.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/linux-security-threat-detection-datadog/security-signal.png?auto=format&amp;fit=max&amp;w=847" alt="Security signals include environment variables and command-line arguments which can help you determine the scope of security attacks."/></picture></figure></div><h2 id="start-today"><a href="#start-today">Start today</a></h2><p>No matter which distribution you work with, processes are at the heart of any Linux system. In this post, we looked at how understanding processes and their relationships can help you spot suspicious behavior and determine the severity of a security breach. Datadog Cloud Workload Security monitors process activity throughout your infrastructure at the kernel level in real time to reveal any suspicious or malicious behavior. Read our <a href="https://docs.datadoghq.com/security_platform/cloud_workload_security/getting_started/?tab=kubernetes">documentation</a> to learn more or sign up today for a 14-day <a href="#">free trial.</a></p></div></div>]]></content:encoded>
      <author>Jordan Obey</author>
      <pubDate>Thu, 19 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Detect security threats with anomaly detection rules</title>
      <link>https://www.datadoghq.com/blog/anomaly-detection-rules-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/security-monitoring-anomaly-detection-hero.png&#34; width=&#34;100%&#34;/&gt;Securing your environment requires being able to quickly detect abnormal activity that could represent a threat. But today&amp;rsquo;s modern cloud infrastructure is large, complex, and can generate vast volumes of logs. This makes it difficult to determine what activity is normal and harder to identify anomalous behavior. Now, in addition to threshold and new term–based Threat Detection Rules, Datadog Security Monitoring provides the ability to create anomaly detection rules. With this detection method, Datadog will analyze relevant logs for the specific entities you query—hosts, IP addresses, users, etc.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Securing your environment requires being able to quickly detect abnormal activity that could represent a threat. But today’s modern cloud infrastructure is large, complex, and can generate vast volumes of logs. This makes it difficult to determine what activity is normal and harder to identify anomalous behavior. Now, in addition to <a href="https://docs.datadoghq.com/security_platform/security_monitoring/log_detection_rules/?tab=threshold#define-a-search-query">threshold</a> and <a href="https://www.datadoghq.com/blog/new-term-detection-method-datadog/#security-on-your-terms">new term</a>–based <a href="https://docs.datadoghq.com/security_platform/detection_rules/">Threat Detection Rules</a>, Datadog Security Monitoring provides the ability to create <a href="https://docs.datadoghq.com/security_platform/security_monitoring/log_detection_rules/?tab=anomaly">anomaly</a> detection rules. With this detection method, Datadog will analyze relevant logs for the specific entities you query—hosts, IP addresses, users, etc.—to identify historical trends and determine baseline behavior. Then, when it detects any type of deviation from this baseline, Datadog will create a <a href="https://www.datadoghq.com/blog/announcing-security-monitoring/#correlate-and-triage-security-signals">Security Signal</a> that includes a timeseries graph to illustrate what happened, enabling you to triage the event and take any necessary action.</p><h2 id="spot-anomalies-in-dynamic-activity"><a href="#spot-anomalies-in-dynamic-activity">Spot anomalies in dynamic activity</a></h2><p>Threshold-based detection rules can notify you if the frequency of certain activity exceeds a specific value (e.g., there are more than 100 access-denied requests from a user within a one-hour timeframe). For situations where you’re not able to establish a set threshold, you can use anomaly detection rules to dynamically generate thresholds based on historical behavior. This can be particularly helpful for monitoring unusual behavior across events like unique API calls, an influx in access denied requests, and more. In these cases, baseline activity is different entity to entity, so it can be difficult to define a set threshold that won’t potentially result in many false positives.</p><p>Let’s say you are monitoring your organization’s <a href="https://docs.datadoghq.com/integrations/google_cloud_platform/">Google Cloud Platform</a> service accounts. Service accounts connect to APIs to access the resources they need to run their workloads, so you expect to see API calls made regularly. If, however, a service account makes an unusual amount of API calls, it could mean that an account has been compromised and an attacker is attempting to access sensitive data. You can create an anomaly-based rule that monitors your audit logs for API activity and alerts you if an unusual volume of calls have been made.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/anomaly-detection01.png?auto=format&amp;fit=max&amp;w=847" alt="anomaly-detection01.png"/></picture><figcaption>An anomaly detection rule that looks for an unusual number of API calls from a GCP service account.</figcaption></figure></div><p>Similarly, if you’re monitoring <a href="https://www.datadoghq.com/blog/monitor-salesforce-logs-datadog/#monitor-salesforce-user-activity-in-real-time">Salesforce user activity</a>, Datadog provides an out-of-the-box Threat Detection Rule that notifies you of any anomalous <a href="https://docs.datadoghq.com/security_platform/default_rules/salesforce-large-volume-of-query-activity/">spikes in query results</a>. While there may be periods when spikes in Salesforce user activity is the norm, anomalous spikes can signal that an unauthorized user may be attempting to access protected data and may require further investigation.</p><h2 id="analyze-security-signals"><a href="#analyze-security-signals">Analyze Security Signals</a></h2><p>If Datadog ingests logs that trigger an anomaly detection rule, Datadog will generate a Security Signal, notifying you of the nature of the anomaly as well as the window of time it occurred in so you can investigate further. Security Signals include key event data like IP addresses and usernames so you can, for instance, look at the user ID associated with an anomalous spike in Salesforce query results to determine if it is a recognized account or an attacker.</p><p>Any Security Signals that Datadog generates based on anomaly detection rules will remain “open” (i.e., continue to report data about the anomaly) as long as analyzed logs indicate the same anomalous behavior over a set interval, or until the anomaly exceeds a specified maximum signal duration (e.g., 24 hours), and has become the new baseline. This helps you determine when an anomaly first occurred, and whether it is still ongoing or has concluded.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/anomaly-detection-rules-datadog/GCP-anomaly.png?auto=format&amp;fit=max&amp;w=847" alt="Security signals can be generated by triggered anomaly detection rules."/></picture></figure></div><h2 id="get-started-today"><a href="#get-started-today">Get started today</a></h2><p>Datadog Security Monitoring’s anomaly-based detection rules identify and alert on anomalous behavior in your dynamic environment, making it easier to identify and investigate suspicious behavior when it appears. If you’re currently a Datadog customer, you can learn more about creating security rules <a href="https://docs.datadoghq.com/security_platform/security_monitoring/log_detection_rules/?tab=anomaly">here</a>. Otherwise, get started today with a 14-day <a href="#">free trial.</a></p></div></div>]]></content:encoded>
      <author>Jordan Obey</author>
      <pubDate>Wed, 18 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Datadog Announces Deep Database Monitoring</title>
      <link>https://www.datadoghq.com/about/latest-news/press-releases/datadog-announces-deep-database-monitoring/</link>
      <description>NEW YORK &amp;ndash; Datadog, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced the general availability of Database Monitoring (DBM). With insights into query performance and explain plans, as well as automatic correlation of query metrics with application and infrastructure metrics, Database Monitoring provides engineers and database administrators the visibility they need to quickly find and fix application performance issues that arise from slow running database queries.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><strong>NEW YORK</strong> – <a href="http://www.datadoghq.com">Datadog</a>, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced the general availability of Database Monitoring (DBM). With insights into query performance and explain plans, as well as automatic correlation of query metrics with application and infrastructure metrics, Database Monitoring provides engineers and database administrators the visibility they need to quickly find and fix application performance issues that arise from slow running database queries. </p><p>Database queries are often the root cause of incidents and application performance issues. When applications make unnecessary queries or fail to use indices, they burden the entire database, causing performance degradation for all applications using the database. Databases do not store historical query performance metrics, which makes it extremely difficult to understand the context around an issue and identify trends. This becomes even harder as engineers typically need to dig into each database individually to investigate, which prolongs downtime and exacerbates the impact on the customer experience.</p><p>Datadog Database Monitoring builds on the existing ability to monitor the general health and availability of the database and underlying infrastructure by allowing users to pinpoint the exact queries that impact application performance and user experience. With DBM, users can see the performance of database queries, troubleshoot slow queries with detailed execution breakdowns, and analyze historical trends in query latencies and overhead. This allows organizations to unlock improvements not only in database performance, but also in the performance of the upstream applications, APIs, and microservices that the database underpins.</p><p>DBM users are also able to automatically correlate query performance data with Datadog infrastructure metrics to easily identify resource bottlenecks. This allows engineers to quickly understand whether performance issues are at the database or infrastructure level, without needing to manually export and reconcile information from multiple, disconnected point solutions. Datadog’s unified data model makes it easy to search and filter information at scale with the same tags that are used everywhere in Datadog.</p><p>“Databases underpin today’s digital experiences. Consequently, a disruption in database uptime and performance can quickly have dramatic effects on business operations,” said Renaud Boutet, Senior Vice President, Product Management, Datadog. “The Datadog platform now enables database administrators and application engineers to detect and act on database issues by sharing the same data. This allows organizations to discover and implement improvements while saving time communicating and reconciling information.”</p><p>“The biggest observability challenge we face is proactively monitoring our databases&#39; performance,” said Chris Seltzer, Engineering Manager, Compass. “Datadog Database Monitoring enables our engineers on both the Product and Infrastructure teams to pinpoint query performance issues and ultimately avoid prolonged downtime that disrupts the end-user experience. The best part is that it’s all within a single tool.”</p><p>Datadog DBM delivers deep visibility into databases and enables organizations to:</p><ul><li>Quickly detect and isolate drops in performance. Users can track the performance of normalized queries across their entire fleet of databases, see which types of queries are executed the most and where they run, and get alerts for long running or expensive queries. For each query, they can drill down further to the hosts that are running that query, and leverage log and network information to understand host performance.</li><li>Pinpoint the root cause of performance drops. DBM provides quick access to explain plans, so users can view the sequence of steps that make up a query. This allows them to localize bottlenecks and identify opportunities to optimize performance and resource efficiency. </li><li>Improve and maintain database health, preventing incidents and saving costs. DBM enables organizations to keep historical query performance data for up to three months, so they can understand changes over time and prevent regressions. </li><li>Provide engineers access to database performance telemetry, without compromising data security. DBM offers a centralized view of database performance data, automatically correlated with infrastructure and application metrics, without requiring direct user access to database instances.</li></ul><p>Datadog DBM for Postgres and MySQL starts at $70 per database server. For more information, please visit <a href="https://www.datadoghq.com/product/database-monitoring/">https://www.datadoghq.com/product/database-monitoring/</a></p><div><p><strong>About Datadog</strong></p><p>Datadog is the monitoring and security platform for cloud applications. Our SaaS platform integrates and automates infrastructure monitoring, application performance monitoring and log management to provide unified, real-time observability of our customers’ entire technology stack. Datadog is used by organizations of all sizes and across a wide range of industries to enable digital transformation and cloud migration, drive collaboration among development, operations, security and business teams, accelerate time to market for applications, reduce time to problem resolution, secure applications and infrastructure, understand user behavior and track key business metrics.</p></div><p><strong>Forward-Looking Statements</strong></p><p>This press release may include certain “forward-looking statements” within the meaning of Section 27A of the Securities Act of 1933, as amended, or the Securities Act, and Section 21E of the Securities Exchange Act of 1934, as amended. These forward-looking statements reflect our current views about our plans, intentions, expectations, strategies and prospects, which are based on the information currently available to us and on assumptions we have made. Actual results may differ materially from those described in the forward-looking statements and are subject to a variety of assumptions, uncertainties, risks and factors that are beyond our control, including those risks detailed under the caption “Risk Factors” and elsewhere in our Securities and Exchange Commission filings and reports, including the Quarterly Report on Form 10-Q filed with the Securities and Exchange Commission on August 6, 2021, as well as future filings and reports by us. Except as required by law, we undertake no duty or obligation to update any forward-looking statements contained in this release as a result of new information, future events, changes in expectations or otherwise.</p></div></div>]]></content:encoded>
      <author>Datadog</author>
      <pubDate>Tue, 17 Aug 2021 21:43:00 +0000</pubDate>
    </item>
    <item>
      <title>Monitor and visualize database performance with Datadog Database Monitoring</title>
      <link>https://www.datadoghq.com/blog/database-performance-monitoring-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/database_monitoring_feature_announcement_210716_v3a.png&#34; width=&#34;100%&#34;/&gt;When you’re running databases at scale, finding performance bottlenecks can often feel like looking for a needle in a haystack. In any troubleshooting scenario, you need to know the exact state of your database at the onset of an issue, as well as its behavior leading up to it. But databases themselves do not store historical performance metrics, which makes it extremely difficult to identify trends and determine whether the issue is caused by inefficient queries, suboptimal database design, or resource saturation.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>When you’re running databases at scale, finding performance bottlenecks can often feel like looking for a needle in a haystack. In any troubleshooting scenario, you need to know the exact state of your database at the onset of an issue, as well as its behavior leading up to it. But databases themselves do not store historical performance metrics, which makes it extremely difficult to identify trends and determine whether the issue is caused by inefficient queries, suboptimal database design, or resource saturation. Developers also typically need to dig into each database individually to investigate, which prolongs downtime and other customer-facing issues.</p><p>Today, we’re excited to announce the release of <a href="https://app.datadoghq.com/databases">Database Monitoring</a>, which delivers deep visibility into databases across all of your hosts. With historical query performance metrics, explain plans, and host-level metrics all in one place, developers and database administrators can easily understand the health and performance of their databases and quickly troubleshoot any issues that arise.</p><p>In this post, we’ll show you how Database Monitoring enables you to:</p><ul><li><a href="#see-the-performance-of-normalized-queries-at-a-glance">See the performance of normalized queries at a glance</a></li><li><a href="#troubleshoot-slow-queries-with-detailed-explain-plans">Troubleshoot slow queries with detailed explain plans</a></li><li><a href="#analyze-historical-trends-in-query-performance">Analyze historical trends in query performance</a></li><li><a href="#explore-and-visualize-sampled-queries">Explore and visualize sampled queries</a></li><li><a href="#detect-infrastructure-level-issues-impacting-your-database">Detect infrastructure-level issues impacting your database</a></li></ul><h2 id="see-the-performance-of-normalized-queries-at-a-glance"><a href="#see-the-performance-of-normalized-queries-at-a-glance">See the performance of normalized queries at a glance</a></h2><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/normalized-queries.png?auto=format&amp;fit=max&amp;w=847" alt="Track the performance of normalized queries with Datadog Database Monitoring"/></picture></figure></div><p>Inefficient queries can deplete your database’s resources and block other queries from running, so it’s important to identify and optimize them in order to ensure your application remains performant. Databases aggregate similar query statements into <a href="https://dev.mysql.com/doc/refman/8.0/en/performance-schema-statement-digests.html">normalized queries</a>—in which literal values, such as names, passwords, and dates, are replaced with question marks—to generate statistics that help database administrators troubleshoot issues with query execution. But because databases do not provide a way to sort or filter normalized queries, it can be challenging to identify the most problematic ones.</p><p>Database Monitoring enables you to track the performance of normalized queries across all of your hosts in a summary graph and sortable list, so you can see at a glance which types of queries are executed the most, how long they’re taking, how many rows are returned, and more. This helps you identify, for instance, if there are any long-running queries that return only a small number of rows, which could be a sign that your data is not indexed properly. You can also drill down to a smaller subset of queries using tags like <code>service</code>, <code>host</code>, and <code>cluster_name</code> to create a more focused view for your investigation.</p><h2 id="troubleshoot-slow-queries-with-detailed-explain-plans"><a href="#troubleshoot-slow-queries-with-detailed-explain-plans">Troubleshoot slow queries with detailed explain plans</a></h2><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-details.png?auto=format&amp;fit=max&amp;w=847" alt="View more details for each normalized query"/></picture></figure></div><p>If you notice that a particular normalized query is taking a long time to execute, you can click on it to open the Query Details panel, which includes detailed <a href="https://dev.mysql.com/doc/refman/8.0/en/execution-plan-information.html">explain plans</a> (also known as execution plans) for that particular query. An explain plan uses a node tree to map the sequence of steps chosen by the query planner to execute the query. Each node in the tree represents a single operation such as a table scan, sort, join, or aggregation.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/explain-plans.png?auto=format&amp;fit=max&amp;w=847" alt="See explain plans used to execute each query"/></picture></figure></div><p>In Database Monitoring, you can see the estimated cost of running each node, as well as the number of rows and bytes expected to be returned, which can help you identify operation hotspots. For instance, if your plan includes a costly sequential scan, you might want to consider creating indexes on important columns to encourage the database to use an index scan instead. Explain plans also show you how table joins are performed (i.e., which joins are used and in which order) so you can adjust your query if the query planner has selected a suboptimal plan.</p><h2 id="analyze-historical-trends-in-query-performance"><a href="#analyze-historical-trends-in-query-performance">Analyze historical trends in query performance</a></h2><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/metrics-tab.png?auto=format&amp;fit=max&amp;w=847" alt="View timeseries graphs for key database performance metrics in the Metrics tab"/></picture></figure></div><p>Historical performance data provides crucial insight into changes in database behavior and the efficacy of your optimizations, but the database itself can only report statistics on its present state. Database Monitoring addresses this issue by providing timeseries graphs for key performance indicators of normalized queries, such as total execution time, number of requests, and shared block activity. These metrics, which are available in the Metrics tab of the Query Details panel, are stored at full granularity for three months, allowing you to track performance trends over the long term. You can easily add these graphs to any dashboard, such as your <a href="https://app.datadoghq.com/dash/integration/30404/mysql">MySQL</a> or <a href="https://app.datadoghq.com/dash/integration/235/postgres---overview">PostgreSQL</a> dashboards, and correlate them with higher-level metrics like throughput, replication, and connections for a more comprehensive view of your database’s performance.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/anomaly-monitor.png?auto=format&amp;fit=max&amp;w=847" alt="Creating an anomaly monitor to notify us if any of our queries take abnormally long to execute"/></picture></figure></div><p>You can also set up automated alerts on any query metric to stay ahead of potential issues. For instance, you can create an <a href="https://docs.datadoghq.com/monitors/monitor_types/anomaly/">anomaly monitor</a> that will notify you if any query to your production cluster takes unusually long to execute, as shown in the screenshot above.</p><h2 id="explore-and-visualize-sampled-queries"><a href="#explore-and-visualize-sampled-queries">Explore and visualize sampled queries</a></h2><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-samples.png?auto=format&amp;fit=max&amp;w=847" alt="Explore query samples from all of your databases"/></picture></figure></div><p>While normalized queries give you a high-level overview of database performance, sampled queries provide more granular insights. Datadog periodically collects a random sample of queries from all your databases—and enables you to see where each sample query was executed (i.e., on which host or application), along with other details such as its duration, cost, and explain plan. Datadog also converts sample query metadata into tags, which you can use to search, filter, and visualize individual queries when troubleshooting an issue or performing open-ended exploration. For example, you can use a table to group your most expensive queries by application in order to determine which ones you should optimize first.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/group-query-samples.png?auto=format&amp;fit=max&amp;w=847" alt="Visualizing the execution plan cost of queries for each application in a table"/></picture></figure></div><h2 id="detect-infrastructure-level-issues-impacting-your-database"><a href="#detect-infrastructure-level-issues-impacting-your-database">Detect infrastructure-level issues impacting your database</a></h2><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-host-metrics.png?auto=format&amp;fit=max&amp;w=847" alt="Database Monitoring brings host metrics into the same view as your queries"/></picture></figure></div><p>Query optimization can resolve some database issues, but others may be rooted in the underlying infrastructure. Database Monitoring automatically correlates normalized queries with host metrics to help you easily identify resource bottlenecks that degrade the performance of your databases. In the Query Details panel, you can see which of your hosts are running that normalized query, along with throughput and client connection metrics that indicate how busy those hosts are. If you see that a particular host is handling a disproportionate amount of traffic, you may need to adjust your load balancer or scale up your resources. To gather more context, you can click on the host and navigate to its default dashboard, which can be customized to include data from any part of your stack. Similarly, as you’re performing analysis in Query Samples, you can click on a sampled query and pivot to its host’s dashboard, logs, and network data for lower-level insights.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/database-performance-monitoring-datadog/query-sample-infrastructure.png?auto=format&amp;fit=max&amp;w=847" alt="Seamlessly pivot from a sampled query to its host&#39;s dashboard, logs, and network data"/></picture></figure></div><h2 id="start-using-database-monitoring-today"><a href="#start-using-database-monitoring-today">Start using Database Monitoring today</a></h2><p>Datadog Database Monitoring tracks historical query performance metrics, explain plans, and host-level metrics from every database in your environment, so you can better understand their performance and troubleshoot issues effectively. Database Monitoring currently supports MySQL 5.6+ and PostgreSQL 9.6+ databases, regardless of whether they’re self-hosted or fully managed. Check out our <a href="https://docs.datadoghq.com/database_monitoring/">documentation</a> to learn how to get started. And if you’re not yet using Datadog, sign up for a 14-day <a href="#">free trial</a> today.</p></div></div>]]></content:encoded>
      <author>Kai Xin Tai</author>
      <pubDate>Tue, 17 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Highlights from Black Hat USA 2021</title>
      <link>https://www.datadoghq.com/blog/blackhat-2021-highlights-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/blackhat-2021-highlights-datadog/black_hat_event_recap_210809_FINAL.png&#34; width=&#34;100%&#34;/&gt;Black Hat USA is one of the industry&amp;rsquo;s oldest and most well-established security events. Last year, the conference was held virtually for the first time in its history. This year’s conference brought together the best of both worlds, with a hybrid event that was held virtually and in person in Las Vegas.Historically, Black Hat has seen about 20,000 attendees at its in-person conference. This year’s Black Hat was no different from a numbers perspective, but the bulk of attendees actually attended virtually.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><a href="https://www.blackhat.com/us-21/">Black Hat USA</a> is one of the industry’s oldest and most well-established security events. Last year, the conference was held virtually for the first time in its history. This year’s conference brought together the best of both worlds, with a hybrid event that was held virtually and in person in Las Vegas.</p><p>Historically, Black Hat has seen <a href="https://www.crn.com/slide-shows/security/black-hat-is-back-scenes-from-the-show">about 20,000 attendees</a> at its in-person conference. This year’s Black Hat was no different from a numbers perspective, but the bulk of attendees actually attended virtually. <a href="https://www.businesswire.com/news/home/20210809005548/en/Black-Hat-USA-2021-Closes-on-the-Industry%E2%80%99s-First-and-Largest-Hybrid-Event">Black Hat reported</a> that nearly 14,600 attendees logged into Swapcard (the platform that hosted the virtual event), which likely makes it the largest hybrid conference in cybersecurity since the shift to virtual.</p><p>The Datadog team was excited to participate in this year’s conference as both an exhibitor and speaker. In this post, we’ll share highlights from the show floor, major themes from the conference, and our picks for noteworthy Briefings.</p><h2 id="notes-from-the-show-floor"><a href="#notes-from-the-show-floor">Notes from the show floor</a></h2><p>This year’s conference marked Datadog’s first time participating in the Black Hat Business Hall. Even though attendance was a little lower in person this year, we were especially excited to share our <a href="https://www.datadoghq.com/blog/cloud-security-posture-management/">Cloud Security Posture Management</a> product with this particular audience. We also announced the general availability of <a href="https://www.datadoghq.com/blog/datadog-workload-security/">Datadog Cloud Workload Security</a>, which monitors real-time file, process, and kernel activity in hosts and containers across your environment. Both are part of the <a href="https://www.datadoghq.com/product/security-platform/">Datadog Cloud Security Platform</a>, which protects an organization’s production environment with a full-stack offering providing threat detection and posture management, as well as workload and application security.</p><p>We were not surprised to see a good number of threat detection solutions on the show floor. SIEM (Security Information Event Management) has been a hot-ticket item for years now, and this event made it clear that it is still very much in high demand. Regardless of your choice of SIEM vendor, it’s clear that companies are increasingly seeking solutions that are cloud native, managed, and integrated with other security tooling, which can be key for maximizing usage.</p><p>Black Hat was also a treat for swag seekers everywhere. Whether you wanted to find a new T-shirt, socks, or even shop for an XDR solution, you’d find it all in the Black Hat Business Hall.</p><h2 id="black-hat-keynotes"><a href="#black-hat-keynotes">Black Hat keynotes</a></h2><p>With more than half of attendees joining the conference virtually, Black Hat’s keynotes were enhanced by an especially lively chat. Whether you attended a keynote from <a href="https://www.blackhat.com/us-21/briefings/schedule/#keynote-hacking-the-cybersecurity-puzzle-25068">Jen Easterly</a> (Director of the Cybersecurity and Infrastructure Security Agency), <a href="https://www.blackhat.com/us-21/briefings/schedule/index.html#keynote-secretary-alejandro-mayorkas-25100">Alejandro N. Mayorkas</a> (Secretary, Department of Homeland Security), <a href="https://www.blackhat.com/us-21/briefings/schedule/#supply-chain-infections-and-the-future-of-contactless-deliveries-24987">Matt Tait</a> (Chief Operating Officer, Corellium), or all of the above, you would have seen a ton of great questions coming in from the audience.</p><p>Across all three keynotes, the message was clear: collaboration will be key for moving our security efforts forward. DevOps has heralded breaking down barriers since its inception. With the rapid evolution of DevSecOps, the industry is now placing even greater emphasis on driving collaboration among development, security, and operations teams. We also expect that external government partnerships like CISA will help catapult private and public security to the next level.</p><h2 id="black-hat-briefings"><a href="#black-hat-briefings">Black Hat Briefings</a></h2><p>Every year, it seems like the breadth of material covered in Black Hat Briefings grows. It was refreshing to see a mixture of Black Hat veteran speakers and new faces. This year, two of the briefings stood out to us:</p><ul><li><a href="https://www.blackhat.com/us-21/briefings/schedule/index.html#cloudy-with-a-chance-of-apt-novel-microsoft--attacks-in-the-wild-23682">Cloudy with a Chance of APT: Novel Microsoft 365 Attacks in the Wild</a> was a great Briefing on the rise of cloud-targeted attacks. It’s worth noting that advanced nation-state threat actors are specifically targeting SaaS applications such as Microsoft 365. If you want to learn more about securing your Microsoft 365 environment, check out our <a href="https://www.datadoghq.com/blog/microsoft-365-integration/">blog post</a>.</li><li><a href="https://www.blackhat.com/us-21/briefings/schedule/#im-a-hacker-get-me-out-of-here-breaking-network-segregation-using-esoteric-command--control-channels-22851">I’m a Hacker Get Me Out of Here! Breaking Network Segregation Using Esoteric Command &amp; Control Channels</a> was one of the few Briefings that focused on privilege escalation and lateral movements. These topics often don’t get as much attention as they deserve in the cybersecurity space, as there is a lot of focus on infiltration. A <a href="https://www.datadoghq.com/product/security-platform/cloud-security-posture-management/">CSPM solution</a> can help with applying the principles of least privilege, while a <a href="https://www.datadoghq.com/product/security-platform/cloud-workload-security/">cloud workload security solution</a> can detect lateral movements.</li></ul><p>Datadog’s team of researchers also spoke at <a href="https://defcon.org/">DEF CON</a> and Black Hat on the relative attack surface of eBPF. We also shared <a href="https://github.com/Gui774ume/ebpfkit-monitor">ebpfkit-monitor</a>, an ethical hacking toolkit that detects and protects against suspicious eBPF activity at runtime. More information about our Black Hat Briefing is available <a href="https://www.blackhat.com/us-21/briefings/schedule/index.html#with-friends-like-ebpf-who-needs-enemies-23619">here</a>, and you can watch our DEF CON talk <a href="https://www.youtube.com/watch?v=5zixNDolLrg">here</a>.</p><h2 id="full-stack-security-with-datadog"><a href="#full-stack-security-with-datadog">Full-stack security with Datadog</a></h2><p>This year’s Black Hat conference gave us an invaluable opportunity to connect with the rest of the cybersecurity community, and we look forward to participating in more Black Hat events in the future. <a href="https://docs.datadoghq.com/security_platform/">Check out our docs</a> to learn more about how Datadog’s Cloud Security Platform can help break down barriers by helping every team across your organization leverage detailed observability data. If you’re not yet using Datadog, you can sign up for a <a href="#">free trial</a> today.</p></div></div>]]></content:encoded>
      <author>Huxley Barbee</author>
      <pubDate>Tue, 17 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Tracking Cloud Security Posture in a Dynamic Environment</title>
      <link>https://www.datadoghq.com/case-studies/marketplacer/</link>
      <description>About Marketplacer Established in 2017 in Australia, Marketplacer is a global technology platform-as-a-service (PaaS) company equipped with all the tools and functionality needed to build a successful and scalable online marketplace at speed. The Marketplacer platform exists to make growth simple. To date, the company has helped over 90 businesses execute their own successful marketplace strategies and connected over 20,000 businesses worldwide. Key Results Reduced MTTD and MTTR Datadog helps Marketplacer reduce the time it takes to identify and mitigate compliance issues via easy filtering and remediation guidance.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><h2 id="about-marketplacer">About Marketplacer</h2><p>Established in 2017 in Australia, Marketplacer is a global technology platform-as-a-service (PaaS) company equipped with all the tools and functionality needed to build a successful and scalable online marketplace at speed. The Marketplacer platform exists to make growth simple. To date, the company has helped over 90 businesses execute their own successful marketplace strategies and connected over 20,000 businesses worldwide.</p><span><hr/><h2 id="key-results">Key Results</h2><h4 id="reduced-mttd-and-mttr">Reduced MTTD and MTTR</h4><p>Datadog helps Marketplacer reduce the time it takes to identify and mitigate compliance issues via easy filtering and remediation guidance.</p><h4 id="unified-platform">Unified platform</h4><p>CSPM is built on the unified Datadog agent and cloud integrations, increasing cost and operational efficiency.</p><h4 id="600-resources-audited">600+ resources audited</h4><p>With Datadog, Marketplacer gets live configuration check results on the 600+ resources so they can track their compliance over time.</p><hr/><h2 id="challenge">Challenge</h2><p>Marketplacer is pursuing ISO:27001 certification and needed a solution to help them identify issues and track their progress along that journey. They needed visibility into the state of their compliance across their dynamic environment, and across different points in time. With a small security team, they wanted an easy-to-use solution that wouldn’t induce alert fatigue or require a high barrier to entry.</p><hr/><h2 id="why-datadog">Why Datadog?</h2><p>Datadog offers Marketplacer a fully integrated Cloud Security Posture Management solution that enables everyone on their team to easily drill down into security posture issues and get actionable links to resources for mitigation.</p><hr/></span></div><div><span><p>Understanding the state of your cloud security posture and the steps you need to take to mitigate misconfigurations is crucial for maintaining a strong security posture. At Marketplacer, keeping up to date with the state of their infrastructure compliance as they progressed toward an ISO:27001 certification was proving to be a challenge.</p><p>As Marketplacer began to expand internationally and work with larger customers, the infrastructure and security team organized around the goal of becoming compliant with ISO:27001 in order to meet the requirements of these new customers. As a cloud-native organization running on AWS, cloud security posture was a core element they needed to track and maintain. However, visibility into this area was limited—developers were working in silos when it came to configuring resources, and lacked a centralized way to manage configurations across the organization.</p><blockquote><p><em>“ Building a compliant and secure platform is a high priority for our customers. We want to be proactive with our security.”</em></p><p>Christian Kornacker<br/>DevOps Lead, Marketplacer</p></blockquote><p>Marketplacer increasingly saw the need for a solution that could help them detect and remediate misconfigurations and other issues quickly in a rapidly changing environment. Furthermore, as big proponents of infrastructure as code, they could easily provision large swathes of resources with a single command—but they needed guardrails in place to help them understand how each deployment would affect both their security posture and adherence to ISO:27001.</p><p>They set out to find a Cloud Security Posture Management solution that could meet their growing needs, but they didn’t like the high expertise requirements, noisy alerting, and complexity of the first few platforms they explored.</p><p>Marketplacer ultimately chose Datadog because it gives the engineers on the infrastructure and security team the ability to drill down into security posture issues as they crop up, with links to resources on how to remediate them. Additionally, Datadog allows them to track the results of their configuration checks each time they deploy, so they can better compare their security posture status across releases, and find ways to move closer to ISO:27001 compliance.</p><blockquote><p><em>“ Datadog is easy to use, but at the same time, very comprehensive. What I like about Datadog is that you don’t need to be a security or compliance expert to go through your misconfigurations and fix them across the team.”</em></p><p>Christian Kornacker<br/>DevOps Lead, Marketplacer</p></blockquote><p>Marketplacer leverages Datadog’s dashboards and executive reporting to get summaries and track conformance to specific industry benchmarking criteria. The out-of-the-box cloud configuration rules map to various benchmarks and relevant controls, making it easy for everyone across the company to understand and get value out of the platform. For a small but growing team, the dashboards and mitigation advice help reduce complexity. Marketplacer also sets up bespoke, actionable alerts for each team, enabling everyone to maximize the impact of time spent on monitoring and maintaining their security posture.</p><p>Each time Markerplacer updates or deploys new resources, the team can check their security posture dashboard in Datadog to see which resource configurations don’t match the available rules. Because Datadog provides rich context around those resources, the team can easily go back to their infrastructure as code definitions to mitigate any issues that arise that may impact their compliance.</p><blockquote><p><em>“ Datadog is the best I’ve seen when it comes to alerting. We can drill down to only see the issues that matter and reduce the noise. Each alert tells us why it exists and what to do about it—which is particularly helpful if you’re a junior infrastructure engineer.”</em></p><p>Christian Kornacker<br/>DevOps Lead, Marketplacer</p></blockquote><p>Additionally, Datadog continuously scans and surveys every resource, no matter how short-lived, so Marketplacer can answer tough questions and identify the state of their security posture down to specific resources and time frames.</p><p>Cloud Security Posture Management is part of the Datadog Cloud Security Platform, which helps an organization protect its production environment with a full-stack offering providing threat detection, posture management, workload security, and application security.</p><p>Because Datadog Cloud Security Posture Management is fully integrated with the rest of the Datadog platform as well, the Marketplacer team can get a single unified view of their environment. They also leverage Datadog for APM and logging, with a focus on finding problems before they impact customers. With the addition of Cloud Security Posture Management, Datadog lets them bring that same focus to security.</p><p>With a Cloud Security Posture Management solution that not only gives them visibility into their security posture, but also enables them to find actionable industry recommendations for resolving issues, Marketplacer is seeing significant reductions in their MTTD and MTTR. As they move closer to ISO:27001 certification, Marketplacer has also been able to proactively address any issues that arise before they impact customers.</p><blockquote><p><em>“ The speed and number of new configuration checks that Datadog adds on a regular basis is incredible. The trajectory of the product is so impressive.”</em></p><p>Christian Kornacker<br/>DevOps Lead, Marketplacer</p></blockquote></span></div></div>]]></content:encoded>
      <author>Datadog</author>
      <pubDate>Fri, 13 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Monitor your entire serverless stack in the Serverless view</title>
      <link>https://www.datadoghq.com/blog/datadog-serverless-view/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/datadog-serverless-view/Serverless-view_Feature-Announcement_210729_v4a.png&#34; width=&#34;100%&#34;/&gt;Serverless event-driven architectures are composed of AWS Lambda functions that regularly interact with databases, APIs, message queues, and other resources to facilitate complex workflows and functionalities. It is therefore crucial to monitor every component of your stack to ensure your applications perform optimally at scale. But traditionally, telemetry data for AWS resources has lived in silos, making it difficult to quickly get the context you need to debug issues. For instance, if the end-to-end latency of a customer request to your application&amp;rsquo;s backend suddenly spiked, you would need to dig into each resource&amp;rsquo;s Amazon CloudWatch metrics and logs to figure out whether an overloaded database, throttled Lambda function, or misconfigured API Gateway endpoint was to blame.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Serverless event-driven architectures are composed of AWS Lambda functions that regularly interact with databases, APIs, message queues, and other resources to facilitate complex workflows and functionalities. It is therefore crucial to monitor every component of your stack to ensure your applications perform optimally at scale. But traditionally, telemetry data for AWS resources has lived in silos, making it difficult to quickly get the context you need to debug issues. For instance, if the end-to-end latency of a customer request to your application’s backend suddenly spiked, you would need to dig into each resource’s Amazon CloudWatch metrics and logs to figure out whether an overloaded database, throttled Lambda function, or misconfigured API Gateway endpoint was to blame.</p><p>As today’s serverless applications become increasingly complex, we’re excited to announce that we’ve fully redesigned the <a href="https://app.datadoghq.com/functions">Serverless view</a> to meet our customers&#39; need for a more seamless debugging experience. The new Serverless view unifies telemetry data from Lambda functions and other AWS resources to give you a full overview of your entire serverless stack—making it the ideal starting point for monitoring, debugging, and optimizing your applications.</p><h2 id="create-a-logical-view-of-your-serverless-application"><a href="#create-a-logical-view-of-your-serverless-application">Create a logical view of your serverless application</a></h2><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/serverless-view.png?auto=format&amp;fit=max&amp;w=847" alt="See all your serverless resources, grouped by service, in the newly-redesigned Serverless view"/></picture></figure></div><p>By default, the Serverless view groups your serverless resources by service to help you easily visualize how each part of your application is performing. For each service, you will see the functions that belong to it, along with the resources (Amazon API Gateway, SNS, SQS, DynamoDB, S3, EventBridge, Kinesis) that invoked them.</p><p>While grouping by service is the default, you can also group your resources by AWS CloudFormation stack name, as well as any other tags you’ve configured (e.g., team, project, or environment). Additionally, <a href="https://docs.datadoghq.com/logs/explorer/saved_views/">Saved Views</a> allows you to preserve your preferred way of grouping, so you don’t need to manually enter it every time you visit the page.</p><h2 id="detect-and-debug-performance-issues-across-your-stack"><a href="#detect-and-debug-performance-issues-across-your-stack">Detect and debug performance issues across your stack</a></h2><p>The Serverless view enables you to correlate high-level metrics from AWS resources with those of Lambda functions, so you can quickly spot issues and jump-start your investigation. In the example below, we can see that one of our Lambda functions is frequently invoked, which is causing our cloud costs to increase. But the age of the oldest message in the SQS queue that invokes the function is 0 seconds, which indicates that SQS is not under heavy load.</p><p>By clicking on the queue, we can seamlessly pivot to the default dashboard for SQS and view additional statistics on message and queue activity. As our application is not latency-sensitive, we can increase the <a href="https://docs.aws.amazon.com/lambda/latest/dg/with-sqs.html#events-sqs-eventsource">queue’s batch size</a>, such that more requests are processed by each Lambda invocation—reducing invocation count and costs.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-sqs.png?auto=format&amp;fit=max&amp;w=847" alt="Increased traffic to a SQS queue is causing a Lambda function to be frequently invoked"/></picture></figure></div><p>Or, say that in a different case, a monitor alerts us of elevated latency in API Gateway. In the Serverless view, we can immediately see that the <code>theme-park-initstate</code> function, which is invoked by our API, is experiencing increased throttling.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-api-gateway.png?auto=format&amp;fit=max&amp;w=847" alt="Correlated error rates in API Gateway and Lambda"/></picture></figure></div><p>To investigate, we can click on the problematic Lambda function to view a full list of its invocations, along with key metrics, traces, and logs. Datadog APM visualizes Lambda functions and the AWS resources they invoke all in one trace, so we can track the flow of requests across our distributed architecture and determine whether the issue has propagated to downstream resources.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-serverless-view/lambda-trace.png?auto=format&amp;fit=max&amp;w=847" alt="Visualize the full lifespan of a request with Datadog APM"/></picture></figure></div><h2 id="start-monitoring-your-serverless-applications-in-the-serverless-view"><a href="#start-monitoring-your-serverless-applications-in-the-serverless-view">Start monitoring your serverless applications in the Serverless view</a></h2><p>All customers can now group their serverless resources using any tag in the new <a href="https://app.datadoghq.com/functions">Serverless view</a>. At this time, only Python and Node.js functions are tied to their related resources, but we plan to add support for more runtimes in the future. To get started, <a href="https://docs.datadoghq.com/serverless/installation">enable Datadog APM for tracing</a> and ensure you’re running Lambda Library v28+ for <a href="https://github.com/DataDog/datadog-lambda-python/releases">Python</a> and v49+ for Node.js. Or if you’re already using AWS X-Ray to trace your applications, all you need to do is <a href="https://docs.datadoghq.com/serverless/troubleshooting/connect_invoking_resources">add the Lambda Library to your functions</a>.</p><p>New to Datadog? Get started with a 14-day <a href="#">free trial</a> today.</p></div></div>]]></content:encoded>
      <author>Alex Cuoci</author>
      <pubDate>Fri, 06 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>How to monitor containerized and service-meshed network communication with Datadog NPM</title>
      <link>https://www.datadoghq.com/blog/monitor-containers-with-npm/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers-hero.png&#34; width=&#34;100%&#34;/&gt;Containers are lightweight, portable, easily scalable, and enable you to run multiple workloads on the same host efficiently, particularly when using an orchestration platform like Kubernetes or Amazon ECS. But containers also introduce monitoring challenges. Containerized environments may comprise vast webs of distributed endpoints and dependencies that rely on complex network communication. Adding further complexity, you need to ensure that each node in your cluster maintains contact with almost every other node.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><a href="https://www.datadoghq.com/container-report/">Containers</a> are lightweight, portable, easily scalable, and enable you to run multiple workloads on the same host efficiently, particularly when using an orchestration platform like Kubernetes or Amazon ECS. But containers also introduce monitoring challenges. Containerized environments may comprise vast webs of distributed endpoints and dependencies that rely on complex network communication. Adding further complexity, you need to ensure that each node in your cluster maintains contact with almost every other node. And containers are highly ephemeral, which makes IP-level connection data unreliable for tracking network traffic between these components, especially in the cloud.</p><p>Datadog <a href="https://docs.datadoghq.com/network_monitoring/performance/">Network Performance Monitoring</a> visualizes network traffic between objects within your entire containerized environment. This makes it easy to monitor network dependencies across all of your containers, services, and deployments so you can spot architectural and performance issues quickly. If you’re using a service mesh in your environment, Datadog NPM also enables you to analyze service mesh traffic to help identify traffic management misconfigurations and ensure the services in your mesh communicate efficiently.</p><p>In this post we’ll look at how you can use Datadog NPM to help you:</p><ul><li><a href="#visualize-your-containerized-architecture-with-the-network-map">visualize</a> network communication across your dynamic containerized infrastructure</li><li><a href="#get-full-visibility-into-each-layer-of-your-containerized-applications">troubleshoot</a> performance issues in containerized applications</li><li><a href="#analyze-service-mesh-and-proxied-traffic-health">analyze</a> service mesh traffic health</li></ul><h2 id="visualize-your-containerized-architecture-with-the-network-map"><a href="#visualize-your-containerized-architecture-with-the-network-map">Visualize your containerized architecture with the Network Map</a></h2><p>Containerized environments are highly distributed and can quickly grow in size and complexity, making them especially vulnerable to network issues. And, because each service may have many dependencies, an isolated problem can have an outsize impact on the rest of your application. This means visibility into network communication across your containerized workloads is key to monitoring the health and performance of your applications. But because containers churn often, tracking communication between them can be difficult.</p><p>Datadog’s <a href="https://docs.datadoghq.com/network_monitoring/performance/network_map/">Network Map</a> uses directional arrows, or <strong>edges</strong>, to visualize traffic flows between containers, pods, deployments, or other tagged objects in your environment, regardless of whether their constituent containers change. This gives you a real-time view of your network’s topology do you can spot architectural inefficiencies and misconfigurations. Visualizing traffic with edges can quickly reveal, for example, if Kubernetes pods in the same cluster are communicating through an <a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/">ingress controller</a> rather than directly to each other. Since you’d expect an ingress controller to be used for traffic between different clusters, intra-cluster ingress traffic indicates misconfiguration which can lead to increased latency.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers00.png?auto=format&amp;fit=max&amp;w=847" alt="npm-for-containers00.png"/></picture><figcaption>Use the Network Map to ensure there&#39;s expected traffic between pods. If there are no edges between pods, it could indicate a misconfiguration.</figcaption></figure></div><p>The Network Map’s visualization options enable you to tie issues like high TCP retransmits and latency to objects within your containerized infrastructure, like ECS tasks or Kubernetes deployments and pods. This enables you to determine at which layer of your environment network problems are occurring. Let’s say you use the Network Map to visualize the TCP latency across your services and see that there’s high latency between two services. You can inspect one of the services and then break the map down further by selecting <code>pod_name</code> in the View dropdown menu, enabling you to dig deeper by viewing latency in the context of your services&#39; underlying pods. This way, you can see if a particular pod is contributing to latency, indicated by thicker lines connected to a pod’s node.</p><p>Once you’ve identified a pod to investigate, you can view it in the <a href="https://app.datadoghq.com/orchestration/overview/pod">Orchestration Center</a> and see its specs (including status), resource consumption down to the process level, logs, and more. If the pod’s CPU usage is high, that is likely the culprit behind the latency you observed. Now that you’ve pinpointed the root cause, you can start taking mitigating steps to reduce latency, like scaling the pod.</p><h2 id="get-full-visibility-into-each-layer-of-your-containerized-applications"><a href="#get-full-visibility-into-each-layer-of-your-containerized-applications">Get full visibility into each layer of your containerized applications</a></h2><p>In containerized environments, requests can propagate across a number of components in your infrastructure. Because of this, it can be difficult to determine whether problems are due to network issues or possible code-level bugs. For example, pod connectivity problems can manifest as application latency or errors if your service can’t reach a dependency.</p><p><a href="https://docs.datadoghq.com/tracing/">Datadog APM</a> provides insight into issues at the application layer of your containerized environment in order to help determine the root cause of a problem. For instance, if you’ve identified a container running on EC2 that’s experiencing high request latency, you can dig into its traces to try to establish whether the cause is a code-level issue. If not, you can then easily pivot to the “Network” tab to view all network connections that are related to that service and identify if the problem stems from an upstream service (i.e., one application’s pods are overwhelmed with traffic from another application and can no longer respond to requests).</p><p>Datadog NPM also supports <a href="https://www.datadoghq.com/blog/monitor-dns-with-datadog/">DNS monitoring</a>, which means you can view the health of the communication between your pods and DNS servers to determine if a service discovery issue is preventing your client pod from finding the pods it needs to reach. You can easily identify which DNS servers (such as CoreDNS pods) may be contributing to the high response time or error rate of incoming DNS requests. Or, you can look for spikes in <code>NXDOMAIN</code> DNS responses. This can help determine whether a DNS server’s latency is a consequence of a client-side issue, like a pod making multiple invalid requests for every valid request, which may be overloading the DNS server.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers02.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog NPM supports DNS montiroing so you can view the health of the traffic between pods and DNS servers."/></picture></figure></div><h2 id="analyze-service-mesh-and-proxied-traffic-health"><a href="#analyze-service-mesh-and-proxied-traffic-health">Analyze service mesh and proxied traffic health</a></h2><p>Service meshes like <a href="https://istio.io/">Istio</a> help manage the access parameters and routing of microservice communication. But they also introduce further monitoring challenges by adding a layer of abstraction across your environment, making it challenging to get visibility into container communication. With Datadog Network Performance Monitoring, you can easily visualize traffic flow across <a href="https://www.datadoghq.com/blog/monitor-istio-with-npm/">Istio-managed networks</a>. And, Datadog’s <a href="https://docs.datadoghq.com/integrations/istio/#pagetitle">Istio integration</a> provides full visibility into every other aspect of your Istio environment. Datadog collects key <a href="https://docs.datadoghq.com/integrations/istio/#metrics">Istio metrics</a> to monitor bandwidth and request performance, <a href="https://docs.datadoghq.com/integrations/istio/#log-collection">logs</a> to investigate control plane health, and distributed <a href="https://docs.datadoghq.com/tracing/setup_overview/proxy_setup/?tab=istio">traces</a> from application requests propagating across your mesh.</p><p>Additionally, Datadog supports <a href="https://istio.io/latest/docs/ops/deployment/architecture/#envoy">Envoy</a> monitoring, enabling you to easily correlate Istio monitoring data with data from its Envoy proxy mesh. Because application containers route traffic through Envoy <strong>sidecars</strong> installed on their local pods to sidecars on separate pods, latency between pods could either be due to latency between application containers and their local Envoy sidecar or to latency between sidecars themselves. Datadog NPM tags Envoy sidecars as containers, which means if you do see latency between pods, you can use the Network Map to visualize the underlying container traffic and determine if it’s a service mesh issue.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/monitor-containers-with-npm/npm-for-containers04.png?auto=format&amp;fit=max&amp;w=847" alt="npm-for-containers04.png"/></picture><figcaption>Visualize service mesh traffic by container_name to look at network communication between Envoy sidecars.</figcaption></figure></div><h2 id="start-monitoring-your-containerized-workloads-with-npm-today"><a href="#start-monitoring-your-containerized-workloads-with-npm-today">Start monitoring your containerized workloads with NPM today</a></h2><p>Whether you’re using orchestration tools like Kubernetes and Amazon ECS, relying on an Istio service mesh, or migrating to any of these platforms, Datadog Network Performance Monitoring provides you with full visibility into your containerized applications and their communication. To get started with NPM, follow the installation instructions <a href="https://docs.datadoghq.com/network_monitoring/performance/setup/?tab=agent#setup">here</a>. And, to learn about how <a href="https://www.deliveryhero.com/">Delivery Hero</a> was able to safely scale to meet 2X their orders in 2020 using Datadog NPM for visibility into their Kubernetes network, <a href="https://www.datadoghq.com/case-studies/deliveryhero-2021/">see the case study</a>.</p><p>If you’re new to Datadog, sign up today for a 14-day <a href="#">free trial.</a></p></div></div>]]></content:encoded>
      <author>Jordan Obey</author>
      <pubDate>Thu, 05 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Key metrics for monitoring Amazon EFS</title>
      <link>https://www.datadoghq.com/blog/amazon-efs-metrics/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/amazon_efs_longform_part-1.png&#34; width=&#34;100%&#34;/&gt;Amazon Elastic File System (EFS) provides shared, persistent, and elastic storage in the AWS cloud. Like Amazon S3, EFS is a highly available managed service that scales with your storage needs, and it also enables you to mount a file system to an EC2 instance, similar to Amazon Elastic Block Store (EBS). But EFS offers other features—like simultaneous access from multiple clients and AWS Lambda integration—that make it well-suited for use cases such as big data workloads, machine learning, and serving web content.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><a href="https://aws.amazon.com/efs/">Amazon Elastic File System (EFS)</a> provides shared, persistent, and elastic storage in the AWS cloud. Like <a href="https://aws.amazon.com/s3/">Amazon S3</a>, EFS is a highly available managed service that scales with your storage needs, and it also enables you to mount a file system to an EC2 instance, similar to <a href="https://aws.amazon.com/ebs/">Amazon Elastic Block Store (EBS)</a>. But EFS offers other features—like simultaneous access from multiple clients and <a href="https://aws.amazon.com/blogs/compute/using-amazon-efs-for-aws-lambda-in-your-serverless-applications/">AWS Lambda integration</a>—that make it well-suited for use cases such as big data workloads, machine learning, and serving web content.</p><p>It’s important to monitor EFS latency, I/O, throughput, and connections in order to ensure the performance of the services and applications that access your file systems. Monitoring EFS can also help you understand costs, which are determined in part by the size and settings of your file systems. In this post, we’ll show you which Amazon EFS metrics are important to monitor, but first, let’s look at how EFS works.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=1140 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=1140&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=942 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=942&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/efs-monitoring-datadog-dashboard.png?auto=format&amp;w=847" alt="I/O, throughput, and connection graphs shown on a Datadog built-in dashboard are useful in monitoring Amazon EFS."/></picture></figure></div><h2 id="an-overview-of-efs"><a href="#an-overview-of-efs">An overview of EFS</a></h2><p>EFS is based on the <a href="https://en.wikipedia.org/wiki/Network_File_System">Network File System (NFS)</a> protocol, and it automatically handles <a href="https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html#consistency">data consistency</a> and manages <a href="https://en.wikipedia.org/wiki/File_locking">file locking</a> to safely allow for parallel access from multiple clients. You can access EFS from EC2 instances, Lambda functions, <a href="https://aws.amazon.com/sagemaker/">Amazon SageMaker</a> notebook instances, and AWS <a href="https://aws.amazon.com/blogs/storage/best-practices-for-using-amazon-efs-for-container-storage/">container services</a> (ECS tasks and EKS pods running on EC2 or Fargate). If you’re using Direct Connect, you can also connect to EFS from on-premise hosts. This flexibility makes EFS appropriate for a variety of use cases: for example, you can store static website data in EFS and serve it from a fleet of EC2 instances or ECS tasks, or run a big data application comprised of Lambda functions that read the data, normalize it, and write it back to the file system.</p><p>By default, EFS stores copies of your data in multiple availability zones (AZs) and provides access to clients via <a href="https://docs.aws.amazon.com/efs/latest/ug/accessing-fs.html"><strong>mount targets</strong></a>. When you create a mount target, AWS creates an <a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_ElasticNetworkInterfaces.html">Elastic Network Interface (ENI)</a> in a subnet you specify, providing a local endpoint for all clients in that subnet (or clients that can <a href="https://docs.aws.amazon.com/efs/latest/ug/manage-fs-access-vpc-peering.html">route to it</a>). AWS recommends creating a mount target in each AZ to minimize latency and avoid cross-zone data transfer charges.</p><p>The diagram below shows an EFS file system that stores its data across two availability zones. A subnet in each AZ contains a mount target, and EC2 instances within the subnet communicate with the local mount target. The diagram also shows a Lambda function accessing the mount target in each subnet via ENIs that are <a href="https://docs.aws.amazon.com/lambda/latest/dg/configuration-vpc.html">created automatically</a> when the function is connected to the VPC.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-metrics/lambda-and-ec2-attach-to-efs.png?auto=format&amp;fit=max&amp;w=847" alt="A diagram of EFS architecture shows a file system inside a VPC. Two availability zones in the VPC contain EC2 instances connected to EFS mount targets. From outside the VPC, a Lambda function connects to the mount targets."/></picture></figure></div><p><a href="https://docs.aws.amazon.com/efs/latest/ug/efs-access-points.html"><strong>Access points</strong></a> enable you to limit a client’s access to a subset of a file system by specifying a path for the client to use as its root directory. You can create multiple access points to give different applications access to different subdirectories, and you can optionally configure an access point to <a href="https://docs.aws.amazon.com/efs/latest/ug/efs-access-points.html#enforce-identity-access-points">enforce a user identity</a> so that all clients access the data as a single user. You can also create a <a href="https://docs.aws.amazon.com/efs/latest/ug/iam-access-control-nfs-efs.html"><strong>file system policy</strong></a> to allow or deny connections to an access point.</p><p>A file system must have an access point in order for Lambda functions to connect to it. Other clients—EC2 instances, ECS tasks, EKS pods, and SageMaker notebooks—can mount a file system without using an access point if the file system policy will allow it, but this may give your applications <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#grant-least-privilege">greater access than necessary</a>.</p><h3 id="performance-modes"><a href="#performance-modes">Performance modes</a></h3><p>EFS operates in one of two <a href="https://docs.aws.amazon.com/efs/latest/ug/performance.html#performancemodes"><strong>performance modes</strong></a>, which influence the file system’s latency and I/O operations per second (IOPS). General Purpose mode is the default, and it provides the lowest latency for most use cases. Max I/O mode provides higher IOPS, although it adds some <a href="https://aws.amazon.com/premiumsupport/knowledge-center/linux-efs-performance-modes/">latency</a> to each operation. If your workload’s data access is parallelized across a large number of clients or processes—for example, training a machine learning algorithm—Max I/O can improve your application’s data storage and retrieval performance.
You can choose either performance mode without affecting your EFS costs, but you can’t change the performance mode of a file system after you’ve created it.</p><h3 id="throughput-modes"><a href="#throughput-modes">Throughput modes</a></h3><p>You can also choose your file system’s <a href="https://docs.aws.amazon.com/efs/latest/ug/performance.html#throughput-modes"><strong>throughput mode</strong></a>, which determines the amount of data your clients can read and write in each disk operation.
Bursting Throughput is the default mode. It provides a consistent baseline level of throughput that is proportional to your file system’s size, but it also allows you to burst above the baseline for relatively short periods of time. Your baseline throughput scales up as your file system grows, and your ability to burst increases (i.e., you accrue <strong>burst credits</strong>) as your file system operates below the baseline throughput rate.</p><p>If your application consistently requires throughput above the baseline level provided by Bursting Throughput mode, you can choose to use Provisioned Throughput mode instead. This mode allows you to specify a level of throughput that is always available regardless of the size of your file system. Provisioned Throughput mode carries an additional cost, but if the amount of data your application uses is small relative to your throughput needs—for example, a static website with high traffic—it can help you ensure that your file system is not a bottleneck for your application’s performance.</p><h3 id="storage-classes"><a href="#storage-classes">Storage classes</a></h3><p>Each file system you create in EFS keeps your data in one or more <a href="https://docs.aws.amazon.com/efs/latest/ug/storage-classes.html"><strong>storage classes</strong></a>, which provide different levels of availability and performance, and which incur different costs. The Standard storage class keeps data in multiple availability zones within the VPC where you created your file system. In contrast, the One Zone class stores data in a single AZ, which reduces both the <a href="https://docs.aws.amazon.com/efs/latest/ug/storage-classes.html#sc-compare">availability</a> of your data and the costs associated with storing it. These tradeoffs make the One Zone class most appropriate for storing temporary data that can be easily recreated, such as staging or build environments.</p><p>You can configure EFS to automatically move data from either of these classes to an infrequent access (IA) class—Standard-Infrequent Access or One Zone-Infrequent Access—if it is not accessed within a <a href="https://docs.aws.amazon.com/efs/latest/ug/lifecycle-management-efs.html">time frame you specify</a>. It’s less expensive to use IA classes, so storing unused data there can help you manage your EFS costs. But you must pay a per-access charge any time you retrieve data from IA, and the latency is higher, so it may or may not be your preferred storage option, depending on your data access patterns.</p><h2 id="key-amazon-efs-metrics-to-monitor"><a href="#key-amazon-efs-metrics-to-monitor">Key Amazon EFS metrics to monitor</a></h2><p>So far in this post, we’ve shown you how EFS provides shared storage to a variety of clients, and we’ve looked at the configuration options that let you balance availability, performance, and cost. In this section, we’ll walk you through the key metrics you should monitor to fully understand the health and performance of your file system. We’ll show you metrics from the following categories:</p><ul><li><a href="#storage-metrics">storage</a></li><li><a href="#latency-metrics">latency</a></li><li><a href="#io-metrics">I/O</a></li><li><a href="#throughput-metrics">throughput</a></li><li><a href="#connection-metrics">client connections</a></li></ul><p>Terminology in this section comes from our <a href="https://www.datadoghq.com/blog/monitoring-101-collecting-data/">Monitoring 101</a> series. Most of the metrics in this section are available from <a href="https://aws.amazon.com/cloudwatch/">Amazon CloudWatch</a>, but some come from Linux utilities. We’ll explore these and some other tools you can use to collect Amazon EFS metrics in <a href="https://www.datadoghq.com/blog/amazon-efs-monitoring-tools">Part 2</a> of this series.</p><h3 id="storage-metrics"><a href="#storage-metrics">Storage metrics</a></h3><p>EFS is elastic and will scale to provide more storage as your needs increase. But the size of your file system affects your EFS costs, so it’s important to track how much data you’re storing—overall and in each storage class—in order to understand and anticipate your monthly charges.</p><table><thead><tr><th>Name</th><th>Description</th><th>Metric type</th><th>Availability</th></tr></thead><tbody><tr><td>File size</td><td>Storage space used by a single file or directory</td><td>Resource: Utilization</td><td>Linux utilities</td></tr><tr><td>File system size</td><td>Aggregate storage space used by a file system</td><td>Resource: Utilization</td><td>CloudWatch, Linux utilities</td></tr></tbody></table><h4 id="metric-to-watch-file-size"><a href="#metric-to-watch-file-size">Metric to watch: File size</a></h4><p>Monitoring the size of individual files or directories can give you granular insight into your EFS usage. You should track the growth of files that contribute significantly to your overall usage—for example, fast-growing log files—to understand and accurately predict your application’s storage needs.</p><h4 id="metric-to-watch-file-system-size"><a href="#metric-to-watch-file-system-size">Metric to watch: File system size</a></h4><p>A typical disk utilization metric doesn’t apply in the case of EFS, which has no fixed upper limit on the amount of data you can store. But monitoring your file system size over time can show you how your application is storing and accessing data in three dimensions: the Standard storage classes, the IA storage classes, and in total.
If you’re using <a href="https://docs.aws.amazon.com/efs/latest/ug/lifecycle-management-efs.html">lifecycle management</a>, this metric will provide insight into how data shifts from Standard to IA storage classes. Seeing the rate of that shift can illustrate patterns in how your application accesses existing data.</p><h3 id="latency-metrics"><a href="#latency-metrics">Latency metrics</a></h3><p>Your file system’s performance mode and storage class can influence its latency, so you’ll want to keep an eye on your latency metrics to ensure that you’ve chosen the most optimal configuration. Because EFS is based on NFS, you can use the <code>nfsiostat</code> tool on an EC2 instance, ECS task (via <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/ecs/execute-command.html"><code>execute-command</code></a>), or EKS pod (via <a href="https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html"><code>kubectl</code></a>) to see the round-trip time required for that client to access data on any attached EFS file system. If you’re using EFS with Lambda, <a href="https://aws.amazon.com/codeguru/">Amazon CodeGuru Profiler</a> can help you visualize the time your application spends <a href="https://docs.aws.amazon.com/codeguru/latest/profiler-ug/working-with-visualizations-summary-page.html">waiting for disk operations</a> to complete.</p><table><thead><tr><th>Name</th><th>Description</th><th>Metric type</th><th>Availability</th></tr></thead><tbody><tr><td>Read round-trip time</td><td>The time between when the client sends a request to read data and when it receives the reply from EFS</td><td>Work: Performance</td><td>Linux utilities</td></tr><tr><td>Write round-trip time</td><td>The time between when the client sends a request to write data and when it receives the reply from EFS</td><td>Work: Performance</td><td>Linux utilities</td></tr></tbody></table><h4 id="metric-to-watch-readwrite-round-trip-time"><a href="#metric-to-watch-readwrite-round-trip-time">Metric to watch: Read/write round-trip time</a></h4><p>You can monitor EFS’s round-trip time (RTT) to understand how storage access contributes to your application’s overall latency. You may be able to reduce average RTT across all of your clients by ensuring that they are connecting to <a href="https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html">mount targets in their local availability zone</a> and by minimizing any competing network traffic within the VPC. If only some clients have a slow RTT, you should optimize the network performance of the relevant nodes—for example, by scaling up to a larger instance size—to prevent sporadic latency in your application. You should also ensure that your file system is using the optimal performance mode and storage class, as Infrequent Access storage classes and Max I/O performance mode generally have higher latencies.</p><h3 id="io-metrics"><a href="#io-metrics">I/O metrics</a></h3><p>Your I/O rate will increase as more clients access a shared file system, and your application’s access to storage could get throttled if your clients collectively require more IOPS than your file system can provide. It’s therefore important for you to monitor I/O utilization, especially if you’ve parallelized storage access across a large number of clients or processes.</p><p>You can use CloudWatch to monitor the I/O utilization of file systems that use General Purpose mode, but this metric isn’t available if you’re using Max I/O mode.</p><table><thead><tr><th>Name</th><th>Description</th><th>Metric type</th><th>Availability</th></tr></thead><tbody><tr><td>I/O utilization</td><td>The percentage of the file system’s available IOPS that is in use</td><td>Resource: Utilization</td><td>Availability: CloudWatch</td></tr></tbody></table><h4 id="metric-to-alert-on-io-utilization"><a href="#metric-to-alert-on-io-utilization">Metric to alert on: I/O utilization</a></h4><p>If your file system reaches its IOPS limit, your application could slow down as it waits to read and write data. You should create an alert that triggers when your file system approaches a specified percentage of its IOPS limit to give your team time to refactor or re-architect your application (e.g., to introduce a caching layer) before its performance degrades. Alternatively, you should consider moving to a new file system configured to use <a href="#performance-modes">Max I/O mode</a>.</p><h3 id="throughput-metrics"><a href="#throughput-metrics">Throughput metrics</a></h3><p>A file system’s throughput limit is determined by its performance mode, size, and level of activity. In Bursting Mode, the throughput limit changes based on the file system’s size and burst credit balance. In Provisioned Throughput mode, you specify the limit in the file system’s configuration. Monitoring the metrics described in this section can help you see whether insufficient throughput presents a risk to your application’s performance—or whether you’ve provisioned more throughput than your application requires.</p><table><thead><tr><th>Name</th><th>Description</th><th>Metric type</th><th>Availability</th></tr></thead><tbody><tr><td>Burst credit balance</td><td>The number of bytes of bursting throughput the file system has available</td><td>Resource: Utilization</td><td>CloudWatch</td></tr><tr><td>Permitted throughput</td><td>The amount of throughput available to the file system, in bytes per second</td><td>Work: Throughput</td><td>CloudWatch</td></tr><tr><td>Metered I/O bytes</td><td>The number of bytes used in reads, writes, and metadata operations on the file system</td><td>Resource: Utilization</td><td>CloudWatch</td></tr></tbody></table><h4 id="metric-to-alert-on-burst-credit-balance"><a href="#metric-to-alert-on-burst-credit-balance">Metric to alert on: Burst credit balance</a></h4><p>In Bursting Throughput mode, your file system can temporarily attain throughput rates above the baseline. The more burst credits you have, the longer you can sustain a higher throughput.</p><p>You accrue burst credits when you’re operating below the baseline throughput, and you spend burst credits when you’re operating above the baseline (i.e., bursting). If your burst credit balance reaches zero, your application’s access to your file system will be limited to the baseline throughput, which could cause user-facing latency.</p><p>Monitor burst credit balance to ensure that you have sufficient credits to support the data access patterns of your workloads. If you find that you are consistently running out of burst credits, you should consider switching to <a href="#throughput-modes">Provisioned Throughput mode</a>, which will enable you to define the amount of throughput you require.</p><h4 id="metric-to-watch-permitted-throughput"><a href="#metric-to-watch-permitted-throughput">Metric to watch: Permitted throughput</a></h4><p>Permitted throughput illustrates the throughput available to you at any moment, and it is calculated differently depending on which performance mode you’re using. In Bursting Throughput mode, this metric changes along with burst credit balance and file system size. If no burst credits are available, permitted throughput will be equal to the file system’s baseline throughput. In Provisioned Throughput mode, the value of this metric will equal the larger of your provisioned amount of throughput or the baseline throughput. If its value is lower than you expected, it could help explain any errors or latency in your application.</p><h4 id="metric-to-alert-on-meterediobytes"><a href="#metric-to-alert-on-meterediobytes">Metric to alert on: MeteredIOBytes</a></h4><p>CloudWatch aggregates the data used on read, write, and metadata operations into a <a href="https://docs.aws.amazon.com/efs/latest/ug/efs-metrics.html"><code>MeteredIOBytes</code></a> metric. If the value of this metric reaches your file system’s permitted throughput, your application’s access will be limited, which could cause user-facing latency. Create an alert on <code>MeteredIOBytes</code> as a percentage of permitted throughput so you can <a href="#throughput-modes">provision</a> enough throughput to meet your application’s requirements and prevent application latency.</p><h3 id="connection-metrics"><a href="#connection-metrics">Connection metrics</a></h3><p>EFS supports <a href="https://docs.aws.amazon.com/efs/latest/ug/limits.html#limits-efs-resources-per-account-per-region">thousands of connections per file system</a>, but even if you’re not at risk of surpassing that limit, it can be helpful to monitor each file system’s connection count to watch for unexpected changes. Fewer connections than usual could indicate a problem with an application or the network. And if you see more connections than you expect, you could have a security issue or an auto-scaling anomaly that you need to investigate.</p><table><thead><tr><th>Name</th><th>Description</th><th>Metric type</th><th>Availability</th></tr></thead><tbody><tr><td>Client connections</td><td>A count of all the clients connected to the file system</td><td>Resource: Utilization</td><td>CloudWatch</td></tr></tbody></table><h4 id="metric-to-alert-on-client-connections"><a href="#metric-to-alert-on-client-connections">Metric to alert on: Client connections</a></h4><p>Your file system’s I/O is a limited resource—especially if you’re using General Purpose mode—and an upward trend in your connection count could be one cause of an increase in <a href="#io-metrics">IOPS</a>. If your application typically has a steady number of clients accessing your file system, you should create an alert to notify you if the client connections metric rises above normal so you can evaluate whether you’re at risk of running out of IOPS.</p><h2 id="monitor-efs-performance-for-healthy-storage"><a href="#monitor-efs-performance-for-healthy-storage">Monitor EFS performance for healthy storage</a></h2><p>In this post, we’ve shown you how EFS works and which EFS metrics you can track to understand your file system’s performance. It’s important to monitor your file system’s latency, I/O, and throughput, as well as your usage, to ensure the health of your application and troubleshoot any bottlenecks that arise. Coming up in <a href="https://www.datadoghq.com/blog/amazon-efs-monitoring-tools">Part 2</a>, we’ll show you some of the tools you can use to gather logs and metrics from EFS.</p><h2 id="acknowledgments"><a href="#acknowledgments">Acknowledgments</a></h2><p>We’d like to thank Ray Zaman at AWS for their technical review of this post.</p><p><em>Source Markdown for this post is available <a href="https://github.com/DataDog/the-monitor/blob/master/efs/amazon-efs-metrics.md">on GitHub</a>. Questions, corrections, additions, etc.? Please <a href="https://github.com/DataDog/the-monitor/issues">let us know</a>.</em></p></div></div>]]></content:encoded>
      <author>David M. Lentz</author>
      <pubDate>Thu, 05 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Amazon EFS monitoring tools</title>
      <link>https://www.datadoghq.com/blog/amazon-efs-monitoring-tools/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/amazon_efs_longform_part-2.png&#34; width=&#34;100%&#34;/&gt;In Part 1 of this series, we looked at EFS metrics from several different categories—storage, latency, I/O, throughput, and client connections. In this post, we&amp;rsquo;ll show you how you can collect those metrics—as well as EFS logs—using built-in and external tools. We&amp;rsquo;ll look at how to: view metrics in the EFS console use the CloudWatch console and API collect metrics with Linux tools collect EFS logs with AWS logging services and Linux logging tools Collect EFS metricsCollecting and analyzing EFS metrics can help you understand your file systems&#39; role in the health and performance of your applications.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>In <a href="https://www.datadoghq.com/blog/amazon-efs-metrics">Part 1</a> of this series, we looked at EFS metrics from several different categories—storage, latency, I/O, throughput, and client connections. In this post, we’ll show you how you can collect those metrics—as well as EFS logs—using built-in and external tools. We’ll look at how to:</p><ul><li>view metrics in <a href="#the-efs-console">the EFS console</a></li><li>use the <a href="#cloudwatch">CloudWatch</a> console and API</li><li>collect metrics with <a href="#linux-tools">Linux tools</a></li><li>collect EFS logs with <a href="#aws-logging-services">AWS logging services</a> and <a href="#non-aws-logging-tools">Linux logging tools</a></li></ul><h2 id="collect-efs-metrics"><a href="#collect-efs-metrics">Collect EFS metrics</a></h2><p>Collecting and analyzing EFS metrics can help you understand your file systems&#39; role in the health and performance of your applications. Because EFS is a managed service, some standard approaches to monitoring, such as monitoring server resource metrics, are not applicable. In this section, we’ll look at some tools provided by AWS and some that are built into Linux that let you collect and visualize key EFS metrics.</p><h3 id="the-efs-console"><a href="#the-efs-console">The EFS console</a></h3><p>You can use the EFS console, which is available from within the <a href="https://console.aws.amazon.com/">AWS Management Console</a>, to create and delete file systems, define their settings, and manage mount targets and access points. You can also see graphs of key metrics we looked at in <a href="https://www.datadoghq.com/blog/amazon-efs-metrics">Part 1</a> of this series, such as throughput, I/O, client connections, and storage, to visualize the performance of each file system over time.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-efs-console.png?auto=format&amp;fit=max&amp;w=847" alt="Graphs of file system metrics shown on the EFS console include throughput, IOPS, connection, and storage data."/></picture></figure></div><h3 id="cloudwatch"><a href="#cloudwatch">CloudWatch</a></h3><p>While the EFS console is a good way to quickly begin monitoring your EFS file systems, <a href="https://aws.amazon.com/cloudwatch/">Amazon CloudWatch</a> allows you to monitor, correlate, and alert on the performance of EFS and the other AWS services you use. In this section, we’ll show you how to use the CloudWatch console to visualize the data that CloudWatch collects, and we’ll introduce you to the CloudWatch API, which allows you to retrieve EFS metrics programmatically.</p><h4 id="cloudwatch-console"><a href="#cloudwatch-console">CloudWatch console</a></h4><p>The CloudWatch console for EFS—shown in the screenshot below—includes a built-in dashboard that expands on the data shown in the <a href="#the-efs-console">EFS console</a> and visualizes connections, IOPS, burst credits, and throughput data from multiple file systems at once.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-metrics-cloudwatch-automatic-dashboard.png?auto=format&amp;fit=max&amp;w=847" alt="The CloudWatch service dashboard for EFS graphs data from multiple file systems, visualizing connection, IOPS, burst credit, and throughput data."/></picture></figure></div><p>You can open any one of these graphs in <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/working_with_metrics.html">CloudWatch metrics</a>, where you can modify it and add it to a custom dashboard. Custom dashboards allow you to graph metrics from multiple AWS services in a single view or even on the same graph, so you can quickly explore possible causes of an issue you need to troubleshoot.
For example, the graph in the screenshot below shows the <code>BurstCreditBalance</code> value for an EFS file system decreasing as the rate of a Lambda function’s <code>Invocations</code> rises. This correlation suggests that the Lambda function’s increased disk activity could be consuming the available burst credits, which, as discussed in the section on <a href="https://www.datadoghq.com/blog/amazon-efs-metrics#throughput-metrics">throughput metrics</a> in Part 1 of this series, could ultimately cause user-facing latency.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/cloudwatch-efs-lambda-correlation.png?auto=format&amp;fit=max&amp;w=847" alt="A CloudWatch graph shows the burst credit balance metric for a file system declining while the rate of invocations of a Lambda function increases."/></picture></figure></div><p>You can create an <a href="https://docs.aws.amazon.com/efs/latest/ug/creating_alarms.html">alarm</a> for any metric you see in the CloudWatch console by defining a threshold value for the metric and an <a href="https://aws.amazon.com/sns/">SNS topic</a> to which AWS will automatically send a message if the metric breaches that value. You can also create anomaly-based CloudWatch Alarms to automatically notify you, for example, if the number of clients connected to your file system changes significantly from its historical range of values.</p><h4 id="cloudwatch-api"><a href="#cloudwatch-api">CloudWatch API</a></h4><p>In the previous section, we discussed how the CloudWatch console lets you visualize and alert on EFS metrics. You can also fetch EFS metrics programmatically from the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/making-api-requests.html">CloudWatch API</a> via AWS SDKs or the AWS command-line interface (CLI). The AWS <a href="https://aws.amazon.com/tools/">SDKs</a> enable you to call the API with Python, Ruby, Go, and <a href="https://aws.amazon.com/tools/#SDKs">many other languages</a>, so you can integrate EFS monitoring into your processes or applications. In contrast, the <a href="https://aws.amazon.com/cli/">CLI</a> is useful for manually executing ad hoc queries or creating scripts that automatically collect metrics.</p><p>To use the AWS CLI, you’ll first need to <a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-install.html">install it</a> on the host where you’ll execute the API calls. You’ll also need to configure the necessary authentication, for example by using an <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/iam-roles-for-amazon-ec2.html">EC2 instance profile</a>.</p><p>To get CloudWatch metrics through the CLI, you use the <code>cloudwatch</code> subcommand. The example below uses the <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_GetMetricStatistics.html"><code>get-metric-statistics</code></a> action to retrieve the value of the <code>StorageBytes</code> metric from the <code>AWS/EFS</code> <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch_concepts.html#Namespace">namespace</a>. The command includes <code>start-time</code> and <code>end-time</code> parameters to scope the request to a one-hour time frame, a <code>period</code> parameter to aggregate the metrics every 15 minutes, and a <code>statistics</code> parameter to request a sum of the collected metric values. The <code>dimensions</code> parameter holds key-value pairs to define the file system (<code>FileSystemId</code>) and the <a href="https://www.datadoghq.com/blog/amazon-efs-metrics#metric-to-watch-file-system-size">storage class</a> (<code>StorageClass</code>) to query.</p><div><pre><code data-lang="text">aws cloudwatch get-metric-statistics \
--metric-name StorageBytes \
--start-time 2021-04-02T16:35:00 \
--end-time 2021-04-02T17:35:00 \
--period 900 \
--statistics Sum \
--namespace AWS/EFS \
--dimensions Name=FileSystemId,Value=&lt;MY-FILE-SYSTEM-ID&gt; Name=StorageClass,Value=Total</code></pre></div><p>The <code>get-metric-statistics</code> action returns a JSON object like the one shown below. This example result contains four records, one every 15 minutes over the one-hour time frame specified in the request. Note that CloudWatch does not guarantee that records returned by <code>get-metric-statistics</code> will appear in chronological order.</p><div><pre><code data-lang="text">{
    &#34;Label&#34;: &#34;StorageBytes&#34;,
    &#34;Datapoints&#34;: [
        {
            &#34;Timestamp&#34;: &#34;2021-04-02T16:50:00+00:00&#34;,
            &#34;Sum&#34;: 4220928.0,
            &#34;Unit&#34;: &#34;Bytes&#34;
        },
        {
            &#34;Timestamp&#34;: &#34;2021-04-02T17:05:00+00:00&#34;,
            &#34;Sum&#34;: 4220928.0,
            &#34;Unit&#34;: &#34;Bytes&#34;
        },
        {
            &#34;Timestamp&#34;: &#34;2021-04-02T16:35:00+00:00&#34;,
            &#34;Sum&#34;: 2123776.0,
            &#34;Unit&#34;: &#34;Bytes&#34;
        },
        {
            &#34;Timestamp&#34;: &#34;2021-04-02T17:20:00+00:00&#34;,
            &#34;Sum&#34;: 4220928.0,
            &#34;Unit&#34;: &#34;Bytes&#34;
        }
    ]
}</code></pre></div><p>See the <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/efs/index.html">AWS CLI documentation</a> to learn more about interacting with the <a href="https://awscli.amazonaws.com/v2/documentation/api/latest/reference/cloudwatch/index.html">CloudWatch API</a>. And to find more information on the CloudWatch metrics available in the EFS namespace, see the <a href="https://docs.aws.amazon.com/efs/latest/ug/efs-metrics.html">EFS documentation</a>.</p><h3 id="linux-tools"><a href="#linux-tools">Linux tools</a></h3><p>If your EFS client is a Linux-based EC2 instance (EFS does not support Windows), you can use Linux utilities to collect metrics that describe the file system and the performance of the client. In this section, we’ll show you how to query an instance to see the size of its mounted file systems, as well as per-client metrics that aren’t available in CloudWatch: the <a href="https://www.datadoghq.com/blog/amazon-efs-metrics#latency-metrics">latency</a>, <a href="https://www.datadoghq.com/blog/amazon-efs-metrics#throughput-metrics">throughput</a>, and error rate of its EFS read and write operations.
To execute the commands shown in this section, you can SSH to your instance’s command line or use <a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/execute-remote-commands.html">AWS Systems Manager Run Command</a>. On EKS, you can use <a href="https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html"><code>kubectl</code></a> to execute these commands, and on ECS, you can use <a href="https://aws.amazon.com/blogs/containers/new-using-amazon-ecs-exec-access-your-containers-fargate-ec2/">ECS Exec</a>. And although Lambda doesn’t provide a CLI, we’ll show you an example of how you can query a file system’s size from within a Lambda function.</p><h4 id="determine-the-storage-used-by-a-file-system"><a href="#determine-the-storage-used-by-a-file-system">Determine the storage used by a file system</a></h4><p>AWS calculates and charges for EFS storage based on <a href="https://docs.aws.amazon.com/efs/latest/ug/metered-sizes.html"><strong>metered size</strong></a>—the space required to store your objects and metadata. Knowing the size of your file system can help you spot unexpected changes in the amount of data your application is storing and can even help you estimate your EFS costs. On a Linux host, you can use the <a href="https://en.wikipedia.org/wiki/Df_(Unix)"><code>df</code></a> tool to see the total space used by a mounted file system, which means you can use <code>df</code> to view the metered size of your EFS file systems. It’s important to note, however, that because the data <code>df</code>provides is <a href="https://docs.aws.amazon.com/efs/latest/ug/metered-sizes.html#metered-sizes-fs">eventually consistent</a>, you should not rely on it for real-time data.</p><p>In addition to viewing the aggregate size of your file system, you may also need to track the sizes of individual objects. Log files, for example, accumulate data over time and can influence your overall storage needs. You can use the <a href="https://en.wikipedia.org/wiki/Du_(Unix)"><code>du</code></a> and <code>stat</code> tools to view the size of any single file you’ve stored in EFS. The command below allows you to see the size of the file <strong>myFile</strong> located in the file system mounted at <strong>/mnt/myFileSystem</strong>:</p><div><pre><code data-lang="text">stat /mnt/myFileSystem/myFile</code></pre></div><p>As shown below, <code>stat</code>’s output includes additional information beyond the file’s size, such as the number of blocks used by the file, its inode, its permissions, and the file’s creation and modification history.</p><div><pre><code data-lang="text">  File: ‘/mnt/myFileSystem/myFile’
  Size: 3048448000	Blocks: 5954000    IO Block: 1048576 regular file
Device: 26h/38d	Inode: 16195615950234888882  Links: 1
Access: (0664/-rw-rw-r--)  Uid: ( 1000/ec2-user)   Gid: ( 1000/ec2-user)
Access: 2021-04-27 21:48:50.398000000 +0000
Modify: 2021-04-27 21:48:50.398000000 +0000
Change: 2021-04-27 21:48:50.398000000 +0000</code></pre></div><p>See the <a href="https://docs.aws.amazon.com/efs/latest/ug/metered-sizes.html">AWS documentation</a> for more information about how to view the metered size of both your file system and the individual objects it contains.</p><h4 id="see-the-aggregate-size-of-a-file-system-from-a-lambda-function"><a href="#see-the-aggregate-size-of-a-file-system-from-a-lambda-function">See the aggregate size of a file system from a Lambda function</a></h4><p>If your EFS client is a Lambda function, you don’t have access to a command line, but some Lambda runtimes allow you to include code in your function that can collect storage metrics. For example, Python’s <a href="https://docs.python.org/3/library/index.html">standard library</a> includes a <a href="https://docs.python.org/3/library/shutil.html"><code>shutil</code></a> package that you can use to check the size of a file system. The following function uses the <code>disk_usage</code> method to check the disk space used by the file system mounted at <strong>/mnt/myFileSystem</strong>:</p><div><pre><code data-lang="text">import shutil

def lambda_handler(event, context):
    return {
        &#39;output&#39;: shutil.disk_usage(&#34;/mnt/myFileSystem&#34;)
    }</code></pre></div><p>This function returns a JSON object like the one shown below. In our case, it shows that the file system is using slightly less than 3,600 MB of storage space.</p><div><pre><code data-lang="text">{
  &#34;output&#34;: {
    &#34;total&#34;: 9223372036853727000,
    &#34;used&#34;: 3598712832,
    &#34;free&#34;: 9223372033255014000
  }
}</code></pre></div><h4 id="measure-efs-performance-with-nfsiostat"><a href="#measure-efs-performance-with-nfsiostat">Measure EFS performance with <code>nfsiostat</code></a></h4><p>To attach your EC2 instance to EFS, AWS recommends that you install the <a href="https://github.com/aws/efs-utils"><code>amazon-efs-utils</code></a> package, which includes an NFS client. This means you can use the <code>nfsiostat</code> utility to view some of the key metrics covered in <a href="https://www.datadoghq.com/blog/amazon-efs-metrics">Part 1</a> of this series, including throughput (<code>kB/s</code>) and latency (<code>avg RTT</code>). For example, to see metrics from the file system mounted at <strong>/mnt/myFileSystem</strong>, you can use this command:</p><div><pre><code data-lang="text">nfsiostat /mnt/myFileSystem</code></pre></div><p>The output, shown below, details the client’s read and write activity since the file system was mounted or since <code>nfsiostat</code> was last executed.</p><div><pre><code data-lang="text">   op/s		rpc bklog
   2.81	   	0.00
read:	ops/s	kB/s	 	kB/op		retrans	avg RTT (ms)	avg exe (ms)
0.000	0.000	 	0.000		0 (0.0%)	0.000		0.000
write:	ops/s	kB/s	 	kB/op		retrans	avg RTT (ms)	avg exe (ms)
2.266	2284.646	1008.283	0 (0.0%)	129.606	356.155</code></pre></div><h2 id="collect-efs-logs"><a href="#collect-efs-logs">Collect EFS logs</a></h2><p>To gain even deeper insight into the performance of your file systems, you can collect logs from your EFS clients. Logs reveal details of each client’s activity—such as when a given client mounted an EFS file system and how much data it sent to the mount target—that can be useful when you need to analyze and troubleshoot EFS performance. In this section, we’ll show you how you can collect and view EFS logs using AWS services and Linux tools.</p><h3 id="aws-logging-services"><a href="#aws-logging-services">AWS logging services</a></h3><p>AWS provides logging services that allow you to gather EFS logs from <a href="#mount-helper-logs">EC2 instances</a>, as well as <a href="#vpc-flow-logs">network logs</a> that show connection activity to your EFS mount targets. You can analyze and alert on these logs using Amazon <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html">CloudWatch Logs</a> and query them with <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html">CloudWatch Logs Insights</a>.</p><h4 id="mount-helper-logs"><a href="#mount-helper-logs">Mount helper logs</a></h4><p>The <a href="https://github.com/aws/efs-utils">EFS client software</a> includes a <a href="https://docs.aws.amazon.com/efs/latest/ug/efs-mount-helper.html">mount helper</a> tool which allows you to collect <a href="https://docs.aws.amazon.com/efs/latest/ug/efs-mount-helper.html#mount-helper-logs">logs</a> from your EC2 instances and forward them to <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/WhatIsCloudWatchLogs.html">CloudWatch Logs</a>. To collect logs from an instance, <a href="https://github.com/aws/efs-utils#step-1-install-botocore">install botocore</a>—the foundation of the <a href="https://aws.amazon.com/sdk-for-python/">AWS SDK for Python</a>—onto the instance, attach the necessary <a href="https://github.com/aws/efs-utils#step-3-attach-the-cloudwatch-logs-policy-to-the-iam-role-attached-to-instance">IAM policy</a> to the instance’s role, and then install the <a href="https://docs.aws.amazon.com/efs/latest/ug/using-amazon-efs-utils.html">EFS client software</a>.</p><p>Logging is disabled by default, so you need to <a href="https://github.com/aws/efs-utils#step-2-enable-cloudwatch-log-feature-in-efs-utils-config-file-etcamazonefsefs-utilsconf">update</a> the client’s configuration file (<a href="https://github.com/aws/efs-utils/blob/master/dist/efs-utils.conf"><strong>/etc/amazon/efs/efs-utils.conf</strong></a>) to enable logging and configure the helper to forward logs to CloudWatch Logs. The <strong>efs-utils.conf</strong> excerpt shown below sets <code>enabled = true</code> in the <code>[cloudwatch-log]</code> section of the configuration file. As a result, this instance will automatically forward its mount helper logs to the CloudWatch Logs group named <code>/aws/my-efs-mount-helper-logs</code>.</p><div><p>efs-utils.conf</p><div><pre><code data-lang="text">[cloudwatch-log]
enabled = true
log_group_name = /aws/my-efs-mount-helper-logs</code></pre></div></div><p>Once you’ve aggregated your mount helper logs in CloudWatch Logs, you can explore the status and history of mount activity across all of the EC2 instances that connect to your file system. You can also use CloudWatch Logs Insights to search and filter your logs, which can reveal patterns and trends in EFS performance and client activity. For example, the CloudWatch Logs Insights query in the screenshot below searches the <code>/aws/my-efs-mount-helper-logs</code> logs group and displays the timestamp, message, and log stream identifier fields from the 20 most recent logs across all of the streams in the group. The timeseries graph above the results visualizes the rate at which the logs occur.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-cloudwatch-logs.png?auto=format&amp;fit=max&amp;w=847" alt="A CloudWatch Logs Insights query searches across all logs streams in the log group and returns three records, each from different log streams."/></picture></figure></div><h4 id="vpc-flow-logs"><a href="#vpc-flow-logs">VPC Flow Logs</a></h4><p><a href="https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.html">VPC Flow Logs</a> allow you to monitor traffic on the network interfaces your AWS resources use. The clients connected to an EFS file system interact with it by sending requests to port 2049 on the <a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-eni.html">Elastic Network Interface (ENI)</a> of one of its <a href="https://www.datadoghq.com/blog/amazon-efs-metrics#an-overview-of-efs">mount targets</a>. By capturing these requests in a flow log, you can aggregate network activity from multiple clients in a single log, which you can then <a href="https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs-cwl.html">publish to Cloudwatch Logs</a>. This allows you to see, for example, the IP addresses of all the <a href="https://aws.amazon.com/premiumsupport/knowledge-center/list-instances-connected-to-efs/">clients that have connected</a> to your file system. You can also <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html">filter</a> your results based on the values contained in fields you identify. For example, the screenshot below illustrates a CloudWatch Logs Insights query that finds flow logs showing data transfers greater than 102,400 bytes to and from the file system’s mount targets.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-tools/efs-flow-logs.png?auto=format&amp;fit=max&amp;w=847" alt="A CloudWatch Logs Insights query shows logs from all logs streams in the log group where the bytes field is greater than 102.4 kilobytes."/></picture></figure></div><p>See <a href="https://aws.amazon.com/premiumsupport/knowledge-center/list-instances-connected-to-efs/">the AWS documentation</a> for more examples about collecting and querying VPC Flow Logs in CloudWatch Logs.</p><h3 id="non-aws-logging-tools"><a href="#non-aws-logging-tools">Non-AWS logging tools</a></h3><p>If your EFS clients are running on EC2 instances, including EC2-backed EKS or ECS clusters, their log activity can reveal important details about changes within the file systems they mount. In this section, we’ll show you Linux utilities you can use to log the activity of clients making changes to the EFS file system.
The <a href="https://aws.amazon.com/premiumsupport/knowledge-center/ec2-monitor-file-system-changes#Short_description">Linux auditing system</a> provides tools that allow you to monitor your Linux hosts for changes that could indicate security concerns. Linux security is a topic that extends beyond file system monitoring, but you can use these tools to <a href="https://aws.amazon.com/premiumsupport/knowledge-center/ec2-monitor-file-system-changes/">increase your visibility into EFS</a> by logging file creation, deletion, modification, and access.
<code>auditd</code> is the process that monitors and logs activity on the host, and <code>auditctl</code> is the program you use to configure <code>auditd</code>. To log changes to your file system, you create rules that tell <code>auditd</code> which directories to monitor and which activities to watch for. When a change takes place in the file system that aligns with a rule you’ve defined—for example, when a client writes to a file that’s being monitored—<code>auditd</code> will create a new log in <strong>/var/log/audit/audit.log</strong>.</p><p>You can then use two complementary utilities—<code>ausearch</code> to filter the log contents and <code>aureport</code> to format the output—to view the contents of <strong>audit.log</strong> and see the activity on the file system. The command below searches for logs created by the <code>mykeyname</code> rule. It includes the <code>-i</code> flag to interpret the <a href="https://man7.org/linux/man-pages/man8/aureport.8.html">output</a> and the <code>-f</code> flag to return log entries related to file activity.</p><div><pre><code data-lang="text">sudo ausearch -k mykeyname | aureport -f -i


File Report
===============================================
# date time file syscall success exe auid event
===============================================
1. 04/16/2021 16:50:27 /mnt/myFileSystem/myFile openat yes /usr/bin/bash ec2-user 124
2. 04/16/2021 16:50:43 /mnt/myFileSystem/myOtherFile openat yes /usr/bin/bash ec2-user 125</code></pre></div><p>You can also use the <code>rpcdebug</code> tool to log an instance’s interactions with an EFS file system, which includes creating, modifying, reading, and executing files. For example, if your application creates and writes to a file named <strong>myNewFile</strong> in the root directory of an EFS file system, <code>rpcdebug</code> will add the following messages to the instance’s system log:</p><div><pre><code data-lang="text">Apr  5 22:17:06 ip-172-31-46-92 kernel: NFS: open file(/myNewFile)
Apr  5 22:17:06 ip-172-31-46-92 kernel: NFS: flush(/myNewFile)
Apr  5 22:17:06 ip-172-31-46-92 kernel: NFS: fsync file(/myNewFile) datasync 0
Apr  5 22:17:06 ip-172-31-46-92 kernel: NFS: write(/myNewFile, 5@0)
Apr  5 22:17:06 ip-172-31-46-92 kernel: NFS: flush(/myNewFile)
Apr  5 22:17:06 ip-172-31-46-92 kernel: NFS: fsync file(/myNewFile) datasync 0
Apr  5 22:17:06 ip-172-31-46-92 kernel: NFS: release(/myNewFile)
Apr  5 22:18:31 ip-172-31-46-92 dhclient[2818]: XMT: Solicit on eth0, interval 121000ms.</code></pre></div><h2 id="monitor-efs-and-your-whole-stack"><a href="#monitor-efs-and-your-whole-stack">Monitor EFS and your whole stack</a></h2><p>In this post, we’ve looked at how you can collect and alert on EFS metrics and logs using AWS and Linux tools. In <a href="https://www.datadoghq.com/blog/amazon-efs-monitoring-datadog">Part 3</a> of this series, we’ll show you how Datadog enables you to visualize and analyze this data alongside telemetry from more than 450 other technologies, so you can gain full visibility into your EFS file systems and the applications they support.</p><h2 id="acknowledgments"><a href="#acknowledgments">Acknowledgments</a></h2><p>We’d like to thank Ray Zaman at AWS for their technical review of this post.</p><p><em>Source Markdown for this post is available <a href="https://github.com/DataDog/the-monitor/blob/master/efs/amazon-efs-monitoring-tools.md">on GitHub</a>. Questions, corrections, additions, etc.? Please <a href="https://github.com/DataDog/the-monitor/issues">let us know</a></em></p></div></div>]]></content:encoded>
      <author>David M. Lentz</author>
      <pubDate>Thu, 05 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>EFS Monitoring with Datadog</title>
      <link>https://www.datadoghq.com/blog/amazon-efs-monitoring-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/amazon_efs_longform_part-3v2.png&#34; width=&#34;100%&#34;/&gt;In Part 1 of this series, we looked at the key EFS metrics you should monitor, and in Part 2 we showed you how you can use tools from AWS and Linux to collect and alert on EFS metrics and logs. Monitoring EFS in isolation, however, can lead to visibility gaps as you try to understand the full context of your application&amp;rsquo;s health and performance. To meet the challenge of monitoring this dynamic storage system and its heterogeneous clients, you need to explore and alert on metrics and logs from EFS alongside data from your clients, related AWS services, and other key technologies.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>In <a href="https://www.datadoghq.com/blog/amazon-efs-metrics">Part 1</a> of this series, we looked at the key EFS metrics you should monitor, and in <a href="https://www.datadoghq.com/blog/amazon-efs-monitoring-tools">Part 2</a> we showed you how you can use tools from AWS and Linux to collect and alert on EFS metrics and logs. Monitoring EFS in isolation, however, can lead to visibility gaps as you try to understand the full context of your application’s health and performance. To meet the challenge of monitoring this dynamic storage system and its heterogeneous clients, you need to explore and alert on metrics and logs from EFS alongside data from your clients, related AWS services, and other key technologies.</p><p>Datadog provides complete EFS visibility, allowing you to monitor the size of your file systems and the behavior of the many different clients—EC2 instances, EKS pods, Lambda functions, and more—that access your data. In this post, we’ll show you how to:</p><ul><li><a href="#integrate-efs-with-datadog">Integrate EFS with Datadog</a></li><li><a href="#bring-on-the-metrics">Visualize EFS metrics</a></li><li><a href="#alert-on-efs-activity-and-performance">Alert on EFS activity and performance</a></li><li><a href="#collect-efs-logs">Collect EFS logs</a></li></ul><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-dashboard.png?auto=format&amp;fit=max&amp;w=847" alt="The out-of-the-box EFS dashboard shows metrics that describe I/O, operation size, and configuration of multiple EFS file systems."/></picture></figure></div><h2 id="integrate-efs-with-datadog"><a href="#integrate-efs-with-datadog">Integrate EFS with Datadog</a></h2><p>Datadog’s AWS integration gives you deep visibility into EFS and the other AWS services you’re using, all in a single platform. In this section, we’ll show you how to add EFS to your AWS monitoring—or how to enable the AWS integration if you’re just getting started—so you can visualize, analyze, and alert on the performance of the AWS services you rely on.</p><h3 id="add-efs-to-your-aws-monitoring"><a href="#add-efs-to-your-aws-monitoring">Add EFS to your AWS monitoring</a></h3><p>If you’re already monitoring some AWS services, you can add EFS to the mix by clicking the <strong>Configuration</strong> tab on the <a href="https://app.datadoghq.com/account/settings#integrations/amazon-web-services">AWS Integration tile</a>. Check the “EFS” box under the “Limit metric collection by AWS Service” list, as well as the boxes for any other AWS services you want to add to your monitoring. If you’re using Lambda with EFS, check the “Lambda” box and follow the steps for <a href="https://docs.datadoghq.com/integrations/amazon_efs/#amazon-efs-for-lambda">enabling EFS for Lambda</a>.</p><p>Once you’ve checked the boxes for all the AWS services you want to monitor, click the “Update Configuration” button. Metrics will begin flowing into your Datadog account within a few minutes so you can quickly get started using EFS <a href="#bring-on-the-metrics">dashboards, tags, and alerts</a>.</p><h3 id="start-monitoring-efs-and-other-aws-services"><a href="#start-monitoring-efs-and-other-aws-services">Start monitoring EFS and other AWS services</a></h3><p>If you’re not yet monitoring AWS services with Datadog, you can start by installing the AWS integration with our <a href="https://www.datadoghq.com/blog/aws-1-click-integration/">1-click installation</a> process. The 1-click process is based on CloudFormation, and you’ll need to create an IAM role and an associated policy. Once you’ve completed the installation steps described in our <a href="https://www.datadoghq.com/blog/aws-1-click-integration/#click-here">blog post</a>, Datadog will begin automatically <a href="#bring-on-the-metrics">collecting EFS metrics</a>, as well as metrics from the other AWS services in your stack.</p><h2 id="bring-on-the-metrics"><a href="#bring-on-the-metrics">Bring on the metrics</a></h2><p>The <a href="https://app.datadoghq.com/screen/integration/30330/aws-efs">built-in EFS dashboard</a>—shown in the screenshot at the beginning of this post—brings together I/O metrics, throughput metrics, and burst credit balance data for all of the file systems in your account, so you can understand each file system’s health and performance at a glance.</p><p>You can easily <a href="https://docs.datadoghq.com/getting_started/dashboards/#start-by-reusing-other-dashboards">customize the dashboard</a> to graph EFS metrics alongside metrics from other AWS services. For example, <a href="https://docs.datadoghq.com/agent/amazon_ecs/?tab=awscli">Amazon ECS</a> Auto Scaling metrics could explain changes in the number of clients connecting to your file system and <a href="https://docs.datadoghq.com/integrations/amazon_sqs/">Amazon SQS</a> metrics might reveal a backlog of work your clients need to process. And you can add even more context to your EFS metrics by correlating them with data from any of Datadog’s more than
450 other integrations.</p><p>You can also leverage Datadog’s tagging system to organize, filter, and explore specific subsets of your data, such as the performance of an individual file system or even a specific client. Datadog automatically tags your EFS metrics to show the AWS account, file system, and region where they came from, and you can also add custom tags (for example, to identify the application for which a file system provides storage) from within the EFS console or by including them in a <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/quickref-efs.html">CloudFormation template</a>.</p><p>You can even <a href="https://docs.datadoghq.com/getting_started/tagging/">create common tags</a> across your metrics, logs, and traces so you can correlate them to understand the context of what you see on your dashboards. For example, if EFS metrics show that a file system’s burst credits are exhausted, you can seamlessly navigate to APM to see if any of your application’s services shows a corresponding increase in latency.</p><h2 id="alert-on-efs-activity-and-performance"><a href="#alert-on-efs-activity-and-performance">Alert on EFS activity and performance</a></h2><p>Dashboards let you visualize real-time metrics, but you can also create alerts to automatically notify you if the value of a metric crosses a threshold that could affect your file systems&#39; performance and your EFS costs.</p><p>For example, you may want to be notified if your file system is running out of <a href="https://www.datadoghq.com/blog/amazon-efs-metrics#metric-to-alert-on-i-o-utilization">IOPS</a> (by creating an alert on the <code>aws.efs.percent_iolimit</code> metric) or <a href="https://www.datadoghq.com/blog/amazon-efs-metrics#metric-to-alert-on-burst-credit-balance">burst credits</a> (<code>aws.efs.burst_credit_balance</code>) so you can proactively address an issue before it causes your application to slow down. And if you want to watch your file system for changes that could indicate cost anomalies or security concerns, you can create alerts to notify you of any unusual changes in metrics like <code>aws.efs.data_write_iobytes*</code> or <code>aws.efs.storage_bytes</code>, as shown in the screenshot below.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-alert.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog&#39;s New Monitor screen defines an alert with a warning threshold of 180 GB and an alert threshold of 200 GB."/></picture></figure></div><p>An alert based on a threshold can keep you informed of unexpected changes in your metrics, but it can be hard to determine the value you should use for the threshold. <a href="https://docs.datadoghq.com/monitors/monitor_types/anomaly/">Anomaly-based monitors</a> can notify you automatically of changes that are out of line with a metric’s history so you don’t have to choose a threshold value to define what’s normal and expected. For example, the number of <a href="https://www.datadoghq.com/blog/amazon-efs-metrics#metric-to-alert-on-client-connections">clients connected</a> to your file system may be dynamic, but if it drops due to a configuration error that prevents new instances from connecting, an anomaly monitor can notify you of the unexpected change. In the screenshot below, the recent history of the <code>aws.efs.client_connections</code> metric appears on the left, and the expected future values of this metric appear in the gray band in the graph on the right.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-datadog-anomaly-monitor.png?auto=format&amp;fit=max&amp;w=847" alt="The New Monitor screen for an Anomaly Monitor shows the history and the expected range of values of the connected clients metric."/></picture></figure></div><h2 id="collect-efs-logs"><a href="#collect-efs-logs">Collect EFS logs</a></h2><p>In Part 2 of this series, we showed you how you can publish <a href="https://www.datadoghq.com/blog/amazon-efs-monitoring-tools#mount-helper-logs">mount helper logs</a> and <a href="https://www.datadoghq.com/blog/amazon-efs-monitoring-tools#vpc-flow-logs">flow logs</a> to CloudWatch. In this section, we’ll show you how to forward those logs from CloudWatch to Datadog so you can explore and correlate them with logs from other technologies in your stack.</p><h3 id="enable-log-collection"><a href="#enable-log-collection">Enable log collection</a></h3><p>Once you’re sending your EFS logs to CloudWatch Logs, you can <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination/">route them to Datadog</a> by way of a <a href="https://docs.aws.amazon.com/firehose/latest/dev/what-is-this-service.html">Kinesis Data Firehose delivery stream</a>. Sending logs from EFS—and other AWS services—through Kinesis allows you to leverage AWS’s managed service for streaming logs and frees you from the challenges of managing concurrency and throttling that come with deploying your own <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-lambda-function/">Lambda forwarder</a>.</p><p>If you’re already collecting AWS service logs into a delivery stream in Firehose, you can add your EFS logs to the same stream. They’ll be delivered to Datadog alongside your other logs, but they’ll be distinguished by <code>service</code> and <code>source</code> values that show the name of the <a href="https://www.datadoghq.com/blog/amazon-efs-monitoring-tools#mount-helper-logs">CloudWatch log</a> group you configured to collect them.</p><p>If you’re not yet collecting AWS service logs through Firehose, create a delivery stream and <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination">configure Datadog as the destination</a>. Then, <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination/?tab=kinesisfirehosedeliverystream#send-aws-logs-to-your-kinesis-stream">add a subscription filter</a> to the CloudWatch log group where you’re collecting your EFS logs and set your Kinesis Data Firehose delivery stream as the filter’s destination. See the <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination/">documentation</a> for more information about sending AWS service logs into Datadog via Kinesis.</p><h3 id="explore-and-analyze-your-logs"><a href="#explore-and-analyze-your-logs">Explore and analyze your logs</a></h3><p>Datadog brings together logs from AWS services—including EFS—and many other technologies into a single platform, where you can explore and analyze them with the help of tags. Just as with <a href="#bring-on-the-metrics">metrics</a>, Datadog automatically tags your EFS logs to show the AWS account, region, and file system where they originated, and you can apply custom tags by adding parameters when you configure Datadog as the <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination">destination</a> for your delivery stream.</p><p>You can also add <a href="https://docs.datadoghq.com/logs/explorer/facets/">facets</a> to your tags to make it easy to group logs from related sources and present a fuller picture of activity across your stack. For example, if you apply an <code>application</code> tag to identify EFS logs originating from a specific application, you can apply the same tag to logs from your clients and related AWS services (e.g., an ELB that distributes incoming requests to your EC2 fleet). Then, you can <a href="https://docs.datadoghq.com/logs/explorer/facets/#create-facets">create a facet</a> based on that tag to group logs from all layers of your application.</p><p>In the screenshot below, we’ve created a facet on the <code>datadog_app</code> tag to isolate logs from a single application, and we’ve grouped them by <code>region</code> to show relative amounts of EFS traffic by geography. We’ve also filtered the logs using a <a href="https://docs.datadoghq.com/logs/explorer/facets/#quantitative-facets">measure</a>—a type of facet based on the value of a log field—to reveal logs that represent a large amount of write activity.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-efs-monitoring-datadog/efs-logs-filtered-by-application.png?auto=format&amp;fit=max&amp;w=847" alt="An area graph shows the rate of bytes written by EFS clients in each AWS region."/></picture></figure></div><h2 id="gain-full-visibility-into-efs-with-datadog"><a href="#gain-full-visibility-into-efs-with-datadog">Gain full visibility into EFS with Datadog</a></h2><p>EFS can serve a key role in your application, supporting simultaneous access across numerous clients, including <a href="https://docs.datadoghq.com/integrations/amazon_ec2/">EC2</a> instances, <a href="https://docs.datadoghq.com/integrations/amazon_lambda/">Lambda</a> functions, and <a href="https://www.datadoghq.com/blog/amazon-ecs-metrics/">Amazon Elastic Container Service (ECS)</a> tasks. Datadog gives you full visibility into each of these services, in addition to more than
450 other technologies, so you can monitor the health and performance of your file systems in context. If you’re not already using Datadog, start today with a <a href="#">14-day free trial</a>.</p><p><em>Source Markdown for this post is available <a href="https://github.com/DataDog/the-monitor/blob/master/efs/amazon-efs-monitoring-datadog.md">on GitHub</a>. Questions, corrections, additions, etc.? Please <a href="https://github.com/DataDog/the-monitor/issues">let us know</a></em></p></div></div>]]></content:encoded>
      <author>David M. Lentz</author>
      <pubDate>Thu, 05 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Datadog Launches Cloud Security Platform to Provide Security Teams with Unprecedented Observability Capabilities</title>
      <link>https://www.datadoghq.com/about/latest-news/press-releases/datadog-launches-cloud-security-platform-to-provide-security-teams-with-unprecedented-observability-capabilities/</link>
      <description>NEW YORK &amp;ndash; Datadog, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced the launch of the Datadog Cloud Security Platform, adding full-stack security context to Datadog’s deep observability capabilities. This new offering enables organizations to use a single platform to correlate security insights with monitoring data across infrastructure, network and application tiers, providing Security teams with the visibility they need to understand and respond to potential threats faster.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><strong>NEW YORK</strong> – <a href="https://www.datadoghq.com/">Datadog</a>, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced the launch of the Datadog Cloud Security Platform, adding full-stack security context to Datadog’s deep observability capabilities. This new offering enables organizations to use a single platform to correlate security insights with monitoring data across infrastructure, network and application tiers, providing Security teams with the visibility they need to understand and respond to potential threats faster. </p><p>In recent years, security attacks have increasingly focused on the application level, prompting DevOps and Security teams to work more closely together to “shift left” and infuse security into the full software development life cycle. Traditionally, this has been difficult because of siloed tools and processes, which has been further exacerbated as organizations move to the cloud and security teams are left with even less visibility.</p><p>Datadog’s Cloud Security Platform addresses these challenges by enabling DevOps and Security teams to access a shared source of truth supported by a common data model. With Datadog, in parallel to detecting potential threats, Security leaders now have access to the underlying infrastructure, network and application data at the time of an attack, meaning they have deeper insights that enable more accurate threat detection and accelerated incident response. And, unlike point solutions, Datadog’s platform approach ensures that this data is automatically correlated and presented in context, without requiring manual analysis.</p><p>“As organizations embark on their digital transformation journey, unifying once disparate security, compliance and engineering practices has become a key requirement to deliver best-in-class customer experiences,” said Amit Agarwal, Chief Product Officer, Datadog. “Built for cloud scale, the Datadog Cloud Security Platform supports organizations in adopting a modern DevSecOps practice that will enable a more holistic and, ultimately, a more robust approach to security, without increasing the operational burden of deploying and maintaining multiple, disconnected point solutions.”</p><p>“With Lemonade’s growth, cloud security has become a primary focus,” said Jonathan Jaffe, Chief Information Security Officer, Lemonade. “Within the first week of an easy integration, Datadog’s security offerings helped my team manage potential threats faster, with less effort, and with higher fidelity and accuracy. What’s more, collaboration with our DevOps colleagues became easier and has helped tie security to the business. We have many security tools and services; Datadog Cloud Security Platform has become one of our top-three tools. We see it supporting our current and future growth with security, and in lockstep with DevOps.” </p><p>Forrester’s State of Application Security report notes that “Applications remain a top cause of external breaches, and the prevalence of open source, API, and containers only adds complexity to the security team. Happily, organizations have started to recognize the importance of application security and are embedding security more tightly into the development phase.” </p><p>The Datadog Cloud Security Platform includes:</p><ul><li>Cloud Security Posture Management (CSPM) makes it easy to track whether your production environment complies with industry standards, such as PCI DSS, SOC 2 and HIPAA, and catches misconfigurations that leave your organization vulnerable to potential attacks.</li><li>Cloud Workload Security (CWS) detects threats to your production workloads by monitoring file and process activity across your environments to help catch host and infrastructure-based attacks.</li><li>Security Monitoring identifies threats to your cloud environments by analyzing operational and security logs. As an easy-to-use cloud-native SIEM, Security Monitoring provides out-of-the-box security integrations and threat detection rules that are easy to extend and customize.</li><li>Application Security, currently in beta, provides protection against application-level threats by identifying and blocking attacks that target code-level vulnerabilities, such as SQL injections and cross-site scripting (XSS) exploits.</li><li>Unified Observability and Security Reporting allows seamless pivots between DevOps telemetry and security insights. This unified experience enables Security teams to understand the operational and business impact of security incidents, and DevOps teams to see security signals alongside the metrics, traces and logs of their services.</li></ul><p><br/>For more information and to get started with the Datadog Cloud Security Platform, please visit <a href="https://www.datadoghq.com/product/security-platform/">https://www.datadoghq.com/product/security-platform/</a>. </p><p>Datadog will be at Black Hat’s USA Summit—both in person and virtually. To listen in on our session, With Friends Like eBPF, Who Needs Enemies? please visit <a href="https://www.blackhat.com/us-21/briefings/schedule/index.html#with-friends-like-ebpf-who-needs-enemies-23619">Black Hat speaker sessions</a>. </p><div><p><strong>About Datadog</strong></p><p>Datadog is the monitoring and security platform for cloud applications. Our SaaS platform integrates and automates infrastructure monitoring, application performance monitoring and log management to provide unified, real-time observability of our customers’ entire technology stack. Datadog is used by organizations of all sizes and across a wide range of industries to enable digital transformation and cloud migration, drive collaboration among development, operations, security and business teams, accelerate time to market for applications, reduce time to problem resolution, secure applications and infrastructure, understand user behavior and track key business metrics.</p></div><p><strong>Forward-Looking Statements</strong> </p><p>This press release may include certain “forward-looking statements” within the meaning of Section 27A of the Securities Act of 1933, as amended, or the Securities Act, and Section 21E of the Securities Exchange Act of 1934, as amended. These forward-looking statements reflect our current views about our plans, intentions, expectations, strategies and prospects, which are based on the information currently available to us and on assumptions we have made. Actual results may differ materially from those described in the forward-looking statements and are subject to a variety of assumptions, uncertainties, risks and factors that are beyond our control, including those risks detailed under the caption “Risk Factors” and elsewhere in our Securities and Exchange Commission filings and reports, including the Quarterly Report on Form 10-Q filed with the Securities and Exchange Commission on May 7, 2021, as well as future filings and reports by us. Except as required by law, we undertake no duty or obligation to update any forward-looking statements contained in this release as a result of new information, future events, changes in expectations or otherwise.</p></div></div>]]></content:encoded>
      <author>Datadog</author>
      <pubDate>Wed, 04 Aug 2021 20:30:44 +0000</pubDate>
    </item>
    <item>
      <title>Best practices for monitoring a cloud migration</title>
      <link>https://www.datadoghq.com/blog/cloud-migration-monitoring/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration_monitoring_210628_FINAL.png&#34; width=&#34;100%&#34;/&gt;When you migrate workloads from on-premise infrastructure into a public cloud, you can improve the performance, reliability, and security of your application, and you might also lower your costs. To execute a successful cloud migration, you need a detailed inventory of your current deployments, visibility into your application&amp;rsquo;s performance as you shift traffic to the cloud, and confirmation that—once you&amp;rsquo;ve landed in the cloud—you&amp;rsquo;re still providing a high-quality user experience.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>When you migrate workloads from on-premise infrastructure into a public cloud, you can improve the performance, reliability, and security of your application, and you might also lower your costs. To execute a successful cloud migration, you need a detailed inventory of your current deployments, visibility into your application’s performance as you shift traffic to the cloud, and confirmation that—once you’ve landed in the cloud—you’re still providing a high-quality user experience.</p><p>In this post, we’ll explore best practices for monitoring your cloud migration and show you how Datadog can give you visibility throughout every phase. We’ll show you how to:</p><ul><li><a href="#take-inventory-to-plan-your-migration">Plan what cloud resources you need</a></li><li><a href="#prepare-create-and-test-your-new-environment">Build visibility into your cloud environment</a></li><li><a href="#cut-over-and-watch-your-cloud-migration-metrics">Monitor your newly migrated application</a></li></ul><h2 id="take-inventory-to-plan-your-migration"><a href="#take-inventory-to-plan-your-migration">Take inventory to plan your migration</a></h2><p>In order to plan a cloud environment that’s capable of supporting your applications, you’ll need a deep understanding of your current environment. In this section, we’ll show you how Datadog can help you plan your migration by understanding the topology and resource requirements of your application in its current state.</p><h3 id="map-your-application-and-infrastructure"><a href="#map-your-application-and-infrastructure">Map your application and infrastructure</a></h3><p>The <a href="https://www.datadoghq.com/blog/service-map/">Service Map</a> helps you gain a complete understanding of your services, their dependencies, and the rate of requests between them. In the screenshot below, the Service Map highlights the <code>web-store</code> service and shows its request, latency, and error rates as well as its request traffic to and from other services. From here, you can click any service to drill down to view request data gathered by <a href="https://www.datadoghq.com/knowledge-center/distributed-tracing/">Application Performance Monitoring (APM) and distributed tracing</a>.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-service-map.png?auto=format&amp;fit=max&amp;w=847" alt="The Service Map shows the request, latency, and error rate of the web store service, and maps its requests to and from other services."/></picture></figure></div><p>The <a href="https://www.datadoghq.com/blog/introducing-host-maps-know-thy-infrastructure/">host map</a> visualizes your current environment and uses colors to represent the real-time value of a metric your hosts are reporting. You can use metadata from your hosts to aggregate, explore, and better understand your infrastructure. The screenshot below shows hosts grouped by environment and color coded to show hosts with high CPU usage in red and low CPU usage in green.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/migration-monitoring-host-map.png?auto=format&amp;fit=max&amp;w=847" alt="The Host map shows hosts grouped by availability zone and uses red to indicate a host with high CPU usage and green to show low CPU usage."/></picture></figure></div><p>The host map can reveal resource-utilization hotspots that help you decide the number, size, and type of the VMs you launch in the cloud. You can click any node on the map to see a dashboard that shows you detailed resource usage patterns. This data can help you understand your infrastructure needs and <a href="https://aws.amazon.com/aws-cost-management/aws-cost-optimization/right-sizing/">right-size</a> your new cloud infrastructure. For example, if the host map shows you that a specific application is running on a large number of underutilized instances, you may be able to save money by migrating it to fewer cloud instances. You could also choose a less expensive instance type, such as one that features fewer CPU cores or provides general-purpose capabilities rather than a compute-optimized instance.</p><h3 id="analyze-your-network"><a href="#analyze-your-network">Analyze your network</a></h3><p>To ensure that your new cloud environment can accommodate the volume and type of network traffic your application generates, you’ll need to take a close look at the behavior of your current network. <a href="https://www.datadoghq.com/blog/network-performance-monitoring/">Datadog Network Performance Monitoring (NPM)</a> gives you visibility into the traffic within and between your on-premise data centers, so you can design the <a href="https://en.wikipedia.org/wiki/Virtual_private_cloud">VPCs</a>, <a href="https://en.wikipedia.org/wiki/Subnetwork">subnets</a>, and other network constructs in your cloud environment to support your application’s traffic.</p><p>The <a href="https://docs.datadoghq.com/network_monitoring/performance/network_map/">Network Map</a> visualizes the traffic between the hosts, pods, containers, and other components of your environment. This can help you spot bottlenecks as you migrate—and provision appropriate cloud network resources to resolve them. The screenshot below shows a Network Map of a testing-related application that generates a small amount of traffic. An application like this could be a preferred, lower-risk candidate for migrating first, ahead of higher-traffic applications.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/network-map.png?auto=format&amp;fit=max&amp;w=847" alt="The network map shows an application called test comprised of only two services."/></picture></figure></div><p><a href="https://www.datadoghq.com/blog/cloud-service-autodetection-datadog/">In the cloud</a>, your network can dynamically scale to include new hosts, subnets, and VPCs. As these cloud resources come and go, you can continue to rely on the Network Map and <a href="https://docs.datadoghq.com/network_monitoring/performance/network_page/">Network Overview</a> to track network flows within your cloud environment. You can sort your NPM data by geography to identify traffic between regions or availability zones. Using this information, you may be able to revise your network traffic flows so you can minimize latency and transit costs in the cloud.</p><h3 id="understand-your-storage"><a href="#understand-your-storage">Understand your storage</a></h3><p>As you plan to provide storage for your application in the cloud (e.g., managed databases, file storage, and object storage), you should have a detailed inventory of the types and amounts of storage required. Our <a href="https://docs.datadoghq.com/integrations/#cat-data-store">data store integrations</a> provide out-of-the-box dashboards that visualize usage metrics like:</p><ul><li><code>postgresql.total_size</code>: the total disk space used by a PostgreSQL table, in bytes</li><li><code>ibm_db2.tablespace.size</code>: the total disk space used by an IBM DB2 table, in bytes</li><li><code>sap_hana.disk.used</code>: the total disk space used by SAP HANA to persist data, in bytes</li></ul><p>And to estimate your future storage costs, you can apply a <a href="https://docs.datadoghq.com/dashboards/functions/algorithms/#forecast">forecast function</a> when you graph these metrics to see where your data storage needs are headed.</p><h2 id="prepare-create-and-test-your-new-environment"><a href="#prepare-create-and-test-your-new-environment">Prepare, create, and test your new environment</a></h2><p>Once you’ve identified the resources to include in your cloud environment, you should make plans to ensure that you’ll have the visibility you need. In this section, we’ll describe steps you can take to leverage monitoring throughout the process of creating your cloud environment. We’ll look at three phases of moving an application to the cloud: preparation, setup, and validation.</p><h3 id="prepare-your-slos-and-dashboards"><a href="#prepare-your-slos-and-dashboards">Prepare your SLOs and dashboards</a></h3><p>You should expect the cloud-based version of your application to be at least as reliable as the on-premise version, so you can continue to use the same <a href="https://www.datadoghq.com/blog/slo-monitoring-tracking/">service level objectives (SLOs)</a>—performance and reliability targets for the services you operate—across the old and new versions. But you may need to adjust what you measure—your service level indicators (SLIs)—to include performance metrics from your newly migrated workloads.</p><p>For example, let’s say you’re planning to move a Redis cache to the managed version that AWS provides—Amazon ElastiCache for Redis—and you’ve created an SLO to ensure that your cache hit rate stays above 90 percent over each seven-day period. You may need to operate that cache temporarily as a hybrid while you transition to the cloud. During this hybrid phase, your SLOs should be based on a combination of SLIs from both the legacy infrastructure (on-premise Redis) and the target infrastructure (ElastiCache). In this case, you could update your SLO to track metrics that reflect cache hits and misses from both services. As you phase out your legacy infrastructure, the legacy Redis deployment will eventually stop reporting any data, and you can remove the <code>redis.stats.keyspace_*</code> metrics from your SLIs.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/redis-cache-hit-rate-slo.png?auto=format&amp;fit=max&amp;w=847" alt="An SLO shows a numerator of Redis cache hits plus Elasticache hits and a denominator of hits from both caches added to misses from both caches."/></picture></figure></div><p>To ensure that you have visibility into your cloud infrastructure from day one, you can leverage the dashboards and alerts you already use to track the health of your application. Export any of your <a href="https://docs.datadoghq.com/dashboards/#copy-import-or-export-dashboard-json">dashboards</a> or <a href="https://docs.datadoghq.com/monitors/monitor_types/#import">alerts</a> to JSON and edit the file to revise the metric names to align with your cloud services. Then import the modified JSON to begin monitoring your application in the cloud.</p><h3 id="set-up-a-cloud-environment-with-monitoring-built-in"><a href="#set-up-a-cloud-environment-with-monitoring-built-in">Set up a cloud environment with monitoring built in</a></h3><p>When you launch your cloud environment, you can use your cloud provider’s resource management service (e.g., AWS CloudFormation) to automatically enable the integrations that will help you track the performance of your cloud services and infrastructure. For example, you can create a CloudFormation template that defines the necessary AWS resources and also enables the Datadog AWS integration that allows you to <a href="https://www.datadoghq.com/blog/monitoring-as-code-with-datadog-and-cloudformation/#automatically-enable-datadogs-aws-integration">monitor them</a>. You can even <a href="https://github.com/DataDog/datadog-cloudformation-resources#resources-available">automatically deploy Datadog resources</a>—such as <a href="#prepare-your-slos-and-dashboards">dashboards, monitors, and SLOs</a>—as part of your migration to the cloud. This way, you can have monitoring in place before you even begin shifting traffic to your new cloud infrastructure.</p><p>Resource management tools also make it easy to apply tags to the infrastructure and services you launch in your cloud environment. For example, you could apply an <code>env:production_cloud</code> tag that allows you to monitor the new version of your application separately from the legacy version. You can add a tag like this automatically by specifying it in the templates or commands you use in <a href="https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/tag-resources">Azure Resource Manager</a>, <a href="https://cloud.google.com/deployment-manager/docs/creating-managing-labels">Google Cloud Platform</a>, and <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-properties-resource-tags.html">AWS CloudFormation</a>.</p><h3 id="validate-test-and-protect-your-cloud-architecture"><a href="#validate-test-and-protect-your-cloud-architecture">Validate, test, and protect your cloud architecture</a></h3><p>When you migrate your application to the cloud, you could be subject to data-protection regulations such as HIPAA, PCI, and GDPR. Datadog <a href="https://www.datadoghq.com/product/security-platform/cloud-security-posture-management/">Cloud Security Posture Management (CSPM)</a> helps you track the compliance posture of your cloud environment to ensure that your application meets the applicable regulations. CSPM provides <a href="https://docs.datadoghq.com/security_platform/cspm/frameworks_and_benchmarks/">out-of-the-box rules</a> that are automatically enabled to continuously evaluate your cloud environment against compliance standards and industry benchmarks. For example, if you’re migrating to Azure Kubernetes Service, Datadog provides a built-in rule to help you confirm that <a href="https://docs.datadoghq.com/security_platform/default_rules/cis-azure-1.3.0-8.5/">RBAC is enabled</a> at all times.</p><p>As you shift traffic to your cloud environment, Datadog <a href="https://www.datadoghq.com/product/security-platform/security-monitoring/">Security Monitoring</a> can help you spot security threats by automatically analyzing application and infrastructure logs in real time. Security Monitoring provides threat detection rules so you can get started quickly. You can also <a href="https://docs.datadoghq.com/security_platform/detection_rules/#creating-and-managing-rules">create custom rules</a> to watch for specific security concerns.</p><p>Once you’ve created your cloud environment and deployed your application there, you can use <a href="https://www.datadoghq.com/product/synthetic-monitoring/">Synthetic Monitoring</a> to automatically test the availability of your API endpoints and key user workflows within your application. It can simulate user journeys—even ones that include <a href="https://www.datadoghq.com/blog/mfa-synthetic-testing-datadog/">multi-factor authentication</a>—and execute simple or <a href="https://www.datadoghq.com/blog/monitor-apis-with-datadog/">multistep API tests</a> to help you proactively identify issues before your users do.</p><p>Once you start running Synthetic tests on your cloud environment, that traffic will appear in the <a href="#map-your-application-and-infrastructure">Service Map</a>. You can compare this to the Service Map of your legacy environment to check for any missing or unexpected request paths in your newly migrated workloads.</p><h2 id="cut-over-and-watch-your-cloud-migration-metrics"><a href="#cut-over-and-watch-your-cloud-migration-metrics">Cut over and watch your cloud migration metrics</a></h2><p>As you shift traffic to the cloud, you can use Datadog to verify that your application’s performance and end user experience remain optimal. In this section, we’ll describe how to use SLOs, dashboards, RUM, and APM to monitor your new cloud environment while you complete your migration.</p><h3 id="track-slos-and-migration-progress-on-dashboards"><a href="#track-slos-and-migration-progress-on-dashboards">Track SLOs and migration progress on dashboards</a></h3><p>To ensure that your migration is not affecting the performance of your application, you can continue to rely on the SLOs you’ve already created. You can <a href="https://www.datadoghq.com/blog/define-and-manage-slos/">share SLO information</a> by displaying <a href="https://docs.datadoghq.com/dashboards/widgets/slo/">SLO widgets</a> and other curated monitoring data on your <a href="https://docs.datadoghq.com/dashboards/">dashboards</a>. These dashboards enable you to easily share a real-time status report of your migration-in-progress—both internally and with stakeholders <a href="https://www.datadoghq.com/blog/dashboard-sharing/">outside of your organization</a>.</p><p>Datadog also provides <a href="https://docs.datadoghq.com/getting_started/dashboards/#explore-out-of-the-box-dashboards">out-of-the-box dashboards</a> for cloud services like <a href="https://docs.datadoghq.com/agent/amazon_ecs/">Amazon ECS</a>, <a href="https://docs.datadoghq.com/integrations/google_cloud_functions/">Google Cloud Functions</a>, and <a href="https://docs.datadoghq.com/integrations/azure_sql_database/">Azure SQL Database</a> to give you real-time information about the health and performance of the services that run your application. You can expect some metrics to rise steadily as you send more traffic to the cloud—for example, the rate of requests and the size of your data stores. And you can watch to ensure that other metrics—such as latency and error rates—hold steady or even decrease as the cloud version of your application begins to outperform the legacy version. To be fully prepared, of course, you should create <a href="https://docs.datadoghq.com/monitors/">alerts</a> to notify you if those metrics increase unexpectedly.</p><h3 id="monitor-end-to-end-with-rum-and-apm"><a href="#monitor-end-to-end-with-rum-and-apm">Monitor end-to-end with RUM and APM</a></h3><p><a href="https://www.datadoghq.com/blog/real-user-monitoring-with-datadog/">Real User Monitoring (RUM)</a> gives you visibility into the experience of your users by measuring their interactions with your application. For example, the <code>view.first_input_delay</code> metric tracks how long your users are waiting for the app to react to their first action on a page, and <code>view.largest_contentful_paint</code> measures how long it takes before the largest object in the DOM is rendered. RUM also shows you data on the rate of errors and crashes in your <a href="https://www.datadoghq.com/blog/datadog-mobile-rum/">mobile apps</a>.</p><p>RUM collects your application’s frontend data—metrics, events, and browser information—and links automatically with Datadog <a href="https://www.datadoghq.com/blog/announcing-apm/">APM</a> to provide <a href="https://www.datadoghq.com/blog/unify-apm-rum-datadog/">end-to-end visibility</a>. If RUM metrics and error rates reveal that your shift to the cloud has caused crashes or introduced latency, you can use APM to pinpoint the source of the problem. <a href="https://www.datadoghq.com/knowledge-center/distributed-tracing/flame-graph/">Flame graphs</a> visualize the sequence of service calls your application executes to fulfill each request, making it easy to spot services that are returning errors or adding latency.</p><p>APM can also help you understand whether the cloud-based version of your application is resource-constrained—for example, running on VMs that are too small or serverless functions that are underprovisioned. If a flame graph reveals a bottleneck in a request, you can click the <a href="https://docs.datadoghq.com/tracing/visualization/#spans">span</a> that represents the slow service call to see resource utilization metrics from the relevant host. In the screenshot below, the <code>check-token</code> call took 3.43 seconds. The <strong>Metrics</strong> tab below the flame graph shows high CPU usage on the host that received the request, indicating that the slow response could be due to insufficient resources.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/datadog-apm-high-cpu.png?auto=format&amp;fit=max&amp;w=847" alt="A flame graph shows one call taking 3.43 seconds or 97.6 percent of the execution time, along with CPU utilization near 100 percent."/></picture></figure></div><h3 id="finalizing"><a href="#finalizing">Finalizing</a></h3><p>Before you call your migration complete, you should confirm that all traffic has shifted and that it’s safe to decommission your legacy infrastructure. The screenshot below shows an example of a graph that you can create to verify the progress of your traffic shift. This <a href="https://www.datadoghq.com/blog/timeseries-metric-graphs-101/#stacked-area-graphs">area graph</a> shows that the combined volume of requests to our legacy and cloud infrastructure has remained consistent throughout the migration. It also indicates that the new cloud environment (represented by the darker area on the bottom and tagged <code>env:production_cloud</code>) has been servicing an increasing share of the traffic, while the on-premise environment’s share (the lighter area on top) has decreased.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/cloud-migration-monitoring/cloud-migration-traffic-shift.png?auto=format&amp;fit=max&amp;w=847" alt="An area graph shows an static total of overall requests, with requests to &#39;production cloud&#39; increasing over 45 minutes."/></picture></figure></div><p>You should also confirm that all sessions have been drained from on-premise servers, and that message queues (e.g., ActiveMQ or RabbitMQ) and data streams (e.g., Kafka or Apache Flink) no longer hold any records.</p><p>When you’ve completed your migration, you can continue to use RUM and APM—along with your SLOs, dashboards, and alerts—to give you ongoing visibility as you operate your applications in the cloud. And as the new version of your application establishes traffic patterns in the cloud, you can take advantage of features like <a href="https://www.datadoghq.com/blog/watchdog/">Watchdog</a> and <a href="https://www.datadoghq.com/blog/introducing-anomaly-detection-datadog/">anomaly detection</a> to help you spot and troubleshoot anomalies in your application’s performance.</p><h2 id="migrate-and-monitor"><a href="#migrate-and-monitor">Migrate and monitor</a></h2><p>By building monitoring into your cloud migration process, you’ll have the visibility you need to confirm a successful launch and take advantage of the increased performance and reliability of the cloud. Datadog provides integrations with more than
450 technologies to ensure that you can always monitor all the layers of your application. If you’re not yet using Datadog, you can start today with a <a href="#">14-day free trial</a>.</p></div></div>]]></content:encoded>
      <author>David M. Lentz</author>
      <pubDate>Wed, 04 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Monitor containerized ASP.NET Core applications on AWS Fargate</title>
      <link>https://www.datadoghq.com/blog/deploy-dotnet-core-aws-fargate/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-hero.png&#34; width=&#34;100%&#34;/&gt;The ASP.NET Core framework enables you to build and deploy .NET applications on a wide variety of platforms, each of which has different observability concerns. In a previous post, we looked at monitoring a containerized ASP.NET Core application. In this guide, we&amp;rsquo;ll show how Datadog provides visibility into ASP.NET Core applications running on AWS Fargate. We&amp;rsquo;ll walk through: instrumenting and packaging a sample .NET application publishing the application to Docker Hub deploying the instrumented .</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>The <a href="https://dotnet.microsoft.com/learn/aspnet/what-is-aspnet-core">ASP.NET Core framework</a> enables you to build and deploy .NET applications on a wide variety of platforms, each of which has different observability concerns. <a href="https://www.datadoghq.com/blog/asp-dotnet-core-monitoring/">In a previous post</a>, we looked at monitoring a containerized ASP.NET Core application. In this guide, we’ll show how Datadog provides visibility into ASP.NET Core applications running on <a href="https://aws.amazon.com/fargate/">AWS Fargate</a>. We’ll walk through:</p><ul><li><a href="#package-an-instrumented-application-with-docker">instrumenting and packaging a sample .NET application</a></li><li><a href="#publish-your-image-to-docker-hub">publishing the application</a> to Docker Hub</li><li><a href="#deploy-a-containerized-net-application-with-aws-fargate">deploying the instrumented .NET application</a> using AWS Fargate</li><li><a href="#monitor-application-performance-with-datadog">monitoring</a> application performance with Datadog APM</li></ul><p>Instrumenting your application enables you to track requests as they move across the application’s service and process boundaries, so you can identify performance bottlenecks and resolve them before they affect end users. Datadog offers out-of-the-box instrumentation for .NET Core and other .NET frameworks with the <a href="https://docs.datadoghq.com/tracing/setup_overview/setup/dotnet-core/?tab=windows">.NET tracer</a>, which submits trace data to Datadog via the Datadog Agent. The Agent can also collect performance data from your Fargate resources, giving you complete visibility into your application and its underlying infrastructure.</p><h3 id="get-started-with-a-sample-application"><a href="#get-started-with-a-sample-application">Get started with a sample application</a></h3><p>To get started, make sure you have at least <a href="https://dotnet.microsoft.com/download/dotnet/5.0">version 5 of the .NET Core SDK</a> installed, which includes <a href="https://docs.microsoft.com/en-us/dotnet/core/tools/">the .NET CLI</a>. This will let you generate the sample ASP.NET Core application we’ll use throughout this guide. We’ll also use <a href="https://hub.docker.com/">Docker Hub</a> to publish the containerized application, though you can use other container registry services such as <a href="https://aws.amazon.com/ecr/">Amazon ECR</a>.</p><p>You can create a new web application project with all of the files needed to run a sample application via the following .NET CLI commands:</p><div><pre><code data-lang="text"> 
dotnet new sln -n DatadogFargateExample
dotnet new webapp -o DatadogFargateExample -n DatadogFargateExample
dotnet sln add DatadogFargateExample</code></pre></div><p>These commands create a new solution file (i.e., <strong>DatadogFargateExample.sln</strong>) and add a new <a href="https://docs.microsoft.com/en-us/aspnet/core/razor-pages/?view=aspnetcore-5.0&amp;tabs=visual-studio">Razor Pages</a> web application project and associated <strong>DatadogFargateExample</strong> directory to the file. Next, we’ll instrument the application with Datadog’s .NET tracer and publish it on Docker Hub as a Linux container.</p><h2 id="package-an-instrumented-application-with-docker"><a href="#package-an-instrumented-application-with-docker">Package an instrumented application with Docker</a></h2><p>Docker enables you to easily package applications and their dependencies together in a single container, which you can then deploy to any environment, such as a Fargate cluster. AWS Fargate currently only supports Linux-based containers, so we will use a Linux container to package the application. To create a container, add the following Dockerfile to your project’s <strong>DatadogFargateExample</strong> directory:</p><div><p>./DatadogFargateExample/Dockerfile</p><div><pre><code data-lang="text">#See https://aka.ms/containerfastmode to understand how Visual Studio uses this Dockerfile to build your images for faster debugging.
 
FROM mcr.microsoft.com/dotnet/aspnet:5.0 AS base
WORKDIR /app
EXPOSE 80
EXPOSE 443
 
FROM mcr.microsoft.com/dotnet/sdk:5.0 AS build
 
# Download the latest version of the tracer but don&#39;t install yet
RUN TRACER_VERSION=$(curl -s \https://api.github.com/repos/DataDog/dd-trace-dotnet/releases/latest | grep tag_name | cut -d &#39;&#34;&#39; -f 4 | cut -c2-) \
    &amp;&amp; curl -Lo /tmp/datadog-dotnet-apm.deb https://github.com/DataDog/dd-trace-dotnet/releases/download/v${TRACER_VERSION}/datadog-dotnet-apm_${TRACER_VERSION}_amd64.deb
 
WORKDIR /src
COPY [&#34;DatadogFargateExample/DatadogFargateExample.csproj&#34;, &#34;DatadogFargateExample/&#34;]
RUN dotnet restore &#34;DatadogFargateExample/DatadogFargateExample.csproj&#34;
COPY . .
WORKDIR &#34;/src/DatadogFargateExample&#34;
RUN dotnet build &#34;DatadogFargateExample.csproj&#34; -c Release -o /app/build
 
FROM build AS publish
RUN dotnet publish &#34;DatadogFargateExample.csproj&#34; -c Release -o /app/publish
 
FROM base AS final
 
# Copy the tracer from build target
COPY --from=build /tmp/datadog-dotnet-apm.deb /tmp/datadog-dotnet-apm.deb
# Install the tracer
RUN mkdir -p /opt/datadog \
    &amp;&amp; mkdir -p /var/log/datadog \
    &amp;&amp; dpkg -i /tmp/datadog-dotnet-apm.deb \
    &amp;&amp; rm /tmp/datadog-dotnet-apm.deb
 
# Enable the tracer
ENV CORECLR_ENABLE_PROFILING=1
ENV CORECLR_PROFILER={846F5F1C-F9AE-4B07-969E-05C26BC060D8}
ENV CORECLR_PROFILER_PATH=/opt/datadog/Datadog.Trace.ClrProfiler.Native.so
ENV DD_DOTNET_TRACER_HOME=/opt/datadog
ENV DD_INTEGRATIONS=/opt/datadog/integrations.json
 
WORKDIR /app
COPY --from=publish /app/publish .
ENTRYPOINT [&#34;dotnet&#34;, &#34;DatadogFargateExample.dll&#34;]</code></pre></div></div><p>The Dockerfile uses <a href="https://docs.docker.com/develop/develop-images/multistage-build/">multi-stage builds</a> to optimize the build process and ensure compatibility with Visual Studio so you can debug issues locally via Visual Studio’s container tools. You can check out <a href="https://docs.microsoft.com/visualstudio/containers/container-build">Microsoft’s documentation</a> for details.</p><p>There are four build stages in the Dockerfile above: <code>base</code>, <code>build</code>, <code>publish</code>, and <code>final</code>. The <code>mcr.microsoft.com/dotnet/aspnet:5.0</code> Docker image in the <code>base</code> stage is based on the Debian operating system and serves as the main image to run the application in the <code>final</code> stage.</p><p>In the <code>build</code> stage, the Dockerfile uses the <code>mcr.microsoft.com/dotnet/sdk:5.0</code> Docker image to first download the latest version of the Datadog .NET tracer (this image has the <code>curl</code> utility needed to download the tracer) then build the <a href="#get-started-with-a-sample-application"><strong>DatadogFargateExample</strong> project</a>. To use a specific version of the tracer, you can remove the <code>RUN TRACER_VERSION</code> step from the Dockerfile and set the <code>TRACER_VERSION</code> environment variable via <a href="https://docs.docker.com/engine/reference/builder/#arg">a build argument</a> instead.</p><p>The <code>publish</code> stage publishes the project and its dependencies to the <strong>/app/publish</strong> directory for deployment, and the <code>final</code> stage installs and enables the tracer with the necessary file configurations and environment variables to auto-instrument your application. This allows the tracer to submit data to the Agent, which we will install via <a href="#create-an-ecs-task-definition">an ECS task definition</a> in a later section.</p><p>You can build your Docker image and launch the container locally using the following commands:</p><div><pre><code data-lang="text">docker build -t test/datadog-fargate-example -f ./DatadogFargateExample/Dockerfile .
docker run --rm --name datadog-test -p 8080:80 datadog-fargate-example</code></pre></div><p>The <code>test/datadog-fargate-example</code> tag allows you to easily push the image to a container registry platform or pull it as a source image for a container deployed via Fargate. Once your container spins up, you can view your instrumented application by navigating to <code>http://localhost:8080/</code>.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app.png?auto=format&amp;fit=max&amp;w=847" alt="A sample .NET Core appliction"/></picture></figure></div><h3 id="publish-your-image-to-docker-hub"><a href="#publish-your-image-to-docker-hub">Publish your image to Docker Hub</a></h3><p>You can push the Docker image to a container registry platform like Docker Hub using the following command:</p><div><pre><code data-lang="text">docker image push test/datadog-fargate-example</code></pre></div><p>This publishes the image to the registry so you can use it in other environments or platforms. We’ll look at how to use the published image to deploy your .NET application via Fargate next.</p><h2 id="deploy-a-containerized-net-application-with-aws-fargate"><a href="#deploy-a-containerized-net-application-with-aws-fargate">Deploy a containerized .NET application with AWS Fargate</a></h2><p><a href="https://www.datadoghq.com/blog/aws-fargate-metrics/">AWS Fargate</a> is a service that enables you to run Amazon Elastic Container Service (Amazon ECS) tasks or Amazon Elastic Kubernetes Service (Amazon EKS) containers without needing to manage any underlying infrastructure. For this guide, we’ll look at leveraging Fargate with ECS by creating:</p><ul><li><a href="#create-an-amazon-ecs-cluster">a new ECS cluster</a></li><li><a href="#create-an-ecs-task-definition">an ECS task definition</a></li><li><a href="#create-an-application-load-balancer">an application load balancer</a></li><li><a href="#create-an-ecs-service">an ECS service</a> for the cluster</li></ul><h3 id="create-an-amazon-ecs-cluster"><a href="#create-an-amazon-ecs-cluster">Create an Amazon ECS cluster</a></h3><p>A core part of the ECS infrastructure is <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ECS_clusters.html">the cluster</a>, which is a group of tasks and services necessary for deploying an application. You can <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/create_cluster.html">create an ECS cluster</a> by navigating to the <a href="https://console.aws.amazon.com/ecs/">Amazon ECS console</a> in your AWS account. Select “Networking Only” as the cluster template and use the default values for the remaining configuration settings. Once provisioned, you can view your new cluster by clicking the “View Cluster” button on the “Launch status” page.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-cluster.png?auto=format&amp;fit=max&amp;w=847" alt="The cluster&#39;s configuration settings"/></picture></figure></div><p>Next, we’ll walk through how to add the Datadog Agent and the application container you <a href="#publish-your-image-to-docker-hub">published to Docker Hub</a> to the new cluster.</p><h3 id="create-an-ecs-task-definition"><a href="#create-an-ecs-task-definition">Create an ECS task definition</a></h3><p>ECS clusters use <a href="https://docs.aws.amazon.com/AmazonECS/latest/userguide/task_definitions.html">task definitions</a> to specify which containers should be created as part of a deployment. For this guide, we will add two containers to the task definition. The first will run the containerized Datadog Agent and the second your instrumented application. You can <a href="https://docs.datadoghq.com/integrations/ecs_fargate/#web-ui">check out our documentation</a> for detailed steps on creating a new task definition with a Datadog Agent container, but we will highlight some of the key container configurations below.</p><h4 id="create-the-datadog-agent-container"><a href="#create-the-datadog-agent-container">Create the Datadog Agent container</a></h4><p>The first container uses the <code>datadog/agent:latest</code> image to run the Agent, which will gather data from the .NET tracer and host and submit it to Datadog. The Agent image uses environment variables (seen below) to enable APM and listen for non-local traffic, which is required when the Agent and application are running in different containers. It also uses a <code>DD_API_KEY</code> environment variable for connecting the Agent to your Datadog account—your unique API key can be found in <a href="https://app.datadoghq.com/account/settings?#api">your account’s settings</a>.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-agent-variables.png?auto=format&amp;fit=max&amp;w=847" alt="Environment variables for the Datadog Agent"/></picture></figure></div><h4 id="create-the-application-container"><a href="#create-the-application-container">Create the application container</a></h4><p>You can use <a href="https://docs.datadoghq.com/integrations/ecs_fargate/#web-ui">the same steps</a> to create the second container, which will launch the instrumented application and use the Agent container as a startup dependency. Make sure that you set the image name to the name of the application container on Docker Hub (e.g., <code>datadog-fargate-example</code>) and, under “Port mappings,” add port 80 over TCP, which is the port we defined in the application’s Dockerfile. There are also a few environment variables that you will need to add to the “Advanced container configuration” section, as seen in the screenshot below.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-app-variables.png?auto=format&amp;fit=max&amp;w=847" alt="Environment variables for the application container"/></picture></figure></div><p>These variables configure the Agent to collect the following data from your application:</p><ul><li><code>DD_ENV</code>, <code>DD_VERSION</code>, <code>DD_SERVICE</code>: sets the <code>env</code>, <code>version</code>, and <code>service</code> tags on traces for <a href="https://docs.datadoghq.com/getting_started/tagging/unified_service_tagging/?tab=kubernetes">Unified Service Tagging</a></li><li><code>DD_TRACE_ROUTE_TEMPLATE_RESOURCE_NAMES_ENABLED</code>: enables <a href="https://docs.datadoghq.com/tracing/setup_overview/setup/dotnet-core/?tab=windows#experimental-features">improved resource names</a> for ASP.NET Core endpoints</li><li><code>DD_RUNTIME_METRICS_ENABLED</code>: enables <a href="https://www.datadoghq.com/blog/monitor-dotnet-runtime-metrics/">runtime metrics for the .NET runtime</a> like thread counts and garbage collection (GC) pressure</li></ul><p>Finally, in the “Startup Dependency Ordering” section, add the Agent container as a dependency by setting the “Container name” to <code>datadog-agent</code> and the “Condition” to “START”.</p><p>In the next section, we will create an application load balancer (ALB) that can automatically route public network traffic to our Agent and application containers.</p><h3 id="create-an-application-load-balancer"><a href="#create-an-application-load-balancer">Create an application load balancer</a></h3><p>Fargate supports <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/load-balancer-types.html">several different types</a> of load balancers for ECS, but we’ll use <a href="https://docs.amazonaws.cn/en_us/AmazonECS/latest/developerguide/create-load-balancer.html">an ALB</a> for this guide. Create a new load balancer by following steps in <a href="https://docs.aws.amazon.com/AmazonECS/latest/userguide/create-application-load-balancer.html">the AWS documentation</a>. You can use the default values for most of the available configuration options, but there are a few new security group rules that you will need to create.</p><p>Load balancer security groups determine what traffic is allowed to access the load balancer. On the “Assign Security Groups” page, <a href="https://docs.aws.amazon.com/AmazonECS/latest/userguide/create-application-load-balancer.html#alb-configure-security-groups">create a new security group</a> with a rule that uses the TCP protocol on port 80 and <code>0.0.0.0/0, ::/0</code> as a custom source. This ensures that the ALB is accessible from the public internet.</p><p>Next, on the “Configure Routing” page, <a href="https://docs.aws.amazon.com/AmazonECS/latest/userguide/create-application-load-balancer.html#alb-configure-routing">create a new target group</a> that uses the “IP address” target type and the HTTP protocol on port 80. You can use <code>/</code> as the health check path. Complete the remaining steps to create your load balancer.</p><p>Once the ALB is created, make note of its DNS name (found in the “Description” tab for the load balancer) as you will need it to access your application. Next, we will create a service to launch the application and all of its resources.</p><h3 id="create-an-ecs-service"><a href="#create-an-ecs-service">Create an ECS service</a></h3><p>The final step for deploying the Agent and .NET application is to create a new <a href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/ecs_services.html">ECS service</a> for the cluster. We can use this service to schedule and launch all of the necessary components to run the application, such as the load balancer we created previously and the containers defined in our task definition.</p><p>You can <a href="https://docs.aws.amazon.com/AmazonECS/latest/userguide/create-service-console-v2.html">create a new service</a> on the “Clusters” page of the Amazon ECS console. Select your ECS cluster and click the “Create” button in the “Services” tab. There are a few settings that you will need to configure for the service. First, make sure the service uses “Fargate” as the launch type and the task definition you created earlier. In the “VPC and security groups” section, use your application load balancer’s VPC, subnets, and security group. In the “Load balancing” section of the “Configure network” page, select the <a href="#create-an-application-load-balancer">load balancer you created earlier</a> and add the application container in the “Container to load balance” section. Finally, the “Production listener port” needs to use the existing “80:HTTP” listener and the “Target group name” needs to use the name of your application container that you defined in your task definition.</p><p>Once the service launches successfully, navigate to the service’s “Details” tab to view the security group and add a new inbound rule. The new rule should use “All TCP&#39;&#39; as the type and your ALB security group as the custom source. This setting allows the ALB to route traffic to your cluster; without it, your cluster may restart repeatedly due to “failed health checks”.</p><p>After finishing these steps, you can use the DNS name associated with the ALB you created earlier to navigate to your application and generate traffic. Since the application is instrumented with the .NET tracer and configured to submit traces via the Agent, you will start seeing real-time performance data for your ECS cluster and .NET application in Datadog.</p><h2 id="monitor-application-performance-with-datadog"><a href="#monitor-application-performance-with-datadog">Monitor application performance with Datadog</a></h2><p>Datadog provides full visibility into the <a href="https://www.datadoghq.com/blog/aws-fargate-monitoring-with-datadog/">health and performance</a> of your Fargate resources, such as the memory and CPU utilization of your ECS tasks. You can use the built-in integration dashboard to get a high-level overview of your Fargate environment and ensure that the underlying infrastructure supporting your .NET application is performing optimally.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-dashboard.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog&#39;s built-in AWS Fargate dashboard"/></picture></figure></div><p>The dashboard can alert you to significant changes in container performance, such as a sudden increase in memory usage for your application’s container, which you can troubleshoot further using Datadog APM.</p><h3 id="visualize-traces-with-datadog"><a href="#visualize-traces-with-datadog">Visualize traces with Datadog</a></h3><p>Datadog APM enables you to track distributed traces from your .NET application so you can get a better understanding of how application services process requests. To view your application’s traces, navigate to the <a href="https://app.datadoghq.com/apm/services/">service page</a> in your Datadog account and locate the <code>DatadogFargateExample</code> service under the <code>my-container-test</code> environment, which reflects the values you set for your <a href="#create-the-application-container">application container’s <code>DD_SERVICE</code> and <code>DD_ENV</code> environment variables</a>. You can select that service to see a high-level overview of application performance and visualizations for key metrics, such as the total number of requests, errors, and request latency.</p><p>You can also view your application’s runtime metrics alongside trace data in order to troubleshoot common performance issues, such as <a href="https://www.datadoghq.com/blog/monitor-dotnet-runtime-metrics/#monitor-first-chance-exceptions">first-chance exceptions</a>, so you have more context for resolving the problem before it becomes more serious.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/deploy-dotnet-core-aws-fargate/dotnet-aws-fargate-runtime-metrics.png?auto=format&amp;fit=max&amp;w=847" alt="Runtime metrics for a .NET Core application service"/></picture></figure></div><p>For even greater visibility into your application, you can <a href="https://docs.datadoghq.com/tracing/connect_logs_and_traces/dotnet/">connect .NET logs to your traces</a> by automatically injecting trace and span IDs into your logs. This enables you to quickly pivot between your traces and .NET logs to get a better picture of what is going on in your application. You can also add <a href="https://docs.datadoghq.com/tracing/setup_overview/custom_instrumentation/dotnet/">custom instrumentation</a> to your application’s business logic to monitor critical services, such as those that process payments, and ensure they are performing optimally.</p><h2 id="net-core--aws-fargate"><a href="#net-core--aws-fargate">.NET Core + AWS Fargate</a></h2><p>In this post, we’ve shown how you can instrument a .NET Core application with Datadog’s .NET tracer and deploy it as a container via AWS Fargate. We also looked at how you can use Datadog to monitor application and infrastructure performance in one place. Check out our documentation for more information about <a href="https://docs.datadoghq.com/tracing/setup_overview/">tracing your applications</a> and getting visibility into application performance, regardless of the environment or platform. If you don’t already have a Datadog account, you can sign up for a <a href="#">free trial</a>.</p></div></div>]]></content:encoded>
      <author>Andrew Lock</author>
      <pubDate>Tue, 03 Aug 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Monitor AWS FSx audit logs with Datadog</title>
      <link>https://www.datadoghq.com/blog/amazon-fsx-audit-logs-monitoring/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/AWS-FSx_integration_FINAL.png&#34; width=&#34;100%&#34;/&gt;Amazon FSx for Windows File Server is a fully managed file storage service built on Windows Server. Migrating on-premise Windows file systems to a managed service like FSx enables organizations to reduce operational overhead and take advantage of the flexibility and scalability of the cloud. But having visibility into file access activity across their environment is key for security and compliance requirements, particularly in sectors such as financial services and healthcare.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><a href="https://aws.amazon.com/fsx/windows/">Amazon FSx for Windows File Server</a> is a fully managed file storage service built on Windows Server. Migrating on-premise Windows file systems to a managed service like FSx enables organizations to reduce operational overhead and take advantage of the flexibility and scalability of the cloud. But having visibility into file access activity across their environment is key for security and compliance requirements, particularly in sectors such as financial services and healthcare. In order to provide this visibility, <a href="https://aws.amazon.com/blogs/aws/file-access-auditing-is-now-available-for-amazon-fsx-for-windows-file-server/">AWS recently added file access auditing to the Amazon FSx service</a>. With this update, Amazon FSx now publishes and stores audit event logs that summarize file system access activity at user-level for all files, folders, and file shares.</p><p>As an <a href="https://partners.amazonaws.com/partners/001E000000Rp57sIAB/Datadog%20Inc">AWS Partner solution</a>, you can use Datadog as an endpoint to send Amazon FSx audit event logs for retention and real-time analysis. You can use Datadog’s <a href="https://app.datadoghq.com/logs">Log Explorer</a> to easily search for file access events of interest or use <a href="https://www.datadoghq.com/blog/announcing-security-monitoring/">Datadog Security Monitoring</a> to look for and alert you to any unusual activity. This way, in addition to monitoring FSx metrics via <a href="https://docs.datadoghq.com/integrations/amazon_fsx/">Datadog’s integration</a>, your teams can audit any suspicious or unauthorized activity and take immediate steps to address any detected violations.</p><p>In this post, we’ll look at what information these logs contain and how you can use Datadog to:</p><ul><li><a href="#analyze-and-monitor-amazon-fsx-audit-event-logs-in-datadog">Monitor access activity</a> across your file systems</li><li><a href="#automatically-detect-security-threats-to-your-fsx-file-system">Create security rules</a> to alert you to possible threats</li></ul><h2 id="analyze-and-monitor-amazon-fsx-audit-event-logs-in-datadog"><a href="#analyze-and-monitor-amazon-fsx-audit-event-logs-in-datadog">Analyze and monitor Amazon FSx audit event logs in Datadog</a></h2><p>Amazon FSx audit event logs record all user attempts to access, create, modify, or delete a <a href="https://docs.aws.amazon.com/fsx/latest/WindowsGuide/using-file-shares.html">file share</a> or individual file or folder object. Each log follows the standard Windows event log format and contains important information regarding the access event, including:</p><ul><li>the type of event (indicated by the <code>EventID</code>)</li><li>the user who performed the action (<code>SubjectUserName</code>)</li><li>the object being accessed (<code>ObjectName</code> or <code>ShareName</code>)</li><li>whether it was successful (<code>Keywords</code>)</li><li>in the case of file shares, the access action performed (<code>AccessMask</code>).</li></ul><p>Datadog’s built-in <a href="https://docs.datadoghq.com/logs/processing/pipelines/">log processing pipeline</a> parses and extracts these key fields from your logs as <a href="https://docs.datadoghq.com/logs/processing/attributes_naming_convention/">attributes</a>, which you can then use to query, sort, and filter your logs. This enables you to perform complex analysis of user and file activity across your logs. For example, you can easily search for activity related to particularly sensitive folders.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-parsing.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog parses AWS FSx logs"/></picture><figcaption>Datadog parses out key data from your Amazon FSx event audit logs.</figcaption></figure></div><p>It’s also important to track overall trends in file system activity to surface any unusual behavior. For example, aggregating logs by file access event type, like create, modify, or delete, makes it easy to spot anomalous spikes in certain activity. You can then dive into the relevant logs to look at the users behind the spikes.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-log-analytics.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog AWS FSx audit log analytics"/></picture></figure></div><p>Using the <code>Keywords</code> attribute, you can further break down events by whether they were successful or not. This can help you identify spikes in failed operations, which might indicate an unauthorized user trying to access files.</p><h2 id="automatically-detect-security-threats-to-your-fsx-file-system"><a href="#automatically-detect-security-threats-to-your-fsx-file-system">Automatically detect security threats to your FSx file system</a></h2><p>Real-time knowledge of potentially suspicious activity across your file system is key to ensuring the security of your sensitive data. Datadog Security Monitoring provides out-of-the-box Threat Detection Rules to notify you when Datadog identifies specific activity. For example, the rule below looks for more than 10 failed file access attempts from a single user, which might indicate someone attempting to access files they don’t have permissions for.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/amazon-fsx-audit-logs-monitoring/datadog-aws-fsx-detection-rule-rev.png?auto=format&amp;fit=max&amp;w=847" alt="Datadog AWS FSx logs threat detection rule"/></picture></figure></div><p>You can easily create custom rules for your specific environment. For example, if you have particularly important file shares (<code>ShareName</code>), or even entire file systems (<code>Computer</code>), you can create rules to monitor them for any delete or modify attempts. You might also want to be alerted to any file share event from an IP address outside your organization. You can create a <a href="https://www.datadoghq.com/blog/new-term-detection-method-datadog/">new term–based</a> rule that notifies you of any activity from an address that Datadog hasn’t seen before, helping alert you to a possible threat.</p><p>Whenever a rule is triggered, Datadog generates a Security Signal that includes key metadata about the relevant event, so you can determine if you need to take further action, such as adjusting security policy settings to modify who can access certain files.</p><h2 id="get-deeper-insight-into-your-amazon-fsx-file-systems"><a href="#get-deeper-insight-into-your-amazon-fsx-file-systems">Get deeper insight into your Amazon FSx file systems</a></h2><p>Amazon FSx’s file access audit event logs give your teams immediate visibility into activity across your Windows Server file directory that, when paired with Datadog’s log management and security platforms, helps ensure that your files are secure. You can send your Amazon FSx logs to Datadog either with our <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-lambda-function/">Forwarder Lambda function</a> or by using a <a href="https://docs.datadoghq.com/logs/guide/send-aws-services-logs-with-the-datadog-kinesis-firehose-destination/">Kinesis Firehose data stream</a>. See our <a href="https://docs.datadoghq.com/integrations/amazon_fsx/#log-collection">documentation</a> to get started. Or, if you’re not a Datadog customer, sign up today for a <a href="#">free 14-day trial</a>.</p></div></div>]]></content:encoded>
      <author>Jonathan Epstein</author>
      <pubDate>Fri, 30 Jul 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Datadog Announces Availability on Google Cloud Marketplace to Support Customers’ Cloud Migrations</title>
      <link>https://www.datadoghq.com/about/latest-news/press-releases/datadog-announces-availability-on-google-cloud-marketplace-to-support-customers-cloud-migrations/</link>
      <description>NEW YORK &amp;ndash; Datadog, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced its availability on Google Cloud Marketplace, deepening its partnership with Google Cloud. Google Cloud customers can now purchase Datadog with just a few clicks on the Google Cloud Marketplace, allowing them to quickly and easily monitor the health of their applications and infrastructure across their Google Cloud and hybrid cloud environments. Google Cloud Marketplace offers integrated solutions vetted by Google Cloud, to support customers’ enterprise IT needs.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p><strong>NEW YORK</strong> – <a href="https://www.datadoghq.com/">Datadog</a>, Inc. (NASDAQ: DDOG), the monitoring and security platform for cloud applications, today announced its availability on <a href="https://console.cloud.google.com/marketplace/product/datadog-public/datadog">Google Cloud Marketplace</a>, deepening its partnership with Google Cloud. Google Cloud customers can now purchase Datadog with just a few clicks on the Google Cloud Marketplace, allowing them to quickly and easily monitor the health of their applications and infrastructure across their Google Cloud and hybrid cloud environments. </p><p>Google Cloud Marketplace offers integrated solutions vetted by Google Cloud, to support customers’ enterprise IT needs. Customers rely on Google Cloud Marketplace to identify and purchase the third-party tools that help them move to, build on and work in Google Cloud. In addition to easier access, customers who purchase Datadog through Google Cloud Marketplace will benefit from consolidated billing and streamlined procurement. Datadog usage will appear directly on customers’ Google Cloud invoices, and customers will be able to pay for a portion of this usage with their committed Google Cloud spend.</p><p>“By making Datadog available on Google Cloud via Marketplace, customers will have access to Datadog’s advanced monitoring and security capabilities,” said Amy Bray, Global Head, Google Cloud Marketplace, Google. “With Datadog on Google Cloud, customers can quickly begin leveraging its capabilities in application monitoring and security, ultimately helping them accelerate their cloud migrations and digital transformations.”</p><p>“We’re excited that Datadog is now available in the Google Cloud Marketplace,” said Marc Weisman, Vice President, Product Management, Datadog. “Monitoring and security are crucial for companies as they move their infrastructure and applications to the cloud, and we look forward to supporting Google Cloud customers as they undertake these initiatives.”</p><p>Datadog’s existing partnership and support for Google Cloud includes:</p><ul><li>Access to Datadog’s 450+ integrations on Google Cloud’s scalable and secure infrastructure, including integrations with Google Cloud services such as Compute Engine, Cloud Storage, BigQuery and more.</li><li>The ability to deploy the Datadog Agent directly on hosts and compute instances in Google Cloud, to collect metrics with greater granularity.</li><li>Extended go-to-market collaboration and deeper sales alignment with Google Cloud and Datadog sales teams.</li><li>Continued investment into product co-innovation with more native joint solutions around Anthos, Open Telemetry and the Google Cloud operations suite.</li></ul><p>For more information and to get started with Datadog, visit <a href="https://console.cloud.google.com/marketplace/product/datadog-public/datadog">Datadog in Google Cloud Marketplace</a>.</p><div><p><strong>About Datadog</strong></p><p>Datadog is the monitoring and security platform for cloud applications. Our SaaS platform integrates and automates infrastructure monitoring, application performance monitoring and log management to provide unified, real-time observability of our customers’ entire technology stack. Datadog is used by organizations of all sizes and across a wide range of industries to enable digital transformation and cloud migration, drive collaboration among development, operations, security and business teams, accelerate time to market for applications, reduce time to problem resolution, secure applications and infrastructure, understand user behavior and track key business metrics.</p></div><p><strong>Forward-Looking Statements</strong></p><p>This press release may include certain “forward-looking statements” within the meaning of Section 27A of the Securities Act of 1933, as amended, or the Securities Act, and Section 21E of the Securities Exchange Act of 1934, as amended. These forward-looking statements reflect our current views about our plans, intentions, expectations, strategies and prospects, which are based on the information currently available to us and on assumptions we have made. Actual results may differ materially from those described in the forward-looking statements and are subject to a variety of assumptions, uncertainties, risks and factors that are beyond our control, including those risks detailed under the caption “Risk Factors” and elsewhere in our Securities and Exchange Commission filings and reports, including the Quarterly Report on Form 10-Q filed with the Securities and Exchange Commission on May 7, 2021, as well as future filings and reports by us. Except as required by law, we undertake no duty or obligation to update any forward-looking statements contained in this release as a result of new information, future events, changes in expectations or otherwise.</p></div></div>]]></content:encoded>
      <author>Datadog</author>
      <pubDate>Thu, 29 Jul 2021 20:30:00 +0000</pubDate>
    </item>
    <item>
      <title>Use Datadog Session Replay to view real-time user journeys</title>
      <link>https://www.datadoghq.com/blog/session-replay-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-hero-1.png&#34; width=&#34;100%&#34;/&gt;When developing large, customer-facing applications, it’s paramount to have visibility into real user behavior in order to optimize your UX. Without a direct view into what users are actually doing when navigating your app, it can be difficult to reproduce bugs and understand how aspects of your frontend design are causing user frustration and churn. With Datadog RUM’s Session Replay feature, currently available in beta, you can watch individual user sessions using a video-like interface.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>When developing large, customer-facing applications, it’s paramount to have visibility into real user behavior in order to optimize your UX. Without a direct view into what users are actually doing when navigating your app, it can be difficult to reproduce bugs and understand how aspects of your frontend design are causing user frustration and churn. With Datadog RUM’s Session Replay feature, currently available in beta, you can watch individual user sessions using a video-like interface. This allows you to view exactly how your users interact with your website, saving you time and guesswork recreating bugs and helping you understand patterns in your users’ behavior. In this post, we’ll discuss how Session Replay can help you <a href="#reproduce-bugs-and-troubleshoot-faster">speed up your debugging</a> and <a href="#understand-user-behavior">find patterns in your users’ behavior</a>.</p><h2 id="reproduce-bugs-and-troubleshoot-faster"><a href="#reproduce-bugs-and-troubleshoot-faster">Reproduce bugs and troubleshoot faster</a></h2><p>As a frontend or support engineer, an essential—and often time-consuming—part of the debugging process is reproducing bugs. But it can be difficult to do so without a clear understanding of the actions a user took before your application threw an error. By recording real user journeys, Session Replay effectively reproduces the bug for you, saving time and eliminating any guesswork.</p><p>For example, let’s say you’re a frontend engineer monitoring a recent release and notice a new issue pop up in <a href="https://www.datadoghq.com/blog/error-tracking/">Error Tracking</a>. After viewing key information about the error, such as the error message, stacktrace, and browser info, you can immediately pivot directly from the issue summary to a live reproduction of the most recent session that experienced the error.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/error-tracking-3.png?auto=format&amp;fit=max&amp;w=847" alt="Pivot to a Session Replay from Error Tracking"/></picture></figure></div><p>When viewing a replay, you can see a video-like reproduction of the entire user journey. Datadog also displays an event timeline that breaks the session down into every page load and DOM change resulting from the user’s actions so you can jump to individual events. The timeline flags any user interaction that results in an error so you can pinpoint when and where issues occurred.</p><p>For example, let’s say you notice a rise in timeout errors on a particular page load. With Session Replay, you can easily identify the exact user action that’s causing the timeout, without needing to guess about how users are triggering the error.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/session-replay-2.png?auto=format&amp;fit=max&amp;w=847" alt="Session Replay"/></picture></figure></div><p>Once you’ve found the user action or page load triggering the timeout error, you can see more details to start troubleshooting. For example, you can see a <a href="https://docs.datadoghq.com/real_user_monitoring/browser/monitoring_page_performance">waterfall</a> of the resources loaded—along with <a href="https://www.datadoghq.com/blog/core-web-vitals-monitoring-datadog-rum-synthetics/">key performance metrics</a>. This helps you determine, for example, if there is a particularly slow asset that is causing a bottleneck for users. For further context, you can pivot to relevant <a href="https://www.datadoghq.com/blog/unify-apm-rum-datadog/">traces, logs, and errors</a> to continue investigating whether, for instance, the root cause of the timeouts is a backend problem like a hanging API call.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/rum-waterfall.png?auto=format&amp;fit=max&amp;w=847" alt="RUM waterfall"/></picture></figure></div><h2 id="understand-user-behavior"><a href="#understand-user-behavior">Understand user behavior</a></h2><p>If you’re a UI or UX designer, real user data can be an important source of truth for understanding the efficacy of your designs. Using Session Replay, you can observe how users traverse your website to get insight into how long it takes them to make decisions, what they hover over before clicking on something else, how they respond to broken UI elements and other errors, and more.</p><p>Let’s say you’re a designer investigating a drop in click-through rate for a key part of your application, such as a checkout page. You might first want to check if something in a common user flow to this endpoint is causing a bottleneck. By filtering the RUM Sessions view to sessions that include common gateways to the checkout page, such as the shopping cart, and sorting the resulting list by duration, you can surface replays that represent cases where the user spent a particularly long time on the previous page.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/session-replay-datadog/sessions-query.png?auto=format&amp;fit=max&amp;w=847" alt="Session Replays query"/></picture></figure></div><p>Examining Session Replays for these slow cases, you can directly observe users’ behavior to not only understand what is happening, but also form hypotheses about why. For example, you might watch the user unsuccessfully attempt to enter their password several times before churning away. Then, you can use the insight you’ve gathered to create design interventions to try and guide these situations. For example, you could build a new password recovery workflow, or add an option to check out as a guest so users can bypass the sign-in form that is causing them to churn. After deploying your change, you can monitor key RUM metrics like the pageview count for the checkout page to see if it rises, indicating more users are successfully getting through the sign-in page.</p><h2 id="get-started-with-session-replay"><a href="#get-started-with-session-replay">Get started with Session Replay</a></h2><p>RUM’s Session Replay feature is a powerful tool for providing qualitative context around your frontend performance metrics, helping designers understand user behavior, and automatically reproducing bugs so your frontend developers can iterate fixes faster. Session Replay is currently available in beta—if you’re a Datadog customer, you can sign up for the beta <a href="https://www.datadoghq.com/session-replay-beta-request-form/">here</a>. Or, you can get started using Datadog with a <a href="#">14-day free trial</a>.</p></div></div>]]></content:encoded>
      <author>Thomas Sobolik</author>
      <pubDate>Wed, 28 Jul 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Datadog at GitLab Commit 2021</title>
      <link>https://www.datadoghq.com/event/micro-gitlabcommit-2021/</link>
      <description>Datadog at GitLab Commit 2021</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><section><a name="main"></a></section><section><a name="raffle"></a><div><p>No purchase necessary to enter or win. Limit 1 entry per person. Void where prohibited. The contest ends August 4, 2021, at 5:00pm EDT. Open to legal residents of Australia, Austria, Belgium, Brazil, Canada, Denmark, France, Germany, Ireland, Japan, Norway, Poland, Singapore, Spain, Sweden, Switzerland, The Netherlands, UK, and USA (excluding Puerto Rico) who are 18 years of age or older (or the age of majority in their state or country of residence, whichever is older) as of the date of entry who attended the event. The Sweepstakes is not open to any employee of a current Datadog customer, any current students or any employee of a competitor of Datadog. In addition, the Sweepstakes is not open to any agent or employee of Datadog or its affiliates or marketing firms, or to any immediate family or household member of those individuals. The winner will be notified via email. By submitting an entry to the contest, the entrant agrees to be bound by the Official Rules. See <a href="http://dtdg.co/gitlabrafflelegal" target="_blank">here</a> for Official Rules. Sponsor: Datadog, Inc., 620 8th Avenue, 45th Floor, New York, NY 10018.</p></div></section><section><a name="trial"></a><div><p>No purchase necessary to enter or win. Limit 1 entry per person. Void where prohibited. The contest ends August 24, 2021, at 11:59pm EDT. Open to legal residents of Australia, Austria, Belgium, Brazil, Canada, Denmark, France, Germany, Ireland, Japan, Norway, Poland, Singapore, Spain, Sweden, Switzerland, The Netherlands, UK, and USA (excluding Puerto Rico) who are 18 years of age or older (or the age of majority in their state or country of residence, whichever is older) as of the date of entry who attended the event. The Sweepstakes is not open to any employee of a current Datadog customer, any current students or any employee of a competitor of Datadog. In addition, the Sweepstakes is not open to any agent or employee of Datadog or its affiliates or marketing firms, or to any immediate family or household member of those individuals. The winner will be notified via email. By submitting an entry to the contest, the entrant agrees to be bound by the Official Rules. See <a href="http://dtdg.co/gitlabcommitlegal" target="_blank">here</a> for Official Rules. Sponsor: Datadog, Inc., 620 8th Avenue, 45th Floor, New York, NY 10018.</p></div></section></div></div>]]></content:encoded>
      <author>Datadog</author>
      <pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Monitor your CI pipelines and tests with Datadog CI Visibility</title>
      <link>https://www.datadoghq.com/blog/datadog-ci-visibility/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/ci-visibility-hero.png&#34; width=&#34;100%&#34;/&gt;Datadog CI Visibility, now available in beta, provides critical visibility into your organization’s CI/CD workflows. CI Visibility complements Datadog’s turn-key CI provider integrations and the integration of synthetic tests in CI pipelines to give you deep insight into key pipeline metrics and help you identify issues with your builds and testing.With modern agile development methods and advances in CI/CD automation, organizations are able to build and ship releases quickly and regularly to deliver new value to customers.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>Datadog CI Visibility, now available in beta, provides critical visibility into your organization’s CI/CD workflows. CI Visibility complements Datadog’s <a href="https://www.datadoghq.com/blog/monitor-ci-pipelines/">turn-key CI provider integrations</a> and the integration of <a href="https://www.datadoghq.com/blog/datadog-synthetic-ci-cd-testing/">synthetic tests in CI pipelines</a> to give you deep insight into key pipeline metrics and help you identify issues with your builds and testing.</p><p>With modern agile development methods and advances in CI/CD automation, organizations are able to build and ship releases quickly and regularly to deliver new value to customers. But without granular visibility into the performance of their pre-production testing and deployment pipelines, organizations can experience development outages due to slow builds or increases in failing or flaky tests.</p><p>Datadog CI Visibility provides deep insight into the performance of your CI pipelines, making it easy to identify issues—like error-prone jobs or flaky tests that cause your builds to fail randomly—and enabling you to make your CI workflows faster and more reliable. In this post, we’ll discuss how you can use CI Visibility to:</p><ul><li><a href="#monitor-your-CI-pipelines">Monitor pipeline builds, stages, and jobs to locate problems</a></li><li><a href="#monitor-test-trends-and-identify-problems">Track test performance and identify flaky tests</a></li></ul><h2 id="monitor-your-ci-pipelines"><a href="#monitor-your-ci-pipelines">Monitor your CI pipelines</a></h2><p>Datadog CI Pipeline Visibility provides comprehensive visibility into all your pipelines—across CI providers—by generating key performance metrics to help you understand, for example, which pipelines, build stages, or jobs are run the most, how often they fail, and how long they take to complete. Datadog visualizes this information in a customizable out-of-the-box Pipelines dashboard. This gives you a high-level overview of performance across all your pipelines, stages, and jobs so you can track trends at a glance and identify where to focus your troubleshooting efforts.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-dashboard.png?auto=format&amp;fit=max&amp;w=847" alt="Pipelines dashboard"/></picture></figure></div><p>The Pipelines Visibility page provides more granular insight into your CI workflows by breaking down health and performance metrics by pipeline. You can sort and filter the list to quickly surface which pipelines are the slowest or experience the most errors. In the example below, we have sorted pipelines by average build duration to show which ones are the slowest.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipelines-list-2.png?auto=format&amp;fit=max&amp;w=847" alt="Pipeline Visibility overview page"/></picture></figure></div><h3 id="drill-into-individual-pipelines"><a href="#drill-into-individual-pipelines">Drill into individual pipelines</a></h3><p>Once you’ve identified a pipeline with a high error rate or long build duration, you can drill into it to get more detailed information about its performance over time. The pipeline summary shows a breakdown of duration and failure rates across the pipeline’s individual stages and jobs to spot where slowdowns or failures might be occurring.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-summary.png?auto=format&amp;fit=max&amp;w=847" alt="Pipeline summary"/></picture></figure></div><p>A pipeline’s summary includes a table of all of that pipeline’s executions. You can easily filter your executions by key attributes like branch, status, and duration, or scope the table to a specific stage or job.</p><p>Once you’ve integrated Datadog with your CI provider, Datadog automatically instruments your pipelines. This means that, if you spot a slow or failing build and need to understand what’s happening, you can drill into a flame graph visualization of the build to look for high duration or errorful jobs. Then, you can dive into the error details to understand the source of the error, or look in the tags for the job URL to find the context you need to identify and remediate the underlying issue.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/pipeline-trace.png?auto=format&amp;fit=max&amp;w=847" alt="Pipeline trace"/></picture></figure></div><h2 id="monitor-test-trends-and-identify-problems"><a href="#monitor-test-trends-and-identify-problems">Monitor test trends and identify problems</a></h2><p>Monitoring your tests is key to identifying faulty tests and understanding overall test suite performance. With Datadog CI Testing Visibility, you can easily monitor your tests across all of your builds to surface common errors and visualize test performance over time to spot regressions. In the Testing Visibility page, you can see each of your services’ test suites along with the corresponding branch, duration, and number of fails, passes, and skips. Datadog also tracks the number of new flaky tests, or tests that variably pass and fail for the same commit, which were previously unseen in the default branch.</p><h3 id="identify-and-troubleshoot-flaky-tests"><a href="#identify-and-troubleshoot-flaky-tests">Identify and troubleshoot flaky tests</a></h3><p>Flaky tests can compromise the effectiveness of your testing and break builds seemingly at random. Locating and debugging flaky tests is important for ensuring the reliability of your test suites. Datadog automatically detects when commits introduce flaky tests and displays that data for the relevant branch.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/tests-list.png?auto=format&amp;fit=max&amp;w=847" alt="Test Visibility overview page"/></picture></figure></div><p>Once you’ve spotted a branch with new flaky tests to examine, you can dive into the commit overviews for that service. Looking at the Latest Commit Overview, you can see which tests failed and the most common errors between them.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/test-summary.png?auto=format&amp;fit=max&amp;w=847" alt="Test summary"/></picture></figure></div><p>The Flaky Tests summary surfaces all the tests in this service’s test suite that flaked. Selecting a test row, you can view runs of the test from the commit that first flaked, which is likely to contain the code change responsible for making the test flaky.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/datadog-ci-visibility/flaky-test.png?auto=format&amp;fit=max&amp;w=847" alt="Flaky tests overview"/></picture></figure></div><h3 id="analyze-test-performance"><a href="#analyze-test-performance">Analyze test performance</a></h3><p>Just like with CI Pipeline Visibility, Datadog Testing Visibility automatically instruments each of your tests so you can trace them from end to end without spending time reproducing test failures. For example, once you’ve found a flaky test you want to debug, you can drill into the test trace for more information. Using the flame graph, you can, for example, easily find the point(s) of failure in a complex integration test. Clicking on an errorful span, you can examine the stacktrace along with related error messages to examine what caused the test to fail in that instance. For more context, Datadog links to the relevant pipeline so you can jump into your CI provider to examine the console output from the test run.</p><h2 id="ensure-smooth-reliable-builds"><a href="#ensure-smooth-reliable-builds">Ensure smooth, reliable builds</a></h2><p>Datadog CI Visibility enables you to fill in the pre-production observability gap. It gives you deep visibility into your test performance, so you can ensure your tests will catch performance issues before they reach customers, while also empowering you to manage your pipelines—saving precious developer time and computing resources. Combined with Datadog’s extensive support for synthetic testing within your CI, you can use Datadog to shift full-stack observability to the left, nipping outages and regressions in the bud.</p><p>CI Visibility is currently in a public beta—see our <a href="https://docs.datadoghq.com/continuous_integration/">documentation</a> for detailed installation steps. Or, if you’re brand new to Datadog, sign up for a <a href="#">14-day free trial</a> to get started.</p></div></div>]]></content:encoded>
      <author>Thomas Sobolik</author>
      <pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Test internal applications with Datadog&#39;s testing tunnel and private locations</title>
      <link>https://www.datadoghq.com/blog/internal-application-testing-with-datadog/</link>
      <description>&lt;img class=&#34;webfeedsFeaturedVisual rss&#34; src=&#34;https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-hero.png&#34; width=&#34;100%&#34;/&gt;As part of your monitoring and testing strategy, you may run tests on different types of applications that are not publicly available—from local versions of production-level websites to internal applications that directly support your employees. Testing each one requires leveraging tools that allow you to verify functionality across a wide range of devices, browsers, and workflows while maintaining a secure environment. Datadog Synthetic Monitoring already lets you create your own custom probes (on-premise test runners) with private locations to routinely test and monitor all of your internal-facing applications.</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><p>As part of your monitoring and testing strategy, you may run tests on different types of applications that are not publicly available—from local versions of production-level websites to internal applications that directly support your employees. Testing each one requires leveraging tools that allow you to verify functionality across a wide range of devices, browsers, and workflows while maintaining a secure environment. <a href="https://docs.datadoghq.com/synthetics/">Datadog Synthetic Monitoring</a> already lets you create your own custom probes (on-premise test runners) with <a href="https://docs.datadoghq.com/synthetics/private_locations?tab=docker">private locations</a> to routinely test and monitor all of your internal-facing applications. Now, for on-demand testing, you can also use Datadog’s <a href="https://docs.datadoghq.com/synthetics/testing_tunnel">testing tunnel</a>, a secure tunnel connection that requires little setup.</p><p>Private locations and the testing tunnel give you more flexibility over how you test applications in your internal environments, but each tool offers some unique benefits to support different testing goals.</p><p>In this post, we’ll look at:</p><ul><li>using the <a href="#ci-and-local-testing-with-the-testing-tunnel">testing tunnel</a> for on-demand testing in local and continuous integration (CI) environments</li><li>creating <a href="#durable-testing-and-monitoring-using-private-locations">private locations</a> for durable testing and monitoring</li></ul><h2 id="ci-and-local-testing-with-the-testing-tunnel"><a href="#ci-and-local-testing-with-the-testing-tunnel">CI and local testing with the testing tunnel</a></h2><p>The testing tunnel leverages Datadog’s <a href="https://docs.datadoghq.com/synthetics/ci/?tab=apitest">command line interface (CLI)</a> to create an end-to-end encrypted HTTP proxy between your infrastructure and Datadog. The CLI is an <a href="https://www.npmjs.com/package/@datadog/datadog-ci">NPM package</a> that enables you to launch Datadog Synthetic tests <a href="https://www.datadoghq.com/blog/datadog-synthetic-ci-cd-testing/">as part of your CI/CD pipelines</a>, so you can identify and fix regressions in your applications before they impact your users. When used in conjunction with the testing tunnel feature, any test requests you send using the CLI are automatically routed through the <code>datadog-ci</code> client, allowing Datadog to access and test your internal applications.</p><p>Datadog’s testing tunnel is designed to support CI pipelines and local development, so you can use it for:</p><ul><li>verifying hotfixes or new features locally before committing code</li><li>running tests in environments reserved for CI pipelines (e.g., staging, user acceptance testing, etc.) or in ephemeral cloud environments</li></ul><p>We’ll look at how the tunnel’s unique features and benefits can support these particular testing goals next.</p><h3 id="an-easy-to-use-tool-for-testing-on-demand"><a href="#an-easy-to-use-tool-for-testing-on-demand">An easy-to-use tool for testing on demand</a></h3><p>A key benefit of the testing tunnel is its ease of use within existing infrastructure; it enables you to incorporate API and end-to-end tests into all of your workflows. For example, your teams (e.g., developers, testers) can use this tool out of the box to quickly verify that a hotfix for a time-sensitive issue, such as a service outage, works as expected locally before deploying it to end users. You can also use the tunnel service to run test suites as part of your CI pipelines without launching multiple browsers directly on CI servers, where processing power may be limited.</p><p>You can instantly create a tunnel connection to run tests using a simple command:</p><div><pre><code data-lang="text"> 
datadog-ci synthetics run-tests --config synthetics.global.json --tunnel</code></pre></div><p>The example command above will open a WebSocket Secure <a href="https://docs.datadoghq.com/synthetics/testing_tunnel/#what-is-the-testing-tunnel">tunnel connection</a> and launch the suite of tests defined in your local machine’s or CI server’s <a href="https://docs.datadoghq.com/synthetics/ci/?tab=apitest#configure-tests">test configuration files</a>. These files include the public IDs of the tests that you want to run, along with other configuration attributes, such as endpoint URLs, device IDs, and locations.</p><p>Since the tunnel is built into Datadog’s CLI, it enables you to quickly start testing your internal applications at any time.</p><h3 id="launch-tests-with-minimal-overhead"><a href="#launch-tests-with-minimal-overhead">Launch tests with minimal overhead</a></h3><p>The tunnel is independent of existing infrastructure, so you can use it without deploying, maintaining, or monitoring additional services. Tests launched via the tunnel are executed from Datadog-managed locations. This means that as long as the host running Datadog’s CI client can create the connections needed to run multiple tests, Datadog will automatically scale to support the increased load as needed. Tunnel connections then end when the Datadog CI client receives all necessary results, so you do not need to track long-running connections to your network.</p><p>The tunnel also makes it easy to dynamically override where your tests run with Datadog’s <a href="https://docs.datadoghq.com/synthetics/ci/?tab=apitest#start-url">built-in environment variables</a>, so you can continue testing your applications without interruption, even as the environment you are testing changes. This includes environments that rely on ephemeral cloud instances and containers. For example, you can automatically pass the URL of a newly deployed application instance as the starting URL for any tests launched with the tunnel, instead of hard coding that data into your tests.</p><p>Datadog shows which tests were launched through the tunnel service so you can monitor them alongside the rest of your synthetic tests. For any test failures, Datadog provides <a href="https://www.datadoghq.com/blog/introducing-synthetic-monitoring/#end-to-end-visibility">end-to-end visibility</a> for troubleshooting and resolving issues, including details such as screenshots of the UI, JavaScript and network errors, load times for page resources, and APM traces if your test is hitting an instrumented service endpoint.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/local-testing-tunnel-test-results-v2.png?auto=format&amp;fit=max&amp;w=847" alt="View test results after using the testing tunnel for local testing"/></picture></figure></div><p>Now that we’ve covered the benefits of using the testing tunnel for straightforward, on-demand testing, we’ll look at how Datadog’s private locations support your long-term testing and monitoring goals.</p><h2 id="durable-testing-and-monitoring-using-private-locations"><a href="#durable-testing-and-monitoring-using-private-locations">Durable testing and monitoring using private locations</a></h2><p>As we’ve seen, the testing tunnel offers a turn-key solution for secure, rapid testing in short-lived environments. For organizations who need to regularly test and monitor applications hosted on permanent environments, Datadog provides <a href="https://www.datadoghq.com/blog/private-synthetic-monitoring/">private locations</a>: Docker containers that you can deploy as custom <a href="https://en.wikipedia.org/wiki/Point_of_presence">points of presence</a> (e.g., data centers, geographic locations) inside of your infrastructure <a href="https://docs.datadoghq.com/synthetics/private_locations/?tab=docker#install-your-private-location">using orchestration tools</a> like Docker Compose, Kubernetes, AWS Fargate, and Amazon ECS.</p><p>Because private locations are deployed as a durable probing service for launching your tests, they can be useful for:</p><ul><li>customizing and managing a centralized testing tool that is readily available for teams across your organization</li><li>triggering tests on long-running environments (e.g., staging, pre-production) as part of your CI/CD pipelines</li><li>regularly running tests on internal applications that are hosted on private networks to ensure you can maintain your availability SLOs</li></ul><p>We’ll look at how you can use private locations to create a customizable, scalable, and easily accessible service in more detail next.</p><h3 id="a-fully-fledged-and-customizable-testing-service-for-internal-applications"><a href="#a-fully-fledged-and-customizable-testing-service-for-internal-applications">A fully-fledged and customizable testing service for internal applications</a></h3><p>Since testing is a crucial part of building resilient applications, you need a system that can support testing a growing network of services as your organization scales. Using private locations, your SRE teams have greater flexibility in not only customizing a probing service for every use case—via their <a href="https://docs.datadoghq.com/synthetics/private_locations/?tab=docker#install-your-private-location">preferred orchestration tool</a>—but also ensuring it can scale to continually verify functionality and monitor application performance.</p><p>Private locations come with a number of parameters you can use to match your infrastructure and private network configurations, such as built-in controls to <a href="https://docs.datadoghq.com/synthetics/private_locations/?tab=docker#blocking-reserved-ips">block IPs</a> in order to prevent users from creating synthetic tests on potentially sensitive endpoints in reserved IP ranges. And, as your applications grow, you can horizontally or vertically <a href="https://docs.datadoghq.com/synthetics/private_locations?tab=docker#scale-your-private-locations">scale your locations</a> in order to run more synthetic tests concurrently, enabling you to seamlessly test newly added features alongside existing functionality. Leveraging these measures ensure your applications—and your test infrastructure—remain secure and continue supporting your users.</p><h4 id="monitoring-private-locations"><a href="#monitoring-private-locations">Monitoring private locations</a></h4><p>Private locations are designed to regularly test and monitor your applications long term. Because of their longevity—and since tests run on the servers where you’ve deployed private locations—you need to ensure that every location is working as expected. Datadog provides visibility into your entire infrastructure, so you can monitor the performance of your custom locations in one place. For example, you can create custom dashboards to get a high-level overview of all of your private locations and easily monitor usage, as seen below.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/internal-application-monitoring-private-location-dashboard.png?auto=format&amp;fit=max&amp;w=847" alt="Create custom dashboards to monitor private locations"/></picture></figure></div><p>You can also use the Datadog Agent to <a href="https://docs.datadoghq.com/infrastructure/livecontainers/?tab=helm">get deeper visibility</a> into the state of your private locations&#39; underlying containers and confirm that they are performing optimally. If you notice unusual changes in the tests executed by your private location, such as a significant increase in response time, you can then drill down to the affected container in order to troubleshoot further.</p><h3 id="self-service-testing-for-every-team"><a href="#self-service-testing-for-every-team">Self-service testing for every team</a></h3><p>Once deployed, private locations provide a centralized and readily available service for testing, so your teams can create their own tests and assign them to specific locations in one click.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-synthetic-test-setup.png?auto=format&amp;fit=max&amp;w=847" alt="Teams can easily set up tests using any deployed private location for internal application monitoring."/></picture><figcaption>All of your teams can easily add available private locations when creating new tests</figcaption></figure></div><p>This enables your teams to routinely test applications under a wide variety of conditions. For example, your corporate IT team can launch tests on private locations deployed to multiple data centers to ensure that your company intranet or a key SaaS provider is performing optimally for a growing team of distributed employees, regardless of their location.</p><div><figure><picture>
<source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=847 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=847&amp;dpr=2 2x" media="(min-width: 1200px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=698 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=698&amp;dpr=2 2x" media="(min-width: 992px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=720 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=720&amp;dpr=2 2x" media="(min-width: 759px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=600 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=600&amp;dpr=2 2x" media="(min-width: 630px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=500 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=500&amp;dpr=2 2x" media="(min-width: 530px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=420px 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=420&amp;dpr=2 2x" media="(min-width: 361px)"/><source srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=360px 1x,
                    https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=360&amp;dpr=2 2x" media="(min-width: 0px)"/><img loading="lazy" srcset="https://imgix.datadoghq.com/img/blog/internal-application-testing-with-datadog/private-locations-monitoring-behind-a-firewall-test-results.png?auto=format&amp;fit=max&amp;w=847" alt="View test results for monitoring behind the firewall using private locations"/></picture></figure></div><p>Or, your QA team can leverage the same tests and private locations as part of their CI/CD pipelines to verify that key workflows are still accessible to users after a canary deployment of new intranet features.</p><h2 id="your-map-for-comprehensive-internal-application-testing"><a href="#your-map-for-comprehensive-internal-application-testing">Your map for comprehensive internal application testing</a></h2><p>With private locations and the testing tunnel, you have more options for testing and monitoring your internal-facing applications. Each service offers unique features to help you accomplish your testing goals, whether they require long-running probing services or the ability to quickly launch tests on demand and with little setup. Check out the documentation for <a href="https://docs.datadoghq.com/synthetics/private_locations?tab=docker">private locations</a> and the <a href="https://docs.datadoghq.com/synthetics/testing_tunnel">tunnel service</a> (currently in public beta) to learn how to get started with both. If you don’t already have a Datadog account, you can sign up for a <a href="#">free 14-day trial</a>.</p></div></div>]]></content:encoded>
      <author>Mallory Mooney</author>
      <pubDate>Tue, 27 Jul 2021 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Partnership Brings Joint Success in LATAM</title>
      <link>https://www.datadoghq.com/case-studies/econocom/</link>
      <description>About Econocom Econocom is a B2B reseller and technology consulting company with an annual revenue of more than $3 billion. As part of their global operations, Econocom Brazil has joined the Datadog Partner Network to better equip their customers with cloud-native monitoring. Key Results 15+ logos New major logos closed via the Datadog + Econocom partnership in the first year3 expansions The number of times Econocom landed and expanded in a single account in 3 months with Datadog</description>
      <content:encoded><![CDATA[<div id="readability-page-1" class="page"><div><span><h2 id="span-classheader-purplegrowing-demand-for-consulting-servicesspan"></h2><p>Econocom Brazil offers a suite of services, including technology resale and consultation work, to help their customers modernize their IT infrastructure, development and operation practices. As their customer base has grown, Econocom has seen an increase in demand not only for implementation of new technologies, but for consultation on cultural changes like shifting to DevOps, as well. “About one-third of our revenue comes from project and consultation activities, and two-thirds are related to other services. We’re really interested in increasing the volume of projects and consulting work that we offer, because it’s such a big value-add for our customers,” said Rodrigo Bocchi, the CEO of Econocom Brazil. “We expect this will be the main portion of the company’s revenue in the near future.”</p><p>To ensure their readiness to help their clients adopt modern technology and practices successfully, Econocom needed to offer a modern monitoring platform designed to facilitate DevOps-style communication within ephemeral, cloud-based and Kubernetes-based systems. Additionally, Econocom was looking for a product that could cover any customer’s stack—and that could be implemented quickly to accelerate their deal cycles. In the end, Econocom Brazil chose to partner with Datadog to provide these services for their customers because of Datadog’s expansive coverage, ease of use, and rapid implementation speed.</p><p>With Datadog, users have access to a unified platform encompassing infrastructure metrics, application management, logs, security, monitoring, and more. Bringing these capabilities together into one platform allows end users to quickly find a reported issue and the root cause in just a few clicks, with all the context they need at hand. This accelerates resolution time, which leads to more productive engineering teams, reduces risk during migrations and transitions, and improves end-user experiences.</p><p>Datadog also provides coverage across modern environments as well as legacy or on-premise installations. With extensive support for containers, including container Autodiscovery, a dedicated Kubernetes Cluster Agent, and out-of-the-box dashboards, Datadog makes it easier for Econocom’s customers to enact digital transformations. “In some cases, we are replacing old technologies (which support systems, applications and logs separately and are from different vendors) inside our client. We are helping them to transform their monitoring and adapt to cloud environments and Kubernetes environments with a unified and fully correlated view, quickly identifying the root cause,” said Rosano Moraes, Head of Sales, Brazil.</p><blockquote><p><em>&#34; We’re replacing old technologies […] and helping them transform their monitoring and adapt to cloud environments and Kubernetes environments.&#34;</em></p><p>Rosano Moraes
Head of Sales, Econocom Brazil</p></blockquote><p>Another big appeal for Econocom is Datadog’s ease of use. The Datadog platform itself can be used by both Dev and Ops teams with minimal training, and it doesn’t require certification or knowledge of a query language. All dashboards can be created using a point-and-click interface, which allows companies to democratize their data so that centralized monitoring teams aren’t backlogged with routine work. Ease of use also reduces troubleshooting time when problems do arise, because the teams that are closest to the problem feel empowered to use Datadog to understand and address the root cause.</p><p>The simplicity of a unified platform is core to Econocom’s DevOps consulting practices. Using Datadog as the single source of truth eliminates the messy communication silos that come from having tooling divisions across teams. “The Datadog platform was attractive because it unifies so many other products. It all drives towards simplicity—so it’s easier to solve problems. That’s something our customers really respond to,” said Moraes. “We use Datadog with our DevOps Excellence consulting program, and it helps our customers adopt DevOps culture more easily,” he added.</p><blockquote><p><em>&#34; It all drives towards simplicity—so it’s easier to solve problems. That’s something our customers really respond to.&#34;</em></p><p>Rosano Moraes
Head of Sales, Econocom Brazil</p></blockquote><p>Datadog also helps Econocom deploy quickly and consistently in every customer’s environment. “Implementation is so simple and fast with Datadog,” said Moraes. Implementation speed is driven by Datadog’s 450+ integrations, which provide key metrics, out-of-the-box dashboards, and recommended monitors for popular technologies. And because Datadog is a SaaS product, it can be deployed as a single agent for all data collection, doesn’t require the setup of any dedicated hosts or collectors, and can be rolled out automatically with a variety of tools like Chef, Puppet, or Helm. This not only saves the customer time, but also gives Econocom more opportunity to focus on the unique needs of each customer while providing higher value-add services like consulting. It also accelerates overall deal cycles, which improves Econocom’s operational efficiency.</p><blockquote><p><em>&#34; Implementation is so simple and fast with Datadog&#34;</em></p><p>Rosano Moraes
Head of Sales, Econocom Brazil</p></blockquote><p>Econocom took advantage of training courses provided by the Datadog Partner Network to enable their staff to understand and position Datadog effectively. Econocom Brazil was one of the first Gold-tier Datadog Partner Network members in Latin America, due to their technical qualifications and certifications, which led to a close relationship with Datadog’s sales team and unlocked better prices for their customers. Within the first year, Datadog and Econocom worked together to land over 15 major new logos, spanning industries like financial services, cloud technology, hospitality, and marketing.</p><p>“Our first year with Datadog has been very successful. The solution is strong, which makes it easy to position, and easy to prove the value. On top of that, Datadog’s commercial and enterprise teams in Brazil have worked really closely with us-” said Bocchi. “It feels like we’re an extension of the Datadog sales team,” added Moraes.</p><p>Bocchi also praised the high demand he’s seen for Datadog, as well as the flexibility it gives Econocom. “With one of our major customers, it took us about nine months to close the deal initially. But in the three months after deploying Datadog, they loved it so much they came back to us twice looking to expand,” said Bocchi, adding: “Datadog’s fresh, it’s easier, it’s more flexible in terms of sizing. There’s no delay in implementation. Our customers are more confident in what they’re getting from us.”</p><blockquote><p><em>&#34; Datadog’s fresh, it’s easier, it’s more flexible in terms of sizing. There’s no delay in implementation. Our customers are more confident in what they’re getting from us.&#34;</em></p><p>Rodrigo Bocchi
CEO, Econocom Brazil</p></blockquote></span></div></div>]]></content:encoded>
      <author>Datadog</author>
      <pubDate>Mon, 26 Jul 2021 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>